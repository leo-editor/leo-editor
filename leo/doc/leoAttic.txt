#@+leo-ver=5-thin
#@+node:ekr.20170302123956.1: * @file ../doc/leoAttic.txt
# This is Leo's final resting place for dead code.
# Much easier to access than a git repo.

#@@language python
#@@killbeautify
#@+all
#@+node:ekr.20190412154439.1: **  Abandoned projects
#@+node:ekr.20170203080350.1: *3* Abandoned #396: Show images in Leo's body pane
https://github.com/leo-editor/leo-editor/issues/396

#@+node:ekr.20170302151109.1: *4* ** Notes
@language rest
@wrap

Unicode 'object replacement character': u+FFFC

QTextDocument may be helpful: http://doc.qt.io/qt-5/qtextdocument.html
See QTextDocument.MetaInformation: http://doc.qt.io/qt-5/qtextdocument.html#MetaInformation-enum

http://stackoverflow.com/questions/3254652/
several-ways-of-placing-an-image-in-a-qtextedit

http://doc.qt.io/qt-5/qtextdocument.html#resource

QVariant QTextDocument::resource(int type, const QUrl &name) const

Returns data of the specified type from the resource with the given name.

This function is called by the rich text engine to request data that isn't directly stored by QTextDocument, but still associated with it. For example, images are referenced indirectly by the name attribute of a QTextImageFormat object.

Resources are cached internally in the document. If a resource can not be found in the cache, loadResource is called to try to load the resource. loadResource should then use addResource to add the resource to the cache.
#@+node:ekr.20170203105538.1: *4* Test inserting picture (new)
# https://github.com/leo-editor/leo-editor/issues/396
g.cls()
images = [i for i in range(len(p.b)) if ord(p.b[i]) > 128]
if images:
    print('images at', images)
else:
    table = (
        'application-x-leo-outline.png',
        'LeoDoc.ico',
    )    
    for image in table:
        path = g.os_path_finalize_join(g.app.loadDir, '..', 'Icons', image)
        assert g.os_path_exists(path), repr(path)
        c.frame.body.wrapper.setInsertPoint(len(p.b))
        if 0:
            format = QtGui.QTextImageFormat()
            format.setName(path)
            cursor = cursor = body.widget.textCursor()
            cursor.insertImage(format)
        c.frame.body.widget.insertHtml('<img src="%s">' % path)
            # style="width:40px;height:80px;"
    for i, ch in enumerate(p.b):
        if ord(ch) > 128: print('new', i, ord(ch))
#
#￼￼
#@+node:ekr.20170204110006.1: *4* test3 insert an image
g.cls()
from leo.core.leoQt import QtGui
body = c.frame.body
table = ('box01.bmp','box02.bmp','box03.bmp',)
d = g.app.permanentScriptDict
images = d.get('images', [])
for image in table:
    path = g.os_path_finalize_join(g.app.loadDir, '..', 'Icons', image)
    assert g.os_path_exists(path), repr(path)
    image = QtGui.QImage(path)
    images.append(image)
    body.wrapper.setInsertPoint(len(p.b))
    cursor = body.widget.textCursor()
    cursor.insertImage(image)
for i, ch in enumerate(p.b):
    if ord(ch) > 128: print('new', i, ord(ch))
d ['images'] = images
#
#
#@+node:ekr.20170204140521.1: *4* clear g.app.permanentScriptDict
g.printDict(g.app.permanentScriptDict)
g.app.permanentScriptDict = {}
#@+node:ekr.20170204135338.1: *4* @@button show-images
from leo.core.leoQt import QtCore
d = g.app.permanentScriptDict
name_index = d.get('name_index', 0)
names = ['leo_image%s' % (i) for i in range(name_index)]
# print('image names', names)
widget = c.frame.body.widget
doc = widget.document()
for i, name in enumerate(names):
    image = doc.resource(doc.ImageResource, QtCore.QUrl(name))
    print(name, image)
#@+node:ekr.20170204105958.1: *4* test2 insert an image
g.cls()
from leo.core.leoQt import QtGui
body = c.frame.body
table = (
    'application-x-leo-outline.png',
    'LeoDoc.ico',
)
g.app.permanentScriptDict = {}
d = g.app.permanentScriptDict
images = d.get('images', [])
cursors = d.get('cursors', [])
name_index = d.get('name_index', 0)
for image in table:
    path = g.os_path_finalize_join(g.app.loadDir, '..', 'Icons', image)
    assert g.os_path_exists(path), repr(path)
    image = QtGui.QImage(path)
    print(image.format().name())
    images.append(image)
    body.wrapper.setInsertPoint(len(p.b))
    cursor = body.widget.textCursor()
    #name = 'leo_image%s' % name_index
    #name_index += 1
    cursor.insertImage(image)
    cursors.append(cursor)
for i, ch in enumerate(p.b):
    if ord(ch) > 128: print('new', i, ord(ch))
d ['images'] = images
d ['cursors'] = cursors
d ['name_index'] = name_index
g.app.permanentScriptDict = d
g.printDict(d)
#
#￼￼￼
#￼
#@+node:ekr.20190910020834.1: *3* black
#@+node:ekr.20190910023018.1: *4* imports
try:
    # pylint: disable=import-error
        # We can't assume the user has this.
    import black
except Exception:
    black = None
#@+node:ekr.20150531042746.1: *4* munging leo directives
#@+node:ekr.20150529084212.1: *5* comment_leo_lines (leoBeautifier.py)
def comment_leo_lines(p):
    '''Replace lines with Leonine syntax with special comments.'''
    # Choose the comment string so it appears nowhere in s.
    s0 = p.b
    n = 5
    while s0.find('#' + ('!' * n)) > -1:
        n += 1
    comment = '#' + ('!' * n)
    # Create a dict of directives.
    d = {}
    for z in g.globalDirectiveList:
        d[z] = True
    # Convert all Leonine lines to special comments.
    i, lines, result = 0, g.splitLines(s0), []
    while i < len(lines):
        progress = i
        s = lines[i]
        # Comment out any containing a section reference.
        j = s.find('<<')
        k = s.find('>>') if j > -1 else -1
        if -1 < j < k:
            result.append(comment + s)
            # Generate a properly-indented pass line.
            j2 = g.skip_ws(s, 0)
            result.append('%spass\n' % (' ' * j2))
        elif s.lstrip().startswith('@'):
            # Comment out all other Leonine constructs.
            if starts_doc_part(s):
                # Comment the entire doc part, until @c or @code.
                result.append(comment + s)
                i += 1
                while i < len(lines):
                    s = lines[i]
                    result.append(comment + s)
                    i += 1
                    if ends_doc_part(s):
                        break
            else:
                j = g.skip_ws(s, 0)
                assert s[j] == '@'
                j += 1
                k = g.skip_id(s, j, chars='-')
                if k > j:
                    word = s[j: k]
                    if word == 'others':
                        # Remember the original @others line.
                        result.append(comment + s)
                        # Generate a properly-indented pass line.
                        result.append('%spass\n' % (' ' * (j - 1)))
                    else:
                        # Comment only Leo directives, not decorators.
                        result.append(comment + s if word in d else s)
                else:
                    result.append(s)
        else:
            # A plain line.
            result.append(s)
        if i == progress:
            i += 1
    return comment, ''.join(result)
#@+node:ekr.20150531042830.1: *5* starts_doc_part & ends_doc_part
def starts_doc_part(s):
    '''Return True if s word matches @ or @doc.'''
    for delim in ('@\n', '@doc\n', '@ ', '@doc '):
        if s.startswith(delim):
            return True
    return False

def ends_doc_part(s):
    '''Return True if s word matches @c or @code.'''
    for delim in ('@c\n', '@code\n', '@c ', '@code '):
        if s.startswith(delim):
            return True
    return False
#@+node:ekr.20150529095117.1: *5* uncomment_leo_lines
def uncomment_leo_lines(comment, p, s0):
    '''Reverse the effect of comment_leo_lines.'''
    lines = g.splitLines(s0)
    i, result = 0, []
    while i < len(lines):
        progress = i
        s = lines[i]
        i += 1
        if s.find(comment) == -1:
            # A regular line.
            result.append(s)
        else:
            # One or more special lines.
            i = uncomment_special_lines(comment, i, lines, p, result, s)
        assert progress < i
    return ''.join(result).rstrip() + '\n'
#@+node:ekr.20150531041720.1: *5* uncomment_special_line & helpers
def uncomment_special_lines(comment, i, lines, p, result, s):
    '''
    s is a line containing the comment delim.
    i points at the *next* line.
    Handle one or more lines, appending stripped lines to result.
    '''
    s = s.lstrip().lstrip(comment)
    if starts_doc_part(s):
        result.append(s)
        while i < len(lines):
            s = lines[i].lstrip().lstrip(comment)
            i += 1
            result.append(s)
            if ends_doc_part(s):
                break
        return i
    j = s.find('<<')
    k = s.find('>>') if j > -1 else -1
    if -1 < j < k or s.find('@others') > -1:
        # A section reference line or an @others line.
        # Such lines are followed by a pass line.
        # The beautifier may insert blank lines before the pass line.
        kind = 'section ref' if -1 < j < k else '@others'
        # Restore the original line, including leading whitespace.
        result.append(s)
        # Skip blank lines.
        while i < len(lines) and not lines[i].strip():
            i += 1
        # Skip the pass line.
        if i < len(lines) and lines[i].lstrip().startswith('pass'):
            i += 1
        else:
            g.trace('*** no pass after %s: %s' % (kind, p.h))
    else:
        # A directive line.
        result.append(s)
    return i
#@+node:ekr.20180328065332.1: *3* Check conventions stuff
#@+node:ekr.20171208042251.1: *4* @@button check-conventions (no longer used)
g.cls()
if c.changed: c.save()

import imp
import leo.core.leoCheck as leoCheck
imp.reload(leoCheck)

do_all = True
do_string = True

fails = []
    # All of Leo's core files pass!
fn = g.os_path_finalize_join(g.app.loadDir, '..', 'core', 'leoTest.py')
<< define s >>
<< old tests >>
if do_all:
    utils = leoCheck.ProjectUtils()
    aList = utils.project_files('leo', force_all=False)
    # g.printList(aList)
    for fn in aList:
        sfn = g.shortFileName(fn)
        if sfn in fails:
            print('===== skipping', sfn)
        else:
            print('==== fn', sfn)
            leoCheck.ConventionChecker(c).check(fn=fn)
elif do_string: # Test string s.
    leoCheck.ConventionChecker(c).check(s=s)
else: # Test an actual file.
    leoCheck.ConventionChecker(c).check(fn=fn)
#@+node:ekr.20171208105236.1: *5* << define s >>
s = '''\
class T:
    
    def __init__(self, tempNode):
        self.tempNode = tempNode.copy()
    
    def setUp(self):
        tempNode = self.tempNode
        while tempNode.firstChild():
            tempNode.firstChild().doDelete()
'''

s_ok2 = '''
class Context(object):
    def __init__ (self, parent_context):
        self.parent_context = parent_context
        if parent_context:
            parent_context.inner_contexts_list.append(self)
'''

s_ok= '''
class TC:
    def __init__(self, c):
        c.tc = self
    def add_tag(self, p):
        print(p.v) # AttributeError if p is a vnode.

class Test:
    def __init__(self,c):
        self.c = c
        self.tc = self.c.tc
    def add_tag(self):
        p = self.c.p
        self.tc.add_tag(p.v) # WRONG: arg should be p.
'''

#@+node:ekr.20171210062719.1: *5* << old tests >>
s_passes_1 = '''\
class C1:
        
    def f1(self, p):
        print(p.v)
        
    def f2(self, p):
        self.f1(p.v) # WRONG

'''


s_1 = '''\
class C1:

    def __init__(self, c):
        self.c = c
        c.theTagController = self
        
    def add_tag(self, p):
        pass

class C2:

    def oops(self, p):
        c.tagController.add_tag(p.v,tag)
            # WRONG: should be p.

'''


s_2 = '''\
class TagController:

    def __init__(self, c):
        self.c = c
        c.theTagController = self

    def add_tag(self, p, tag):
        # Will fail if p is a vnode
        tags = set(p.v.u.get('__node_tags', set([])))

class LeoTagWidget(QtWidgets.QWidget):

    def __init__(self,c,parent=None):
        self.c = c
        self.tc = self.c.theTagController

    def add_tag(self, event=None):
        p = self.c.p
        self.tc.add_tag(p.v,tag) # WRONG: should be p.

'''
#@+node:ekr.20160109150703.1: *4* class Stats (old & stupid, from leoCheck.py)
class Stats(object):
    '''A class containing global statistics & other data'''
    @others
#@+node:ekr.20160109150703.2: *5*  sd.ctor
def __init__ (self):

    # Files...
    # self.completed_files = [] # Files handled by do_files.
    # self.failed_files = [] # Files that could not be opened.
    # self.files_list = [] # Files given by user or by import statements.
    # self.module_names = [] # Module names corresponding to file names.

    # Contexts.
    # self.context_list = {}
        # Keys are fully qualified context names; values are contexts.
    # self.modules_dict = {}
        # Keys are full file names; values are ModuleContext's.

    # Statistics...
    # self.n_chains = 0
    self.n_contexts = 0
    # self.n_errors = 0
    self.n_lambdas = 0
    self.n_modules = 0
    # self.n_relinked_pointers = 0
    # self.n_resolvable_names = 0
    # self.n_resolved_contexts = 0
    # self.n_relinked_names = 0

    # Names...
    self.n_attributes = 0
    self.n_expressions = 0
    self.n_ivars = 0
    self.n_names = 0        # Number of symbol table entries.
    self.n_del_names = 0
    self.n_load_names = 0
    self.n_param_names = 0
    self.n_param_refs = 0
    self.n_store_names = 0

    # Statements...
    self.n_assignments = 0
    self.n_calls = 0
    self.n_classes = 0
    self.n_defs = 0
    self.n_fors = 0
    self.n_globals = 0
    self.n_imports = 0
    self.n_lambdas = 0
    self.n_list_comps = 0
    self.n_returns = 0
    self.n_withs = 0

    # Times...
    self.parse_time = 0.0
    self.pass1_time = 0.0
    self.pass2_time = 0.0
    self.total_time = 0.0
#@+node:ekr.20160109150703.6: *5* sd.print_times
def print_times (self):

    sd = self
    times = (
        'parse_time',
        'pass1_time',
        # 'pass2_time', # the resolve_names pass is no longer used.
        'total_time',
    )
    max_n = 5
    for s in times:
        max_n = max(max_n,len(s))
    print('\nScan times...\n')
    for s in times:
        pad = ' ' * (max_n - len(s))
        print('%s%s: %2.2f' % (pad,s,getattr(sd,s)))
    print('')
#@+node:ekr.20160109150703.7: *5* sd.print_stats
def print_stats (self):

    sd = self
    table = (
        '*', 'errors',

        '*Contexts',
        'classes','contexts','defs','modules',

        '*Statements',
        'assignments','calls','fors','globals','imports',
        'lambdas','list_comps','returns','withs',

        '*Names',
        'attributes','del_names','load_names','names',
        'param_names','param_refs','store_names',
        #'resolvable_names','relinked_names','relinked_pointers',
        # 'ivars',
        # 'resolved_contexts',
    )
    max_n = 5
    for s in table:
        max_n = max(max_n,len(s))
    print('\nStatistics...\n')
    for s in table:
        var = 'n_%s' % s
        pad = ' ' * (max_n - len(s))
        if s.startswith('*'):
            if s[1:].strip():
                print('\n%s\n' % s[1:])
            else:
                pass # print('')
        else:
            pad = ' ' * (max_n - len(s))
            print('%s%s: %s' % (pad,s,getattr(sd,var)))
    print('')
#@+node:ekr.20171211054600.1: *4* OLD checkConventions (leoCheck.py)
def checkConventions(c):
    '''
    A stand-alone version of the @button node that tested the
    ConventionChecker class.
    
    The check-conventions command in checkerCommands.py saves c and reloads
    the leoCheck module before calling this function.
    '''
    g.cls()
    kind = 'all'
    project_name = 'leo'  # 'coverage', 'leo', 'lib2to3', 'pylint', 'rope'
    assert kind in ('all', 'file', 'production', 'string'), repr(kind)
    fn = g.os_path_finalize_join(g.app.loadDir, '..', 'plugins', 'qt_tree.py')
    report_stats = True # and kind != 'production'
    trace_fn = True
    trace_skipped = False
    fails_dict = {
        'coverage': ['cmdline.py',],
        'lib2to3': ['fixer_util.py', 'fix_dict.py', 'patcomp.py', 'refactor.py'],
        'leo': [], # All of Leo's core files pass.
        'pylint': [
            'base.py', 'classes.py', 'format.py',
            'logging.py', 'python3.py', 'stdlib.py', 
            'docparams.py', 'lint.py',
        ],
        'rope': ['objectinfo.py', 'objectdb.py', 'runmod.py',],
    }
    fails = fails_dict.get(project_name, [])
    << define s >>
    s = g.adjustTripleString(s, c.tab_width)
    << old tests >>
    stats = Stats()
    if kind == 'production':
        for p in g.findRootsWithPredicate(c, c.p, predicate=None):
            x = ConventionChecker(c, stats)
            x.check(fn=g.fullPath(c, p), trace_fn=trace_fn)
    elif kind == 'all':
        utils = ProjectUtils()
        aList = utils.project_files(project_name, force_all=False)
        if aList:
            t1 = time.clock()
            for fn in aList:
                sfn = g.shortFileName(fn)
                if sfn in fails or fn in fails:
                    if trace_skipped: print('===== skipping', sfn)
                else:
                    ConventionChecker(c, stats).check(fn=fn, trace_fn=trace_fn)
            t2 = time.clock()
            print('%s files in %4.2f sec.' % (len(aList), (t2-t1)))
        else:
            print('no files for project: %s' % (project_name))
    elif kind == 'string':
        ConventionChecker(c, stats).check(s=s)
    else:
        assert kind == 'file', repr(kind)
        ConventionChecker(c, stats).check(fn=fn)
    if report_stats:
        stats.report()
#@+node:ekr.20171211054736.2: *5* << define s >>
s = '''\
class T:
    
    def __init__(self, tempNode):
        self.tempNode = tempNode.copy()
    
    def setUp(self):
        tempNode = self.tempNode
        while tempNode.firstChild():
            tempNode.firstChild().doDelete()
'''

s_ok2 = '''
class Context(object):
    def __init__ (self, parent_context):
        self.parent_context = parent_context
        if parent_context:
            parent_context.inner_contexts_list.append(self)
'''
assert s_ok2

s_ok= '''
class TC:
    def __init__(self, c):
        c.tc = self
    def add_tag(self, p):
        print(p.v) # AttributeError if p is a vnode.

class Test:
    def __init__(self,c):
        self.c = c
        self.tc = self.c.tc
    def add_tag(self):
        p = self.c.p
        self.tc.add_tag(p.v) # WRONG: arg should be p.
'''
assert s_ok

#@+node:ekr.20171211054736.3: *5* << old tests >>
s_passes_1 = '''\
class C1:
        
    def f1(self, p):
        print(p.v)
        
    def f2(self, p):
        self.f1(p.v) # WRONG

'''
assert s_passes_1

s_1 = '''\
class C1:

    def __init__(self, c):
        self.c = c
        c.theTagController = self
        
    def add_tag(self, p):
        pass

class C2:

    def oops(self, p):
        c.tagController.add_tag(p.v,tag)
            # WRONG: should be p.

'''
assert s_1


s_2 = '''\
class TagController:

    def __init__(self, c):
        self.c = c
        c.theTagController = self

    def add_tag(self, p, tag):
        # Will fail if p is a vnode
        tags = set(p.v.u.get('__node_tags', set([])))

class LeoTagWidget(QtWidgets.QWidget):

    def __init__(self,c,parent=None):
        self.c = c
        self.tc = self.c.theTagController

    def add_tag(self, event=None):
        p = self.c.p
        self.tc.add_tag(p.v,tag) # WRONG: should be p.

'''
assert s_2
#@+node:ekr.20180813063846.1: *3* Fast-draw branches
#@+node:ekr.20180808075509.1: *4* qtree.partialDraw & helpers (never used)
def partialDraw(self, p):

    trace = True and not g.unitTesting
    c = self.c
    if 1:
        self.drawVisible()
    else:
        first_p = c.hoistStack[-1].p if c.hoistStack else c.rootPosition()
        aList1 = self.countVisible(first_p=first_p, target_p=p)
        aList2 = self.countVisible(first_p=p, target_p=None)
        if trace:
            n1, n2 = len(aList1), len(aList2)
            g.trace('%s + %s = %s' % (n1, n2, n1+n2))
        if 1:
            # Draw everything.
            self.drawList(aList1 + aList2)
        else:
            aList = self.computeVisiblePositions(aList1, aList2, p)
            self.drawList(aList)
#@+node:ekr.20180809110957.1: *5* qtree.computeVisiblePositions
def computeVisiblePositions(self, aList1, aList2, p):
    '''
    Compute the list of *visible* positions to be drawn.
    
    This is tricky.  We don't want to scroll the screen unnecessarily.
    '''
    # Show everything if possible.
    if len(aList1) + len(aList2) <= self.size:
        return aList1 + aList2
    c = self.c
    while p.hasParent():
        p.moveToParent()
    aList = []
    for i in range(self.size):
        aList.append(p.copy())
        p.moveToVisNext(c)
        if not p:
            break
    return aList
#@+node:ekr.20180809123937.1: *5* qtree.countVisible
def countVisible(self, first_p, target_p):
    """
    Return the number of visible positions from first_p to target_p.
    """
    c = self.c
    aList, p = [first_p.copy()], first_p.copy()
    while p:
        if p == target_p:
            return aList[:-1]
        v = p.v
        # if v.isExpanded() and v.hasChildren():
        if (v.statusBits & v.expandedBit) != 0 and v.children:
            # p.moveToFirstChild()
            p.stack.append((v, p._childIndex),)
            p.v = v.children[0]
            p._childIndex = 0
            aList.append(p.copy())
            continue
        # if p.hasNext():
        parent_v = p.stack[-1][0] if p.stack else c.hiddenRootNode
        if p._childIndex + 1 < len(parent_v.children):
            # p.moveToNext()
            p._childIndex += 1
            p.v = parent_v.children[p._childIndex]
            aList.append(p.copy())
            continue
        #
        # A fast version of p.moveToThreadNext().
        # We look for a parent with a following sibling.
        while p.stack:
            # p.moveToParent()
            p.v, p._childIndex = p.stack.pop()
            # if p.hasNext():
            parent_v = p.stack[-1][0] if p.stack else c.hiddenRootNode
            if p._childIndex + 1 < len(parent_v.children):
                # p.moveToNext()
                p._childIndex += 1
                p.v = parent_v.children[p._childIndex]
                break # Found: moveToThreadNext()
        else:
            break # Not found.
        # Found moveToThreadNext()
        aList.append(p.copy())
        continue
    if target_p:
        g.trace('NOT FOUND:', target_p.h)
    return aList
#@+node:ekr.20180809115019.1: *5* qtree.drawList
def drawList(self, aList):
    
    trace = False
    c = self.c
    parents = []
    # Clear the widget.
    w = self.treeWidget
    w.clear()
    # Clear the dicts.
    self.initData()
    for p in aList:
        level = p.level()
        parent_item = w if level == 0 else parents[level-1]
        item = QtWidgets.QTreeWidgetItem(parent_item)
        item.setFlags(item.flags() | QtCore.Qt.ItemIsEditable)
        item.setChildIndicatorPolicy(
            item.ShowIndicator if p.hasChildren()
            else item.DontShowIndicator)
        item.setExpanded(bool(p.hasChildren() and p.isExpanded()))
        self.items.append(item)
        if trace:
            print('')
            g.trace('===== level', level, p.h)
            g.trace('parent', id(parent_item), parent_item.__class__.__name__)
            g.trace('item  ', id(item), item.__class__.__name__)
            self.print_parents(parents, 1)
        # Update parents.
        if level == 0:
            parents = []
        else:
            parents = parents[:level]
        parents.append(item)
        if trace:
            self.print_parents(parents, 2)
        # Update the dicts.  Like rememberItem.
        itemHash = self.itemHash(item)
        self.item2positionDict[itemHash] = p.copy()
        self.item2vnodeDict[itemHash] = p.v
        self.position2itemDict[p.key()] = item
        d = self.vnode2itemsDict
        v = p.v
        aList = d.get(v, [])
        aList.append(item)
        d[v] = aList
        # Enter the headline.
        item.setText(0, p.h)
        # Set current item.
        if p == c.p:
            w.setCurrentItem(item)
#@+node:ekr.20180809111725.1: *5* qtree.printParents
def print_parents(self, parents, tag):
    print(tag)
    g.printObj([
        '%10s %s' % (id(z), z.__class__.__name__)
            for z in parents])
#@+node:ekr.20180810060655.1: *4* test vieldVisible
g.cls()
import time
tree = c.frame.tree
if 1: # works
    for p in c.all_positions():
        p.expand()
elif 1:
    for p in c.all_positions():
        p.v.expandedPositions = []
    for p in c.all_positions():
        p.v.expand()
        p.v.expandedPositions.append(p.copy())
else: # Doesn't work
    for v in c.all_nodes():
        v.expand()
    c.redraw() # This would be wrong.
if 1:
    t1 = time.clock()
    for i in range(1):
        aList1 = [z.copy() for z in tree.slowYieldVisible(c.rootPosition())]
    t2 = time.clock()
    print('slow: %6.3f' % (t2-t1))
if 1:
    t1 = time.clock()
    for i in range(1):
        aList2 = [z.copy() for z in tree.yieldVisible(c.rootPosition())]
    t2 = time.clock()
    print('fast: %6.3f' % (t2-t1))
v1 = [z.v for z in aList1]
v2 = [z.v for z in aList2]
try:
    i = 0
    while i < min(len(aList1), len(aList2)) and aList1[i] == aList2[i]:
        # print(i, aList1[i].h)
        i += 1
    if i == len(aList1) == len(aList2):
        print('OK')
    else:
        print('FAIL', i, len(aList1), len(aList2))
    assert aList1 == aList2, (len(aList1), len(aList2))
    assert v1 == v2, (len(v1), len(v2))
finally:
    for v in c.all_nodes():
        v.contract()
    c.redraw()
#@+node:ekr.20180810111515.1: *4* benchmark
import time
t1 = time.clock()
c.expandAllHeadlines()
t2 = time.clock()
print('expand: %5.2f sec' % (t2-t1))
t3 = time.clock()
tree = c.frame.tree
w = tree.treeWidget
n = 0
for p in tree.yieldVisible(c.rootPosition()):
    n += 1
    # c.selectPosition(p)
    item = tree.position2itemDict.get(c.p.key())
    if item:
        w.setCurrentItem(item)
t4 = time.clock()
print('%s nodes in %5.2f sec' % (n, t4-t3))
#@+node:ekr.20110605121601.17879: *4* qtree.rememberItem
def rememberItem(self, p, item):

    v = p.v
    # Update position dicts.
    itemHash = self.itemHash(item)
    self.position2itemDict[p.key()] = item
    self.item2positionDict[itemHash] = p.copy() # was item
    # Update item2vnodeDict.
    self.item2vnodeDict[itemHash] = v # was item
    # Update vnode2itemsDict.
    d = self.vnode2itemsDict
    aList = d.get(v, [])
    if item in aList:
        g.trace('*** ERROR *** item already in list: %s, %s' % (item, aList))
    else:
        aList.append(item)
    d[v] = aList
#@+node:ekr.20120219154958.10488: *4* LM.initFocusAndDraw (not used)
def initFocusAndDraw(self, c, fileName):

    def init_focus_handler(timer, c=c, p=c.p):
        '''Idle-time handler for initFocusAndDraw'''
        c.initialFocusHelper()
        c.outerUpdate()
        timer.stop()

    # This must happen after the code in getLeoFile.
    timer = g.IdleTime(init_focus_handler, delay=0.1, tag='getLeoFile')
    if timer:
        timer.start()
    else:
        # Default code.
        c.selectPosition(c.p)
        c.initialFocusHelper()
        c.k.showStateAndMode()
        c.outerUpdate()
#@+node:ekr.20150312225028.29: *3* leoViews project
This was a major project, now abandoned.
#@+node:ekr.20150312225028.31: *4* class OrganizerData
class OrganizerData:
    '''A class containing all data for a particular organizer node.'''
    def __init__ (self,h,unl,unls):
        self.anchor = None # The anchor position of this od node.
        self.children = [] # The direct child od nodes of this od node.
        self.closed = False # True: this od node no longer accepts new child od nodes.
        self.drop = True # Drop the unl for this od node when associating positions with unls.
        self.descendants = None # The descendant od nodes of this od node.
        self.exists = False # True: this od was created by @existing-organizer:
        self.h = h # The headline of this od node.
        self.moved = False # True: the od node has been moved to a global move list.
        self.opened = False # True: the od node has been opened.
        self.organized_nodes = [] # The list of positions organized by this od node.
        self.parent_od = None # The parent od node of this od node. (None is valid.)
        self.p = None # The position of this od node.
        self.parent = None # The original parent position of all nodes organized by this od node.
            # If parent_od is None, this will be the parent position of the od node.
        self.source_unl = None # The unl of self.parent.
        self.unl = unl # The unl of this od node.
        self.unls = unls # The unls contained in this od node.
        self.visited = False # True: demote_helper has already handled this od node.
    def __repr__(self):
        return 'OrganizerData: %s' % (self.h or '<no headline>')
    __str__ = __repr__
#@+node:ekr.20150312225028.32: *4* class ViewController
class ViewController:
    << docstring >>
    @others
#@+node:ekr.20150312225028.33: *5*  << docstring >> (class ViewController)
'''
A class to handle @views trees and related operations.
Such trees have the following structure:

- @views
  - @auto-view <unl of @auto node>
    - @organizers
      - @organizer <headline>
    - @clones
    
The body text of @organizer and @clones consists of unl's, one per line.
'''
#@+node:ekr.20150312225028.34: *5*  vc.ctor & vc.init
def __init__ (self,c):
    '''Ctor for ViewController class.'''
    self.c = c
    self.headline_ivar = '_imported_headline'
    self.init()
    
def init(self):
    '''
    Init all ivars of this class.
    Unit tests may call this method to ensure that this class is re-inited properly.
    '''
    self.all_ods = []
        # List of all od nodes.
    self.anchors_d = {}
        # Keys are anchoring positions, values are sorted lists of ods.
    self.anchor_offset_d = {}
        # Keys are anchoring positions, values are ints.
    self.existing_ods = []
        # List of od instances corresponding to @existing-organizer: nodes.
    self.global_bare_organizer_node_list = []
        # List of organizers that have no parent organizer node.
        # This list excludes existing organizer nodes.
    self.headlines_dict = {}
        # Keys are vnodes; values are list of child headlines.
    self.imported_organizers_list = []
        # The list of nodes that have children on entry, such as class nodes.
    self.n_nodes_scanned = 0
        # Number of nodes scanned by demote.
    self.organizer_ods = []
        # List of od instances corresponding to @organizer: nodes.
    self.organizer_unls = []
        # The list of od.unl for all od instances in self.organizer_ods.
    self.root = None
        # The position of the @auto node.
    self.pending = []
        # The list of nodes pending to be added to an organizer.
    self.stack = []
        # The stack containing real and virtual parent nodes during the main loop.
    self.temp_node = None
        # The parent position of all holding cells.
    self.trail_write_1 = None
        # The trial write on entry.
    self.views_node = None
        # The position of the @views node.
    self.work_list = []
        # A gloal list of (parent,child) tuples for all nodes that are
        # to be moved to **non-existing** organizer nodes.
        # **Important**: Nodes are moved in the order they appear in this list:
        # the tuples contain no childIndex component!
        # This list is the "backbone" of this class:
        # - The front end (demote and its helpers) adds items to this list.
        # - The back end (move_nodes and its helpers) moves nodes using this list.
#@+node:ekr.20150312225028.35: *5* vc.Entry points
#@+node:ekr.20150312225028.36: *6* vc.convert_at_file_to_at_auto
def convert_at_file_to_at_auto(self,root):
    # Define class ConvertController.
    @others
    vc = self
    c = vc.c
    if root.isAtFileNode():
        ConvertController(c,root).run()
    else:
        g.es_print('not an @file node:',root.h)
#@+node:ekr.20150312225028.37: *7* class ConvertController
class ConvertController:
    def __init__ (self,c,p):
        self.c = c
        # self.ic = c.importCommands
        self.vc = c.viewController
        self.root = p.copy()
    @others
#@+node:ekr.20150312225028.38: *8* cc.delete_at_auto_view_nodes
def delete_at_auto_view_nodes(self,root):
    '''Delete all @auto-view nodes pertaining to root.'''
    cc = self
    vc = cc.vc
    while True:
        p = vc.has_at_auto_view_node(root)
        if not p: break
        p.doDelete()
#@+node:ekr.20150312225028.39: *8* cc.import_from_string
def import_from_string(self,s):
    '''Import from s into a temp outline.'''
    cc = self # (ConvertController)
    c = cc.c
    ic = c.importCommands
    root = cc.root
    language = g.scanForAtLanguage(c,root) 
    ext = '.'+g.app.language_extension_dict.get(language)
    scanner = ic.scanner_for_ext(ext)
    # g.trace(language,ext,scanner.__name__)
    p = root.insertAfter()
    ok = scanner(atAuto=True,parent=p,s=s)
    p.h = root.h.replace('@file','@auto' if ok else '@@auto')
    return ok,p
#@+node:ekr.20150312225028.40: *8* cc.run
def run(self):
    '''Convert an @file tree to @auto tree.'''
    trace = True and not g.unitTesting
    trace_s = False
    cc = self
    c = cc.c
    root,vc = cc.root,c.viewController
    # set the headline_ivar for all vnodes.
    t1 = time.clock()
    cc.set_expected_imported_headlines(root)
    t2 = time.clock()
    # Delete all previous @auto-view nodes for this tree.
    cc.delete_at_auto_view_nodes(root)
    t3 = time.clock()
    # Ensure that all nodes of the tree are regularized.
    ok = vc.prepass(root)
    t4 = time.clock()
    if not ok:
        g.es_print('Can not convert',root.h,color='red')
        if trace: g.trace(
            '\n  set_expected_imported_headlines: %4.2f sec' % (t2-t1),
            # '\n  delete_at_auto_view_nodes:     %4.2f sec' % (t3-t2),
            '\n  prepass:                         %4.2f sec' % (t4-t3),
            '\n  total:                           %4.2f sec' % (t4-t1))
        return
    # Create the appropriate @auto-view node.
    at_auto_view = vc.update_before_write_at_auto_file(root)
    t5 = time.clock()
    # Write the @file node as if it were an @auto node.
    s = cc.strip_sentinels()
    t6 = time.clock()
    if trace and trace_s:
        g.trace('source file...\n',s)
    # Import the @auto string.
    ok,p = cc.import_from_string(s)
    t7 = time.clock()
    if ok:
        # Change at_auto_view.b so it matches p.gnx.
        at_auto_view.b = vc.at_auto_view_body(p)
        # Recreate the organizer nodes, headlines, etc.
        ok = vc.update_after_read_at_auto_file(p)
        t8 = time.clock()
        if not ok:
            p.h = '@@' + p.h
            g.trace('restoring original @auto file')
            ok,p = cc.import_from_string(s)
            if ok:
                p.h = '@@' + p.h + ' (restored)'
                if p.next():
                    p.moveAfter(p.next())
        t9 = time.clock()
    else:
        t8 = t9 = time.clock()
    if trace: g.trace(
        '\n  set_expected_imported_headlines: %4.2f sec' % (t2-t1),
        # '\n  delete_at_auto_view_nodes:     %4.2f sec' % (t3-t2),
        '\n  prepass:                         %4.2f sec' % (t4-t3),
        '\n  update_before_write_at_auto_file:%4.2f sec' % (t5-t4),
        '\n  strip_sentinels:                 %4.2f sec' % (t6-t5),
        '\n  import_from_string:              %4.2f sec' % (t7-t6),
        '\n  update_after_read_at_auto_file   %4.2f sec' % (t8-t7),
        '\n  import_from_string (restore)     %4.2f sec' % (t9-t8),
        '\n  total:                           %4.2f sec' % (t9-t1))
    if p:
        c.selectPosition(p)
    c.redraw()
#@+node:ekr.20150312225028.41: *8* cc.set_expected_imported_headlines
def set_expected_imported_headlines(self,root):
    '''Set the headline_ivar for all vnodes.'''
    trace = False and not g.unitTesting
    cc = self
    c = cc.c
    ic = cc.c.importCommands
    language = g.scanForAtLanguage(c,root) 
    ext = '.'+g.app.language_extension_dict.get(language)
    aClass = ic.classDispatchDict.get(ext)
    scanner = aClass(importCommands=ic,atAuto=True)
    # Duplicate the fn logic from ic.createOutline.
    theDir = g.setDefaultDirectory(c,root,importing=True)
    fn = c.os_path_finalize_join(theDir,root.h)
    fn = root.h.replace('\\','/')
    junk,fn = g.os_path_split(fn)
    fn,junk = g.os_path_splitext(fn)
    if aClass and hasattr(scanner,'headlineForNode'):
        ivar = cc.vc.headline_ivar
        for p in root.subtree():
            if not hasattr(p.v,ivar):
                h = scanner.headlineForNode(fn,p)
                setattr(p.v,ivar,h)
                if trace and h != p.h:
                    g.trace('==>',h) # p.h,'==>',h
#@+node:ekr.20150312225028.42: *8* cc.strip_sentinels
def strip_sentinels(self):
    '''Write the file to a string without headlines or sentinels.'''
    trace = False and not g.unitTesting
    cc = self
    at = cc.c.atFileCommands
    # ok = at.writeOneAtAutoNode(cc.root,
        # toString=True,force=True,trialWrite=True)
    at.errors = 0
    at.write(cc.root,
        kind = '@file',
        nosentinels = True,
        perfectImportFlag = False,
        scriptWrite = False,
        thinFile = True,
        toString = True)
    ok = at.errors == 0
    s = at.stringOutput
    if trace: g.trace('ok:',ok,'s:...\n'+s)
    return s
#@+node:ekr.20150312225028.43: *6* vc.pack & helper
def pack(self):
    '''
    Undoably convert c.p to a packed @view node, replacing all cloned
    children of c.p by unl lines in c.p.b.
    '''
    vc = self
    c,u = vc.c,vc.c.undoer
    vc.init()
    changed = False
    root = c.p
    # Create an undo group to handle changes to root and @views nodes.
    # Important: creating the @views node does *not* invalidate any positions.'''
    u.beforeChangeGroup(root,'view-pack')
    if not vc.has_at_views_node():
        changed = True
        bunch = u.beforeInsertNode(c.rootPosition())
        views = vc.find_at_views_node()
            # Creates the @views node as the *last* top-level node
            # so that no positions become invalid as a result.
        u.afterInsertNode(views,'create-views-node',bunch)
    # Prepend @view if need.
    if not root.h.strip().startswith('@'):
        changed = True
        bunch = u.beforeChangeNodeContents(root)
        root.h = '@view ' + root.h.strip()
        u.afterChangeNodeContents(root,'view-pack-update-headline',bunch)
    # Create an @view node as a clone of the @views node.
    bunch = u.beforeInsertNode(c.rootPosition())
    new_clone = vc.create_view_node(root)
    if new_clone:
        changed = True
        u.afterInsertNode(new_clone,'create-view-node',bunch)
    # Create a list of clones that have a representative node
    # outside of the root's tree.
    reps = [vc.find_representative_node(root,p)
        for p in root.children()
            if vc.is_cloned_outside_parent_tree(p)]
    reps = [z for z in reps if z is not None]
    if reps:
        changed = True
        bunch = u.beforeChangeTree(root)
        c.setChanged(True)
        # Prepend a unl: line for each cloned child.
        unls = ['unl: %s\n' % (vc.unl(p)) for p in reps]
        root.b = ''.join(unls) + root.b
        # Delete all child clones in the reps list.
        v_reps = set([p.v for p in reps])
        while True:
            for child in root.children():
                if child.v in v_reps:
                    child.doDelete()
                    break
            else: break
        u.afterChangeTree(root,'view-pack-tree',bunch)
    if changed:
        u.afterChangeGroup(root,'view-pack')
        c.selectPosition(root)
        c.redraw()
#@+node:ekr.20150312225028.44: *7* vc.create_view_node
def create_view_node(self,root):
    '''
    Create a clone of root as a child of the @views node.
    Return the *newly* cloned node, or None if it already exists.
    '''
    vc = self
    c = vc.c
    # Create a cloned child of the @views node if it doesn't exist.
    views = vc.find_at_views_node()
    for p in views.children():
        if p.v == c.p.v:
            return None
    p = root.clone()
    p.moveToLastChildOf(views)
    return p
#@+node:ekr.20150312225028.45: *6* vc.unpack
def unpack(self):
    '''
    Undoably unpack nodes corresponding to leading unl lines in c.p to child clones.
    Return True if the outline has, in fact, been changed.
    '''
    vc = self
    c,root,u = vc.c,vc.c.p,vc.c.undoer
    vc.init()
    # Find the leading unl: lines.
    i,lines,tag = 0,g.splitLines(root.b),'unl:'
    for s in lines:
        if s.startswith(tag): i += 1
        else: break
    changed = i > 0
    if changed:
        bunch = u.beforeChangeTree(root)
        # Restore the body
        root.b = ''.join(lines[i:])
        # Create clones for each unique unl.
        unls = list(set([s[len(tag):].strip() for s in lines[:i]]))
        for unl in unls:
            p = vc.find_absolute_unl_node(unl)
            if p: p.clone().moveToLastChildOf(root)
            else: g.trace('not found: %s' % (unl))
        c.setChanged(True)
        c.undoer.afterChangeTree(root,'view-unpack',bunch)
        c.redraw()
    return changed
#@+node:ekr.20150312225028.46: *6* vc.update_before_write_at_auto_file
def update_before_write_at_auto_file(self,root):
    '''
    Update the @auto-view node for root, an @auto node. Create @organizer,
    @existing-organizer, @clones and @headlines nodes as needed.
    This *must not* be called for trial writes.
    '''
    trace = False and not g.unitTesting
    vc = self
    c = vc.c
    changed = False
    t1 = time.clock()
    # Create lists of cloned and organizer nodes.
    clones,existing_organizers,organizers = \
        vc.find_special_nodes(root)
    # Delete all children of the @auto-view node for this @auto node.
    at_auto_view = vc.find_at_auto_view_node(root)
    if at_auto_view.hasChildren():
        changed = True
        at_auto_view.deleteAllChildren()
    # Create the single @clones node.
    if clones:
        at_clones = vc.find_at_clones_node(root)
        at_clones.b = ''.join(
            ['gnx: %s\nunl: %s\n' % (z[0],z[1]) for z in clones])
    # Create the single @organizers node.
    if organizers or existing_organizers:
        at_organizers = vc.find_at_organizers_node(root)
    # Create one @organizers: node for each organizer node.
    for p in organizers:
        # g.trace('organizer',p.h)
        at_organizer = at_organizers.insertAsLastChild()
        at_organizer.h = '@organizer: %s' % p.h
        # The organizer node's unl is implicit in each child's unl.
        at_organizer.b = '\n'.join([
            'unl: '+vc.relative_unl(z,root) for z in p.children()])
    # Create one @existing-organizer node for each existing organizer.
    ivar = vc.headline_ivar
    for p in existing_organizers:
        at_organizer = at_organizers.insertAsLastChild()
        h = getattr(p.v,ivar,p.h)
        if trace and h != p.h: g.trace('==>',h) # p.h,'==>',h
        at_organizer.h = '@existing-organizer: %s' % h
        # The organizer node's unl is implicit in each child's unl.
        at_organizer.b = '\n'.join([
            'unl: '+vc.relative_unl(z,root) for z in p.children()])
    # Create the single @headlines node.
    vc.create_at_headlines(root)
    if changed and not g.unitTesting:
        g.es_print('updated @views node in %4.2f sec.' % (
            time.clock()-t1))
    if changed:
        c.redraw()
    return at_auto_view # For at-file-to-at-auto command.
#@+node:ekr.20150312225028.47: *7* vc.create_at_headlines
def create_at_headlines(self,root):
    '''Create the @headlines node for root, an @auto file.'''
    vc = self
    c = vc.c
    result = []
    ivar = vc.headline_ivar
    for p in root.subtree():
        h = getattr(p.v,ivar,None)
        if h is not None and p.h != h:
            # g.trace('custom:',p.h,'imported:',h)
            unl = vc.relative_unl(p,root)
            aList = unl.split('-->')
            aList[-1] = h
            unl = '-->'.join(aList)
            result.append('imported unl: %s\nhead: %s\n' % (
                unl,p.h))
            delattr(p.v,ivar)
    if result:
        p = vc.find_at_headlines_node(root)
        p.b = ''.join(result)
#@+node:ekr.20150312225028.48: *7* vc.find_special_nodes
def find_special_nodes(self,root):
    '''
    Scan root's tree, looking for organizer and cloned nodes.
    Exclude organizers on imported organizers list.
    '''
    trace = False and not g.unitTesting
    verbose = False
    vc = self
    clones,existing_organizers,organizers = [],[],[]
    if trace: g.trace('imported existing',
        [v.h for v in vc.imported_organizers_list])
    for p in root.subtree():
        if p.isCloned():
            rep = vc.find_representative_node(root,p)
            if rep:
                unl = vc.relative_unl(p,root)
                gnx = rep.v.gnx
                clones.append((gnx,unl),)
        if p.v in vc.imported_organizers_list:
            # The node had children created by the importer.
            if trace and verbose: g.trace('ignore imported existing',p.h)
        elif vc.is_organizer_node(p,root):
            # p.hasChildren and p.b is empty, except for comments.
            if trace and verbose: g.trace('organizer',p.h)
            organizers.append(p.copy())
        elif p.hasChildren():
            if trace and verbose: g.trace('existing',p.h)
            existing_organizers.append(p.copy())
    return clones,existing_organizers,organizers
#@+node:ekr.20150312225028.49: *6* vc.update_after_read_at_auto_file & helpers
def update_after_read_at_auto_file(self,root):
    '''
    Recreate all organizer nodes and clones for a single @auto node
    using the corresponding @organizer: and @clones nodes.
    '''
    trace = True and not g.unitTesting
    vc = self
    c = vc.c
    if not vc.is_at_auto_node(root):
        return # Not an error: it might be and @auto-rst node.
    old_changed = c.isChanged()
    try:
        vc.init()
        vc.root = root.copy()
        t1 = time.clock()
        vc.trial_write_1 = vc.trial_write(root)
        t2 = time.clock()
        at_organizers = vc.has_at_organizers_node(root)
        t3 = time.clock()
        if at_organizers:
            vc.create_organizer_nodes(at_organizers,root)
        t4 = time.clock()
        at_clones = vc.has_at_clones_node(root)
        if at_clones:
            vc.create_clone_links(at_clones,root)
        t5 = time.clock()
        n = len(vc.work_list)
        ok = vc.check(root)
        t6 = time.clock()
        if ok:
            vc.update_headlines_after_read(root)
        t7 = time.clock()
        c.setChanged(old_changed if ok else False)
            # To do: revert if not ok.
    except Exception:
        g.es_exception()
        n = 0
        ok = False
    if trace:
        if t7-t1 > 0.5: g.trace(
            '\n  trial_write:                 %4.2f sec' % (t2-t1),
            # '\n  has_at_organizers_node:    %4.2f sec' % (t3-t2),
            '\n  create_organizer_nodes:      %4.2f sec' % (t4-t3),
            '\n  create_clone_links:          %4.2f sec' % (t5-t4),
            '\n  check:                       %4.2f sec' % (t6-t5),
            '\n  update_headlines_after_read: %4.2f sec' % (t7-t6),
            '\n  total:                       %4.2f sec' % (t7-t1))
            # '\n  file:',root.h)
        # else: g.trace('total: %4.2f sec' % (t7-t1),root.h)
    if ok and n > 0:
        g.es('rearragned: %s' % (root.h),color='blue')
        g.es('moved %s nodes in %4.2f sec.' % (n,t7-t1))
        g.trace('@auto-view moved %s nodes in %4.2f sec. for' % (
            n,t2),root.h,noname=True)
    c.selectPosition(root)
    c.redraw()
    return ok
#@+node:ekr.20150312225028.50: *7* vc.check
def check (self,root):
    '''
    Compare a trial write or root with the vc.trail_write_1.
    Unlike the perfect-import checks done by the importer,
    we expecct an *exact* match, regardless of language.
    '''
    trace = True # and not g.unitTesting
    vc = self
    trial1 = vc.trial_write_1
    trial2 = vc.trial_write(root)
    if trial1 != trial2:
        g.pr('') # Don't use print: it does not appear with the traces.
        g.es_print('perfect import check failed for:',color='red')
        g.es_print(root.h,color='red')
        if trace:
            vc.compare_trial_writes(trial1,trial2)
            g.pr('')
    return trial1 == trial2
#@+node:ekr.20150312225028.51: *7* vc.create_clone_link
def create_clone_link(self,gnx,root,unl):
    '''
    Replace the node in the @auto tree with the given unl by a
    clone of the node outside the @auto tree with the given gnx.
    '''
    trace = False and not g.unitTesting
    vc = self
    p1 = vc.find_position_for_relative_unl(root,unl)
    p2 = vc.find_gnx_node(gnx)
    if p1 and p2:
        if trace: g.trace('relink',gnx,p2.h,'->',p1.h)
        if p1.b == p2.b:
            p2._relinkAsCloneOf(p1)
            return True
        else:
            g.es('body text mismatch in relinked node',p1.h)
            return False
    else:
        if trace: g.trace('relink failed',gnx,root.h,unl)
        return False
#@+node:ekr.20150312225028.52: *7* vc.create_clone_links
def create_clone_links(self,at_clones,root):
    '''
    Recreate clone links from an @clones node.
    @clones nodes contain pairs of lines (gnx,unl)
    '''
    vc = self
    lines = g.splitLines(at_clones.b)
    gnxs = [s[4:].strip() for s in lines if s.startswith('gnx:')]
    unls = [s[4:].strip() for s in lines if s.startswith('unl:')]
    # g.trace('at_clones.b',at_clones.b)
    if len(gnxs) == len(unls):
        vc.headlines_dict = {} # May be out of date.
        ok = True
        for gnx,unl in zip(gnxs,unls):
            ok = ok and vc.create_clone_link(gnx,root,unl)
        return ok
    else:
        g.trace('bad @clones contents',gnxs,unls)
        return False
#@+node:ekr.20150312225028.53: *7* vc.create_organizer_nodes & helpers
def create_organizer_nodes(self,at_organizers,root):
    '''
    root is an @auto node. Create an organizer node in root's tree for each
    child @organizer: node of the given @organizers node.
    '''
    vc = self
    c = vc.c
    trace = False and not g.unitTesting
    t1 = time.clock()
    vc.pre_move_comments(root)
        # Merge comment nodes with the next node.
    t2 = time.clock()
    vc.precompute_all_data(at_organizers,root)
        # Init all data required for reading.
    t3 = time.clock()
    vc.demote(root)
        # Traverse root's tree, adding nodes to vc.work_list.
    t4 = time.clock()
    vc.move_nodes()
        # Move nodes on vc.work_list to their final locations.
    t5 = time.clock()
    vc.post_move_comments(root)
        # Move merged comments to parent organizer nodes.
    t6 = time.clock()
    if trace: g.trace(
        '\n  pre_move_comments:   %4.2f sec' % (t2-t1),
        '\n  precompute_all_data: %4.2f sec' % (t3-t2),
        '\n  demote:              %4.2f sec' % (t4-t3),
        '\n  move_nodes:          %4.2f sec' % (t5-t4),
        '\n  post_move_comments:  %4.2f sec' % (t6-t5))
#@+node:ekr.20150312225028.54: *7* vc.update_headlines_after_read
def update_headlines_after_read(self,root):
    '''Handle custom headlines for all imported nodes.'''
    trace = False and not g.unitTesting
    vc = self
    # Remember the original imported headlines.
    ivar = vc.headline_ivar
    for p in root.subtree():
        if not hasattr(p.v,ivar):
            setattr(p.v,ivar,p.h)
    # Update headlines from @headlines nodes.
    at_headlines = vc.has_at_headlines_node(root)
    tag1,tag2 = 'imported unl: ','head: '
    n1,n2 = len(tag1),len(tag2)
    if at_headlines:
        lines = g.splitLines(at_headlines.b)
        unls  = [s[n1:].strip() for s in lines if s.startswith(tag1)]
        heads = [s[n2:].strip() for s in lines if s.startswith(tag2)]
    else:
        unls,heads = [],[]
    if len(unls) == len(heads):
        vc.headlines_dict = {} # May be out of date.
        for unl,head in zip(unls,heads):
            p = vc.find_position_for_relative_unl(root,unl)
            if p:
                if trace: g.trace('unl:',unl,p.h,'==>',head)
                p.h = head
    else:
        g.trace('bad @headlines body',at_headlines.b)
#@+node:ekr.20150312225028.55: *5* vc.Main Lines
#@+node:ekr.20150312225028.56: *6* vc.precompute_all_data & helpers
def precompute_all_data(self,at_organizers,root):
    '''Precompute all data needed to reorganize nodes.'''
    trace = False and not g.unitTesting
    vc = self
    t1 = time.clock() 
    vc.find_imported_organizer_nodes(root)
        # Put all nodes with children on vc.imported_organizer_node_list
    t2 = time.clock()
    vc.create_organizer_data(at_organizers,root)
        # Create OrganizerData objects for all @organizer:
        # and @existing-organizer: nodes.
    t3 = time.clock()
    vc.create_actual_organizer_nodes()
        # Create the organizer nodes in holding cells so positions remain valid.
    t4 = time.clock()
    vc.create_tree_structure(root)
        # Set od.parent_od, od.children & od.descendants for all ods.
    t5 = time.clock()
    vc.compute_all_organized_positions(root)
        # Compute the positions organized by each organizer.
        # ** Most of the time is spent here **.
    t6 = time.clock()
    vc.create_anchors_d()
        # Create the dictionary that associates positions with ods.
    t7 = time.clock()
    if trace: g.trace(
        '\n  find_imported_organizer_nodes:   %4.2f sec' % (t2-t1),
        '\n  create_organizer_data:           %4.2f sec' % (t3-t2),
        '\n  create_actual_organizer_nodes:   %4.2f sec' % (t4-t3),
        '\n  create_tree_structure:           %4.2f sec' % (t5-t4),
        '\n  compute_all_organized_positions: %4.2f sec' % (t6-t5),
        '\n  create_anchors_d:                %4.2f sec' % (t7-t6))
#@+node:ekr.20150312225028.57: *7* 1: vc.find_imported_organizer_nodes
def find_imported_organizer_nodes(self,root):
    '''
    Put the VNode of all imported nodes with children on
    vc.imported_organizers_list.
    '''
    trace = False # and not g.unitTesting
    vc = self
    aList = []
    for p in root.subtree():
        if p.hasChildren():
            aList.append(p.v)
    vc.imported_organizers_list = list(set(aList))
    if trace: g.trace([z.h for z in vc.imported_organizers_list])
#@+node:ekr.20150312225028.58: *7* 2: vc.create_organizer_data (od.p & od.parent)
def create_organizer_data(self,at_organizers,root):
    '''
    Create OrganizerData nodes for all @organizer: and @existing-organizer:
    nodes in the given @organizers node.
    '''
    vc = self
    vc.create_ods(at_organizers)
    vc.finish_create_organizers(root)
    vc.finish_create_existing_organizers(root)
    for od in vc.all_ods:
        assert od.parent,(od.exists,od.h)
#@+node:ekr.20150312225028.59: *8* vc.create_ods
def create_ods(self,at_organizers):
    '''Create all organizer nodes and the associated lists.'''
    # Important: we must completely reinit all data here.
    vc = self
    tag1 = '@organizer:'
    tag2 = '@existing-organizer:'
    vc.all_ods,vc.existing_ods,vc.organizer_ods = [],[],[]
    for at_organizer in at_organizers.children():
        h = at_organizer.h
        for tag in (tag1,tag2):
            if h.startswith(tag):
                unls = vc.get_at_organizer_unls(at_organizer)
                if unls:
                    organizer_unl = vc.drop_unl_tail(unls[0])
                    h = h[len(tag):].strip()
                    od = OrganizerData(h,organizer_unl,unls)
                    vc.all_ods.append(od)
                    if tag == tag1:
                        vc.organizer_ods.append(od)
                        vc.organizer_unls.append(organizer_unl)
                    else:
                        vc.existing_ods.append(od)
                        # Do *not* append organizer_unl to the unl list.
                else:
                    g.trace('===== no unls:',at_organizer.h)
#@+node:ekr.20150312225028.60: *8* vc.finish_create_organizers
def finish_create_organizers(self,root):
    '''Finish creating all organizers.'''
    trace = False # and not g.unitTesting
    vc = self
    # Careful: we may delete items from this list.
    for od in vc.organizer_ods[:]: 
        od.source_unl = vc.source_unl(vc.organizer_unls,od.unl)
        od.parent = vc.find_position_for_relative_unl(root,od.source_unl)
        if od.parent:
            od.anchor = od.parent
            if trace: g.trace(od.h,
                # '\n  exists:',od.exists,
                # '\n  unl:',od.unl,
                # '\n  source (unl):',od.source_unl or repr(''),
                # '\n  anchor (pos):',od.anchor.h,
                # '\n  parent (pos):',od.parent.h,
            )
        else:
            # This is, most likely, a true error.
            g.trace('===== removing od:',od.h)
            vc.organizer_ods.remove(od)
            vc.all_ods.remove(od)
            assert od not in vc.existing_ods
            assert od not in vc.all_ods
#@+node:ekr.20150312225028.61: *8* vc.finish_create_existing_organizers
def finish_create_existing_organizers(self,root):
    '''Finish creating existing organizer nodes.'''
    trace = False # and not g.unitTesting
    vc = self
    # Careful: we may delete items from this list.
    for od in vc.existing_ods[:]:
        od.exists = True
        assert od.unl not in vc.organizer_unls
        od.source_unl = vc.source_unl(vc.organizer_unls,od.unl)
        od.p = vc.find_position_for_relative_unl(root,od.source_unl)
        if od.p:
            od.anchor = od.p
            assert od.p.h == od.h,(od.p.h,od.h)  
            od.parent = od.p # Here, od.parent represents the "source" p.
            if trace: g.trace(od.h,
                # '\n  exists:',od.exists,
                # '\n  unl:',od.unl,
                # '\n  source (unl):',od.source_unl or repr(''),
                # '\n  anchor (pos):',od.anchor.h,
                # '\n  parent (pos):',od.parent.h,
            )
        else:
            # This arises when the imported node name doesn't match.
            g.trace('===== removing existing organizer:',od.h)
            vc.existing_ods.remove(od)
            vc.all_ods.remove(od)
            assert od not in vc.existing_ods
            assert od not in vc.all_ods

#@+node:ekr.20150312225028.62: *7* 3: vc.create_actual_organizer_nodes
def create_actual_organizer_nodes(self):
    '''
    Create all organizer nodes as children of holding cells. These holding
    cells ensure that moving an organizer node leaves all other positions
    unchanged.
    '''
    vc = self
    c = vc.c
    last = c.lastTopLevel()
    temp = vc.temp_node = last.insertAfter()
    temp.h = 'ViewController.temp_node'
    for od in vc.organizer_ods:
        holding_cell = temp.insertAsLastChild()
        holding_cell.h = 'holding cell for ' + od.h
        od.p = holding_cell.insertAsLastChild()
        od.p.h = od.h
#@+node:ekr.20150312225028.63: *7* 4: vc.create_tree_structure & helper
def create_tree_structure(self,root):
    '''Set od.parent_od, od.children & od.descendants for all ods.'''
    trace = False and not g.unitTesting
    vc = self
    # if trace: g.trace([z.h for z in data_list],g.callers())
    organizer_unls = [z.unl for z in vc.all_ods]
    for od in vc.all_ods:
        for unl in od.unls:
            if unl in organizer_unls:
                i = organizer_unls.index(unl)
                d2 = vc.all_ods[i]
                # if trace: g.trace('found organizer unl:',od.h,'==>',d2.h)
                od.children.append(d2)
                d2.parent_od = od
    # create_organizer_data now ensures od.parent is set.
    for od in vc.all_ods:
        assert od.parent,od.h
    # Extend the descendant lists.
    for od in vc.all_ods:
        vc.compute_descendants(od)
        assert od.descendants is not None
    if trace:
        def tail(head,unl):
            return str(unl[len(head):]) if unl.startswith(head) else str(unl)
        for od in vc.all_ods:
            g.trace(
                '\n  od:',od.h,
                '\n  unl:',od.unl,
                '\n  unls:', [tail(od.unl,z) for z in od.unls],
                '\n  source (unl):',od.source_unl or repr(''),
                '\n  parent (pos):', od.parent.h,
                '\n  children:',[z.h for z in od.children],
                '\n  descendants:',[str(z.h) for z in od.descendants])
#@+node:ekr.20150312225028.64: *8* vc.compute_descendants
def compute_descendants(self,od,level=0,result=None):
    '''Compute the descendant od nodes of od.'''
    trace = False # and not g.unitTesting
    vc = self
    if level == 0:
        result = []
    if od.descendants is None:
        for child in od.children:
            result.append(child)
            result.extend(vc.compute_descendants(child,level+1,result))
            result = list(set(result))
        if level == 0:
            od.descendants = result
            if trace: g.trace(od.h,[z.h for z in result])
        return result
    else:
        if trace: g.trace('cached',od.h,[z.h for z in od.descendants])
        return od.descendants
#@+node:ekr.20150312225028.65: *7* 5: vc.compute_all_organized_positions
def compute_all_organized_positions(self,root):
    '''Compute the list of positions organized by every od.'''
    trace = False and not g.unitTesting
    vc = self
    for od in vc.all_ods:
        if od.unls:
            # Do a full search only for the first unl.
            # parent = vc.find_position_for_relative_unl(root,od.unls[0])
            if True: # parent:
                for unl in od.unls:
                    p = vc.find_position_for_relative_unl(root,unl)
                    # p = vc.find_position_for_relative_unl(parent,vc.unl_tail(unl))
                    if p:
                        od.organized_nodes.append(p.copy())
                    if trace: g.trace('exists:',od.exists,
                        'od:',od.h,'unl:',unl,
                        'p:',p and p.h or '===== None')
            else:
                g.trace('fail',od.unls[0])
#@+node:ekr.20150312225028.66: *7* 6: vc.create_anchors_d
def create_anchors_d (self):
    '''
    Create vc.anchors_d.
    Keys are positions, values are lists of ods having that anchor.
    '''
    trace = False # and not g.unitTesting
    vc = self
    d = {}
    if trace: g.trace('all_ods',[z.h for z in vc.all_ods])
    for od in vc.all_ods:
        # Compute the anchor if it does not yet exists.
        # Valid now that p.__hash__ exists.
        key = od.anchor
        # key = '.'.join([str(z) for z in od.anchor.sort_key(od.anchor)])
        # key = '%s (%s)' % (key,od.anchor.h)
        aList = d.get(key,[])
        # g.trace(od.h,od.anchor.h,key,aList)
        aList.append(od)
        d[key] = aList
    if trace:
        for key in sorted(d.keys()):
            g.trace('od.anchor: %s ods: [%s]' % (key.h,','.join(z.h for z in d.get(key))))
    vc.anchors_d = d
#@+node:ekr.20150312225028.67: *6* vc.demote & helpers
def demote(self,root):
    '''
    The main line of the @auto-view algorithm. Traverse root's entire tree,
    placing items on the global work list.
    '''
    trace = False # and not g.unitTesting
    trace_loop = True
    vc = self
    active = None # The active od.
    vc.pending = [] # Lists of pending demotions.
    d = vc.anchor_offset_d # For traces.
    for p in root.subtree():
        parent = p.parent()
        if trace and trace_loop:
            if 1:
                g.trace('-----',p.childIndex(),p.h)
            else:
                g.trace(
                    '=====\np:',p.h,
                    'childIndex',p.childIndex(),
                    '\nparent:',parent.h,
                    'parent:offset',d.get(parent,0))
        vc.n_nodes_scanned += 1
        vc.terminate_organizers(active,parent)
        found = vc.find_organizer(parent,p)
        if found:
            pass # vc.enter_organizers(found,p)
        else:
            pass # vc.terminate_all_open_organizers()
        if trace and trace_loop:
            g.trace(
                'active:',active and active.h or 'None',
                'found:',found and found.h or 'None')
        # The main case statement...
        if found is None and active:
            vc.add_to_pending(active,p)
        elif found is None and not active:
            # Pending nodes will *not* be organized.
            vc.clear_pending(None,p)
        elif found and found == active:
            # Pending nodes *will* be organized.
            for z in vc.pending:
                active2,child2 = z
                vc.add(active2,child2,'found==active:pending')
            vc.pending = []
            vc.add(active,p,'found==active')
        elif found and found != active:
            # Pending nodes will *not* be organized.
            vc.clear_pending(found,p)
            active = found
            vc.enter_organizers(found,p)
            vc.add(active,p,'found!=active')
        else: assert False,'can not happen'
#@+node:ekr.20150312225028.68: *7* vc.add
def add(self,active,p,tag):
    '''
    Add p, an existing (imported) node to the global work list.
    Subtract 1 from the vc.anchor_offset_d entry for p.parent().
    
    Exception: do *nothing* if p is a child of an existing organizer node.
    '''
    trace = False # and not g.unitTesting
    verbose = False
    vc = self
    # g.trace(active,g.callers())
    if active.p == p.parent() and active.exists:
        if trace and verbose: g.trace('===== do nothing',active.h,p.h)
    else:
        data = active.p,p.copy()
        vc.add_to_work_list(data,tag)
        vc.anchor_decr(anchor=p.parent(),p=p)
        
#@+node:ekr.20150312225028.69: *7* vc.add_organizer_node
def add_organizer_node (self,od,p):
    '''
    Add od to the appropriate move list.
    p is the existing node that caused od to be added.
    '''
    trace = True # and not g.unitTesting
    verbose = False
    vc = self
    # g.trace(od.h,'parent',od.parent_od and od.parent_od.h or 'None')
    if od.parent_od:
        # Not a bare organizer: a child of another organizer node.
        # If this is an existing organizer, it's *position* may have
        # been moved without active.moved being set.
        data = od.parent_od.p,od.p
        if data in vc.work_list:
            if trace and verbose: g.trace(
                '**** duplicate 1: setting moved bit.',od.h)
            od.moved = True
        elif od.parent_od.exists:    
            anchor = od.parent_od.p
            n = vc.anchor_incr(anchor,p) + p.childIndex()
            data = anchor,od.p,n
            # g.trace('anchor:',anchor.h,'p:',p.h,'childIndex',p.childIndex())
            vc.add_to_bare_list(data,'non-bare existing')
        else:
            vc.add_to_work_list(data,'non-bare')
    elif od.p == od.anchor:
        if trace and verbose: g.trace(
            '***** existing organizer: do not move:',od.h)
    else:
        # This can be pre-computed?
        bare_list = [p for parent,p,n in vc.global_bare_organizer_node_list]
        if od.p in bare_list:
            if trace and verbose: g.trace(
                '**** duplicate 2: setting moved bit.',od.h)
            od.moved = True
        else:
            # A bare organizer node: a child of an *ordinary* node.
            anchor = p.parent()
            n = vc.anchor_incr(anchor,p) + p.childIndex()
            data = anchor,od.p,n
            vc.add_to_bare_list(data,'bare')
#@+node:ekr.20150312225028.70: *7* vc.add_to_bare_list
def add_to_bare_list(self,data,tag):
    '''Add data to the bare organizer list, with tracing.'''
    trace = False # and not g.unitTesting
    vc = self
    # Prevent duplicagtes.
    anchor,p,n = data
    for data2 in vc.global_bare_organizer_node_list:
        a2,p2,n2 = data2
        if p == p2:
            if trace: g.trace('ignore duplicate',
                'n:',n,anchor.h,'==>',p.h)
            return
    vc.global_bare_organizer_node_list.append(data)
    if trace:
        anchor,p,n = data
        g.trace('=====',tag,'n:',n,anchor.h,'==>',p.h)
            # '\n  anchor:',anchor.h,
            # '\n  p:',p.h)
#@+node:ekr.20150312225028.71: *7* vc.add_to_pending
def add_to_pending(self,active,p):
    trace = False # and not g.unitTesting
    vc = self
    if trace: g.trace(active.p.h,'==>',p.h)
    vc.pending.append((active,p.copy()),)
#@+node:ekr.20150312225028.72: *7* vc.add_to_work_list
def add_to_work_list(self,data,tag):
    '''Append the data to the work list, with tracing.'''
    trace = False # and not g.unitTesting
    vc = self
    vc.work_list.append(data)
    if trace:
        active,p = data
        g.trace('=====',tag,active.h,'==>',p.h)
#@+node:ekr.20150312225028.73: *7* vc.anchor_decr
def anchor_decr(self,anchor,p): # p is only for traces.
    '''
    Decrement the anchor dict for the given anchor node.
    Return the *previous* value.
    '''
    trace = False # and not g.unitTesting
    vc = self
    d = vc.anchor_offset_d
    n = d.get(anchor,0)
    d[anchor] = n - 1
    if trace: g.trace(n-1,anchor.h,'==>',p.h)
    return n
#@+node:ekr.20150312225028.74: *7* vc.anchor_incr
def anchor_incr(self,anchor,p): # p is only for traces.
    '''
    Increment the anchor dict for the given anchor node.
    Return the *previous* value.
    '''
    trace = False # and not g.unitTesting
    vc = self
    d = vc.anchor_offset_d
    n = d.get(anchor,0)
    d[anchor] = n + 1
    if trace: g.trace(n+1,anchor.h,'==>',p.h)
    return n
#@+node:ekr.20150312225028.75: *7* vc.clear_pending
def clear_pending(self,active,p):
    '''Clear the appropriate entries from the pending list.'''
    trace = False # and not g.unitTesting
    vc = self
    if trace: g.trace('===== clear pending',len(vc.pending))
    if False: # active and active.parent_od:
        for data in vc.pending:
            data = active.parent_od.p,data[1]
            vc.add_to_work_list(data,'clear-pending-to-active')
    vc.pending = []
#@+node:ekr.20150312225028.76: *7* vc.enter_organizers
def enter_organizers(self,od,p):
    '''Enter all organizers whose anchors are p.'''
    vc = self
    ods = []
    while od:
        ods.append(od)
        od = od.parent_od
    if ods:
        for od in reversed(ods):
            vc.add_organizer_node(od,p)
#@+node:ekr.20150312225028.77: *7* vc.find_organizer
def find_organizer(self,parent,p):
    '''Return the organizer that organizers p, if any.'''
    trace = False # and not g.unitTesting
    vc = self
    anchor = parent
    ods = vc.anchors_d.get(anchor,[])
    for od in ods:
        if p in od.organized_nodes:
            if trace: g.trace('found:',od.h,'for',p.h)
            return od
    return None
#@+node:ekr.20150312225028.78: *7* vc.terminate_organizers
def terminate_organizers(self,active,p):
    '''Terminate all organizers whose anchors are not ancestors of p.'''
    trace = False # and not g.unitTesting
    od = active
    while od and od.anchor != p and od.anchor.isAncestorOf(p):
        if not od.closed:
            if trace: g.trace('===== closing',od.h)
            od.closed = True
        od = od.parent_od
#@+node:ekr.20150312225028.79: *7* vc.terminate_all_open_organizers
def terminate_all_open_organizers(self):
    '''Terminate all open organizers.'''
    trace = True # and not g.unitTesting
    if 0:
        g.trace()
        for od in self.all_ods:
            if od.opened and not od.closed:
                if trace: g.trace('===== closing',od.h)
                od.closed = True
#@+node:ekr.20150312225028.80: *6* vc.move_nodes & helpers
def move_nodes(self):
    '''Move nodes to their final location and delete the temp node.'''
    trace = False # and not g.unitTesting
    vc = self
    vc.move_nodes_to_organizers(trace)
    vc.move_bare_organizers(trace)
    vc.temp_node.doDelete()
#@+node:ekr.20150312225028.81: *7* vc.move_nodes_to_organizers
def move_nodes_to_organizers(self,trace):
    '''Move all nodes in the work_list.'''
    trace = False # and not g.unitTesting
    trace_dict = False
    trace_moves = False
    trace_deletes = False
    vc = self
    if trace: # A highly useful trace!
        g.trace('\n\nunsorted_list...\n%s' % (
            '\n'.join(['%40s ==> %s' % (parent.h,p.h)
                for parent,p in vc.work_list])))
    # Create a dictionary of each organizers children.
    d = {}
    for parent,p in vc.work_list:
        # This key must remain stable if parent moves.
        key = parent
        aList = d.get(key,[])
        aList.append(p)
        # g.trace(key,[z.h for z in aList])
        d[key] = aList
    if trace and trace_dict:
        # g.trace('d...',sorted([z.h for z in d.keys()]))
        g.trace('d{}...')
        for key in sorted(d.keys()):
            aList = [z.h for z in d.get(key)]
            g.trace('%s %-20s %s' % (id(key),key.h,vc.dump_list(aList,indent=29)))
    # Move *copies* of non-organizer nodes to each organizer.
    organizers = list(d.keys())
    existing_organizers = [z.p.copy() for z in vc.existing_ods]
    moved_existing_organizers = {} # Keys are vnodes, values are positions.
    for parent in organizers:
        aList = d.get(parent,[])
        if trace and trace_moves:
            g.trace('===== moving/copying:',parent.h,
                'with %s children:' % (len(aList)),
                '\n  '+'\n  '.join([z.h for z in aList]))
        for p in aList:
            if p in existing_organizers:
                if trace and trace_moves:
                    g.trace('copying existing organizer:',p.h)
                    g.trace('children:',
                    '\n  '+'\n  '.join([z.h for z in p.children()]))
                copy = vc.copy_tree_to_last_child_of(p,parent)
                old = moved_existing_organizers.get(p.v)
                if old and trace_moves:
                    g.trace('*********** overwrite',p.h)
                moved_existing_organizers[p.v] = copy
            elif p in organizers:
                if trace and trace_moves:
                    g.trace('moving organizer:',p.h)
                aList = d.get(p)
                if aList:
                    if trace and trace_moves: g.trace('**** relocating',
                        p.h,'children:',
                        '\n  '+'\n  '.join([z.h for z in p.children()]))
                    del d[p]
                p.moveToLastChildOf(parent)
                if aList:
                    d[p] = aList
            else:
                parent2 = moved_existing_organizers.get(parent.v)
                if parent2:
                    if trace and trace_moves:
                        g.trace('***** copying to relocated parent:',p.h)
                    vc.copy_tree_to_last_child_of(p,parent2)
                else:
                    if trace and trace_moves: g.trace('copying:',p.h)
                    vc.copy_tree_to_last_child_of(p,parent)
    # Finally, delete all the non-organizer nodes, in reverse outline order.
    def sort_key(od):
        parent,p = od
        return p.sort_key(p)
    sorted_list = sorted(vc.work_list,key=sort_key)
    if trace and trace_deletes:
        g.trace('===== deleting nodes in reverse outline order...')
    for parent,p in reversed(sorted_list):
        if p.v in moved_existing_organizers:
            if trace and trace_deletes:
                g.trace('deleting moved existing organizer:',p.h)
            p.doDelete()
        elif p not in organizers:
            if trace and trace_deletes:
                g.trace('deleting non-organizer:',p.h)
            p.doDelete()
#@+node:ekr.20150312225028.82: *7* vc.move_bare_organizers
def move_bare_organizers(self,trace):
    '''Move all nodes in global_bare_organizer_node_list.'''
    trace = False # and not g.unitTesting
    trace_data = True
    trace_move = True
    vc = self
    # For each parent, sort nodes on n.
    d = {} # Keys are vnodes, values are lists of tuples (n,parent,p)
    existing_organizers = [od.p for od in vc.existing_ods]
    if trace: g.trace('ignoring existing organizers:',
        [p.h for p in existing_organizers])
    for parent,p,n in vc.global_bare_organizer_node_list:
        if p not in existing_organizers:
            key = parent.v
            aList = d.get(key,[])
            if (parent,p,n) not in aList:
                aList.append((parent,p,n),)
                d[key] = aList
    # For each parent, add nodes in childIndex order.
    def key_func(obj):
        return obj[0]
    for key in d.keys():
        aList = d.get(key)
        for data in sorted(aList,key=key_func):
            parent,p,n = data
            n2 = parent.numberOfChildren()
            if trace and trace_data:
                g.trace(n,parent.h,'==>',p.h)
            if trace and trace_move: g.trace(
                'move: %-20s:' % (p.h),
                'to child: %2s' % (n),
                'of: %-20s' % (parent.h),
                'with:',n2,'children')
            p.moveToNthChildOf(parent,n)
#@+node:ekr.20150312225028.83: *7* vc.copy_tree_to_last_child_of
def copy_tree_to_last_child_of(self,p,parent):
    '''Copy p's tree to the last child of parent.'''
    vc = self
    assert p != parent,p
        # A failed assert leads to unbounded recursion.
    # print('copy_tree_to_last_child_of',p.h,parent.h)
    root = parent.insertAsLastChild()
    root.b,root.h = p.b,p.h
    root.v.u = copy.deepcopy(p.v.u)
    for child in p.children():
        vc.copy_tree_to_last_child_of(child,root)
    return root
#@+node:ekr.20150312225028.84: *5* vc.Helpers
#@+node:ekr.20150312225028.85: *6* vc.at_auto_view_body and match_at_auto_body
def at_auto_view_body(self,p):
    '''Return the body text for the @auto-view node for p.'''
    # Note: the unl of p relative to p is simply p.h,
    # so it is pointless to add that to the @auto-view node.
    return 'gnx: %s\n' % p.v.gnx

def match_at_auto_body(self,p,auto_view):
    '''Return True if any line of auto_view.b matches the expected gnx line.'''
    if 0: g.trace(p.b == 'gnx: %s\n' % auto_view.v.gnx,
        g.shortFileName(p.h),auto_view.v.gnx,p.b.strip())
    return p.b == 'gnx: %s\n' % auto_view.v.gnx
#@+node:ekr.20150312225028.86: *6* vc.clean_nodes (not used)
def clean_nodes(self):
    '''Delete @auto-view nodes with no corresponding @auto nodes.'''
    vc = self
    c = vc.c
    views = vc.has_at_views_node()
    if not views:
        return
    # Remember the gnx of all @auto nodes.
    d = {}
    for p in c.all_unique_positions():
        if vc.is_at_auto_node(p):
            d[p.v.gnx] = True
    # Remember all unused @auto-view nodes.
    delete = []
    for child in views.children():
        s = child.b and g.splitlines(child.b)
        gnx = s[len('gnx'):].strip()
        if gnx not in d:
            g.trace(child.h,gnx)
            delete.append(child.copy())
    for p in reversed(delete):
        p.doDelete()
    c.selectPosition(views)
#@+node:ekr.20150312225028.87: *6* vc.comments...
#@+node:ekr.20150312225028.88: *7* vc.comment_delims
def comment_delims(self,p):
    '''Return the comment delimiter in effect at p, an @auto node.'''
    vc = self
    c = vc.c
    d = g.get_directives_dict(p)
    s = d.get('language') or c.target_language
    language,single,start,end = g.set_language(s,0)
    return single,start,end
#@+node:ekr.20150312225028.89: *7* vc.delete_leading_comments
def delete_leading_comments(self,delims,p):
    '''
    Scan for leading comments from p and return them.
    At present, this only works for single-line comments.
    '''
    single,start,end = delims
    if single:
        lines = g.splitLines(p.b)
        result = []
        for s in lines:
            if s.strip().startswith(single):
                result.append(s)
            else: break
        if result:
            p.b = ''.join(lines[len(result):])
            # g.trace('len(result)',len(result),p.h)
            return ''.join(result)
    return None
#@+node:ekr.20150312225028.90: *7* vc.is_comment_node
def is_comment_node(self,p,root,delims=None):
    '''Return True if p.b contains nothing but comments or blank lines.'''
    vc = self
    if not delims:
        delims = vc.comment_delims(root)
    # pylint: disable=unpacking-non-sequence
    single,start,end = delims
    assert single or start and end,'bad delims: %r %r %r' % (single,start,end)
    if single:
        for s in g.splitLines(p.b):
            s = s.strip()
            if s and not s.startswith(single) and not g.isDirective(s):
                return False
        return True
    else:
        def check_comment(s):
            done,in_comment = False,True
            i = s.find(end)
            if i > -1:
                tail = s[i+len(end):].strip()
                if tail: done = True
                else: in_comment = False
            return done,in_comment
        
        done,in_comment = False,False
        for s in g.splitLines(p.b):
            s = s.strip()
            if not s:
                pass
            elif in_comment:
                done,in_comment = check_comment(s)
            elif g.isDirective(s):
                pass
            elif s.startswith(start):
                done,in_comment = check_comment(s[len(start):])
            else:
                # g.trace('fail 1: %r %r %r...\n%s' % (single,start,end,s)
                return False
            if done:
                return False
        # All lines pass.
        return True
#@+node:ekr.20150312225028.91: *7* vc.is_comment_organizer_node
# def is_comment_organizer_node(self,p,root):
    # '''
    # Return True if p is an organizer node in the given @auto tree.
    # '''
    # return p.hasChildren() and vc.is_comment_node(p,root)
#@+node:ekr.20150312225028.92: *7* vc.post_move_comments
def post_move_comments(self,root):
    '''Move comments from the start of nodes to their parent organizer node.'''
    vc = self
    c = vc.c
    delims = vc.comment_delims(root)
    for p in root.subtree():
        if p.hasChildren() and not p.b:
            s = vc.delete_leading_comments(delims,p.firstChild())
            if s:
                p.b = s
                # g.trace(p.h)
#@+node:ekr.20150312225028.93: *7* vc.pre_move_comments
def pre_move_comments(self,root):
    '''
    Move comments from comment nodes to the next node.
    This must be done before any other processing.
    '''
    vc = self
    c = vc.c
    delims = vc.comment_delims(root)
    aList = []
    for p in root.subtree():
        if p.hasNext() and vc.is_comment_node(p,root,delims=delims):
            aList.append(p.copy())
            next = p.next()
            if p.b: next.b = p.b + next.b
    # g.trace([z.h for z in aList])
    c.deletePositionsInList(aList)
        # This sets c.changed.
#@+node:ekr.20150312225028.94: *6* vc.find...
# The find commands create the node if not found.
#@+node:ekr.20150312225028.95: *7* vc.find_absolute_unl_node
def find_absolute_unl_node(self,unl,priority_header=False):
    '''Return a node matching the given absolute unl.
    If priority_header == True and the node is not found, it will return the longest matching UNL starting from the tail
    '''
    import re
    pos_pattern = re.compile(r':(\d+),?(\d+)?$')
    vc = self
    aList = unl.split('-->')
    if aList:
        first,rest = aList[0],'-->'.join(aList[1:])
        count = 0
        pos = re.findall(pos_pattern,first)
        nth_sib,pos = pos[0] if pos else (0,0)
        pos = int(pos) if pos else 0
        nth_sib = int(nth_sib)
        first = re.sub(pos_pattern,"",first).replace('--%3E','-->')
        for parent in vc.c.rootPosition().self_and_siblings():
            if parent.h.strip() == first.strip():
                if pos == count:
                    if rest:
                        return vc.find_position_for_relative_unl(parent,rest,priority_header=priority_header)
                    else:
                        return parent
                count = count+1
        #Here we could find and return the nth_sib if an exact header match was not found
    return None
#@+node:ekr.20150312225028.96: *7* vc.find_at_auto_view_node & helper
def find_at_auto_view_node (self,root):
    '''
    Return the @auto-view node for root, an @auto node.
    Create the node if it does not exist.
    '''
    vc = self
    views = vc.find_at_views_node()
    p = vc.has_at_auto_view_node(root)
    if not p:
        p = views.insertAsLastChild()
        p.h = '@auto-view:' + root.h[len('@auto'):].strip()
        p.b = vc.at_auto_view_body(root)
    return p
#@+node:ekr.20150312225028.97: *7* vc.find_clones_node
def find_at_clones_node(self,root):
    '''
    Find the @clones node for root, an @auto node.
    Create the @clones node if it does not exist.
    '''
    vc = self
    c = vc.c
    h = '@clones'
    auto_view = vc.find_at_auto_view_node(root)
    p = g.findNodeInTree(c,auto_view,h)
    if not p:
        p = auto_view.insertAsLastChild()
        p.h = h
    return p
#@+node:ekr.20150312225028.98: *7* vc.find_at_headlines_node
def find_at_headlines_node(self,root):
    '''
    Find the @headlines node for root, an @auto node.
    Create the @headlines node if it does not exist.
    '''
    vc = self
    c = vc.c
    h = '@headlines'
    auto_view = vc.find_at_auto_view_node(root)
    p = g.findNodeInTree(c,auto_view,h)
    if not p:
        p = auto_view.insertAsLastChild()
        p.h = h
    return p
#@+node:ekr.20150312225028.99: *7* vc.find_gnx_node
def find_gnx_node(self,gnx):
    '''Return the first position having the given gnx.'''
    # This is part of the read logic, so newly-imported
    # nodes will never have the given gnx.
    vc = self
    for p in vc.c.all_unique_positions():
        if p.v.gnx == gnx:
            return p
    return None
#@+node:ekr.20150312225028.100: *7* vc.find_organizers_node
def find_at_organizers_node(self,root):
    '''
    Find the @organizers node for root, and @auto node.
    Create the @organizers node if it doesn't exist.
    '''
    vc = self
    c = vc.c
    h = '@organizers'
    auto_view = vc.find_at_auto_view_node(root)
    p = g.findNodeInTree(c,auto_view,h)
    if not p:
        p = auto_view.insertAsLastChild()
        p.h = h
    return p
#@+node:ekr.20150312225028.101: *7* vc.find_position_for_relative_unl
def find_position_for_relative_unl(self,parent,unl,priority_header=False):
    '''
    Return the node in parent's subtree matching the given unl.
    The unl is relative to the parent position.
    If priority_header == True and the node is not found, it will return the longest matching UNL starting from the tail
    '''
    # This is called from finish_create_organizers & compute_all_organized_positions.
    trace = False # and not g.unitTesting
    trace_loop = True
    trace_success = False
    vc = self
    if not unl:
        if trace and trace_success:
            g.trace('return parent for empty unl:',parent.h)
        return parent
    # The new, simpler way: drop components of the unl automatically.
    drop,p = [],parent # for debugging.
    # if trace: g.trace('p:',p.h,'unl:',unl)
    import re
    pos_pattern = re.compile(r':(\d+),?(\d+)?$')
    for s in unl.split('-->'):
        found = False # The last part must match.
        if 1:
            # Create the list of children on the fly.
            aList = vc.headlines_dict.get(p.v)
            if aList is None:
                aList = [z.h for z in p.children()]
                vc.headlines_dict[p.v] = aList
            try:
                pos = re.findall(pos_pattern,s)
                nth_sib,pos = pos[0] if pos else (0,0)
                pos = int(pos) if pos else 0
                nth_sib = int(nth_sib)
                s = re.sub(pos_pattern,"",s).replace('--%3E','-->')
                indices = [i for i, x in enumerate(aList) if x == s]
                if len(indices)>pos:
                    #First we try the nth node with same header
                    n = indices[pos]
                    p = p.nthChild(n)
                    found = True
                elif len(indices)>0:
                    #Then we try any node with same header
                    n = indices[-1]
                    p = p.nthChild(n)
                    found = True
                elif not priority_header:
                    #Then we go for the child index if return_pos is true
                    if len(aList)>nth_sib:
                        n = nth_sib
                    else:
                        n = len(aList)-1
                    if n>-1:
                        p = p.nthChild(n)
                    else:
                        g.es('Partial UNL match: Referenced level is higher than '+str(p.level()))
                    found = True
                if trace and trace_loop: g.trace('match:',s)
            except ValueError: # s not in aList.
                if trace and trace_loop: g.trace('drop:',s)
                drop.append(s)
        else: # old code.
            for child in p.children():
                if child.h == s:
                    p = child
                    found = True
                    if trace and trace_loop: g.trace('match:',s)
                    break
                # elif trace and trace_loop: g.trace('no match:',child.h)
            else:
                if trace and trace_loop: g.trace('drop:',s)
                drop.append(s)
    if not found and priority_header:
        aList = []
        for p in vc.c.all_unique_positions():
            if p.h.replace('--%3E','-->') in unl:
                aList.append((p.copy(),p.get_UNL(False,False,True)))
        unl_list = [re.sub(pos_pattern,"",x).replace('--%3E','-->') for x in unl.split('-->')]
        for iter_unl in aList:
            maxcount = 0
            count = 0
            compare_list = unl_list[:]
            for header in reversed(iter_unl[1].split('-->')):
                if re.sub(pos_pattern,"",header).replace('--%3E','-->') == compare_list[-1]:
                    count = count+1
                    compare_list.pop(-1)
                else:
                    break
            if count > maxcount:
                p = iter_unl[0]
                found = True
    if found:
        if trace and trace_success:
            g.trace('found unl:',unl,'parent:',p.h,'drop',drop)
    else:
        if trace: g.trace('===== unl not found:',unl,'parent:',p.h,'drop',drop)
    return p if found else None
#@+node:ekr.20150312225028.102: *7* vc.find_representative_node
def find_representative_node (self,root,target):
    '''
    root is an @auto node. target is a clones node within root's tree.
    Return a node *outside* of root's tree that is cloned to target,
    preferring nodes outside any @<file> tree.
    Never return any node in any @views or @view tree.
    '''
    trace = False and not g.unitTesting
    assert target
    assert root
    vc = self
    # Pass 1: accept only nodes outside any @file tree.
    p = vc.c.rootPosition()
    while p:
        if p.h.startswith('@view'):
            p.moveToNodeAfterTree()
        elif p.isAnyAtFileNode():
            p.moveToNodeAfterTree()
        elif p.v == target.v:
            if trace: g.trace('success 1:',p,p.parent())
            return p
        else:
            p.moveToThreadNext()
    # Pass 2: accept any node outside the root tree.
    p = vc.c.rootPosition()
    while p:
        if p.h.startswith('@view'):
            p.moveToNodeAfterTree()
        elif p == root:
            p.moveToNodeAfterTree()
        elif p.v == target.v:
            if trace: g.trace('success 2:',p,p.parent())
            return p
        else:
            p.moveToThreadNext()
    g.trace('no representative node for:',target,'parent:',target.parent())
    return None
#@+node:ekr.20150312225028.103: *7* vc.find_views_node
def find_at_views_node(self):
    '''
    Find the first @views node in the outline.
    If it does not exist, create it as the *last* top-level node,
    so that no existing positions become invalid.
    '''
    vc = self
    c = vc.c
    p = g.findNodeAnywhere(c,'@views')
    if not p:
        last = c.rootPosition()
        while last.hasNext():
            last.moveToNext()
        p = last.insertAfter()
        p.h = '@views'
        # c.selectPosition(p)
        # c.redraw()
    return p
#@+node:ekr.20150312225028.104: *6* vc.has...
# The has commands return None if the node does not exist.
#@+node:ekr.20150312225028.105: *7* vc.has_at_auto_view_node
def has_at_auto_view_node(self,root):
    '''
    Return the @auto-view node corresponding to root, an @root node.
    Return None if no such node exists.
    '''
    vc = self
    c = vc.c
    assert vc.is_at_auto_node(root) or vc.is_at_file_node(root),root
    views = g.findNodeAnywhere(c,'@views')
    if views:
        # Find a direct child of views with matching headline and body.
        for p in views.children():
            if vc.match_at_auto_body(p,root):
                return p
    return None
#@+node:ekr.20150312225028.106: *7* vc.has_clones_node
def has_at_clones_node(self,root):
    '''
    Find the @clones node for an @auto node with the given unl.
    Return None if it does not exist.
    '''
    vc = self
    p = vc.has_at_auto_view_node(root)
    return p and g.findNodeInTree(vc.c,p,'@clones')
#@+node:ekr.20150312225028.107: *7* vc.has_at_headlines_node
def has_at_headlines_node(self,root):
    '''
    Find the @clones node for an @auto node with the given unl.
    Return None if it does not exist.
    '''
    vc = self
    p = vc.has_at_auto_view_node(root)
    return p and g.findNodeInTree(vc.c,p,'@headlines')
#@+node:ekr.20150312225028.108: *7* vc.has_organizers_node
def has_at_organizers_node(self,root):
    '''
    Find the @organizers node for root, an @auto node.
    Return None if it does not exist.
    '''
    vc = self
    p = vc.has_at_auto_view_node(root)
    return p and g.findNodeInTree(vc.c,p,'@organizers')
#@+node:ekr.20150312225028.109: *7* vc.has_views_node
def has_at_views_node(self):
    '''Return the @views or None if it does not exist.'''
    vc = self
    return g.findNodeAnywhere(vc.c,'@views')
#@+node:ekr.20150312225028.110: *6* vc.is...
#@+node:ekr.20150312225028.111: *7* vc.is_at_auto_node
def is_at_auto_node(self,p):
    '''Return True if p is an @auto node.'''
    return g.match_word(p.h,0,'@auto') and not g.match(p.h,0,'@auto-')
        # Does not match @auto-rst, etc.

def is_at_file_node(self,p):
    '''Return True if p is an @file node.'''
    return g.match_word(p.h,0,'@file')
#@+node:ekr.20150312225028.112: *7* vc.is_cloned_outside_parent_tree
def is_cloned_outside_parent_tree(self,p):
    '''Return True if a clone of p exists outside the tree of p.parent().'''
    return len(list(set(p.v.parents))) > 1
#@+node:ekr.20150312225028.113: *7* vc.is_organizer_node
def is_organizer_node(self,p,root):
    '''
    Return True if p is an organizer node in the given @auto tree.
    '''
    vc = self
    return p.hasChildren() and vc.is_comment_node(p,root)

#@+node:ekr.20150312225028.114: *6* vc.testing...
#@+node:ekr.20150312225028.115: *7* vc.compare_test_trees
def compare_test_trees(self,root1,root2):
    '''
    Compare the subtrees whose roots are given.
    This is called only from unit tests.
    '''
    vc = self
    s1,s2 = vc.trial_write(root1),vc.trial_write(root2)
    if s1 == s2:
        return True
    g.trace('Compare:',root1.h,root2.h)
    p2 = root2.copy().moveToThreadNext()
    for p1 in root1.subtree():
        if p1.h == p2.h:
            g.trace('Match:',p1.h)
        else:
            g.trace('Fail: %s != %s' % (p1.h,p2.h))
            break
        p2.moveToThreadNext()
    return False
#@+node:ekr.20150312225028.116: *7* vc.compare_trial_writes
def compare_trial_writes(self,s1,s2):
    '''
    Compare the two strings, the results of trial writes.
    Stop the comparison after the first mismatch.
    '''
    trace_matches = False
    full_compare = False
    lines1,lines2 = g.splitLines(s1),g.splitLines(s2)
    i,n1,n2 = 0,len(lines1),len(lines2)
    while i < n1 and i < n2:
        s1,s2 = lines1[i].rstrip(),lines2[i].rstrip()
        i += 1
        if s1 == s2:
            if trace_matches: g.trace('Match:',s1)
        else:
            g.trace('Fail:  %s != %s' % (s1,s2))
            if not full_compare: return
    if i < n1:
        g.trace('Extra line 1:',lines1[i])
    if i < n2:
        g.trace('Extra line 2:',lines2[i])
#@+node:ekr.20150312225028.117: *7* vc.dump_list
def dump_list(self,aList,indent=4):
    '''Dump a list, one item per line.'''
    lead = '\n' + ' '*indent
    return lead+lead.join(sorted(aList))
#@+node:ekr.20150312225028.118: *7* vc.trial_write
def trial_write(self,root):
    '''
    Return a trial write of outline whose root is given.
    
    **Important**: the @auto import and write code end all nodes with
    newlines. Because no imported nodes are empty, the code below is
    *exactly* equivalent to the @auto write code as far as trailing
    newlines are concerned. Furthermore, we can treat Leo directives as
    ordinary text here.
    '''
    vc = self
    if 1:
        # Do a full trial write, exactly as will be done later.
        at = vc.c.atFileCommands
        ok = at.writeOneAtAutoNode(root,
            toString=True,force=True,trialWrite=True)
        if ok:
            return at.stringOutput
        else:
            g.trace('===== can not happen')
            return ''
    elif 1:
        # Concatenate all body text.  Close, but not exact.
        return ''.join([p.b for p in root.self_and_subtree()])
    else:
        # Compare headlines, ignoring nodes without body text and comment nodes.
        # This was handy during early development.
        return '\n'.join([p.h for p in root.self_and_subtree()
            if p.b and not p.h.startswith('#')])
#@+node:ekr.20150312225028.119: *6* vc.unls...
#@+node:ekr.20150312225028.120: *7* vc.drop_all_organizers_in_unl
def drop_all_organizers_in_unl(self,organizer_unls,unl):
    '''Drop all organizer unl's in unl, recreating the imported unl.'''
    vc = self
    def unl_sort_key(s):
        return s.count('-->')
    for s in reversed(sorted(organizer_unls,key=unl_sort_key)):
        if unl.startswith(s):
            s2 = vc.drop_unl_tail(s)
            unl = s2 + unl[len(s):]
    return unl[3:] if unl.startswith('-->') else unl
#@+node:ekr.20150312225028.121: *7* vc.drop_unl_tail & vc.drop_unl_parent
def drop_unl_tail(self,unl):
    '''Drop the last part of the unl.'''
    return '-->'.join(unl.split('-->')[:-1])

def drop_unl_parent(self,unl):
    '''Drop the penultimate part of the unl.'''
    aList = unl.split('-->')
    return '-->'.join(aList[:-2] + aList[-1:])
#@+node:ekr.20150312225028.122: *7* vc.get_at_organizer_unls
def get_at_organizer_unls(self,p):
    '''Return the unl: lines in an @organizer: node.'''
    return [s[len('unl:'):].strip()
        for s in g.splitLines(p.b)
            if s.startswith('unl:')]

#@+node:ekr.20150312225028.123: *7* vc.relative_unl & unl
def relative_unl(self,p,root):
    '''Return the unl of p relative to the root position.'''
    vc = self
    result = []
    ivar = vc.headline_ivar
    for p in p.self_and_parents():
        if p == root:
            break
        else:
            h = getattr(p.v,ivar,p.h)
            result.append(h)
    return '-->'.join(reversed(result))

def unl(self,p):
    '''Return the unl corresponding to the given position.'''
    vc = self
    return '-->'.join(reversed([
        getattr(p.v,vc.headline_ivar,p.h)
            for p in p.self_and_parents()]))
    # return '-->'.join(reversed([p.h for p in p.self_and_parents()]))
#@+node:ekr.20150312225028.124: *7* vc.source_unl
def source_unl(self,organizer_unls,organizer_unl):
    '''Return the unl of the source node for the given organizer_unl.'''
    vc = self
    return vc.drop_all_organizers_in_unl(organizer_unls,organizer_unl)
#@+node:ekr.20150312225028.125: *7* vc.unl_tail
def unl_tail(self,unl):
    '''Return the last part of a unl.'''
    return unl.split('-->')[:-1][0]
#@+node:ekr.20150312225028.126: *4* vc.Commands
@g.command('view-pack')
def view_pack_command(event):
    c = event.get('c')
    if c and c.viewController:
        c.viewController.pack()

@g.command('view-unpack')
def view_unpack_command(event):
    c = event.get('c')
    if c and c.viewController:
        c.viewController.unpack()
        
@g.command('at-file-to-at-auto')
def at_file_to_at_auto_command(event):
    c = event.get('c')
    if c and c.viewController:
        c.viewController.convert_at_file_to_at_auto(c.p)
#@+node:ekr.20140711111623.17795: *4* class ConvertController (leoPersistence.py)
class ConvertController(object):
    '''A class to convert @file trees to @auto trees.'''

    def __init__(self, c, p):
        self.c = c
        self.pd = c.persistenceController
        self.root = p.copy()
    @others
#@+node:ekr.20140711111623.17796: *5* convert.delete_at_data_nodes
def delete_at_data_nodes(self, root):
    '''Delete all @data nodes pertaining to root.'''
    cc = self
    pd = cc.pd
    while True:
        p = pd.has_at_data_node(root)
        if not p: break
        p.doDelete()
#@+node:ekr.20140711111623.17797: *5* convert.import_from_string
def import_from_string(self, s):
    '''Import from s into a temp outline.'''
    cc = self # (ConvertController)
    c = cc.c
    # ic = c.importCommands
    root = cc.root
    language = g.scanForAtLanguage(c, root)
    ext = '.' + g.app.language_extension_dict.get(language)
    scanner = g.app.scanner_for_ext(c, ext)
    # g.trace(language,ext,scanner.__name__)
    p = root.insertAfter()
    ok = scanner(atAuto=True, c=c, parent=p, s=s)
    p.h = root.h.replace('@file', '@auto' if ok else '@@auto')
    return ok, p
#@+node:ekr.20140711111623.17798: *5* convert.run
def run(self):
    '''Convert an @file tree to @auto tree.'''
    trace = True and not g.unitTesting
    trace_s = False
    cc = self
    c = cc.c
    root, pd = cc.root, c.persistenceController
    # set the expected imported headline for all vnodes.
    t1 = time.time()
    cc.set_expected_imported_headlines(root)
    t2 = time.time()
    # Delete all previous @data nodes for this tree.
    cc.delete_at_data_nodes(root)
    t3 = time.time()
    # Ensure that all nodes of the tree are regularized.
    ok = pd.prepass(root)
    t4 = time.time()
    if not ok:
        g.es_print('Can not convert', root.h, color='red')
        if trace: g.trace(
            '\n  set_expected_imported_headlines: %4.2f sec' % (t2 - t1),
            # '\n  delete_at_data_nodes:          %4.2f sec' % (t3-t2),
            '\n  prepass:                         %4.2f sec' % (t4 - t3),
            '\n  total:                           %4.2f sec' % (t4 - t1))
        return
    # Create the appropriate @data node.
    at_auto_view = pd.update_before_write_foreign_file(root)
    t5 = time.time()
    # Write the @file node as if it were an @auto node.
    s = cc.strip_sentinels()
    t6 = time.time()
    if trace and trace_s:
        g.trace('source file...\n', s)
    # Import the @auto string.
    ok, p = cc.import_from_string(s)
    t7 = time.time()
    if ok:
        # Change at_auto_view.b so it matches p.gnx.
        at_auto_view.b = pd.at_data_body(p)
        # Recreate the organizer nodes, headlines, etc.
        pd.update_after_read_foreign_file(p)
        t8 = time.time()
        # if not ok:
            # p.h = '@@' + p.h
            # g.trace('restoring original @auto file')
            # ok,p = cc.import_from_string(s)
            # if ok:
                # p.h = '@@' + p.h + ' (restored)'
                # if p.next():
                    # p.moveAfter(p.next())
        t9 = time.time()
    else:
        t8 = t9 = time.time()
    if trace: g.trace(
        '\n  set_expected_imported_headlines: %4.2f sec' % (t2 - t1),
        # '\n  delete_at_data_nodes:          %4.2f sec' % (t3-t2),
        '\n  prepass:                         %4.2f sec' % (t4 - t3),
        '\n  update_before_write_foreign_file:%4.2f sec' % (t5 - t4),
        '\n  strip_sentinels:                 %4.2f sec' % (t6 - t5),
        '\n  import_from_string:              %4.2f sec' % (t7 - t6),
        '\n  update_after_read_foreign_file   %4.2f sec' % (t8 - t7),
        '\n  import_from_string (restore)     %4.2f sec' % (t9 - t8),
        '\n  total:                           %4.2f sec' % (t9 - t1))
    if p:
        c.selectPosition(p)
    c.redraw()
#@+node:ekr.20140711111623.17799: *5* convert.set_expected_imported_headlines
def set_expected_imported_headlines(self, root):
    '''Set v._imported_headline for every vnode.'''
    trace = False and not g.unitTesting
    cc = self
    c = cc.c
    ic = cc.c.importCommands
    language = g.scanForAtLanguage(c, root)
    ext = '.' + g.app.language_extension_dict.get(language)
    aClass = g.app.classDispatchDict.get(ext)
    scanner = aClass(importCommands=ic, atAuto=True)
    # Duplicate the fn logic from ic.createOutline.
    theDir = g.setDefaultDirectory(c, root, importing=True)
    fn = c.os_path_finalize_join(theDir, root.h)
    fn = root.h.replace('\\', '/')
    junk, fn = g.os_path_split(fn)
    fn, junk = g.os_path_splitext(fn)
    if aClass and hasattr(scanner, 'headlineForNode'):
        for p in root.subtree():
            if not hasattr(p.v, '_imported_headline'):
                h = scanner.headlineForNode(fn, p)
                setattr(p.v, '_imported_headline', h)
                if trace and h != p.h:
                    g.trace('==>', h) # p.h,'==>',h
#@+node:ekr.20140711111623.17800: *5* convert.strip_sentinels
def strip_sentinels(self):
    '''Write the file to a string without headlines or sentinels.'''
    trace = False and not g.unitTesting
    cc = self
    at = cc.c.atFileCommands
    # ok = at.writeOneAtAutoNode(cc.root,
        # toString=True,force=True,trialWrite=True)
    at.errors = 0
    at.write(cc.root,
        kind='@file',
        nosentinels=True,
        perfectImportFlag=False,
        scriptWrite=False,
        thinFile=True,
        toString=True)
    ok = at.errors == 0
    s = at.stringOutput
    if trace: g.trace('ok:', ok, 's:...\n' + s)
    return s
#@+node:ekr.20140711111623.17794: *4* pd.convert_at_file_to_at_auto
def convert_at_file_to_at_auto(self, root):
    if root.isAtFileNode():
        ConvertController(self.c, root).run()
    else:
        g.es_print('not an @file node:', root.h)
#@+node:ekr.20140131101641.15495: *4* pd.prepass & helper
def prepass(self, root):
    '''Make sure root's tree has no hard-to-handle nodes.'''
    c, pd = self.c, self
    ic = c.importCommands
    ic.tab_width = c.getTabWidth(root)
    language = g.scanForAtLanguage(c, root)
    ext = g.app.language_extension_dict.get(language)
    if not ext: return
    if not ext.startswith('.'): ext = '.' + ext
    scanner = g.app.scanner_for_ext(c, ext)
    if not scanner:
        g.trace('no scanner for', root.h)
        return True # Pretend all went well.
    # Pass 1: determine the nodes to be inserted.
    ok = True
    # parts_list = []
    for p in root.subtree():
        ok2 = pd.regularize_node(p, scanner)
        ok = ok and ok2
    return ok
#@+node:ekr.20140131101641.15496: *5* pd.regularize_node
def regularize_node(self, p, scanner):
    '''Regularize node p so that it will not cause problems.'''
    c = self.c
    ok = scanner(atAuto=True, c=c, parent=p, s=p.b)
        # The scanner is a callback returned by g.app.scanner_for_ext.
        # It must have a c argument.
    if not ok:
        g.es_print('please regularize:', p.h)
    return ok
#@+node:ekr.20150312225028.6: *3* class LogManager (not used yet)
class LogManager:

    '''A class to handle the global log, and especially
    switching the log from commander to commander.'''

    def __init__ (self):

        trace = (False or g.trace_startup) and not g.unitTesting
        if trace: g.es_debug('(LogManager)')

        self.log = None             # The LeoFrame containing the present log.
        self.logInited = False      # False: all log message go to logWaiting list.
        self.logIsLocked = False    # True: no changes to log are allowed.
        self.logWaiting = []        # List of messages waiting to go to a log.
        self.printWaiting = []      # Queue of messages to be sent to the printer.
        self.signon_printed = False # True: the global signon has been printed.

    @others
#@+node:ekr.20150312225028.7: *4* LogM.setLog, lockLog, unlocklog
def setLog (self,log):

    """set the frame to which log messages will go"""

    # print("app.setLog:",log,g.callers())
    if not self.logIsLocked:
        self.log = log

def lockLog(self):
    """Disable changes to the log"""
    self.logIsLocked = True

def unlockLog(self):
    """Enable changes to the log"""
    self.logIsLocked = False
#@+node:ekr.20150312225028.8: *4* LogM.writeWaitingLog
def writeWaitingLog (self,c):
    '''Write all waiting lines to the log.'''
    trace = True
    lm = self
    if trace:
        # Do not call g.es, g.es_print, g.pr or g.trace here!
        print('** writeWaitingLog','silent',g.app.silentMode,c.shortFileName())
        # print('writeWaitingLog',g.callers())
        # import sys ; print('writeWaitingLog: argv',sys.argv)
    if not c or not c.exists:
        return
    if g.unitTesting:
        lm.printWaiting = []
        lm.logWaiting = []
        g.app.setLog(None) # Prepare to requeue for other commanders.
        return
    table = [
        ('Leo Log Window','red'),
        (g.app.signon,'black'),
        (g.app.signon2,'black'),
    ]
    table.reverse()
    c.setLog()
    lm.logInited = True # Prevent recursive call.
    if not lm.signon_printed:
        lm.signon_printed = True
        if not g.app.silentMode:
            print('')
            print('** isPython3: %s' % g.isPython3)
            if not g.enableDB:
                print('** caching disabled')
            print(g.app.signon)
            print(g.app.signon2)
    if not g.app.silentMode:
        for s in lm.printWaiting:
            print(s)
    lm.printWaiting = []
    if not g.app.silentMode:
        for s,color in table:
            lm.logWaiting.insert(0,(s+'\n',color),)
        for s,color in lm.logWaiting:
            g.es('',s,color=color,newline=0)
                # The caller must write the newlines.
    lm.logWaiting = []
    # Essential when opening multiple files...
    lm.setLog(None)
#@+node:ekr.20200209055601.1: **  Archived test stuff
#@+node:ekr.20200209055610.1: *3* @@button test
g.cls()
import os
leo_editor_dir = os.path.join(g.app.loadDir, '..', '..')
os.chdir(leo_editor_dir)
if 0: # Run all tests
    commands = f"python -m unittest leo.core.leoAst"
    g.execute_shell_commands(commands, trace=False)
else:
    file_ = '.leoAst'
    class_, test = '', ''
    class_, test = '.TestOrange', '.test_join_leading_whitespace'
    # class_, test = '.TestOrange', '.test_leo_sentinels'
    # class_, test = '.TestOrange', '.test_start_of_line_whitespace'
    # class_, test = '.TestOrange', '.test_join_lines'
    #
    # Older
    #
    # file_ = '.leoAst'
    # class_, test = '.TestTOG', ''
    # class_, test = '.TestFiles', '.compare_tog_vs_asttokens'
    # class_, test = '.TestFiles', '.optional_file_tests'
    # class_, test = '.TestTokens', '.show_asttokens_script'
    # class_, test = '.TestFstringify', '.test_call_with_comments'
        # # 'test_call_in_rhs' # '.test_braces'
    # class_, test = '.TestOrange','.test_join_lines'
        # # 'test_sync_tokens' # '.test_multi_line_pet_peeves'
    # class_, test = '.TestTokens', '.show_example_dump'
        # # 'test_line_links'
    # class_, test = '.TestTopLevelFunctions', '.test_get_encoding_directive'
    # class_, test = '.TestReassignTokens', ''
    # class_, test = '.TestTOT', ''
    commands = f"python -m unittest leo.core{file_}{class_}{test}"
    g.execute_shell_commands(commands, trace=False)
#@+node:ekr.20200209055640.1: *3* @@button pt
# Run pytest coverage tests.
g.cls()
import os
leo_editor_dir = os.path.join(g.app.loadDir, '..', '..')
os.chdir(leo_editor_dir)
commands = "pytest --cov-report html --cov-report term-missing --cov leo.core.leoAst leo/core/leoAst.py"
g.execute_shell_commands(commands, trace=False)
#@+node:ekr.20191028161708.1: *3*  Old test runners
#@+node:ekr.20191101150059.1: *4* function: check_roundtrip 
import unittest
# from tokenize import tokenize, untokenize

def check_roundtrip(f, expect_failure=False):
    """
    Called from unit tests in unitTest.leo.
    
    Test python's token.untokenize method and Leo's Untokenize class.
    """
    check_python_roundtrip(f, expect_failure)
    check_leo_roundtrip(f)

def check_leo_roundtrip(code, trace=False):
    """Check Leo's Untokenize class"""
    # pylint: disable=import-self
    import leo.core.leoBeautify as leoBeautify
    assert isinstance(code, str), repr(code)
    tokens = tokenize.tokenize(io.BytesIO(code.encode('utf-8')).readline)
    u = leoBeautify.InputTokenizer()
    u.trace=False and not g.unitTesting
    result_tokens = u.create_input_tokens(code, tokens)
    result = ''.join([z.to_string() for z in result_tokens])
    unittest.TestCase().assertEqual(code, result)

def check_python_roundtrip(f, expect_failure):
    """
    This is tokenize.TestRoundtrip.check_roundtrip, without the wretched fudges.
    """
    if isinstance(f, str):
        code = f.encode('utf-8')
    else:
        code = f.read()
        f.close()
    readline = iter(code.splitlines(keepends=True)).__next__
    tokens = list(tokenize.tokenize(readline))
    bytes = tokenize.untokenize(tokens)
    readline5 = iter(bytes.splitlines(keepends=True)).__next__
    result_tokens = list(tokenize.tokenize(readline5))
    if expect_failure:
        unittest.TestCase().assertNotEqual(result_tokens, tokens)
    else:
        unittest.TestCase().assertEqual(result_tokens, tokens)
#@+node:ekr.20191102062105.1: *4* @@command show tokens @key=Ctrl-1
g.cls()
import io
import tokenize
import imp
import leo.core.leoBeautify as leoBeautify
imp.reload(leoBeautify)

contents = r'''
print('hi')
'''
print("Ctrl-1: Round trip tests...\n")
leoBeautify.show(contents, 'Contents', dump=False)
contents = contents.strip() + '\n'
tokens = tokenize.tokenize(io.BytesIO(contents.encode('utf-8')).readline)
# Untokenize the tokens.
x = leoBeautify.InputTokenizer()
result_tokens = list(x.create_input_tokens(contents, tokens))
result = ''.join([z.to_string() for z in result_tokens])
if result == contents:
     print("\nPASS Ctrl-1: Round trip tests")
else:
    g.printObj(result)
    print(result)
    print('FAIL')
    print("FAIL Ctrl-1: Round trip tests")
#@+node:ekr.20191107160414.1: *5* Old tests
a = "b\
c\
d"
print ( 'aa \
bb')
print('xx \
yy')
#@+node:ekr.20191028095948.1: *4* @@command test FstringifyTokens @key=Ctrl-2
g.cls()
import imp
import leo.core.leoBeautify as leoBeautify
imp.reload(leoBeautify)

contents = r'''
return ''.join(['\n  %s' % z for z in result])
'''

print("Ctrl-2: Test of FStringifyTokens...\n")
contents = contents.strip() + '\n'
leoBeautify.test_FstringifyTokens(c, contents,
    dump=False,
    dump_input_tokens=False,
    dump_output_tokens=False)
print("\nEnd Ctrl-2: Test of FStringifyTokens")
#@+node:ekr.20191106073220.1: *5* Former fails that pass
g.es('%s blah blah' % (
    g.angleBrackets('*')))
    
mods = ''.join(['%s+' % z.capitalize() for z in self.mods])

args = '(%s)' % self.get_args(frame1) if self.show_args else ''
print(f"{path}{dots}{leadin}{full_name}{args}")

return '[%s]' % ' '.join(result).strip()

ret = '[\n%s]' % ('\n,'.join([self.show(z) for z in arg]))
#@+node:ekr.20191106074238.1: *5* Test that pass
#@+node:ekr.20191029072408.1: *6* fstringify tests
contents = r'''
print(
    'scanned %s node%s,' % (total, g.plural(total)),
    'changed %s node%s,' % (changed, g.plural(changed)),
    'in %4.2f sec.' % (t2-t1),
)
'''
#@+node:ekr.20191106024827.1: *6* fstringify tests 2
# These all pass
print('%2s' % a)
print('%2r' % b)
'%2.4f'%0.1
'%2.5f' % 0.2
'%s+' % z.capitalize()
''.join(['%s+' % z.capitalize() for z in self.mods])
#@+node:ekr.20191104221335.1: *6* fstring indentation tests
if 1:
  # Input:
    mods = ''.join(['%s+' % z.capitalize() for z in self.mods])
  # Results should be:
  # mods = ''.join([f'{z.capitalize()}+' for z in self.mods])
    mods = ''.join(['%s+' % z.capitalize() for z in self.mods])

# Single-line comment 2.
print('hi')
print(
    'thing 1',
    'thing 2',
)
print(
    'thing 3\
    thing4'
)
print \
    ('done')
#@+node:ekr.20191106064649.1: *6* fstring bs-nl tests
# backslash test.
a = "b\
c\
d"
print\
(
    'thing 3\
    thing4'
)
#@+node:ekr.20191106142223.1: *5* To do (small problems)
g.es('%s blah blah' % (g.angleBrackets('*')))

ret = '[%s]' % ','.join([self.show(z) for z in arg])

return ''.join(['\n  %s' % z for z in result])

g.trace('done: %5s page: %3s found: %s label: %s' % (
    done, page, n, label))
    
result = ['g.Bunch(%s)' % (tag or '')]
#@+node:ekr.20191106064850.1: *5* FAIL: missing ws
ret = '[%s]' % ','.join([self.show(z) for z in arg])

return ''.join(['\n  %s' % z for z in result])

g.trace('done: %5s page: %3s found: %s label: %s' % (
    done, page, n, label))
    
result = ['g.Bunch(%s)' % (tag or '')]
#@+node:ekr.20191026103522.1: *4* @@command test NullTokenBeautifier @key=Ctrl-3
"""Test NullTokenBeautifier on the given contents."""
g.cls()
import imp
import leo.core.leoBeautify as leoBeautify
imp.reload(leoBeautify)
# Between-token whitespace, w/o bs-nl
contents = r'''
# Backslash-newline
a = "b\
c\
d"
print(
    'thing 3\
    thing4'
)
# String concatenation, w/ trailing ws
'a' 'b' 
# String concatenation, w/ trailing ws at eof
'c', 'd' 
'''
print("Ctrl-3: Test of NullTokenBeautifier...\n")
contents = contents.strip() + '\n'
ok = leoBeautify.test_NullTokenBeautifier(c, contents,
    dump=False, dump_input_tokens=True, dump_output_tokens=False)
status = 'PASS' if ok else 'FAIL'
print(f"{status} End Ctrl-3: Test of NullTokenBeautifier")
#@+node:ekr.20191102055312.1: *5* << define contents >>
#@+node:ekr.20191029072313.1: *5* old test 1 (long)
if 1:
    # Single-line comment.
    print ( "hello" )
    if 0:
        print("bs-nl\
            continued\
            again")
    print(
        f"scanned {total} node{g.plural(total)}, "
        f"changed {changed} node{g.plural(changed)}, "
                # f"{errors} error{g.plural(errors)} "
        f"in {t2-t1:4.2f} sec."
    )
    print(
        'scanned %s node%s,' % (total, g.plural(total)),
        'changed %s node%s,' % (changed, g.plural(changed)),
        'in %4.2f sec.' % (t2-t1),
    )
print(a[1 : 2])
#@+node:ekr.20191030164855.1: *5* old test 2 (short)
if 1:
    # Single-line comment.
    print ( "hello" )
print('done')
#@+node:ekr.20191031091233.1: *5* old test 3
if 1:
    # Single-line comment.
    print ( "hello" )
    if 0:
        print("bs-nl\
            continued \
            again")
        print\
            ('next')
    print(
        f"scanned {total} node{g.plural(total)}, "
        f"changed {changed} node{g.plural(changed)}, "
                # f"{errors} error{g.plural(errors)} "
        f"in {t2-t1:4.2f} sec."
    )
    print(
        'scanned %s node%s,' % (total, g.plural(total)),
        'changed %s node%s,' % (changed, g.plural(changed)),
        'in %4.2f sec.' % (t2-t1),
    )
print(a[1 : 2])
#@+node:ekr.20191102055214.1: *5* old test: python bug
# Python bug: space after 'print' not round-tripped properly.
a = "b\
    c\
    d"
    
print\
    (\
    a,\
    b\
#@+node:ekr.20191029184302.1: *4* @@command test PythonTokenBeautifier @key=Ctrl-4
g.cls()
import imp
import leo.core.leoBeautify as leoBeautify
imp.reload(leoBeautify)

table = (
# New fail 1 from leoAst.py
r'''
def get_fields(self, node):
    return (
        (a, b) for a, b in ast.iter_fields(node)
            if a not in self.disabled_fields and b not in (None, [])
    )
''',
# Fail 1 from leoAst.py
r'''
raise AstNotEqual(
    f"node1.__class__.__name__: {node1.__class__.__name__}\n"
    f"node2.__class__.__name__: {node2.__class__.__name_}"
)
''',
# Fail 2 from leoAst.py
r'''
remove = [
    'Interactive', 'Suite',  # Not necessary.
    'PyCF_ONLY_AST',  # A constant,
    'AST',  # The base class,
]
''',
# Fail 3 from leoAst.py.
'''
table = (
    AstFullTraverser,
    AstFormatter,
    AstPatternFormatter,
    HTMLReportTraverser,
)
''',
# Basic indentation test.
r'''
def foo(a, b):
    foo()
    bar()
''',
# Backslash-newline tests.
# There must be a single blank before the bs-nl
# because *regularizes* whitespace before bs-nl.
r'''
print \
    ( \
    a, \
    b \
)
a = "b \
c \
d"
print \
    ('done')
''',
# Indentation test.
# Note: ptb retains the exact spelling of all strings.
r'''
print('hi')
print(
    'thing 1',
    'thing 2',
)
print(
    'thing 3\
    thing 4 \
    thing5'
)
''',
)
print("Ctrl-4: Test of PythonTokenBeautifier...\n")
ok = True
for test in table:
    contents = test.strip() + '\n'
    same = leoBeautify.test_PythonTokenBeautifier(c, contents,
        dump=False, # Use g.printObj to show results.
        dump_input_tokens=False,
        dump_output_tokens=False,
    )
    if not same:
        ok = False
        if 0: # Possible.
            g.cls()
            leoBeautify.test_PythonTokenBeautifier(c, contents,
                dump=True, # Use g.printObj to show results.
                dump_input_tokens=True,
                dump_output_tokens=True,
            )
        break #
print(
    f"{'PASS' if ok else 'FAIL'} "
    f"Ctrl-4: Test of PythonTokenBeautifier")
#@+node:ekr.20191029184302.2: *5* fstring test
contents = r'''
print('abc\
   xyz')
print("hello %s" % 'world')
print(
    f"scanned {total} node{g.plural(total)}, "
    f"changed {changed} node{g.plural(changed)}, "
            # f"{errors} error{g.plural(errors)} "
    f"in {t2-t1:4.2f} sec."
)
print(
    'scanned %s node%s,' % (total, g.plural(total)),
    'changed %s node%s,' % (changed, g.plural(changed)),
    'in %4.2f sec.' % (t2-t1),
)
'''
#@+node:ekr.20191030195606.1: *5* comment indent test
verbatim = False
# Single-line comment.
if self.test: # not single-line comment.
    pass
    # This comment ruins the indentation!
else:
    pass # not a single-line comment.
# Single-line comment.
# Single-line comment 2
#@+node:ekr.20191031170857.1: *5* backslash test
if 1:
    pass
while(a or \
    b or \
    c):
    pass
print \
    ('hi')
print(
    "abc"
    "xyz"
)
#@+node:ekr.20191105090751.1: *5* full test
@language python
@
This is a doc part.
@c

def spam():
    if 1:
        # Regular comment.
        print('-----')
            # Indented comment.
    else:
        pass
#@+node:ekr.20200219073857.1: *3* @@suite run all doctests
tm = c.testManager
path = g.os_path_join(g.app.loadDir,"..","core")
exclude = ['leoIPython.py',]
    # leoIPython.py will give an annoying error if IPython can't be imported.
modules = tm.importAllModulesInPath(path,exclude=exclude)
suite   = tm.createUnitTestsFromDoctests(modules)
#@+node:ekr.20191224054725.1: **  Retired plugins
#@+node:ekr.20191224054733.1: *3* Retired plugin: scripts_menu.py
"""Creates a Scripts menu for LeoPy.leo."""

# The new Execute Script command seems much safer and more convenient.

@language python
@tabwidth -4

import leo.core.leoGlobals as g
import glob
import os

__version__ = "1.5"

@others
#@+node:ekr.20191224054733.2: *4*  init
def init():
    '''Return True if the plugin has loaded successfully.'''
    # Ok for unit testing: creates menu.
    g.registerHandler("create-optional-menus",create_scripts_menu)
    g.plugin_signon(__name__)
    return True
#@+node:ekr.20191224054733.3: *4* create_scripts_menu & helpers
def create_scripts_menu (tag,keywords):
    """
    Populate a new Scripts menu with all .py files
    in leo/scripts and subdirectories.
    """
    c = keywords.get("c")
    if not c:
        return
    # finalize = g.os_path_finalize
    join = g.os_path_finalize_join
    path = join(g.app.loadDir,"..","scripts")
    if not os.path.exists(path):
        return
    # Get all files and directories.
    entries = glob.glob(join(path, "*"))
    # Get all top-level modules.
    top_mods = glob.glob(join(path, "*.py"))
    top_mods = [z for z in top_mods
        if not z.endswith('__init__.py')]
    # Get all inner modules.
    dirs = [f for f in entries if os.path.isdir(f)]
    inner_mods = [glob.glob(join(z, "*.py")) for z in dirs]
    inner_mods = [z for z in inner_mods if z]
    # g.printObj(top_mods, tag='top_mods')
    # g.printObj(inner_mods, tag='inner_mods')
    if not top_mods and not inner_mods:
        return
    # Create the top-level scripts menu.
    scriptsMenu = c.frame.menu.createNewMenu("&Scripts")
    create_top_level_scripts(c, scriptsMenu, top_mods)
    for directory in dirs:
        files = glob.glob(join(directory, "*.py"))
        if files:
            create_inner_scripts(c, directory, files)
#@+node:ekr.20191224054733.4: *5* create_inner_scripts
def create_inner_scripts(c, directory, files):
    """Create a submenu of the Scripts menu."""
    name = os.path.join("scripts", g.shortFileName(directory))
    menu = c.frame.menu.createNewMenu(name,"&Scripts")
    
    # Populate the submenu.
    table = []
    for filename in files:
        if filename.endswith('__init__.py'):
            continue
        prefix = g.os_path_finalize_join(g.app.loadDir, "..", "..")
        name = filename[len(prefix)+1:-3]
        name = name.replace('\\','.').replace('/','.')
        
        def inner_script_callback(event=None, name=name):
            g.import_module(name)

        table.append((name, None, inner_script_callback))
    c.frame.menu.createMenuEntries(menu, table, dynamicMenu=True)
#@+node:ekr.20191224054733.5: *5* create_top_level_scripts
def create_top_level_scripts(c, scriptsMenu, top_scripts):
 
    table = []
    for script in sorted(top_scripts):
        name = g.shortFileName(script)[:-3]

        def script_callback(event=None, name=name):
            g.import_module(f"leo.scripts.{name}")

        table.append((name, None, script_callback))
    c.frame.menu.createMenuEntries(
        scriptsMenu, table, dynamicMenu=True)
#@+node:ekr.20190506094028.1: ** Demo stuff
#@+node:ekr.20190506094028.2: *3* @@button demo1 @key=Ctrl-8
g.cls()
if c.isChanged(): c.save()
import imp
import leo.plugins.demo as demo
imp.reload(demo)
<< class MyDemo >>
h = 'demo1-commands'
button_p = g.findNodeAnywhere(c, '@button demo1 @key=Ctrl-8')
commands = g.findNodeInTree(c, button_p, h)
if commands:
    MyDemo(c).start(commands)
else:
    print('not found', h, c.p.h)
#@+node:ekr.20190506094028.3: *4* << class MyDemo >>
class MyDemo(demo.Demo):
    
    @others
    
#@+node:ekr.20190506094028.4: *5* setup
def setup(self, p):
    
    c = self.c
    self.delta = 0
    self.clear_log()
    p = g.findNodeAnywhere(c, 'Demo area')
    if p:
        c.selectPosition(p)
#@+node:ekr.20190506094028.5: *5* teardown
def teardown(self):
    
    c = self.c
    if self.delta:
        self.set_text_delta(-self.delta)
    p = g.findNodeAnywhere(c, 'Demo area')
    if p:
        c.selectPosition(p)
        next = p.next()
        if next and next.h == 'This is a test':
            c.selectPosition(next)
            next.doDelete()
            c.selectPosition(p)
            c.setChanged(False)
            c.redraw()
    

#@+node:ekr.20190506094028.6: *4* demo1-commands
print('demo1-commands')
# c.contractAllHeadlines()
#@+node:ekr.20190506094028.7: *5* @ignore-tree
#@+node:ekr.20190506094028.8: *6* set_text_delta
print('increasing text size by 10')
demo.delta = 10
demo.set_text_delta(demo.delta)
#@+node:ekr.20190506094028.9: *6* undo
undo_type = c.undoer.undoType
if undo_type == 'Insert Node':
    c.undoer.undo()
#@+node:ekr.20190506094028.10: *6* caption
demo.caption('My Caption', 'body')
#@+node:ekr.20190506094028.11: *6* @image
demo.delete_widgets()
fn = 'SplashScreen.ico'
demo.image('body', fn, center=True, height=None, width=None)
#@+node:ekr.20190506094028.12: *6* open menu
demo.delete_widgets()
demo.open_menu('Import')
#@+node:ekr.20190506094028.13: *6* close menu
demo.dismiss_menu_bar()
#@+node:ekr.20190506094028.14: *6* Alt-X insert-node
demo.key('Alt+x') # Not the same as Alt-X
demo.keys('insert-node')
# demo.wait(0.8)
# demo.key('\n') # Works.
#@+node:ekr.20190506094028.15: *6* Return
demo.key('\n')
#@+node:ekr.20190506094028.16: *5* headline
c.k.simulateCommand('insert-node')
demo.head_keys('This is a test')
#@+node:ekr.20190506094028.17: *3* Test: import c:\test\demo-it.el
g.cls()
import imp
import leo.plugins.importers.linescanner as linescanner
import leo.plugins.importers.elisp as elisp
imp.reload(linescanner)
imp.reload(elisp)
x = elisp.Elisp_Importer(c.importCommands, atAuto=False)
with open('c:/test/demo-it.el') as f:
    s = f.read()
parent = p.next()
assert parent.h == 'demo.el', parent.h
parent.b = ''
parent.deleteAllChildren()
try:
    x.run(s, parent)
except Exception:
    g.es_exception()
parent.expand()
c.selectPosition(parent)
c.redraw()
# g.printList(g.splitLines(s))
#@+node:ekr.20190506094028.18: *3* demo.image & helper
def image(self, fn, center=None, height=None, pane=None, width=None):
    '''Put an image in the indicated pane.'''
    parent = self.pane_widget(pane or 'body')
    if parent:
        w = QtWidgets.QLabel('label', parent)
        fn = self.resolve_icon_fn(fn)
        if not fn: return None
        pixmap = QtGui.QPixmap(fn)
        if not pixmap:
            return g.trace('Not a pixmap: %s' % (fn))
        if height:
            pixmap = pixmap.scaledToHeight(height)
        if width:
            pixmap = pixmap.scaledToWidth(width)
        w.setPixmap(pixmap)
        if center:
            g_w = w.geometry()
            g_p = parent.geometry()
            dx = (g_p.width() - g_w.width()) / 2
            w.move(g_w.x() + dx, g_w.y() + 10)
        w.show()
        self.widgets.append(w)
        return w
    else:
        g.trace('bad pane: %s' % (pane))
        return None
#@+node:ekr.20190506094028.19: *4* demo.resolve_icon_fn
def resolve_icon_fn(self, fn):
    '''Resolve fn relative to the Icons directory.'''
    dir_ = g.os_path_finalize_join(g.app.loadDir, '..', 'Icons')
    path = g.os_path_finalize_join(dir_, fn)
    if g.os_path_exists(path):
        return path
    else:
        g.trace('does not exist: %s' % (path))
        return None
#@+node:ekr.20190506094028.20: *3* demo.caption & body, log, tree
def caption(self, s, pane): # To do: center option.
    '''Pop up a QPlainTextEdit in the indicated pane.'''
    parent = self.pane_widget(pane)
    if parent:
        s = s.rstrip()
        if s and s[-1].isalpha(): s = s + '.'
        w = QtWidgets.QPlainTextEdit(s, parent)
        w.setObjectName('screencastcaption')
        self.widgets.append(w)
        w2 = self.pane_widget(pane)
        geom = w2.geometry()
        w.resize(geom.width(), min(150, geom.height() / 2))
        off = QtCore.Qt.ScrollBarAlwaysOff
        w.setHorizontalScrollBarPolicy(off)
        w.setVerticalScrollBarPolicy(off)
        w.show()
        return w
    else:
        g.trace('bad pane: %s' % (pane))
        return None

def body(self, s):
    return self.caption(s, 'body')

def log(self, s):
    return self.caption(s, 'log')

def tree(self, s):
    return self.caption(s, 'tree')
#@+node:ekr.20190506094028.21: *3* demo.body, log, tree
def body(self, s):
    return TextEdit(s, 'body')

def log(self, s):
    return TextEdit(s, 'log')

def tree(self, s):
    return TextEdit(s, 'tree')
#@+node:ekr.20190506094028.22: *3* Demo area
@language python

# A python comment.
#@+node:ekr.20190508062044.1: ** Do not delete
#@+node:ekr.20180826065640.1: *3* vr.embed_pyplot_widget (not used)
def embed_pyplot_widget(self):

    pc = self
    c = pc.c
    # Careful: we may be unit testing.
    splitter = c.free_layout.get_top_splitter()
    if not splitter:
        return
    if not pc.pyplot_canvas:

        # TODO Create the widgets.
        w = None
        ### Ref
        # pc.gs = QtWidgets.QGraphicsScene(splitter)
        # pc.gv = QtWidgets.QGraphicsView(pc.gs)
        # w = pc.gv.viewport() # A QWidget
        # Embed the widgets.
        pc.pyplot_canvas = w

        def delete_callback():
            pc.pyplot_canvas.deleteLater()
            pc.pyplot_canvas = None

    if pc.pyplot_canvas:
        pc.embed_widget(w, delete_callback=delete_callback)
#@+node:ekr.20150521114057.1: *3* test_beautifier (prints stats)
def test_beautifier(c, h, p, settings):
    '''Test Leo's beautifier code'''
    if not p:
        g.trace('not found: %s' % h)
        return None
    s = g.getScript(c, p,
            useSelectedText=False,
            forcePythonSentinels=True,
            useSentinels=False)
    g.trace(h.strip())
    t1 = time.time()
    s1 = g.toEncodedString(s)
    node1 = ast.parse(s1, filename='before', mode='exec')
    t2 = time.time()
    readlines = g.ReadLinesClass(s).next
    tokens = list(tokenize.generate_tokens(readlines))
    t3 = time.time()
    beautifier = PythonTokenBeautifier(c)
    keep_blank_lines = settings.get('tidy-keep-blank-lines')
    if keep_blank_lines is not None:
        beautifier.delete_blank_lines = not keep_blank_lines
    s2 = beautifier.run(tokens)
    t4 = time.time()
    try:
        s2_e = g.toEncodedString(s2)
        node2 = ast.parse(s2_e, filename='before', mode='exec')
        ok = compare_ast(node1, node2)
    except Exception:
        g.es_exception()
        ok = False
    t5 = time.time()
    #  Update the stats
    beautifier.n_input_tokens += len(tokens)
    beautifier.n_output_tokens += len(beautifier.code_list)
    beautifier.n_strings += len(s2)
    beautifier.parse_time += (t2 - t1)
    beautifier.tokenize_time += (t3 - t2)
    beautifier.beautify_time += (t4 - t3)
    beautifier.check_time += (t5 - t4)
    beautifier.total_time += (t5 - t1)
    if settings.get('input_string'):
        print('==================== input_string')
        for i, z in enumerate(g.splitLines(s)):
            print('%4s %s' % (i + 1, z.rstrip()))
    if settings.get('input_lines'):
        print('==================== input_lines')
        dump_tokens(tokens, verbose=False)
    if settings.get('input_tokens'):
        print('==================== input_tokens')
        dump_tokens(tokens, verbose=True)
    if settings.get('output_tokens'):
        print('==================== code_list')
        for i, z in enumerate(beautifier.code_list):
            print('%4s %s' % (i, z))
    if settings.get('output_string'):
        print('==================== output_string')
        for i, z in enumerate(g.splitLines(s2)):
            if z == '\n':
                print('%4s' % (i + 1))
            elif z.rstrip():
                print('%4s %s' % (i + 1, z.rstrip()))
            else:
                print('%4s %r' % (i + 1, str(z)))
    if settings.get('stats'):
        beautifier.print_stats()
    if not ok:
        print('*************** fail: %s ***************' % (h))
    return beautifier
        # For statistics.
#@+node:ekr.20191217092340.1: ** From leoAtFile.py
@nosearch
#@+node:ekr.20190111112432.1: *3* at.checkDirectory
def checkDirectory(self, directory):
    """Return True if directory exists or could be created."""
    at, c = self, self.c
    assert directory, g.callers()
    if g.os_path_exists(directory):
        return at.isWritable(directory)
    if c.config and c.config.create_nonexistent_directories:
        directory = c.expand_path_expression(directory)
        ok = g.makeAllNonExistentDirectories(directory)
        if not ok:
            g.error(f"did not create {directory}")
            return False
    return at.isWritable(directory)
#@+node:ekr.20190111111608.1: *3* at.checkPath
def checkPath(self, fileName):
    """Return True if we can write to the file's directory."""
    at = self
    assert g.os_path_isabs(fileName), (repr(fileName), g.callers())
    directory = g.os_path_dirname(fileName)
    if not at.checkDirectory(directory):
        return False
    if g.os_path_exists(fileName):
        return at.isWritable(fileName)
    return True
#@+node:ekr.20150602204757.1: *3* at.autoBeautify
def autoBeautify(self, p):
    """Auto beautify p's tree if allowed by settings and directives."""
    c = self.c
    try:
        if not p.isDirty():
            return
        if leoBeautify.should_kill_beautify(p):
            return
        if c.config.getBool('beautify-autobeautify'):
            leoBeautify.beautifyPythonTree(event={'c': c, 'p0': p.copy()})
    except Exception:
        g.es('unexpected exception')
        g.es_exception()
#@+node:ekr.20191229062845.1: ** From leoAst.py
#@+node:ekr.20141012064706.18399: *3* class AstFormatter
class AstFormatter:
    """
    A class to recreate source code from an AST.

    This does not have to be perfect, but it should be close.

    Also supports optional annotations such as line numbers, file names, etc.
    """
    # No ctor.
    # pylint: disable=consider-using-enumerate

    in_expr = False
    level = 0

    @others
#@+node:ekr.20141012064706.18402: *4* f.format
def format(self, node, level, *args, **keys):
    """Format the node and possibly its descendants, depending on args."""
    self.level = level
    val = self.visit(node, *args, **keys)
    return val.rstrip() if val else ''
#@+node:ekr.20141012064706.18403: *4* f.visit
def visit(self, node, *args, **keys):
    """Return the formatted version of an Ast node, or list of Ast nodes."""

    if isinstance(node, (list, tuple)):
        return ','.join([self.visit(z) for z in node])
    if node is None:
        return 'None'
    assert isinstance(node, ast.AST), node.__class__.__name__
    method_name = 'do_' + node.__class__.__name__
    method = getattr(self, method_name)
    s = method(node, *args, **keys)
    assert isinstance(s, str), type(s)
    return s
#@+node:ekr.20141012064706.18469: *4* f.indent
def indent(self, s):
    return f'%s%s' % (' ' * 4 * self.level, s)
#@+node:ekr.20141012064706.18404: *4* f: Contexts
#@+node:ekr.20141012064706.18405: *5* f.ClassDef
# 2: ClassDef(identifier name, expr* bases,
#             stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def do_ClassDef(self, node, print_body=True):

    result = []
    name = node.name  # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            bases.append(f'%s=%s' % (keyword.arg, self.visit(keyword.value)))
    if getattr(node, 'starargs', None):  # Python 3
        bases.append(f'*%s' % self.visit(node.starargs))
    if getattr(node, 'kwargs', None):  # Python 3
        bases.append(f'*%s' % self.visit(node.kwargs))
    if bases:
        result.append(self.indent(f'class %s(%s):\n' % (name, ','.join(bases))))
    else:
        result.append(self.indent(f'class %s:\n' % name))
    if print_body:
        for z in node.body:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18406: *5* f.FunctionDef & AsyncFunctionDef
# 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def do_FunctionDef(self, node, async_flag=False, print_body=True):
    """Format a FunctionDef node."""
    result = []
    if node.decorator_list:
        for z in node.decorator_list:
            result.append(f'@%s\n' % self.visit(z))
    name = node.name  # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    asynch_prefix = 'asynch ' if async_flag else ''
    if getattr(node, 'returns', None):  # Python 3.
        returns = self.visit(node.returns)
        result.append(self.indent(f'%sdef %s(%s): -> %s\n' % (
            asynch_prefix, name, args, returns)))
    else:
        result.append(self.indent(f'%sdef %s(%s):\n' % (
            asynch_prefix, name, args)))
    if print_body:
        for z in node.body:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

def do_AsyncFunctionDef(self, node):
    return self.do_FunctionDef(node, async_flag=True)
#@+node:ekr.20141012064706.18407: *5* f.Interactive
def do_Interactive(self, node):
    for z in node.body:
        self.visit(z)
#@+node:ekr.20141012064706.18408: *5* f.Module
def do_Module(self, node):
    assert 'body' in node._fields
    result = ''.join([self.visit(z) for z in node.body])
    return result
#@+node:ekr.20141012064706.18409: *5* f.Lambda
def do_Lambda(self, node):
    return self.indent(f'lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))
#@+node:ekr.20141012064706.18410: *4* f: Expressions
#@+node:ekr.20141012064706.18411: *5* f.Expr
def do_Expr(self, node):
    """An outer expression: must be indented."""
    assert not self.in_expr
    self.in_expr = True
    value = self.visit(node.value)
    self.in_expr = False
    return self.indent(f'%s\n' % value)
#@+node:ekr.20141012064706.18412: *5* f.Expression
def do_Expression(self, node):
    """An inner expression: do not indent."""
    return f'%s\n' % self.visit(node.body)
#@+node:ekr.20141012064706.18413: *5* f.GeneratorExp
def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '<**None**>' for z in gens]  # Kludge: probable bug.
    return f'<gen %s for %s>' % (elt, ','.join(gens))
#@+node:ekr.20141012064706.18414: *5* f.ctx nodes
def do_AugLoad(self, node):
    return 'AugLoad'

def do_Del(self, node):
    return 'Del'

def do_Load(self, node):
    return 'Load'

def do_Param(self, node):
    return 'Param'

def do_Store(self, node):
    return 'Store'
#@+node:ekr.20141012064706.18415: *4* f: Operands
#@+node:ekr.20141012064706.18416: *5* f.arguments
# 2: arguments = (expr* args, identifier? vararg, identifier?
#                arg? kwarg, expr* defaults)
# 3: arguments = (arg*  args, arg? vararg,
#                arg* kwonlyargs, expr* kw_defaults,
#                arg? kwarg, expr* defaults)

def do_arguments(self, node):
    """Format the arguments node."""
    kind = node.__class__.__name__
    assert kind == 'arguments', kind
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    args2 = []
    n_plain = len(args) - len(defaults)
    for i in range(len(node.args)):
        if i < n_plain:
            args2.append(args[i])
        else:
            args2.append(f'%s=%s' % (args[i], defaults[i-n_plain]))
    # Add the vararg and kwarg expressions.
    vararg = getattr(node, 'vararg', None)
    if vararg: args2.append('*'+self.visit(vararg))
    kwarg = getattr(node, 'kwarg', None)
    if kwarg: args2.append(f'**'+self.visit(kwarg))
    return ','.join(args2)
#@+node:ekr.20141012064706.18417: *5* f.arg (Python3 only)
# 3: arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    if getattr(node, 'annotation', None):
        return self.visit(node.annotation)
    return node.arg
#@+node:ekr.20141012064706.18418: *5* f.Attribute
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    return f'%s.%s' % (
        self.visit(node.value),
        node.attr)  # Don't visit node.attr: it is always a string.
#@+node:ekr.20141012064706.18419: *5* f.Bytes
def do_Bytes(self, node):  # Python 3.x only.
    return str(node.s)
#@+node:ekr.20141012064706.18420: *5* f.Call & f.keyword
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):

    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append(f'*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append(f'**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z]  # Kludge: Defensive coding.
    s = f'%s(%s)' % (func, ','.join(args))
    return s if self.in_expr else self.indent(s+'\n')
        # 2017/12/15.
#@+node:ekr.20141012064706.18421: *6* f.keyword
# keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return f'%s=%s' % (node.arg, value)
#@+node:ekr.20141012064706.18422: *5* f.comprehension
def do_comprehension(self, node):
    result = []
    name = self.visit(node.target)  # A name.
    it = self.visit(node.iter)  # An attribute.
    result.append(f'%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(f' if %s' % (''.join(ifs)))
    return ''.join(result)
#@+node:ekr.20170721073056.1: *5* f.Constant (Python 3.6+)
def do_Constant(self, node):  # Python 3.6+ only.
    return str(node.s)  # A guess.
#@+node:ekr.20141012064706.18423: *5* f.Dict
def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{\n' if keys else '{')
        items = []
        for i in range(len(keys)):
            items.append(f'  %s:%s' % (keys[i], values[i]))
        result.append(',\n'.join(items))
        result.append('\n}' if keys else '}')
    else:
        print(
            f"Error: f.Dict: len(keys) != len(values)\n"
            f"keys: {repr(keys)}\nvals: {repr(values)}")
    return ''.join(result)
#@+node:ekr.20160523101618.1: *5* f.DictComp
# DictComp(expr key, expr value, comprehension* generators)

def do_DictComp(self, node):
    key = self.visit(node.key)
    value = self.visit(node.value)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '<**None**>' for z in gens]  # Kludge: probable bug.
    return f'%s:%s for %s' % (key, value, ''.join(gens))
#@+node:ekr.20141012064706.18424: *5* f.Ellipsis
def do_Ellipsis(self, node):
    return '...'
#@+node:ekr.20141012064706.18425: *5* f.ExtSlice
def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])
#@+node:ekr.20170721075130.1: *5* f.FormattedValue (Python 3.6+)
# FormattedValue(expr value, int? conversion, expr? format_spec)

def do_FormattedValue(self, node):  # Python 3.6+ only.
    return f'%s%s%s' % (
        self.visit(node.value),
        self.visit(node.conversion) if node.conversion else '',
        self.visit(node.format_spec) if node.format_spec else '')
#@+node:ekr.20141012064706.18426: *5* f.Index
def do_Index(self, node):
    return self.visit(node.value)
#@+node:ekr.20170721080559.1: *5* f.JoinedStr (Python 3.6)
# JoinedStr(expr* values)

def do_JoinedStr(self, node):

    if node.values:
        for value in node.values:
            self.visit(value)
#@+node:ekr.20141012064706.18427: *5* f.List
def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elts = [z for z in elts if z]  # Defensive.
    return f'[%s]' % ','.join(elts)
#@+node:ekr.20141012064706.18428: *5* f.ListComp
def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '<**None**>' for z in gens]  # Kludge: probable bug.
    return f'%s for %s' % (elt, ''.join(gens))
#@+node:ekr.20141012064706.18429: *5* f.Name & NameConstant
def do_Name(self, node):
    return node.id

def do_NameConstant(self, node):  # Python 3 only.
    s = repr(node.value)
    return s
#@+node:ekr.20141012064706.18430: *5* f.Num
def do_Num(self, node):
    return repr(node.n)
#@+node:ekr.20141012064706.18431: *5* f.Repr
# Python 2.x only

def do_Repr(self, node):
    return f'repr(%s)' % self.visit(node.value)
#@+node:ekr.20160523101929.1: *5* f.Set
# Set(expr* elts)

def do_Set(self, node):
    for z in node.elts:
        self.visit(z)
#@+node:ekr.20160523102226.1: *5* f.SetComp
# SetComp(expr elt, comprehension* generators)

def do_SetComp(self, node):

    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    return f'%s for %s' % (elt, ''.join(gens))
#@+node:ekr.20141012064706.18432: *5* f.Slice
def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
    if step:
        return f'%s:%s:%s' % (lower, upper, step)
    return f'%s:%s' % (lower, upper)
#@+node:ekr.20141012064706.18433: *5* f.Str
def do_Str(self, node):
    """This represents a string constant."""
    return repr(node.s)
#@+node:ekr.20141012064706.18434: *5* f.Subscript
# Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    value = self.visit(node.value)
    the_slice = self.visit(node.slice)
    return f'%s[%s]' % (value, the_slice)
#@+node:ekr.20141012064706.18435: *5* f.Tuple
def do_Tuple(self, node):
    elts = [self.visit(z) for z in node.elts]
    return f'(%s)' % ','.join(elts)
#@+node:ekr.20141012064706.18436: *4* f: Operators
#@+node:ekr.20141012064706.18437: *5* f.BinOp
def do_BinOp(self, node):
    return f'%s%s%s' % (
        self.visit(node.left),
        op_name(node.op),
        self.visit(node.right))
#@+node:ekr.20141012064706.18438: *5* f.BoolOp
def do_BoolOp(self, node):
    op_name_ = op_name(node.op)
    values = [self.visit(z).strip() for z in node.values]
    return op_name_.join(values)
#@+node:ekr.20141012064706.18439: *5* f.Compare
def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    # ops   = [self.visit(z) for z in node.ops]
    ops = [op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    assert len(ops) == len(comps), repr(node)
    for i in range(len(ops)):
        result.append(f'%s%s' % (ops[i], comps[i]))
    return ''.join(result)
#@+node:ekr.20141012064706.18440: *5* f.UnaryOp
def do_UnaryOp(self, node):
    return f'%s%s' % (
        op_name(node.op),
        self.visit(node.operand))
#@+node:ekr.20141012064706.18441: *5* f.ifExp (ternary operator)
def do_IfExp(self, node):
    return f'%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))
#@+node:ekr.20141012064706.18442: *4* f: Statements
#@+node:ekr.20170721074105.1: *5* f.AnnAssign
# AnnAssign(expr target, expr annotation, expr? value, int simple)

def do_AnnAssign(self, node):
    return self.indent(f'%s:%s=%s\n' % (
        self.visit(node.target),
        self.visit(node.annotation),
        self.visit(node.value),
    ))
#@+node:ekr.20141012064706.18443: *5* f.Assert
def do_Assert(self, node):
    test = self.visit(node.test)
    if getattr(node, 'msg', None):
        message = self.visit(node.msg)
        return self.indent(f'assert %s, %s' % (test, message))
    return self.indent(f'assert %s' % test)
#@+node:ekr.20141012064706.18444: *5* f.Assign
def do_Assign(self, node):
    return self.indent(f'%s=%s\n' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value)))
#@+node:ekr.20141012064706.18445: *5* f.AugAssign
def do_AugAssign(self, node):
    return self.indent(f'%s%s=%s\n' % (
        self.visit(node.target),
        op_name(node.op),  # Bug fix: 2013/03/08.
        self.visit(node.value)))
#@+node:ekr.20160523100504.1: *5* f.Await (Python 3)
# Await(expr value)

def do_Await(self, node):

    return self.indent(f'await %s\n' % (
        self.visit(node.value)))
#@+node:ekr.20141012064706.18446: *5* f.Break
def do_Break(self, node):
    return self.indent(f'break\n')
#@+node:ekr.20141012064706.18447: *5* f.Continue
def do_Continue(self, node):
    return self.indent(f'continue\n')
#@+node:ekr.20141012064706.18448: *5* f.Delete
def do_Delete(self, node):
    targets = [self.visit(z) for z in node.targets]
    return self.indent(f'del %s\n' % ','.join(targets))
#@+node:ekr.20141012064706.18449: *5* f.ExceptHandler
def do_ExceptHandler(self, node):
    
    result = []
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(f' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):
            result.append(f' as %s' % self.visit(node.name))
        else:
            result.append(f' as %s' % node.name)  # Python 3.x.
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18450: *5* f.Exec
# Python 2.x only

def do_Exec(self, node):
    body = self.visit(node.body)
    args = []  # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        return self.indent(f'exec %s in %s\n' % (
            body, ','.join(args)))
    return self.indent(f'exec {body}\n')
#@+node:ekr.20141012064706.18451: *5* f.For & AsnchFor (Python 3)
def do_For(self, node, async_flag=False):
    result = []
    result.append(self.indent(f'%sfor %s in %s:\n' % (
        'async ' if async_flag else '',
        self.visit(node.target),
        self.visit(node.iter))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

def do_AsyncFor(self, node):
    return self.do_For(node, async_flag=True)
#@+node:ekr.20141012064706.18452: *5* f.Global
def do_Global(self, node):
    return self.indent(f'global %s\n' % (
        ','.join(node.names)))
#@+node:ekr.20141012064706.18453: *5* f.If
def do_If(self, node):
    result = []
    result.append(self.indent(f'if %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent(f'else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18454: *5* f.Import & helper
def do_Import(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append(f'%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent(f'import %s\n' % (
        ','.join(names)))
#@+node:ekr.20141012064706.18455: *6* f.get_import_names
def get_import_names(self, node):
    """Return a list of the the full file names in the import statement."""
    result = []
    for ast2 in node.names:
        assert ast2.__class__.__name__ == 'alias', (repr(ast2))
        data = ast2.name, ast2.asname
        result.append(data)
    return result
#@+node:ekr.20141012064706.18456: *5* f.ImportFrom
def do_ImportFrom(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append(f'%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent(f'from %s import %s\n' % (
        node.module,
        ','.join(names)))
#@+node:ekr.20160317050557.2: *5* f.Nonlocal (Python 3)
# Nonlocal(identifier* names)

def do_Nonlocal(self, node):

    return self.indent(f'nonlocal %s\n' % ', '.join(node.names))
#@+node:ekr.20141012064706.18457: *5* f.Pass
def do_Pass(self, node):
    return self.indent('pass\n')
#@+node:ekr.20141012064706.18458: *5* f.Print
# Python 2.x only

def do_Print(self, node):
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None):
        vals.append(f'dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None):
        # vals.append('nl=%s' % self.visit(node.nl))
        vals.append(f'nl=%s' % node.nl)
    return self.indent(f'print(%s)\n' % (
        ','.join(vals)))
#@+node:ekr.20141012064706.18459: *5* f.Raise
# Raise(expr? type, expr? inst, expr? tback)    Python 2
# Raise(expr? exc, expr? cause)                 Python 3

def do_Raise(self, node):
    args = []
    for attr in ('exc', 'cause'):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    if args:
        return self.indent(f'raise %s\n' % (
            ','.join(args)))
    return self.indent('raise\n')
#@+node:ekr.20141012064706.18460: *5* f.Return
def do_Return(self, node):
    if node.value:
        return self.indent(f'return %s\n' % (
            self.visit(node.value)))
    return self.indent('return\n')
#@+node:ekr.20160317050557.3: *5* f.Starred (Python 3)
# Starred(expr value, expr_context ctx)

def do_Starred(self, node):

    return '*' + self.visit(node.value)
#@+node:ekr.20141012064706.18461: *5* f.Suite
# def do_Suite(self,node):
    # for z in node.body:
        # s = self.visit(z)
#@+node:ekr.20160317050557.4: *5* f.Try (Python 3)
# Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node):  # Python 3

    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    if node.finalbody:
        result.append(self.indent('finally:\n'))
        for z in node.finalbody:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18462: *5* f.TryExcept
def do_TryExcept(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18463: *5* f.TryFinally
def do_TryFinally(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append(self.indent('finally:\n'))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18464: *5* f.While
def do_While(self, node):
    result = []
    result.append(self.indent(f'while %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
#@+node:ekr.20141012064706.18465: *5* f.With & AsyncWith (Python 3)
# 2:  With(expr context_expr, expr? optional_vars,
#          stmt* body)
# 3:  With(withitem* items,
#          stmt* body)
# withitem = (expr context_expr, expr? optional_vars)

def do_With(self, node, async_flag=False):
    result = []
    result.append(self.indent(f'%swith ' % ('async ' if async_flag else '')))
    if getattr(node, 'context_expression', None):
        result.append(self.visit(node.context_expresssion))
    vars_list = []
    if getattr(node, 'optional_vars', None):
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError:  # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    if getattr(node, 'items', None):  # Python 3.
        for item in node.items:
            result.append(self.visit(item.context_expr))
            if getattr(item, 'optional_vars', None):
                try:
                    for z in item.optional_vars:
                        vars_list.append(self.visit(z))
                except TypeError:  # Not iterable.
                    vars_list.append(self.visit(item.optional_vars))
    result.append(','.join(vars_list))
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append('\n')
    return ''.join(result)

def do_AsyncWith(self, node):
    return self.do_With(node, async_flag=True)
#@+node:ekr.20141012064706.18466: *5* f.Yield
def do_Yield(self, node):
    if getattr(node, 'value', None):
        return self.indent(f'yield %s\n' % (
            self.visit(node.value)))
    return self.indent('yield\n')
#@+node:ekr.20160317050557.5: *5* f.YieldFrom (Python 3)
# YieldFrom(expr value)

def do_YieldFrom(self, node):

    return self.indent(f'yield from %s\n' % (
        self.visit(node.value)))
#@+node:ekr.20141012064706.18471: *3* class AstFullTraverser
class AstFullTraverser:
    """
    A fast traverser for AST trees: it visits every node (except node.ctx fields).

    Sets .context and .parent ivars before visiting each node.
    """

    def __init__(self):
        """Ctor for AstFullTraverser class."""
        self.context = None
        self.level = 0  # The context level only.
        self.parent = None

    @others
#@+node:ekr.20141012064706.18472: *4* ft.contexts
#@+node:ekr.20141012064706.18473: *5* ft.ClassDef
# 2: ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def do_ClassDef(self, node, visit_body=True):
    old_context = self.context
    self.context = node
    self.level += 1
    for z in node.decorator_list:
        self.visit(z)
    for z in node.bases:
        self.visit(z)
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            self.visit(keyword.value)
    if getattr(node, 'starargs', None):  # Python 3
        self.visit(node.starargs)
    if getattr(node, 'kwargs', None):  # Python 3
        self.visit(node.kwargs)
    if visit_body:
        for z in node.body:
            self.visit(z)
    self.level -= 1
    self.context = old_context
#@+node:ekr.20141012064706.18474: *5* ft.FunctionDef
# 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def do_FunctionDef(self, node, visit_body=True):

    old_context = self.context
    self.context = node
    self.level += 1
    # Visit the tree in token order.
    for z in node.decorator_list:
        self.visit(z)
    assert isinstance(node.name, str)
    self.visit(node.args)
    if getattr(node, 'returns', None):  # Python 3.
        self.visit(node.returns)
    if visit_body:
        for z in node.body:
            self.visit(z)
    self.level -= 1
    self.context = old_context

do_AsyncFunctionDef = do_FunctionDef
#@+node:ekr.20141012064706.18475: *5* ft.Interactive
def do_Interactive(self, node):
    assert False, 'Interactive context not supported'
#@+node:ekr.20141012064706.18476: *5* ft.Lambda
# Lambda(arguments args, expr body)

def do_Lambda(self, node):
    old_context = self.context
    self.context = node
    self.visit(node.args)
    self.visit(node.body)
    self.context = old_context
#@+node:ekr.20141012064706.18477: *5* ft.Module
def do_Module(self, node):
    self.context = node
    for z in node.body:
        self.visit(z)
    self.context = None
#@+node:ekr.20141012064706.18478: *4* ft.ctx nodes
# Not used in this class, but may be called by subclasses.

def do_AugLoad(self, node):
    pass

def do_Del(self, node):
    pass

def do_Load(self, node):
    pass

def do_Param(self, node):
    pass

def do_Store(self, node):
    pass
#@+node:ekr.20171214200319.1: *4* ft.format
def format(self, node, level, *args, **keys):
    """Format the node and possibly its descendants, depending on args."""
    s = AstFormatter().format(node, level, *args, **keys)
    return s.rstrip()
#@+node:ekr.20141012064706.18480: *4* ft.operators & operands
#@+node:ekr.20160521102250.1: *5* ft.op_name
def op_name(self, node, strict=True):
    """Return the print name of an operator node."""
    name = _op_names.get(node.__class__.__name__, f'<%s>' % node.__class__.__name__)
    if strict:
        assert name, node.__class__.__name__
    return name
#@+node:ekr.20141012064706.18482: *5* ft.arguments & arg
# 2: arguments = (
# expr* args,
#   identifier? vararg,
#   identifier? kwarg,
#   expr* defaults)
# 3: arguments = (
#   arg*  args,
#   arg? vararg,
#   arg* kwonlyargs,
#   expr* kw_defaults,
#   arg? kwarg,
#   expr* defaults)

def do_arguments(self, node):

    for z in node.args:
        self.visit(z)
    if getattr(node, 'vararg', None):
        # An identifier in Python 2.
        self.visit(node.vararg)
    if getattr(node, 'kwarg', None):
        # An identifier in Python 2.
        self.visit_list(node.kwarg)
    if getattr(node, 'kwonlyargs', None):  # Python 3.
        self.visit_list(node.kwonlyargs)
    if getattr(node, 'kw_defaults', None):  # Python 3.
        self.visit_list(node.kw_defaults)
    for z in node.defaults:
        self.visit(z)

# 3: arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    if getattr(node, 'annotation', None):
        self.visit(node.annotation)
#@+node:ekr.20141012064706.18483: *5* ft.Attribute
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    self.visit(node.value)
    # self.visit(node.ctx)
#@+node:ekr.20141012064706.18484: *5* ft.BinOp
# BinOp(expr left, operator op, expr right)

def do_BinOp(self, node):
    self.visit(node.left)
    # self.op_name(node.op)
    self.visit(node.right)
#@+node:ekr.20141012064706.18485: *5* ft.BoolOp
# BoolOp(boolop op, expr* values)

def do_BoolOp(self, node):
    for z in node.values:
        self.visit(z)
#@+node:ekr.20141012064706.18481: *5* ft.Bytes
def do_Bytes(self, node):
    pass  # Python 3.x only.
#@+node:ekr.20141012064706.18486: *5* ft.Call
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    # Call the nodes in token order.
    self.visit(node.func)
    for z in node.args:
        self.visit(z)
    for z in node.keywords:
        self.visit(z)
    if getattr(node, 'starargs', None):
        self.visit(node.starargs)
    if getattr(node, 'kwargs', None):
        self.visit(node.kwargs)
#@+node:ekr.20141012064706.18487: *5* ft.Compare
# Compare(expr left, cmpop* ops, expr* comparators)

def do_Compare(self, node):
    # Visit all nodes in token order.
    self.visit(node.left)
    assert len(node.ops) == len(node.comparators)
    for i in range(len(node.ops)):
        self.visit(node.ops[i])
        self.visit(node.comparators[i])
    # self.visit(node.left)
    # for z in node.comparators:
        # self.visit(z)
#@+node:ekr.20150526140323.1: *5* ft.Compare ops
# Eq | NotEq | Lt | LtE | Gt | GtE | Is | IsNot | In | NotIn

def do_Eq(self, node): pass

def do_Gt(self, node): pass

def do_GtE(self, node): pass

def do_In(self, node): pass

def do_Is(self, node): pass

def do_IsNot(self, node): pass

def do_Lt(self, node): pass

def do_LtE(self, node): pass

def do_NotEq(self, node): pass

def do_NotIn(self, node): pass
#@+node:ekr.20141012064706.18488: *5* ft.comprehension
# comprehension (expr target, expr iter, expr* ifs)

def do_comprehension(self, node):
    self.visit(node.target)  # A name.
    self.visit(node.iter)  # An attribute.
    for z in node.ifs:
        self.visit(z)
#@+node:ekr.20170721073315.1: *5* ft.Constant (Python 3.6+)
def do_Constant(self, node):  # Python 3.6+ only.
    pass
#@+node:ekr.20141012064706.18489: *5* ft.Dict
# Dict(expr* keys, expr* values)

def do_Dict(self, node):
    # Visit all nodes in token order.
    assert len(node.keys) == len(node.values)
    for i in range(len(node.keys)):
        self.visit(node.keys[i])
        self.visit(node.values[i])
#@+node:ekr.20160523094910.1: *5* ft.DictComp
# DictComp(expr key, expr value, comprehension* generators)

def do_DictComp(self, node):
    # EKR: visit generators first, then value.
    for z in node.generators:
        self.visit(z)
    self.visit(node.value)
    self.visit(node.key)
#@+node:ekr.20150522081707.1: *5* ft.Ellipsis
def do_Ellipsis(self, node):
    pass
#@+node:ekr.20141012064706.18490: *5* ft.Expr
# Expr(expr value)

def do_Expr(self, node):
    self.visit(node.value)
#@+node:ekr.20141012064706.18491: *5* ft.Expression
def do_Expression(self, node):
    """An inner expression"""
    self.visit(node.body)
#@+node:ekr.20141012064706.18492: *5* ft.ExtSlice
def do_ExtSlice(self, node):
    for z in node.dims:
        self.visit(z)
#@+node:ekr.20170721075714.1: *5* ft.FormattedValue (Python 3.6+)
# FormattedValue(expr value, int? conversion, expr? format_spec)

def do_FormattedValue(self, node):  # Python 3.6+ only.
    self.visit(node.value)
    if node.conversion:
        self.visit(node.conversion)
    if node.format_spec:
        self.visit(node.format_spec)
#@+node:ekr.20141012064706.18493: *5* ft.GeneratorExp
# GeneratorExp(expr elt, comprehension* generators)

def do_GeneratorExp(self, node):
    self.visit(node.elt)
    for z in node.generators:
        self.visit(z)
#@+node:ekr.20141012064706.18494: *5* ft.ifExp (ternary operator)
# IfExp(expr test, expr body, expr orelse)

def do_IfExp(self, node):
    self.visit(node.body)
    self.visit(node.test)
    self.visit(node.orelse)
#@+node:ekr.20141012064706.18495: *5* ft.Index
def do_Index(self, node):
    self.visit(node.value)
#@+node:ekr.20170721080935.1: *5* ft.JoinedStr (Python 3.6+)
# JoinedStr(expr* values)

def do_JoinedStr(self, node):
    for value in node.values or []:
        self.visit(value)
#@+node:ekr.20141012064706.18496: *5* ft.keyword
# keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    self.visit(node.value)
#@+node:ekr.20141012064706.18497: *5* ft.List & ListComp
# List(expr* elts, expr_context ctx)

def do_List(self, node):
    for z in node.elts:
        self.visit(z)
    # self.visit(node.ctx)
# ListComp(expr elt, comprehension* generators)

def do_ListComp(self, node):
    self.visit(node.elt)
    for z in node.generators:
        self.visit(z)
#@+node:ekr.20141012064706.18498: *5* ft.Name (revise)
# Name(identifier id, expr_context ctx)

def do_Name(self, node):
    # self.visit(node.ctx)
    pass

def do_NameConstant(self, node):  # Python 3 only.
    pass
    # s = repr(node.value)
    # return 'bool' if s in ('True', 'False') else s
#@+node:ekr.20150522081736.1: *5* ft.Num
def do_Num(self, node):
    pass  # Num(object n) # a number as a PyObject.
#@+node:ekr.20141012064706.18499: *5* ft.Repr
# Python 2.x only
# Repr(expr value)

def do_Repr(self, node):
    self.visit(node.value)
#@+node:ekr.20160523094939.1: *5* ft.Set
# Set(expr* elts)

def do_Set(self, node):
    for z in node.elts:
        self.visit(z)

#@+node:ekr.20160523095142.1: *5* ft.SetComp
# SetComp(expr elt, comprehension* generators)

def do_SetComp(self, node):
    # EKR: visit generators first.
    for z in node.generators:
        self.visit(z)
    self.visit(node.elt)
#@+node:ekr.20141012064706.18500: *5* ft.Slice
def do_Slice(self, node):
    if getattr(node, 'lower', None):
        self.visit(node.lower)
    if getattr(node, 'upper', None):
        self.visit(node.upper)
    if getattr(node, 'step', None):
        self.visit(node.step)
#@+node:ekr.20150522081748.1: *5* ft.Str
def do_Str(self, node):
    pass  # represents a string constant.
#@+node:ekr.20141012064706.18501: *5* ft.Subscript
# Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    self.visit(node.value)
    self.visit(node.slice)
    # self.visit(node.ctx)
#@+node:ekr.20141012064706.18502: *5* ft.Tuple
# Tuple(expr* elts, expr_context ctx)

def do_Tuple(self, node):
    for z in node.elts:
        self.visit(z)
    # self.visit(node.ctx)
#@+node:ekr.20141012064706.18503: *5* ft.UnaryOp
# UnaryOp(unaryop op, expr operand)

def do_UnaryOp(self, node):
    # self.op_name(node.op)
    self.visit(node.operand)
#@+node:ekr.20141012064706.18504: *4* ft.statements
#@+node:ekr.20141012064706.18505: *5* ft.alias
# identifier name, identifier? asname)

def do_alias(self, node):
    # self.visit(node.name)
    # if getattr(node,'asname')
        # self.visit(node.asname)
    pass
#@+node:ekr.20170721074528.1: *5* ft.AnnAssign
# AnnAssign(expr target, expr annotation, expr? value, int simple)

def do_AnnAssign(self, node):
    self.visit(node.target)
    self.visit(node.annotation)
    self.visit(node.value)
#@+node:ekr.20141012064706.18506: *5* ft.Assert
# Assert(expr test, expr? msg)

def do_Assert(self, node):
    self.visit(node.test)
    if node.msg:
        self.visit(node.msg)
#@+node:ekr.20141012064706.18507: *5* ft.Assign
# Assign(expr* targets, expr value)

def do_Assign(self, node):
    for z in node.targets:
        self.visit(z)
    self.visit(node.value)
#@+node:ekr.20141012064706.18508: *5* ft.AugAssign
# AugAssign(expr target, operator op, expr value)

def do_AugAssign(self, node):

    self.visit(node.target)
    self.visit(node.value)
#@+node:ekr.20141012064706.18509: *5* ft.Break
def do_Break(self, tree):
    pass
#@+node:ekr.20141012064706.18510: *5* ft.Continue
def do_Continue(self, tree):
    pass
#@+node:ekr.20141012064706.18511: *5* ft.Delete
# Delete(expr* targets)

def do_Delete(self, node):
    for z in node.targets:
        self.visit(z)
#@+node:ekr.20141012064706.18512: *5* ft.ExceptHandler
# Python 2: ExceptHandler(expr? type, expr? name, stmt* body)
# Python 3: ExceptHandler(expr? type, identifier? name, stmt* body)

def do_ExceptHandler(self, node):

    if node.type:
        self.visit(node.type)
    if node.name and isinstance(node.name, ast.Name):
        self.visit(node.name)
    for z in node.body:
        self.visit(z)
#@+node:ekr.20141012064706.18513: *5* ft.Exec
# Python 2.x only
# Exec(expr body, expr? globals, expr? locals)

def do_Exec(self, node):
    self.visit(node.body)
    if getattr(node, 'globals', None):
        self.visit(node.globals)
    if getattr(node, 'locals', None):
        self.visit(node.locals)
#@+node:ekr.20141012064706.18514: *5* ft.For & AsyncFor
# For(expr target, expr iter, stmt* body, stmt* orelse)

def do_For(self, node):
    self.visit(node.target)
    self.visit(node.iter)
    for z in node.body:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)

do_AsyncFor = do_For
#@+node:ekr.20141012064706.18515: *5* ft.Global
# Global(identifier* names)

def do_Global(self, node):
    pass
#@+node:ekr.20141012064706.18516: *5* ft.If
# If(expr test, stmt* body, stmt* orelse)

def do_If(self, node):
    self.visit(node.test)
    for z in node.body:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
#@+node:ekr.20141012064706.18517: *5* ft.Import & ImportFrom
# Import(alias* names)

def do_Import(self, node):
    pass
# ImportFrom(identifier? module, alias* names, int? level)

def do_ImportFrom(self, node):
    # for z in node.names:
        # self.visit(z)
    pass
#@+node:ekr.20160317051434.2: *5* ft.Nonlocal (Python 3)
# Nonlocal(identifier* names)

def do_Nonlocal(self, node):

    pass
#@+node:ekr.20141012064706.18518: *5* ft.Pass
def do_Pass(self, node):
    pass
#@+node:ekr.20141012064706.18519: *5* ft.Print
# Python 2.x only
# Print(expr? dest, expr* values, bool nl)

def do_Print(self, node):
    if getattr(node, 'dest', None):
        self.visit(node.dest)
    for expr in node.values:
        self.visit(expr)
#@+node:ekr.20141012064706.18520: *5* ft.Raise
# Raise(expr? type, expr? inst, expr? tback)    Python 2
# Raise(expr? exc, expr? cause)                 Python 3

def do_Raise(self, node):

    for attr in ('exc', 'cause'):
        if getattr(node, attr, None):
            self.visit(getattr(node, attr))
#@+node:ekr.20141012064706.18521: *5* ft.Return
# Return(expr? value)

def do_Return(self, node):
    if node.value:
        self.visit(node.value)
#@+node:ekr.20160317051434.3: *5* ft.Starred (Python 3)
# Starred(expr value, expr_context ctx)

def do_Starred(self, node):

    self.visit(node.value)
#@+node:ekr.20141012064706.18522: *5* ft.Try (Python 3)
# Python 3 only: Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node):
    for z in node.body:
        self.visit(z)
    for z in node.handlers:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
    for z in node.finalbody:
        self.visit(z)
#@+node:ekr.20141012064706.18523: *5* ft.TryExcept
# TryExcept(stmt* body, excepthandler* handlers, stmt* orelse)

def do_TryExcept(self, node):
    for z in node.body:
        self.visit(z)
    for z in node.handlers:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
#@+node:ekr.20141012064706.18524: *5* ft.TryFinally
# TryFinally(stmt* body, stmt* finalbody)

def do_TryFinally(self, node):
    for z in node.body:
        self.visit(z)
    for z in node.finalbody:
        self.visit(z)
#@+node:ekr.20141012064706.18525: *5* ft.While
# While(expr test, stmt* body, stmt* orelse)

def do_While(self, node):
    self.visit(node.test)  # Bug fix: 2013/03/23.
    for z in node.body:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
#@+node:ekr.20141012064706.18526: *5* ft.With & AsyncWith
# 2:  With(expr context_expr, expr? optional_vars,
#          stmt* body)
# 3:  With(withitem* items,
#          stmt* body)
# withitem = (expr context_expr, expr? optional_vars)

def do_With(self, node):
    if getattr(node, 'context_expr', None):
        self.visit(node.context_expr)
    if getattr(node, 'optional_vars', None):
        self.visit(node.optional_vars)
    if getattr(node, 'items', None):  # Python 3.
        for item in node.items:
            self.visit(item.context_expr)
            if getattr(item, 'optional_vars', None):
                try:
                    for z in item.optional_vars:
                        self.visit(z)
                except TypeError:  # Not iterable.
                    self.visit(item.optional_vars)
    for z in node.body:
        self.visit(z)

do_AsyncWith = do_With
#@+node:ekr.20141012064706.18527: *5* ft.Yield, YieldFrom & Await (Python 3)
# Yield(expr? value)
# Await(expr value)         Python 3 only.
# YieldFrom (expr value)    Python 3 only.

def do_Yield(self, node):
    if node.value:
        self.visit(node.value)

do_Await = do_YieldFrom = do_Yield
#@+node:ekr.20141012064706.18528: *4* ft.visit (supports before_* & after_*)
def visit(self, node):
    """Visit a *single* ast node.  Visitors are responsible for visiting children!"""
    name = node.__class__.__name__
    assert isinstance(node, ast.AST), repr(node)
    # Visit the children with the new parent.
    old_parent = self.parent
    self.parent = node
    before_method = getattr(self, 'before_'+name, None)
    if before_method:
        before_method(node)
    do_method = getattr(self, 'do_'+name, None)
    if do_method:
        val = do_method(node)
    after_method = getattr(self, 'after_'+name, None)
    if after_method:
        after_method(node)
    self.parent = old_parent
    return val

def visit_children(self, node):
    assert False, 'must visit children explicitly'
#@+node:ekr.20141012064706.18529: *4* ft.visit_list
def visit_list(self, aList):
    """Visit all ast nodes in aList or ast.node."""
    if isinstance(aList, (list, tuple)):
        for z in aList:
            self.visit(z)
        return None
    assert isinstance(aList, ast.AST), repr(aList)
    return self.visit(aList)
#@+node:ekr.20141012064706.18530: *3* class AstPatternFormatter (AstFormatter)
class AstPatternFormatter(AstFormatter):
    """
    A subclass of AstFormatter that replaces values of constants by Bool,
    Bytes, Int, Name, Num or Str.
    """
    # No ctor.
    @others
#@+node:ekr.20141012064706.18531: *4* Constants & Name
# Return generic markers allow better pattern matches.

def do_BoolOp(self, node):  # Python 2.x only.
    return 'Bool'

def do_Bytes(self, node):  # Python 3.x only.
    return 'Bytes'  # return str(node.s)

def do_Constant(self, node):  # Python 3.6+ only.
    return 'Constant'

def do_Name(self, node):
    return 'Bool' if node.id in ('True', 'False') else node.id

def do_NameConstant(self, node):  # Python 3 only.
    s = repr(node.value)
    return 'Bool' if s in ('True', 'False') else s

def do_Num(self, node):
    return 'Num'  # return repr(node.n)

def do_Str(self, node):
    """This represents a string constant."""
    return 'Str'  # return repr(node.s)
#@+node:ekr.20150722204300.1: *3* class HTMLReportTraverser
class HTMLReportTraverser:
    """
    Create html reports from an AST tree.

    Inspired by Paul Boddie.

    This version writes all html to a global code list.

    At present, this code does not show comments.
    The TokenSync class is probably the best way to do this.
    """
    # To do: revise report-traverser-debug.css.
    @others
#@+node:ekr.20150722204300.2: *4* rt.__init__
def __init__(self, debug=False):
    """Ctor for the NewHTMLReportTraverser class."""
    self.code_list = []
    self.debug = debug
    self.div_stack = []
        # A check to ensure matching div/end_div.
    self.last_doc = None
    # List of divs & spans to generate...
    self.enable_list = [
        'body', 'class', 'doc', 'function',
        'keyword', 'name', 'statement'
    ]
    # Formatting stuff...
    debug_css = 'report-traverser-debug.css'
    plain_css = 'report-traverser.css'
    self.css_fn = debug_css if debug else plain_css
    self.html_footer = '\n</body>\n</html>\n'
    self.html_header = self.define_html_header()
#@+node:ekr.20150722204300.3: *5* define_html_header
def define_html_header(self):
    # Use string catenation to avoid using g.adjustTripleString.
    return (
        '<?xml version="1.0" encoding="iso-8859-15"?>\n'
        '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"\n'
        '"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\n'
        '<html xmlns="http://www.w3.org/1999/xhtml">\n'
        '<head>\n'
        '  <title>%(title)s</title>\n'
        '  <link rel="stylesheet" type="text/css" href="%(css-fn)s" />\n'
        '</head>\n<body>'
    )
#@+node:ekr.20150723094359.1: *4* rt.code generators
#@+node:ekr.20150723100236.1: *5* rt.blank
def blank(self):
    """Insert a single blank."""
    self.clean(' ')
    if self.code_list[-1] not in ' \n':
        self.gen(' ')
#@+node:ekr.20150723100208.1: *5* rt.clean
def clean(self, s):
    """Remove s from the code list."""
    s2 = self.code_list[-1]
    if s2 == s:
        self.code_list.pop()
#@+node:ekr.20150723105702.1: *5* rt.colon
def colon(self):

    self.clean('\n')
    self.clean(' ')
    self.clean('\n')
    self.gen(':')
#@+node:ekr.20150723100346.1: *5* rt.comma & clean_comma
def comma(self):

    self.clean(' ')
    self.gen(', ')

def clean_comma(self):

    self.clean(', ')
#@+node:ekr.20150722204300.21: *5* rt.doc
# Called by ClassDef & FunctionDef visitors.

def doc(self, node):
    doc = ast.get_docstring(node)
    if doc:
        self.docstring(doc)
        self.last_doc = doc  # Attempt to suppress duplicate.
#@+node:ekr.20150722204300.22: *5* rt.docstring
def docstring(self, s):

    import textwrap
    self.gen("<pre class='doc'>")
    self.gen('"""')
    self.gen(self.text(textwrap.dedent(s.replace('"""', '\\"\\"\\"'))))
    self.gen('"""')
    self.gen("</pre>")
#@+node:ekr.20150722211115.1: *5* rt.gen
def gen(self, s):
    """Append s to the global code list."""
    if s:
        self.code_list.append(s)
#@+node:ekr.20150722204300.23: *5* rt.keyword (code generator)
def keyword(self, name):

    self.blank()
    self.span('keyword')
    self.gen(name)
    self.end_span('keyword')
    self.blank()
#@+node:ekr.20150722204300.24: *5* rt.name
def name(self, name):

    # Div would put each name on a separate line.
    # span messes up whitespace, for now.
    # self.span('name')
    self.gen(name)
    # self.end_span('name')
#@+node:ekr.20150723100417.1: *5* rt.newline
def newline(self):

    self.clean(' ')
    self.clean('\n')
    self.clean(' ')
    self.gen('\n')
#@+node:ekr.20150722204300.26: *5* rt.op
def op(self, op_name, leading=False, trailing=True):

    if leading:
        self.blank()
    # self.span('operation')
    # self.span('operator')
    self.gen(self.text(op_name))
    # self.end_span('operator')
    if trailing:
        self.blank()
    # self.end_span('operation')
#@+node:ekr.20160315184954.1: *5* rt.string (code generator)
def string(self, s):

    import xml.sax.saxutils as saxutils
    s = repr(s.strip().strip())
    s = saxutils.escape(s)
    self.gen(s)
#@+node:ekr.20150722204300.27: *5* rt.simple_statement
def simple_statement(self, name):

    class_name = f'%s nowrap' % name
    self.div(class_name)
    self.keyword(name)
    self.end_div(class_name)
#@+node:ekr.20150722204300.16: *4* rt.html helpers
#@+node:ekr.20150722204300.17: *5* rt.attr & text
def attr(self, s):
    return self.text(s).replace("'", "&apos;").replace('"', "&quot;")

def text(self, s):
    return s.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
#@+node:ekr.20150722204300.18: *5* rt.br
def br(self):
    return '\n<br />'
#@+node:ekr.20150722204300.19: *5* rt.comment
def comment(self, comment):

    self.span('comment')
    self.gen('# '+comment)
    self.end_span('comment')
    self.newline()
#@+node:ekr.20150722204300.20: *5* rt.div
def div(self, class_name, extra=None, wrap=False):
    """Generate the start of a div element."""
    if class_name in self.enable_list:
        if class_name:
            full_class_name = class_name if wrap else class_name + ' nowrap'
        self.newline()
        if class_name and extra:
            self.gen(f"<div class='%s' %s>" % (full_class_name, extra))
        elif class_name:
            self.newline()
            self.gen(f"<div class='%s'>" % (full_class_name))
        else:
            assert not extra
            self.gen("<div>")
    self.div_stack.append(class_name)
#@+node:ekr.20150722222149.1: *5* rt.div_body
def div_body(self, aList):
    if aList:
        self.div_list('body', aList)
#@+node:ekr.20150722221101.1: *5* rt.div_list & div_node
def div_list(self, class_name, aList, sep=None):

    self.div(class_name)
    self.visit_list(aList, sep=sep)
    self.end_div(class_name)

def div_node(self, class_name, node):

    self.div(class_name)
    self.visit(node)
    self.end_div(class_name)
#@+node:ekr.20150723095033.1: *5* rt.end_div
def end_div(self, class_name):

    if class_name in self.enable_list:
        # self.newline()
        self.gen('</div>')
        # self.newline()
    class_name2 = self.div_stack.pop()
    assert class_name2 == class_name, (class_name2, class_name)
#@+node:ekr.20150723095004.1: *5* rt.end_span
def end_span(self, class_name):

    if class_name in self.enable_list:
        self.gen('</span>')
        self.newline()
    class_name2 = self.div_stack.pop()
    assert class_name2 == class_name, (class_name2, class_name)
#@+node:ekr.20150722221408.1: *5* rt.keyword_colon
# def keyword_colon(self, keyword):

    # self.keyword(keyword)
    # self.colon()
#@+node:ekr.20150722204300.5: *5* rt.link
def link(self, class_name, href, a_text):

    return f"<a class='%s' href='%s'>%s</a>" % (
        class_name, href, a_text)
#@+node:ekr.20150722204300.6: *5* rt.module_link
def module_link(self, module_name, classes=None):

    return self.link(
        class_name=classes or 'name',
        href=f'%s.xhtml' % module_name,
        a_text=self.text(module_name))
#@+node:ekr.20150722204300.7: *5* rt.name_link
def name_link(self, module_name, full_name, name, classes=None):

    return self.link(
        class_name=classes or "specific-ref",
        href=f'%s.xhtml#%s' % (module_name, self.attr(full_name)),
        a_text=self.text(name))
#@+node:ekr.20150722204300.8: *5* rt.object_name_ref
def object_name_ref(self, module, obj, name=None, classes=None):
    """
    Link to the definition for 'module' using 'obj' with the optional 'name'
    used as the label (instead of the name of 'obj'). The optional 'classes'
    can be used to customise the CSS classes employed.
    """
    return self.name_link(
        module.full_name(),
        obj.full_name(),
        name or obj.name, classes)
#@+node:ekr.20150722204300.9: *5* rt.popup
def popup(self, classes, aList):

    self.span_list(classes or 'popup', aList)
#@+node:ekr.20150722204300.28: *5* rt.span
def span(self, class_name, wrap=False):

    if class_name in self.enable_list:
        self.newline()
        if class_name:
            full_class_name = class_name if wrap else class_name + ' nowrap'
            self.gen(f"<span class='%s'>" % (full_class_name))
        else:
            self.gen('<span>')
        # self.newline()
    self.div_stack.append(class_name)
#@+node:ekr.20150722224734.1: *5* rt.span_list & span_node
def span_list(self, class_name, aList, sep=None):

    self.span(class_name)
    self.visit_list(aList, sep=sep)
    self.end_span(class_name)

def span_node(self, class_name, node):

    self.span(class_name)
    self.visit(node)
    self.end_span(class_name)
#@+node:ekr.20150722204300.10: *5* rt.summary_link
def summary_link(self, module_name, full_name, name, classes=None):

    return self.name_link(
        f"{module_name}-summary", full_name, name, classes)
#@+node:ekr.20160315161259.1: *4* rt.main
def main(self, fn, node):
    """Return a report for the given ast node as a string."""
    self.gen(self.html_header % {
            'css-fn': self.css_fn,
            'title': f"Module: {fn}"
        })
    self.parent = None
    self.parents = [None]
    self.visit(node)
    self.gen(self.html_footer)
    return ''.join(self.code_list)
#@+node:ekr.20150722204300.44: *4* rt.visit
def visit(self, node):
    """Walk a tree of AST nodes."""
    assert isinstance(node, ast.AST), node.__class__.__name__
    method_name = 'do_' + node.__class__.__name__
    method = getattr(self, method_name)
    method(node)
#@+node:ekr.20150722204300.45: *4* rt.visit_list
def visit_list(self, aList, sep=None):
    # pylint: disable=arguments-differ
    if aList:
        for z in aList:
            self.visit(z)
            self.gen(sep)
        self.clean(sep)
#@+node:ekr.20150722204300.46: *4* rt.visitors
#@+node:ekr.20170721074613.1: *5* rt.AnnAssign
# AnnAssign(expr target, expr annotation, expr? value, int simple)

def do_AnnAssign(self, node):

    self.div('statement')
    self.visit(node.target)
    self.op('=:', leading=True, trailing=True)
    self.visit(node.annotation)
    self.blank()
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20150722204300.49: *5* rt.Assert
# Assert(expr test, expr? msg)

def do_Assert(self, node):

    self.div('statement')
    self.keyword("assert")
    self.visit(node.test)
    if node.msg:
        self.comma()
        self.visit(node.msg)
    self.end_div('statement')
#@+node:ekr.20150722204300.50: *5* rt.Assign
def do_Assign(self, node):

    self.div('statement')
    for z in node.targets:
        self.visit(z)
        self.op('=', leading=True, trailing=True)
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20150722204300.51: *5* rt.Attribute
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):

    self.visit(node.value)
    self.gen('.')
    self.gen(node.attr)
#@+node:ekr.20160523102939.1: *5* rt.Await (Python 3)
# Await(expr value)

def do_Await(self, node):

    self.div('statement')
    self.keyword('await')
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20150722204300.52: *5* rt.AugAssign
#  AugAssign(expr target, operator op, expr value)

def do_AugAssign(self, node):

    op_name_ = op_name(node.op)
    self.div('statement')
    self.visit(node.target)
    self.op(op_name_, leading=True)
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20150722204300.53: *5* rt.BinOp
def do_BinOp(self, node):

    op_name_ = op_name(node.op)
    # self.span(op_name_)
    self.visit(node.left)
    self.op(op_name_, leading=True)
    self.visit(node.right)
    # self.end_span(op_name_)
#@+node:ekr.20150722204300.54: *5* rt.BoolOp
def do_BoolOp(self, node):

    op_name_ = op_name(node.op).strip()
    self.span(op_name_)
    for i, node2 in enumerate(node.values):
        if i > 0:
            self.keyword(op_name_)
        self.visit(node2)
    self.end_span(op_name_)
#@+node:ekr.20150722204300.55: *5* rt.Break
def do_Break(self, node):

    self.simple_statement('break')
#@+node:ekr.20160523103529.1: *5* rt.Bytes (Python 3)
def do_Bytes(self, node):  # Python 3.x only.
    return str(node.s)
#@+node:ekr.20150722204300.56: *5* rt.Call & do_keyword
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):

    # self.span("callfunc")
    self.visit(node.func)
    # self.span("call")
    self.gen('(')
    self.visit_list(node.args, sep=',')
    if node.keywords:
        self.visit_list(node.keywords, sep=',')
    if getattr(node, 'starargs', None):
        self.op('*', trailing=False)
        self.visit(node.starargs)
        self.comma()
    if getattr(node, 'kwargs', None):
        self.op('**', trailing=False)
        self.visit(node.kwargs)
        self.comma()
    self.clean_comma()
    self.gen(')')
    # self.end_span('call')
    # self.end_span('callfunc')
#@+node:ekr.20150722204300.57: *6* rt.do_keyword
# keyword = (identifier arg, expr value)
# keyword arguments supplied to call

def do_keyword(self, node):

    self.span('keyword-arg')
    self.gen(node.arg)
    self.blank()
    self.gen('=')
    self.blank()
    self.visit(node.value)
    self.end_span('keyword-arg')
#@+node:ekr.20150722204300.58: *5* rt.ClassDef
# 2: ClassDef(identifier name, expr* bases,
#             stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def do_ClassDef(self, node):

    has_bases = (node.bases or hasattr(node, 'keywords') or
        hasattr(node, 'starargs') or hasattr(node, 'kwargs'))
    self.div('class')
    self.keyword("class")
    self.gen(node.name)  # Always a string.
    if has_bases:
        self.gen('(')
        self.visit_list(node.bases, sep=', ')
        if getattr(node, 'keywords', None):  # Python 3
            for keyword in node.keywords:
                self.gen(f'%s=%s' % (keyword.arg, self.visit(keyword.value)))
        if getattr(node, 'starargs', None):  # Python 3
            self.gen(f'*%s' % self.visit(node.starargs))
        if getattr(node, 'kwargs', None):  # Python 3
            self.gen(f'*%s' % self.visit(node.kwargs))
        self.gen(')')
    self.colon()
    self.div('body')
    self.doc(node)
    self.visit_list(node.body)
    self.end_div('body')
    self.end_div('class')
#@+node:ekr.20150722204300.59: *5* rt.Compare
def do_Compare(self, node):

    assert len(node.ops) == len(node.comparators)
    # self.span('compare')
    self.visit(node.left)
    for i in range(len(node.ops)):
        op_name_ = op_name(node.ops[i])
        self.op(op_name_, leading=True)
        self.visit(node.comparators[i])
    # self.end_span('compare')
#@+node:ekr.20150722204300.60: *5* rt.comprehension
# comprehension = (expr target, expr iter, expr* ifs)

def do_comprehension(self, node):

    self.visit(node.target)
    self.keyword('in')
    # self.span('collection')
    self.visit(node.iter)
    if node.ifs:
        self.keyword('if')
        # self.span_list("conditional", node.ifs, sep=' ')
        for z in node.ifs:
            self.visit(z)
            self.blank()
        self.clean(' ')
    # self.end_span('collection')
#@+node:ekr.20170721073431.1: *5* rt.Constant (Python 3.6+)
def do_Constant(self, node):  # Python 3.6+ only.
    return str(node.s)  # A guess.
#@+node:ekr.20150722204300.61: *5* rt.Continue
def do_Continue(self, node):

    self.simple_statement('continue')
#@+node:ekr.20150722204300.62: *5* rt.Delete
def do_Delete(self, node):

    self.div('statement')
    self.keyword('del')
    if node.targets:
        self.visit_list(node.targets, sep=',')
    self.end_div('statement')
#@+node:ekr.20150722204300.63: *5* rt.Dict
def do_Dict(self, node):

    assert len(node.keys) == len(node.values)
    # self.span('dict')
    self.gen('{')
    for i in range(len(node.keys)):
        self.visit(node.keys[i])
        self.colon()
        self.visit(node.values[i])
        self.comma()
    self.clean_comma()
    self.gen('}')
    # self.end_span('dict')
#@+node:ekr.20160523104330.1: *5* rt.DictComp
# DictComp(expr key, expr value, comprehension* generators)

def do_DictComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '<**None**>' for z in gens]  # Kludge: probable bug.
    return f'%s for %s' % (elt, ''.join(gens))
#@+node:ekr.20150722204300.47: *5* rt.do_arguments & helpers
# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def do_arguments(self, node):

    assert isinstance(node, ast.arguments), node
    first_default = len(node.args) - len(node.defaults)
    for n, arg in enumerate(node.args):
        if isinstance(arg, (list, tuple)):
            self.tuple_parameter(arg)
        else:
            self.visit(arg)
        if n >= first_default:
            default = node.defaults[n - first_default]
            self.gen("=")
            self.visit(default)
        self.comma()
    if getattr(node, 'vararg', None):
        self.gen('*')
        self.gen(self.name(node.vararg))
        self.comma()
    if getattr(node, 'kwarg', None):
        self.gen('**')
        self.gen(self.name(node.kwarg))
        self.comma()
    self.clean_comma()
#@+node:ekr.20160315182225.1: *6* rt.arg (Python 3 only)
# 3: arg = (identifier arg, expr? annotation)

def do_arg(self, node):

    self.gen(node.arg)
    if getattr(node, 'annotation', None):
        self.colon()
        self.visit(node.annotation)
#@+node:ekr.20150722204300.48: *6* rt.tuple_parameter
def tuple_parameter(self, node):

    assert isinstance(node, (list, tuple)), node
    self.gen("(")
    for param in node:
        if isinstance(param, tuple):
            self.tuple_parameter(param)
        else:
            self.visit(param)
    self.gen(")")
#@+node:ekr.20150722204300.64: *5* rt.Ellipsis
def do_Ellipsis(self, node):

    self.gen('...')
#@+node:ekr.20150722204300.65: *5* rt.ExceptHandler
def do_ExceptHandler(self, node):

    self.div('excepthandler')
    self.keyword("except")
    if not node.type:
        self.clean(' ')
    if node.type:
        self.visit(node.type)
    if node.name:
        self.keyword('as')
        self.visit(node.name)
    self.colon()
    self.div_body(node.body)
    self.end_div('excepthandler')
#@+node:ekr.20150722204300.66: *5* rt.Exec
# Python 2.x only.

def do_Exec(self, node):

    self.div('statement')
    self.keyword('exec')
    self.visit(node.body)
    if node.globals:
        self.comma()
        self.visit(node.globals)
    if node.locals:
        self.comma()
        self.visit(node.locals)
    self.end_div('statement')
#@+node:ekr.20150722204300.67: *5* rt.Expr
def do_Expr(self, node):

    self.div_node('expr', node.value)
#@+node:ekr.20160523103429.1: *5* rf.Expression
def do_Expression(self, node):
    """An inner expression: do not indent."""
    return f'%s' % self.visit(node.body)
#@+node:ekr.20160523103751.1: *5* rt.ExtSlice
def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])
#@+node:ekr.20150722204300.68: *5* rt.For & AsyncFor (Python 3)
# For(expr target, expr iter, stmt* body, stmt* orelse)

def do_For(self, node, async_flag=False):

    self.div('statement')
    if async_flag:
        self.keyword('async')
    self.keyword("for")
    self.visit(node.target)
    self.keyword("in")
    self.visit(node.iter)
    self.colon()
    self.div_body(node.body)
    if node.orelse:
        self.keyword('else')
        self.colon()
        self.div_body(node.orelse)
    self.end_div('statement')

def do_AsyncFor(self, node):
    self.do_For(node, async_flag=True)
#@+node:ekr.20170721075845.1: *5* rf.FormattedValue (Python 3.6+: unfinished)
# FormattedValue(expr value, int? conversion, expr? format_spec)

def do_FormattedValue(self, node):  # Python 3.6+ only.
    self.div('statement')
    self.visit(node.value)
    if node.conversion:
        self.visit(node.conversion)
    if node.format_spec:
        self.visit(node.format_spec)
    self.end_div('statement')
#@+node:ekr.20150722204300.69: *5* rt.FunctionDef
# 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def do_FunctionDef(self, node, async_flag=False):

    self.div('function', extra=f'id="%s"' % node.name)
    if async_flag:
        self.keyword('async')
    self.keyword("def")
    self.name(node.name)
    self.gen('(')
    self.visit(node.args)
    self.gen(')')
    if getattr(node, 'returns', None):
        self.blank()
        self.gen('->')
        self.blank()
        self.visit(node.returns)
    self.colon()
    self.div('body')
    self.doc(node)
    self.visit_list(node.body)
    self.end_div('body')
    self.end_div('function')

def do_AsyncFunctionDef(self, node):
    self.do_FunctionDef(node, async_flag=True)
#@+node:ekr.20150722204300.70: *5* rt.GeneratorExp
def do_GeneratorExp(self, node):

    # self.span('genexpr')
    self.gen('(')
    if node.elt:
        self.visit(node.elt)
    self.keyword('for')
    # self.span_node('item', node.elt)
    self.visit(node.elt)
    # self.span_list('generators', node.generators)
    self.visit_list(node.generators)
    self.gen(')')
    # self.end_span('genexpr')
#@+node:ekr.20150722204300.71: *5* rt.get_import_names
def get_import_names(self, node):
    """Return a list of the the full file names in the import statement."""
    result = []
    for ast2 in node.names:
        assert isinstance(ast2, ast.alias), repr(ast2)
        data = ast2.name, ast2.asname
        result.append(data)
    return result
#@+node:ekr.20150722204300.72: *5* rt.Global
def do_Global(self, node):

    self.div('statement')
    self.keyword("global")
    for z in node.names:
        self.gen(z)
        self.comma()
    self.clean_comma()
    self.end_div('statement')
#@+node:ekr.20150722204300.73: *5* rt.If
# If(expr test, stmt* body, stmt* orelse)

def do_If(self, node, elif_flag=False):
    
    self.div('statement')
    self.keyword('elif' if elif_flag else 'if')
    self.visit(node.test)
    self.colon()
    self.div_body(node.body)
    if node.orelse:
        node1 = node.orelse[0]
        if isinstance(node1, ast.If) and len(node.orelse) == 1:
            self.do_If(node1, elif_flag=True)
        else:
            self.keyword('else')
            self.colon()
            self.div_body(node.orelse)
    self.end_div('statement')
#@+node:ekr.20150722204300.74: *5* rt.IfExp (TernaryOp)
# IfExp(expr test, expr body, expr orelse)

def do_IfExp(self, node):

    # self.span('ifexp')
    self.visit(node.body)
    self.keyword('if')
    self.visit(node.test)
    self.keyword('else')
    self.visit(node.orelse)
    # self.end_span('ifexp')
#@+node:ekr.20150722204300.75: *5* rt.Import
def do_Import(self, node):

    self.div('statement')
    self.keyword("import")
    for name, alias in self.get_import_names(node):
        self.name(name)  # self.gen(self.module_link(name))
        if alias:
            self.keyword("as")
            self.name(alias)
    self.end_div('statement')
#@+node:ekr.20150722204300.76: *5* rt.ImportFrom
def do_ImportFrom(self, node):

    self.div('statement')
    self.keyword("from")
    self.gen(self.module_link(node.module))
    self.keyword("import")
    for name, alias in self.get_import_names(node):
        self.name(name)
        if alias:
            self.keyword("as")
            self.name(alias)
        self.comma()
    self.clean_comma()
    self.end_div('statement')
#@+node:ekr.20160315190818.1: *5* rt.Index
def do_Index(self, node):

    self.visit(node.value)
#@+node:ekr.20170721080959.1: *5* rf.JoinedStr (Python 3.6+: unfinished)
# JoinedStr(expr* values)

def do_JoinedStr(self, node):
    for value in node.values or []:
        self.visit(value)
#@+node:ekr.20150722204300.77: *5* rt.Lambda
def do_Lambda(self, node):

    # self.span('lambda')
    self.keyword('lambda')
    self.visit(node.args)
    self.comma()
    self.span_node("code", node.body)
    # self.end_span('lambda')
#@+node:ekr.20150722204300.78: *5* rt.List
# List(expr* elts, expr_context ctx)

def do_List(self, node):

    # self.span('list')
    self.gen('[')
    if node.elts:
        for z in node.elts:
            self.visit(z)
            self.comma()
        self.clean_comma()
    self.gen(']')
    # self.end_span('list')
#@+node:ekr.20150722204300.79: *5* rt.ListComp
# ListComp(expr elt, comprehension* generators)

def do_ListComp(self, node):

    # self.span('listcomp')
    self.gen('[')
    if node.elt:
        self.visit(node.elt)
    self.keyword('for')
    # self.span('ifgenerators')
    self.visit_list(node.generators)
    self.gen(']')
    # self.end_span('ifgenerators')
    # self.end_span('listcomp')
#@+node:ekr.20150722204300.80: *5* rt.Module
def do_Module(self, node):

    self.doc(node)
    self.visit_list(node.body)
#@+node:ekr.20150722204300.81: *5* rt.Name
def do_Name(self, node):

    self.name(node.id)
#@+node:ekr.20160315165109.1: *5* rt.NameConstant
def do_NameConstant(self, node):  # Python 3 only.

    self.name(repr(node.value))
#@+node:ekr.20160317051849.2: *5* rt.Nonlocal (Python 3)
# Nonlocal(identifier* names)

def do_Nonlocal(self, node):

    self.div('statement')
    self.keyword('nonlocal')
    self.gen(', '.join(node.names))
    self.end_div('statement')
#@+node:ekr.20150722204300.82: *5* rt.Num
def do_Num(self, node):

    self.gen(self.text(repr(node.n)))
#@+node:ekr.20150722204300.83: *5* rt.Pass
def do_Pass(self, node):

    self.simple_statement('pass')
#@+node:ekr.20150722204300.84: *5* rt.Print
# Print(expr? dest, expr* values, bool nl)

def do_Print(self, node):

    self.div('statement')
    self.keyword("print")
    self.gen('(')
    if node.dest:
        self.op('>>\n')
        self.visit(node.dest)
        self.comma()
        self.newline()
        if node.values:
            for z in node.values:
                self.visit(z)
                self.comma()
                self.newline()
    self.clean('\n')
    self.clean_comma()
    self.gen(')')
    self.end_div('statement')
#@+node:ekr.20150722204300.85: *5* rt.Raise
# Raise(expr? type, expr? inst, expr? tback)    Python 2
# Raise(expr? exc, expr? cause)                 Python 3

def do_Raise(self, node):

    self.div('statement')
    self.keyword("raise")
    for attr in ('exc', 'cause'):
        if getattr(node, attr, None) is not None:
            self.visit(getattr(node, attr))
    self.end_div('statement')
#@+node:ekr.20160523105022.1: *5* rt.Repr
# Python 2.x only

def do_Repr(self, node):
    return f'repr(%s)' % self.visit(node.value)
#@+node:ekr.20150722204300.86: *5* rt.Return
def do_Return(self, node):

    self.div('statement')
    self.keyword("return")
    if node.value:
        self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20160523104433.1: *5* rt.Set
# Set(expr* elts)

def do_Set(self, node):
    for z in node.elts:
        self.visit(z)
#@+node:ekr.20160523104454.1: *5* rt.SetComp
# SetComp(expr elt, comprehension* generators)

def do_SetComp(self, node):

    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    return f'%s for %s' % (elt, ''.join(gens))
#@+node:ekr.20150722204300.87: *5* rt.Slice
def do_Slice(self, node):

    # self.span("slice")
    if node.lower:
        self.visit(node.lower)
    self.colon()
    if node.upper:
        self.visit(node.upper)
    if node.step:
        self.colon()
        self.visit(node.step)
    # self.end_span("slice")
#@+node:ekr.20160317051849.3: *5* rt.Starred (Python 3)
# Starred(expr value, expr_context ctx)

def do_Starred(self, node):

    self.gen('*')
    self.visit(node.value)
#@+node:ekr.20150722204300.88: *5* rt.Str
def do_Str(self, node):
    """This represents a string constant."""

    def clean(s):
        return s.replace(' ', '').replace('\n', '').replace('"', '').replace("'", '')

    assert isinstance(node.s, str)
    if self.last_doc and clean(self.last_doc) == clean(node.s):
        # Already seen.
        self.last_doc = None
    else:
        self.string(node.s)
#@+node:ekr.20150722204300.89: *5* rt.Subscript
def do_Subscript(self, node):

    # self.span("subscript")
    self.visit(node.value)
    self.gen('[')
    self.visit(node.slice)
    self.gen(']')
    # self.end_span("subscript")
#@+node:ekr.20160315190913.1: *5* rt.Try (Python 3)
# Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node):

    self.div('statement')
    self.keyword('try')
    self.colon()
    self.div_list('body', node.body)
    for z in node.handlers:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
    if node.finalbody:
        self.keyword('finally')
        self.colon()
        self.div_list('body', node.finalbody)
    self.end_div('statement')
#@+node:ekr.20150722204300.90: *5* rt.TryExcept
def do_TryExcept(self, node):

    self.div('statement')
    self.keyword('try')
    self.colon()
    self.div_list('body', node.body)
    if node.orelse:
        self.keyword('else')
        self.colon()
        self.div_body(node.orelse)
    self.div_body(node.handlers)
    self.end_div('statement')
#@+node:ekr.20150722204300.91: *5* rt.TryFinally
def do_TryFinally(self, node):

    self.div('statement')
    self.keyword('try')
    self.colon()
    self.div_body(node.body)
    self.keyword('finally')
    self.colon()
    self.div_body(node.final.body)
    self.end_div('statement')
#@+node:ekr.20150722204300.92: *5* rt.Tuple
# Tuple(expr* elts, expr_context ctx)

def do_Tuple(self, node):

    # self.span('tuple')
    self.gen('(')
    for z in node.elts or []:
        self.visit(z)
        self.comma()
    self.clean_comma()
    self.gen(')')
    # self.end_span('tuple')
#@+node:ekr.20150722204300.94: *5* rt.While
def do_While(self, node):

    self.div('statement')
    self.div(None)
    self.keyword("while")
    self.visit(node.test)
    self.colon()
    self.end_div(None)
    self.div_list('body', node.body)
    if node.orelse:
        self.keyword('else')
        self.colon()
        self.div_body(node.orelse)
    self.end_div('statement')
#@+node:ekr.20150722204300.93: *5* rt.UnaryOp
def do_UnaryOp(self, node):

    op_name_ = op_name(node.op).strip()
    # self.span(op_name_)
    self.op(op_name_, trailing=False)
    self.visit(node.operand)
    # self.end_span(op_name_)
#@+node:ekr.20150722204300.95: *5* rt.With & AsyncWith (Python 3)
# 2:  With(expr context_expr, expr? optional_vars,
#          stmt* body)
# 3:  With(withitem* items,
#          stmt* body)
# withitem = (expr context_expr, expr? optional_vars)

def do_With(self, node, async_flag=False):

    context_expr = getattr(node, 'context_expr', None)
    optional_vars = getattr(node, 'optional_vars', None)
    items = getattr(node, 'items', None)
    self.div('statement')
    if async_flag:
        self.keyword('async')
    self.keyword('with')
    if context_expr:
        self.visit(context_expr)
    if optional_vars:
        self.keyword('as')
        self.visit_list(optional_vars)
    if items:
        for item in items:
            self.visit(item.context_expr)
            if getattr(item, 'optional_vars', None):
                self.keyword('as')
                self.visit(item.optional_vars)
    self.colon()
    self.div_body(node.body)
    self.end_div('statement')

def do_AsyncWith(self, node):
    self.do_With(node, async_flag=True)
#@+node:ekr.20150722204300.96: *5* rt.Yield
def do_Yield(self, node):

    self.div('statement')
    self.keyword('yield')
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20160317051849.5: *5* rt.YieldFrom (Python 3)
# YieldFrom(expr value)

def do_YieldFrom(self, node):

    self.div('statement')
    self.keyword('yield from')
    self.visit(node.value)
    self.end_div('statement')
#@+node:ekr.20190910081550.1: *3* class SyntaxSanitizer
class SyntaxSanitizer:

    << SyntaxSanitizer docstring >>

    def __init__(self, c, keep_comments):
        self.c = c
        self.keep_comments = keep_comments

    @others
#@+node:ekr.20190910093739.1: *4* << SyntaxSanitizer docstring >>
r"""
This class converts section references, @others and Leo directives to
comments. This allows ast.parse to handle the result.

Within section references, these comments must *usually* be executable:
    
BEFORE:
    if condition:
        <\< do something >\>
AFTER:
    if condition:
        pass # do something
        
Alas, sanitation can result in a syntax error. For example, leoTips.py contains:
    
BEFORE:
    tips = [
        <\< define tips >\>
        ]

AFTER:
    tips = [
        pass # define tips
    ]
    
This fails because tips = [pass] is a SyntaxError.

The beautify* and black* commands clearly report such failures.
"""
#@+node:ekr.20190910022637.2: *4* sanitize.comment_leo_lines
def comment_leo_lines(self, p=None, s0=None):
    """
    Replace lines containing Leonine syntax with **special comment lines** of the form:
        
        {lws}#{lws}{marker}{line}
        
    where: 
    - lws is the leading whitespace of the original line
    - marker appears nowhere in p.b
    - line is the original line, unchanged.
    
    This convention allows uncomment_special_lines to restore these lines.
    """
    # Choose a marker that appears nowhere in s.
    if p:
        s0 = p.b
    n = 5
    while('#'+ ('!'*n)) in s0:
        n += 1
    comment = '#' + ('!' * n)
    # Create a dict of directives.
    d = {z: True for z in g.globalDirectiveList}
    # Convert all Leonine lines to special comments.
    i, lines, result = 0, g.splitLines(s0), []
    while i < len(lines):
        progress = i
        s = lines[i]
        s_lstrip = s.lstrip()
        # Comment out any containing a section reference.
        j = s.find('<<')
        k = s.find('>>') if j > -1 else -1
        if -1 < j < k:
            result.append(comment+s)
            # Generate a properly-indented pass line.
            j2 = g.skip_ws(s, 0)
            result.append(f'{" "*j2}pass\n')
        elif s_lstrip.startswith('@'):
            # Comment out all other Leonine constructs.
            if self.starts_doc_part(s):
                # Comment the entire doc part, until @c or @code.
                result.append(comment+s)
                i += 1
                while i < len(lines):
                    s = lines[i]
                    result.append(comment+s)
                    i += 1
                    if self.ends_doc_part(s):
                        break
            else:
                j = g.skip_ws(s, 0)
                assert s[j] == '@'
                j += 1
                k = g.skip_id(s, j, chars='-')
                if k > j:
                    word = s[j : k]
                    if word == 'others':
                        # Remember the original @others line.
                        result.append(comment+s)
                        # Generate a properly-indented pass line.
                        result.append(f'{" "*(j-1)}pass\n')
                    else:
                        # Comment only Leo directives, not decorators.
                        result.append(comment+s if word in d else s)
                else:
                    result.append(s)
        elif s_lstrip.startswith('#') and self.keep_comments:
            # A leading comment.
            # Bug fix: Preserve lws in comments, too.
            j2 = g.skip_ws(s, 0)
            result.append(" "*j2+comment+s)
        else:
            # A plain line.
            result.append(s)
        if i == progress:
            i += 1
    return comment, ''.join(result)
#@+node:ekr.20190910022637.3: *4* sanitize.starts_doc_part & ends_doc_part
def starts_doc_part(self, s):
    """Return True if s word matches @ or @doc."""
    return s.startswith(('@\n', '@doc\n', '@ ', '@doc '))

def ends_doc_part(self, s):
    """Return True if s word matches @c or @code."""
    return s.startswith(('@c\n', '@code\n', '@c ', '@code '))
#@+node:ekr.20190910022637.4: *4* sanitize.uncomment_leo_lines
def uncomment_leo_lines(self, comment, p, s0):
    """Reverse the effect of comment_leo_lines."""
    lines = g.splitLines(s0)
    i, result = 0, []
    while i < len(lines):
        progress = i
        s = lines[i]
        i += 1
        if comment in s:
            # One or more special lines.
            i = self.uncomment_special_lines(comment, i, lines, p, result, s)
        else:
            # A regular line.
            result.append(s)
        assert progress < i
    return ''.join(result).rstrip() + '\n'
#@+node:ekr.20190910022637.5: *4* sanitize.uncomment_special_line & helpers
def uncomment_special_lines(self, comment, i, lines, p, result, s):
    """
    This method restores original lines from the special comment lines
    created by comment_leo_lines. These lines have the form:
        
        {lws}#{marker}{line}
        
    where: 
    - lws is the leading whitespace of the original line
    - marker appears nowhere in p.b
    - line is the original line, unchanged.
    
    s is a line containing the comment delim.
    i points at the *next* line.
    Handle one or more lines, appending stripped lines to result.
    """
    #
    # Delete the lws before the comment.
    # This works because the tail contains the original whitespace.
    assert comment in s
    s = s.lstrip().replace(comment, '')
    #
    # Here, s is the original line.
    if comment in s:
        g.trace(f"can not happen: {s!r}")
        return i
    if self.starts_doc_part(s):
        result.append(s)
        while i < len(lines):
            s = lines[i].lstrip().replace(comment, '')
            i += 1
            result.append(s)
            if self.ends_doc_part(s):
                break
        return i
    j = s.find('<<')
    k = s.find('>>') if j > -1 else -1
    if -1 < j < k or '@others' in s:
        #
        # A section reference line or an @others line.
        # Such lines are followed by a pass line.
        #
        # The beautifier may insert blank lines before the pass line.
        kind = 'section ref' if -1 < j < k else '@others'
        # Restore the original line, including leading whitespace.
        result.append(s)
        # Skip blank lines.
        while i < len(lines) and not lines[i].strip():
            i += 1
        # Skip the pass line.
        if i < len(lines) and lines[i].lstrip().startswith('pass'):
            i += 1
        else:
            g.trace(f"*** no pass after {kind}: {p.h}")
    else:
        # A directive line or a comment line.
        result.append(s)
    return i
#@+node:ekr.20191113133338.1: *3* class TestRunner
class TestRunner:
    """
    A testing framework for TokenOrderGenerator and related classes.
    """
    
    counts, times = {}, {}
    << define valid actions & flags >>
    @others
   
#@+node:ekr.20191222064729.1: *4* << define valid actions & flags >>
valid_actions = [
    'run-ast-tokens',       # Alternate pass 0.
    'make-tokens-and-tree', # Pass 0.
    'create-links',         # Pass 1.
    'fstringify',           # Pass 2.
    # Dumps...
    'dump-all',
    'dump-ast', # Was dump-raw-tree.
    'dump-contents',
    'dump-lines',
    'dump-results',
    'dump-times',
    'dump-tokens',
    'dump-tree',
]

valid_flags = [
    'all',
    'all-leo-files',
    'coverage',
    'dump-all-after-fail',
    'dump-ast-tree-first',
    'dump-results',
    'dump-tokens-after-fail',
    'dump-tokens-first',
    'dump-tree-after-fail',
    'no-trace-after-fail',
    'set-trace-mode',
    'show-pass0-times',
    'show-create-links-time',
    'show-fstringify-time',
    'show-exception-after-fail',
    'show-make-tokens-time',
    'show-test-description',
    'show-test-kind',
    'summarize',
    'trace-tokenizer-tokens',
    'verbose-fail',
]
#@+node:ekr.20191205160754.4: *4* TR.run_tests & helpers
def run_tests(self, actions, flags, root, contents=None):
    """The outer test runner."""
    # Startup.
    self.fails = []
    self.root = root
    self.times = {}
    # Create self.actions and self.flags.
    ok = self.make_actions_and_flags(actions, flags)
    if not ok:
        print('Aborting...')
        return
    flags = self.flags
    self.show_status()
    if contents:
        self.tests = [(contents, root.h or 'None')]
    elif 'all-leo-files' in flags:
        self.tests = self.make_leo_tests()
    else:
        self.tests = self.make_tests(root)
    # Execute all tests.
    t1 = get_time()
    for contents, description in self.tests:
        # run_one_test catches all exceptions.
        if 'show-test-description' in flags:
            print(f"Running {description}...")
        ok = self.run_one_test(contents, description)
        if not ok:
            self.fails.append(description)
        if 'fail-fast' in flags:
            break
    # End-of-tests reports.
    t2 = get_time()
    self.times['total_time'] = t2 - t1
    if 'coverage' in flags:
        self.show_coverage()
    if 'summarize' in flags:
        self.summarize()
#@+node:ekr.20191205163727.1: *5* TR.make_actions_and_flags
def make_actions_and_flags(self, actions, flags):
    """
    Create self.actions and self.flags.
    
    Return False if there are unknow actions or flags.
    """
    valid_actions, valid_flags = self.valid_actions, self.valid_flags
    # Check valid actions.
    for z in valid_actions:
        assert hasattr(self, z.replace('-','_')), repr(z)
    # Clean and check actions.
    self.actions = [z for z in actions if z in valid_actions]
    bad_actions = [z for z in actions if z not in valid_actions]
    if bad_actions:
        for z in bad_actions:
            print('Unknown action:', z)
        return False
    # Clean and check flags.
    flags = [z.lower() for z in flags or []]
    self.flags = [z for z in flags if z in valid_flags]
    bad_flags = [z for z in flags if z not in valid_flags]
    if bad_flags:
        for z in bad_flags:
            print('Unknown flag:', z)
        return False
    return True
#@+node:ekr.20191205172431.1: *5* TR.make_leo_tests
def make_leo_tests(self):
    """
    Leo-specific code for unit tests.
    
    Return a list of tuples (contents, description) for all of Leo's core
    .py files.
    """
    import leo.core.leoGlobals as leo_g
    core_directory = leo_g.os_path_finalize_join(leo_g.app.loadDir, '..', 'core')
    assert os.path.exists(core_directory), core_directory
    paths = glob.glob(core_directory + os.path.sep + 'leo*.py')
    tests = []
    for path in paths:
        assert os.path.exists(path), path
        with open(path, 'r') as f:
            contents = f.read()
        description = path
        tests.append((contents, description))   
    return tests

#@+node:ekr.20191205160754.2: *5* TR.make_tests
def make_tests(self, root):
    """
    Leo-specific code for unit tests.
    
    Return a list of tuples (contents, description) found in all children
    of the root, except this node.
    """
    import leo.core.leoGlobals as leo_g
    tests = []
    contents_tag = 'test:'
    file_tag = 'file:'
    after = root.nodeAfterTree()
    p = root.copy()
    while p and p != after:
        if p.h.startswith(('fail:', 'fails')):
            # Ignore all fails, regardless of 'all' flag.
            p.moveToNodeAfterTree()
        elif 'all' not in self.flags and p.h.startswith('ignore:'):
            # Honor 'ignore' only when *not* runnining all tests.
            p.moveToNodeAfterTree()
        elif p.h.startswith(contents_tag):
            description = p.h
            contents = p.b.strip() + '\n'
            tests.append((contents, description))
            p.moveToThreadNext()
        elif p.h.startswith(file_tag):
            description = p.h
            s = p.h[len(file_tag):].strip()
            parts = [leo_g.app.loadDir, '..'] + s.split('..')
            path = os.path.sep.join(parts)
            if os.path.exists(path):
                with open(path, 'r') as f:
                    contents = f.read()
                tests.append((contents, description))
                p.moveToThreadNext()
            else:
                assert False, f"file not found: {path}"
        else:
            # Ignore organizer nodes.
            p.moveToThreadNext()
    if not tests:
        print(f"no tests in {root.h}")
    return tests
#@+node:ekr.20191122025155.1: *5* TR.show_coverage
def show_coverage(self):
    if self.toi:
        self.toi.report_coverage()
#@+node:ekr.20191205160754.5: *5* TR.show_status
def show_status(self):
    """Show the preliminary status."""
    flags = self.flags
    print('')
    if 'show-test-kind' in flags:
        if 'all-leo-files' in flags:
            kind = 'Testing all Leo files'
        elif 'all' in flags:
            kind = 'Running *all* unit tests'
        else:
            kind = 'Running *selected* unit tests'
        print(f"{self.root.h}: {kind}...")
    if 'run-ast-tokens' in self.actions:
        print('\nUsing asttokens, *not* the TOG classes')
#@+node:ekr.20191205160754.6: *5* TR.summarize
def summarize(self):
    fails, tests = self.fails, self.tests
    status = 'FAIL' if fails else 'PASS'
    if fails:
        print('')
        g.printObj(fails, tag='Failed tests')
    print(
        f"\n{status} Ran "
        f"{len(tests)} test{g.plural(len(tests))}")
    if not 'dump-times' in self.flags:
        self.dump_times()
#@+node:ekr.20191122021515.1: *4* TR.run_one_test
def run_one_test(self, contents, description):
    """
    Run the test given by the contents and description.
    """
    tag = 'run_tests'
    self.description = description
    # flags = self.flags
    # Clean the contents.
    self.contents = contents = contents.strip() + '\n'
    
    #
    # Execute actions, in the user-defined order.
    bad_actions = []
    for action in self.actions:
        helper = getattr(self, action.replace('-', '_'), None)
        if helper:
            try:
                helper()
            except Exception as e:
                print(f"{tag}: Exception in {action}: {e}")
                if 'show-exception-after-fail' in self.flags:
                    g.es_exception()
                return False
        else:
            bad_actions.append(action)
    if bad_actions:
        for action in list(set(bad_actions)):
            print(f"{tag}: bad action option: {action!r}")
    return True
#@+node:ekr.20191205160624.1: *4* TR: actions...
# Actions should fail by throwing an exception.
#@+node:ekr.20191226064933.1: *5* TR.create_links (pass 1)
def create_links(self):
    """Pass 1: TOG.create_links"""
    flags, toi = self.flags, self.toi
    # Catch exceptions so we can get data late.
    try:
        t1 = get_time()
        # Yes, list *is* required here.
        list(toi.create_links(self.tokens, self.tree, file_name=self.description))
        t2 = get_time()
        self.update_times('10: create-links', t2 - t1)
    except Exception as e:
        g.trace(f"\nFAIL: make-tokens\n")
        # Don't use g.trace.  It doesn't handle newlines properly.
        print(e)
        if 'show-exception-after-fail' in flags:
            g.es_exception()
        if 'dump-all-after-fail' in flags:
            self.dump_all()
        else:
            if 'dump-tokens-after-fail' in flags:
                self.dump_tokens()
            if 'dump-tree-after-fail' in flags:
                self.dump_tree()
        if 'no-trace-after-fail':
            toi.trace_mode = False
        raise
#@+node:ekr.20191122022728.1: *5* TR.dump_all
def dump_all(self):

    if self.toi:
        self.dump_contents()
        self.dump_tokens()
        self.dump_tree()
        # self.dump_ast()

#@+node:ekr.20191122025306.2: *5* TR.dump_ast
def dump_ast(self):
    """Dump an ast tree.  Similar to ast.dump()."""
    print('\nast tree...\n')
    print(AstDumper().dump_ast(self.tree))
    print('')
#@+node:ekr.20191122025303.1: *5* TR.dump_contents
def dump_contents(self):
    contents = self.contents
    print('\nContents...\n')
    for i, z in enumerate(g.splitLines(contents)):
        print(f"{i+1:<3} ", z.rstrip())
    print('')
#@+node:ekr.20191122025306.1: *5* TR.dump_lines
def dump_lines(self):
    print('\nTOKEN lines...\n')
    for z in self.tokens:
        if z.line.strip():
            print(z.line.rstrip())
        else:
            print(repr(z.line))
    print('')
#@+node:ekr.20191225063758.1: *5* TR.dump_results
def dump_results(self):
    print('\nResults...\n')
    print(tokens_to_string(self.tokens))
#@+node:ekr.20191226095129.1: *5* TR.dump_times
def dump_times(self):
    """
    Show all calculated times.
    
    Keys should start with a priority (sort order) of the form `[0-9][0-9]:`
    """
    if not self.times:
        return
    print('')
    for key in sorted(self.times):
        t = self.times.get(key)
        key2 = key[3:]
        print(f"{key2:>16}: {t:6.3f} sec.")
#@+node:ekr.20191122025418.1: *5* TR.dump_tokens
def dump_tokens(self):
    tokens = self.tokens
    print('\nTokens...\n')
    print("Note: values shown are repr(value) *except* for 'string' tokens.\n")
    # pylint: disable=not-an-iterable
    if self.toi:
        for z in tokens:
            print(z.dump())
        print('')
    else:
        import token as tm
        for z in tokens:
            kind = tm.tok_name[z.type].lower()
            print(f"{z.index:4} {kind:>12} {z.string!r}")
#@+node:ekr.20191122025419.1: *5* TR.dump_tree
def dump_tree(self):
    print('\nPatched tree...\n')
    tokens, tree = self.tokens, self.tree
    if self.toi:
        print(dump_tree_and_links(tree))
        return
    try:
        # pylint: disable=import-error
        from asttokens.util import walk
    except Exception:
        return
    for z in walk(tree):
        class_name = z.__class__.__name__
        first, last = z.first_token.index, z.last_token.index
        token_range = f"{first:>4}..{last:<4}"
        if isinstance(z, ast.Module):
            tokens_s = ''
        else:
            tokens_s = ' '.join(
                repr(z.string) for z in tokens[first:last] if z)
        print(f"{class_name:>12} {token_range:<10} {tokens_s}")
#@+node:ekr.20191222074711.1: *5* TR.fstringify (pass 2)
def fstringify(self):
    """Pass 2: TOG.fstringify."""
    toi = self.toi
    assert isinstance(toi, TokenOrderGenerator), repr(toi)
    t1 = get_time()
    toi.fstringify(toi.tokens, toi.tree, filename='unit test')
    t2 = get_time()
    self.update_times('20: fstringify', t2 - t1)
#@+node:ekr.20191226063007.1: *5* TR.make_tokens_and_tree (pass 0)
def make_tokens_and_tree(self):
    """Pass 0: TOG.make_tokens_and_tree."""
    contents, flags = self.contents, self.flags
    t1 = get_time()
    # Create and remember the toi.
    toi = self.toi = TokenOrderInjector()
    toi.trace_mode = 'set-trace-mode' in flags
    # Tokenize.
    self.tokens = make_tokens(contents)
    t2 = get_time()
    self.update_times('01: make-tokens', t2 - t1)
    # Parse.
    self.tree = parse_ast(contents)
    t3 = get_time()
    self.update_times('01: parse-ast', t3 - t2)
    # Dump.
    if 'dump-tokens-first' in flags:
        dump_tokens(self.tokens)
    if 'dump-ast-tree-first' in flags:
        dump_ast(self.tree)
#@+node:ekr.20191226063942.1: *5* TR.run_ast_tokens
def run_ast_tokens(self):
    # pylint: disable=import-error
    # It's ok to raise ImportError here.
    import asttokens
    t1 = get_time()
    atok = asttokens.ASTTokens(self.contents, parse=True)
    self.tree = atok.tree
    self.tokens = atok._tokens
    t2 = get_time()
    self.update_times('01: ast-tokens', t2 - t1)
#@+node:ekr.20191228183156.1: *5* TR.update_counts & update_times
def update_counts(self, key, n):
    """Update the count statistic given by key, n."""
    old_n = self.times.get(key, 0)
    self.counts [key] = old_n + n

def update_times(self, key, t):
    """Update the timing statistic given by key, t."""
    old_t = self.times.get(key, 0.0)
    self.times [key] = old_t + t
#@+node:ekr.20191113054314.1: *3* class TokenOrderInjector (TOG)
class TokenOrderInjector (TokenOrderGenerator):
    """
    A class that injects parent/child data into tokens and ast nodes.
    """
    @others
#@+node:ekr.20191113054550.1: *4* toi.begin_visitor
def begin_visitor(self, node):
    """
    TokenOrderInjector.begin_visitor.
    
    Enter a visitor, inject data into the ast node, and update stats.
    """
    #
    # Do this first, *before* updating self.node.
    self.coverage_set.add(node.__class__.__name__)
    node.parent = self.node
    if self.node:
        children = getattr(self.node, 'children', [])
        children.append(node)
        self.node.children = children
    #
    # *Now* update self.node, etc.
    super().begin_visitor(node)
#@+node:ekr.20191121122230.1: *3* class TokenOrderNodeGenerator (TOG)
class TokenOrderNodeGenerator(TokenOrderGenerator):
    """A class that yields a stream of nodes."""

    # Other overrides...
    def sync_token(self, kind, val):
        pass
        
    @others
#@+node:ekr.20191228153344.1: *4* tong.generate_nodes
def generate_nodes(self, tokens, tree, file_name=''):
    """Entry: yield a stream of nodes."""
    #
    # Init all ivars.
    self.file_name = file_name
        # For tests.
    self.level = 0
        # Python indentation level.
    self.node = None
        # The node being visited.
        # The parent of the about-to-be visited node.
    self.tokens = tokens
        # The immutable list of input tokens.
    self.tree = tree
        # The tree of ast.AST nodes.
    #
    # Traverse the tree.
    try:
        while True:
            next(self.visitor(tree))
    except StopIteration:
        pass
#@+node:ekr.20191228152949.1: *4* tong.begin/end_visitor
def begin_visitor(self, node):
    """TONG.begin_visitor: Enter a visitor."""
    # begin_visitor and end_visitor must be paired.
    self.begin_end_stack.append(node.__class__.__name__)
    # Push the previous node.
    self.node_stack.append(self.node)
    # Update self.node *last*.
    self.node = node

def end_visitor(self, node):
    """TONG.end_visitor: Leave a visitor."""
    # begin_visitor and end_visitor must be paired.
    entry_name = self.begin_end_stack.pop()
    assert entry_name == node.__class__.__name__, (repr(entry_name), node.__class__.__name__)
    assert self.node == node, (repr(self.node), repr(node))
    # Restore self.node.
    self.node = self.node_stack.pop()
#@+node:ekr.20160225102931.1: *3* class TokenSync (deprecated)
class TokenSync:
    """A class to sync and remember tokens."""
    # To do: handle comments, line breaks...
    @others
#@+node:ekr.20160225102931.2: *4*  ts.ctor & helpers
def __init__(self, s, tokens):
    """Ctor for TokenSync class."""
    assert isinstance(tokens, list)  # Not a generator.
    self.s = s
    self.first_leading_line = None
    self.lines = [z.rstrip() for z in g.splitLines(s)]
    # Order is important from here on...
    self.nl_token = self.make_nl_token()
    self.line_tokens = self.make_line_tokens(tokens)
    self.blank_lines = self.make_blank_lines()
    self.string_tokens = self.make_string_tokens()
    self.ignored_lines = self.make_ignored_lines()
#@+node:ekr.20160225102931.3: *5* ts.make_blank_lines
def make_blank_lines(self):
    """Return of list of line numbers of blank lines."""
    result = []
    for i, aList in enumerate(self.line_tokens):
        # if any([self.token_kind(z) == 'nl' for z in aList]):
        if len(aList) == 1 and self.token_kind(aList[0]) == 'nl':
            result.append(i)
    return result
#@+node:ekr.20160225102931.4: *5* ts.make_ignored_lines
def make_ignored_lines(self):
    """
    Return a copy of line_tokens containing ignored lines,
    that is, full-line comments or blank lines.
    These are the lines returned by leading_lines().
    """
    result = []
    for i, aList in enumerate(self.line_tokens):
        for z in aList:
            if self.is_line_comment(z):
                result.append(z)
                break
        else:
            if i in self.blank_lines:
                result.append(self.nl_token)
            else:
                result.append(None)
    assert len(result) == len(self.line_tokens)
    for i, aList in enumerate(result):
        if aList:
            self.first_leading_line = i
            break
    else:
        self.first_leading_line = len(result)
    return result
#@+node:ekr.20160225102931.5: *5* ts.make_line_tokens (trace tokens)
def make_line_tokens(self, tokens):
    """
    Return a list of lists of tokens for each list in self.lines.
    The strings in self.lines may end in a backslash, so care is needed.
    """
    import token as tm
    n, result = len(self.lines), []
    for i in range(0, n+1):
        result.append([])
    for token in tokens:
        t1, t2, t3, t4, t5 = token
        kind = tm.tok_name[t1].lower()
        srow, scol = t3
        erow, ecol = t4
        line = erow - 1 if kind == 'string' else srow - 1
        result[line].append(token)
    assert len(self.lines) + 1 == len(result), len(result)
    return result
#@+node:ekr.20160225102931.6: *5* ts.make_nl_token
def make_nl_token(self):
    """Return a newline token with '\n' as both val and raw_val."""
    import token as tm
    t1 = tm.NEWLINE
    t2 = '\n'
    t3 = (0, 0)  # Not used.
    t4 = (0, 0)  # Not used.
    t5 = '\n'
    return t1, t2, t3, t4, t5
#@+node:ekr.20160225102931.7: *5* ts.make_string_tokens
def make_string_tokens(self):
    """Return a copy of line_tokens containing only string tokens."""
    result = []
    for aList in self.line_tokens:
        result.append([z for z in aList if self.token_kind(z) == 'string'])
    assert len(result) == len(self.line_tokens)
    return result
#@+node:ekr.20160225102931.8: *4* ts.check_strings
def check_strings(self):
    """Check that all strings have been consumed."""
    for i, aList in enumerate(self.string_tokens):
        if aList:
            g.trace(f"warning: line {i}. unused strings: {aList}")
#@+node:ekr.20160225102931.10: *4* ts.is_line_comment
def is_line_comment(self, token):
    """Return True if the token represents a full-line comment."""
    import token as tm
    t1, t2, t3, t4, t5 = token
    kind = tm.tok_name[t1].lower()
    raw_val = t5
    return kind == 'comment' and raw_val.lstrip().startswith('#')
#@+node:ekr.20160225102931.12: *4* ts.last_node
def last_node(self, node):
    """Return the node of node's tree with the largest lineno field."""

    class LineWalker(ast.NodeVisitor):

        def __init__(self):
            """Ctor for LineWalker class."""
            self.node = None
            self.lineno = -1

        def visit(self, node):
            """LineWalker.visit."""
            if hasattr(node, 'lineno'):
                if node.lineno > self.lineno:
                    self.lineno = node.lineno
                    self.node = node
            if isinstance(node, list):
                for z in node:
                    self.visit(z)
            else:
                self.generic_visit(node)

    w = LineWalker()
    w.visit(node)
    return w.node
#@+node:ekr.20160225102931.13: *4* ts.leading_lines
def leading_lines(self, node):
    """Return a list of the preceding comment and blank lines"""
    # This can be called on arbitrary nodes.
    leading = []
    if hasattr(node, 'lineno'):
        i, n = self.first_leading_line, node.lineno
        while i < n:
            token = self.ignored_lines[i]
            if token:
                s = self.token_raw_val(token).rstrip() + '\n'
                leading.append(s)
            i += 1
        self.first_leading_line = i
    return leading
#@+node:ekr.20160225102931.14: *4* ts.leading_string
def leading_string(self, node):
    """Return a string containing all lines preceding node."""
    return ''.join(self.leading_lines(node))
#@+node:ekr.20160225102931.15: *4* ts.line_at
def line_at(self, node, continued_lines=True):
    """Return the lines at the node, possibly including continuation lines."""
    n = getattr(node, 'lineno', None)
    if n is None:
        return f'<no line> for %s' % node.__class__.__name__
    if continued_lines:
        aList, n = [], n - 1
        while n < len(self.lines):
            s = self.lines[n]
            if s.endswith('\\'):
                aList.append(s[:-1])
                n += 1
            else:
                aList.append(s)
                break
        return ''.join(aList)
    return self.lines[n - 1]
#@+node:ekr.20160225102931.16: *4* ts.sync_string
def sync_string(self, node):
    """Return the spelling of the string at the given node."""
    n = node.lineno
    tokens = self.string_tokens[n - 1]
    if tokens:
        token = tokens.pop(0)
        self.string_tokens[n - 1] = tokens
        return self.token_val(token)
    g.trace('===== underflow', n, node.s)
    return node.s
#@+node:ekr.20160225102931.18: *4* ts.tokens_for_statement
def tokens_for_statement(self, node):
    assert isinstance(node, ast.AST), node
    name = node.__class__.__name__
    if hasattr(node, 'lineno'):
        tokens = self.line_tokens[node.lineno - 1]
        g.trace(' '.join([self.dump_token(z) for z in tokens]))
    else:
        g.trace('no lineno', name)
#@+node:ekr.20160225102931.19: *4* ts.trailing_comment
def trailing_comment(self, node):
    """
    Return a string containing the trailing comment for the node, if any.
    The string always ends with a newline.
    """
    if hasattr(node, 'lineno'):
        return self.trailing_comment_at_lineno(node.lineno)
    g.trace('no lineno', node.__class__.__name__, g.callers())
    return '\n'
#@+node:ekr.20160225102931.20: *4* ts.trailing_comment_at_lineno
def trailing_comment_at_lineno(self, lineno):
    """Return any trailing comment at the given node.lineno."""
    tokens = self.line_tokens[lineno - 1]
    for token in tokens:
        if self.token_kind(token) == 'comment':
            raw_val = self.token_raw_val(token).rstrip()
            if not raw_val.strip().startswith('#'):
                val = self.token_val(token).rstrip()
                s = f' %s\n' % val
                return s
    return '\n'
#@+node:ekr.20160225102931.21: *4* ts.trailing_lines
def trailing_lines(self):
    """return any remaining ignored lines."""
    trailing = []
    i = self.first_leading_line
    while i < len(self.ignored_lines):
        token = self.ignored_lines[i]
        if token:
            s = self.token_raw_val(token).rstrip() + '\n'
            trailing.append(s)
        i += 1
    self.first_leading_line = i
    return trailing
#@+node:ekr.20191122105543.1: *4* ts:dumps
#@+node:ekr.20160225102931.9: *5* ts.dump_token
def dump_token(self, token, verbose=False):
    """Dump the token. It is either a string or a 5-tuple."""
    import token as tm
    if isinstance(token, str):
        return token
    t1, t2, t3, t4, t5 = token
    kind = g.toUnicode(tm.tok_name[t1].lower())
    # raw_val = g.toUnicode(t5)
    val = g.toUnicode(t2)
    if verbose:
        return f'token: %10s %r' % (kind, val)
    return val
#@+node:ekr.20160225102931.17: *5* ts.token_kind/raw_val/val
def token_kind(self, token):
    """Return the token's type."""
    t1, t2, t3, t4, t5 = token
    import token as tm
    return g.toUnicode(tm.tok_name[t1].lower())

def token_raw_val(self, token):
    """Return the value of the token."""
    t1, t2, t3, t4, t5 = token
    return g.toUnicode(t5)

def token_val(self, token):
    """Return the raw value of the token."""
    t1, t2, t3, t4, t5 = token
    return g.toUnicode(t2)
#@+node:ekr.20160225102931.11: *5* ts.join
def join(self, aList, sep=','):
    """return the items of the list joined by sep string."""
    tokens = []
    for i, token in enumerate(aList or []):
        tokens.append(token)
        if i < len(aList) - 1:
            tokens.append(sep)
    return tokens
#@+node:ekr.20200129084258.21: *3* function: replace_node_and_tokens
def replace_node_and_tokens(old_node, new_node, old_tokens, new_token, token_list):
    """
    Replace old_node with new_node.
    Replace all old_tokens with a single new_token.
    """
    # Replace the tokens...
        # tokens = tokens_for_node(old_node, token_list)
        # i1 = i = tokens[0].index
        # replace_token(self.tokens[i], 'string', s)
        # replace_token(token_list[i], new_token.kind, new_token.value)
    replace_token(old_token, new_token.kind, new_token.value)
    i1 = old_token.index
    j = 1
    while j < len(tokens):
        replace_token(token_list[i1 + j], 'killed', '')
        j += 1
    # Replace the node.
        # new_node = ast.Str()
        # new_node.s = s
    replace_node(new_node, old_node)
    # Update the token.
        # token = token_list[i1]
    new_token.node = new_node
    # Update the token list.
    new_node.token_list = [token]
#@+node:ekr.20200209135643.1: *3* orange.clean_leo_nodes (black only)
def clean_leo_nodes(self):  # pragma: no cover (black)
    """
    Remove all blank lines before and after Leo @+node and @+others sentinels.
    
    This is a post pass, for last-minute cleanups.
    """

    def clean_before(i):
        """Replace blank lines before self.code_list[i] with a single newline."""
        i -= 1
        cleaned = 0
        while i > 0:
            t = self.code_list[i]
            i -= 1
            if t.kind == 'blank-lines':
                t.kind, t.value = 'killed', ''  # pragma: no cover (defensive)
            elif t.kind == 'line-end':
                if cleaned > 0:
                    t.kind, t.value = 'killed', ''  # pragma: no cover (defensive)
                cleaned += 1
            else:
                break

    def clean_after(i):
        """Replace blank lines after self.code_list[i] with a single newline."""
        i += 1
        cleaned = 0
        while i < len(self.code_list):
            t = self.code_list[i]
            i += 1
            if t.kind == 'blank-lines':
                t.kind, t.value = 'killed', ''  # pragma: no cover (defensive)
            elif t.kind == 'line-end':
                if cleaned > 0:
                    t.kind, t.value = 'killed', ''  # pragma: no cover (defensive)
                cleaned += 1
            else:
                break

    for i, t in enumerate(self.code_list):
        if t.kind == 'comment' and (
            self.node_pat.match(t.value) or
            self.at_others_pat.match(t.value)
        ):
            clean_before(i)
            clean_after(i)
#@+node:ekr.20200107165250.50: *3* orange.find_delims (never used)
def find_delims(self, tokens):
    """
    Compute the net number of each kind of delim in the given range of tokens.
    
    Return (curlies, parens, squares)
    """
    parens, curlies, squares = 0, 0, 0
    for token in tokens:
        value = token.value
        if token.kind == 'lt':
            assert value in '([{', f"Bad lt value: {token.kind} {value}"
            if value == '{':
                curlies += 1
            elif value == '(':
                parens += 1
            elif value == '[':
                squares += 1
        elif token.kind == 'rt':
            assert value in ')]}', f"Bad rt value: {token.kind} {value}"
            if value == ')':
                parens -= 1
            elif value == ']':
                squares -= 1
            elif value == '}':
                curlies += 1
    return curlies, parens, squares
#@+node:ekr.20200212072951.1: *3* TestOrange.test_bad_break
def test_bad_break(self):

    # From setup.py.
    # The total length of the ''' string should not affect line length.
    contents = r"""\
def get_semver(tag):
    if 1:
        print(
            '''*** Failed to parse Semantic Version from git tag '{0}'.
        Expecting tag name like '5.7b2', 'leo-4.9.12', 'v4.3' for releases.
        This version can't be uploaded to PyPi.org.'''.format(tag))
    return version
"""
    contents, tokens, tree = self.make_data(contents)
    # expected = self.blacken(contents).rstrip() + '\n'
    expected = contents.rstrip() + '\n'
    results = self.beautify(contents, tokens, tree)
    if results != expected:
        g.printObj(tokens)
        g.printObj(expected, tag='expected')
        g.printObj(results, tag='results')
        assert False
#@+node:ekr.20200108180111.1: ** From leoBeautify.py
#@+node:ekr.20200103055140.1: *3* commands
#@+node:ekr.20190725154916.7: *4* black.blacken_node
def blacken_node(self, root, diff_flag, check_flag=False):
    """Run black on all Python @<file> nodes in root's tree."""
    c = self.c
    if not black or not root:
        return
    t1 = time.process_time()
    self.changed, self.errors, self.total = 0, 0, 0
    self.undo_type = 'blacken-node'
    self.blacken_node_helper(root, check_flag, diff_flag)
    t2 = time.process_time()
    if not g.unitTesting:
        print(
            f'{root.h}: scanned {self.total} node{g.plural(self.total)}, '
            f'changed {self.changed} node{g.plural(self.changed)}, '
            f'{self.errors} error{g.plural(self.errors)} '
            f'in {t2-t1:5.2f} sec.'
        )
    if self.changed or self.errors:
        c.redraw()
#@+node:ekr.20190726013924.1: *4* black.blacken_node_helper
def blacken_node_helper(self, p, check_flag, diff_flag):
    """
    blacken p.b, incrementing counts and stripping unnecessary blank lines.
    
    Return True if p.b was actually changed.
    """
    trace = 'black' in g.app.debug and not g.unitTesting
    if not should_beautify(p):
        return False
    c = self.c
    self.total += 1
    language = g.findLanguageDirectives(c, p)
    if language != 'python':
        g.trace(f"skipping node: {p.h}")
        return False
    body = p.b.rstrip() + '\n'
    comment_string, body2 = self.sanitizer.comment_leo_lines(p=p)
    try:
        # Support black, version 19.3b0.
        mode = black.FileMode()
        mode.line_length = self.line_length
        mode.string_normalization = self.normalize_strings
        # Note: format_str does not check parse trees,
        #       so in effect, it already runs in fast mode.
        body3 = black.format_str(body2, mode=mode)
    except IndentationError:
        g.warning(f"IndentationError: Can't blacken {p.h}")
        g.es_print(f"{p.h} will not be changed")
        g.printObj(body2, tag='Sanitized syntax')
        if g.unitTesting:
            raise
        p.setMarked()
        p.setDirty()
        return False
    except(SyntaxError, black.InvalidInput):
        g.warning(f"SyntaxError: Can't blacken {p.h}")
        g.es_print(f"{p.h} will not be changed")
        g.printObj(body2, tag='Sanitized syntax')
        if g.unitTesting:
            raise
        p.setMarked()
        p.setDirty()
        return False
    except Exception:
        g.warning(f"Unexpected exception: {p.h}")
        g.es_print(f"{p.h} will not be changed")
        g.printObj(body2, tag='Sanitized syntax')
        g.es_exception()
        if g.unitTesting:
            raise
        p.setMarked()
        p.setDirty()
        return False
    if trace:
        g.printObj(body2, tag='Sanitized syntax')
    result = self.sanitizer.uncomment_leo_lines(comment_string, p, body3)
    if check_flag or result == body:
        if not g.unitTesting:
            return False
    if diff_flag:
        print('=====', p.h)
        print(black.diff(body, result, "old", "new")[16:].rstrip()+'\n')
        return False
    # Update p.b and set undo params.
    self.changed += 1
    p.b = result
    c.frame.body.updateEditors()
    p.v.contentModified()
    c.undoer.setUndoTypingParams(p, 'blacken-node', oldText=body, newText=result)
    p.setDirty()
    return True
#@+node:ekr.20190729065756.1: *4* black.blacken_tree
def blacken_tree(self, root, diff_flag, check_flag=False):
    """Run black on all Python @<file> nodes in root's tree."""
    c = self.c
    if not black or not root:
        return
    t1 = time.process_time()
    self.changed, self.errors, self.total = 0, 0, 0
    undo_type = 'blacken-tree'
    bunch = c.undoer.beforeChangeTree(root)
    # Blacken *only* the selected tree.
    changed = False
    for p in root.self_and_subtree():
        if self.blacken_node_helper(p, check_flag, diff_flag):
            changed = True
    if changed:
        c.setChanged()
        c.undoer.afterChangeTree(root, undo_type, bunch)
    t2 = time.process_time()
    if not g.unitTesting:
        print(
            f'{root.h}: scanned {self.total} node{g.plural(self.total)}, '
            f'changed {self.changed} node{g.plural(self.changed)}, '
            f'{self.errors} error{g.plural(self.errors)} '
            f'in {t2-t1:5.2f} sec.'
        )
    if self.changed and not c.changed:
        c.setChanged()
    if self.changed or self.errors:
        c.redraw()
#@+node:ekr.20190830043650.1: *4* blacken-check-tree
@g.command('blkc')
@g.command('blacken-check-tree')
def blacken_check_tree(event):
    """
    Run black on all nodes of the selected tree, reporting only errors.
    """
    c = event.get('c')
    if not c:
        return
    if black:
        BlackCommand(c).blacken_tree(c.p, diff_flag=False, check_flag=True)
    else:
        g.es_print('can not import black')
#@+node:ekr.20190829163640.1: *4* blacken-diff-node
@g.command('blacken-diff-node')
def blacken_diff_node(event):
    """
    Run black on the selected node.
    """
    c = event.get('c')
    if not c:
        return
    if black:
        BlackCommand(c).blacken_node(c.p, diff_flag=True)
    else:
        g.es_print('can not import black')
#@+node:ekr.20190829163652.1: *4* blacken-diff-tree
@g.command('blkd')
@g.command('blacken-diff-tree')
def blacken_diff_tree(event):
    """
    Run black on all nodes of the selected tree,
    or the first @<file> node in an ancestor.
    """
    c = event.get('c')
    if not c:
        return
    if black:
        BlackCommand(c).blacken_tree(c.p, diff_flag=True)
    else:
        g.es_print('can not import black')
#@+node:ekr.20190725155006.1: *4* blacken-node
@g.command('blacken-node')
def blacken_node(event):
    """
    Run black on the selected node.
    """
    c = event.get('c')
    if not c:
        return
    if black:
        BlackCommand(c).blacken_node(c.p, diff_flag=False)
    else:
        g.es_print('can not import black')
#@+node:ekr.20190729105252.1: *4* blacken-tree
@g.command('blk')
@g.command('blacken-tree')
def blacken_tree(event):
    """
    Run black on all nodes of the selected tree,
    or the first @<file> node in an ancestor.
    """
    c = event.get('c')
    if not c:
        return
    if black:
        BlackCommand(c).blacken_tree(c.p, diff_flag=False)
    else:
        g.es_print('can not import black')
#@+node:ekr.20150528131012.5: *4* beautify-tree
@g.command('beautify-tree')
@g.command('pretty-print-tree')
def beautifyPythonTree(event):
    """Beautify all python files in the selected outline."""
    c = event.get('c')
    if c:
        PythonTokenBeautifier(c).beautify_tree(c.p)
#@+node:ekr.20150528131012.4: *4* beautify-node
@g.command('beautify-node')
@g.command('pretty-print-node')
def prettyPrintPythonNode(event):
    """Beautify a single Python node."""
    c = event.get('c')
    if c:
        PythonTokenBeautifier(c).beautify_node(c.p)
    
    
#@+node:ekr.20200108180155.1: *3* functions & tests
#@+node:ekr.20200110014220.2: *4* @@test leoBeautify.CPrettyPrinter
import leo.core.leoBeautify as leoBeautify
cpp = leoBeautify.CPrettyPrinter(c)
fn = 'c tokenize test'
p2 = g.findNodeInTree(c,p,fn)
assert p2,'not found: %s' % (fn)

if 1: # test of indent.
    # import os ; os.system('cls')
    cpp.indent(p2)
if 0: # test of tokenize.
    aList = cpp.tokenize(p2.b)
    assert(p2.b == ''.join(aList))
#@+node:ekr.20200110014220.3: *5* c tokenize test
@language c

static exit_values_ty indent_main_loop(void)
{
    codes_ty         hd_type         = code_eof;
    char           * t_ptr           = NULL;
    codes_ty         type_code       = start_token;
    exit_values_ty   file_exit_value = total_success;
    int              dec_ind         = 0; /* current indentation for declarations */

    BOOLEAN          scase           = false; /* true when we've just see a "case";
                                               * determines what to do with the
                                               * following colon */
    BOOLEAN          flushed_nl;              /* Used when buffering up comments to remember that
                                               * a newline was passed over */
    BOOLEAN          sp_sw           = false; /* true when in the expression part of if(...),
                                               * while(...), etc. */
    BOOLEAN          force_nl        = false;

    /* last_token_ends_sp: True if we have just encountered the end of an if (...),
     * etc. (i.e. the ')' of the if (...) was the last token).  The variable is
     * set to 2 in the middle of the main token reading loop and is decremented
     * at the beginning of the loop, so it will reach zero when the second token
     * after the ')' is read.
     */

    BOOLEAN          last_token_ends_sp = false;

    BOOLEAN          last_else = false; /* true if last keyword was an else */

    for (;;)
    {
        /* this is the main loop.  it will go until
         * we reach eof */

        BOOLEAN is_procname_definition;
        bb_code_ty can_break;

        if (type_code != newline)
        {
            can_break = parser_state_tos->can_break;
        }

        parser_state_tos->last_saw_nl = false;
        parser_state_tos->can_break = bb_none;

        type_code = lexi ();    /* lexi reads one token.  "token" points to
                                 * the actual characters. lexi returns a code
                                 * indicating the type of token */

        /* If the last time around we output an identifier or
         * a paren, then consider breaking the line here if it's
         * too long.
         *
         * A similar check is performed at the end of the loop, after
         * we've put the token on the line. */

        if ((settings.max_col > 0) &&
            (buf_break != NULL) &&
            ( ( (parser_state_tos->last_token == ident) &&
                (type_code != comma) &&
                (type_code != semicolon) &&
                (type_code != newline) &&
                (type_code != form_feed) &&
                (type_code != rparen) &&
                (type_code != struct_delim)) ||
              ( (parser_state_tos->last_token == rparen) &&
                (type_code != comma) &&
                (type_code != rparen) ) ) &&
            (output_line_length () > settings.max_col))
        {
            break_line = 1;
        }

        if (last_token_ends_sp > 0)
        {
            last_token_ends_sp--;
        }

        is_procname_definition =
                (((parser_state_tos->procname[0] != '\0') &&
                  parser_state_tos->in_parameter_declaration) ||
                 (parser_state_tos->classname[0] != '\0'));

        /* The following code moves everything following an if (), while (),
         * else, etc. up to the start of the following stmt to a buffer. This
         * allows proper handling of both kinds of brace placement.
         */

        flushed_nl = false;

        if (!search_brace(&type_code, &force_nl, &flushed_nl, &last_else, &is_procname_definition))
        {
            /* Hit EOF unexpectedly in comment. */
            return indent_punt;
        }
        
        if (type_code == code_eof)
        {
            /* we got eof */
            if (s_lab != e_lab || s_code != e_code || s_com != e_com)   /* must dump end of line */
            {
                dump_line(true, &paren_target);
            }

            if (parser_state_tos->tos > 1)      /* check for balanced braces */
            {
                ERROR (_("Unexpected end of file"), 0, 0);
                file_exit_value = indent_error;
            }

            if (settings.verbose)
            {
                printf (_("There were %d non-blank output lines and %d comments\n"),
                        (int) out_lines, (int) com_lines);
                if (com_lines > 0 && code_lines > 0)
                {
                    printf (_("(Lines with comments)/(Lines with code): %6.3f\n"),
                            (1.0 * com_lines) / code_lines);
                }
            }
            flush_output ();

            return file_exit_value;                                              /* RETURN */
        }

        if ((type_code != comment) &&
            (type_code != cplus_comment) &&
            (type_code != newline) &&
            (type_code != preesc) &&
            (type_code != form_feed))
        {
            if (force_nl &&
                (type_code != semicolon) &&
                ( (type_code != lbrace) ||
                  (!parser_state_tos->in_decl && !settings.btype_2) ||
                  (parser_state_tos->in_decl && !settings.braces_on_struct_decl_line) ||
                  (parser_state_tos->last_token == rbrace)))
            {
                if (settings.verbose && !flushed_nl)
                {
                    WARNING (_("Line broken 2"), 0, 0);
                }

                flushed_nl = false;
                dump_line(true, &paren_target);
                parser_state_tos->want_blank = false;
                force_nl = false;
            }

            parser_state_tos->in_stmt = true;   /* turn on flag which causes
                                                 * an extra level of
                                                 * indentation. this is
                                                 * turned off by a ; or } */
            if (s_com != e_com)
            {
                /* the code has an embedded comment in the
                 * line. Move it from the com buffer to the
                 * code buffer.
                 *
                 * Do not add a space before the comment if it is the first
                 * thing on the line.
                 */

                if (e_code != s_code)
                {
                    set_buf_break (bb_embedded_comment_start, paren_target);
                    *e_code++ = ' ';
                    embedded_comment_on_line = 2;
                }
                else
                {
                    embedded_comment_on_line = 1;
                }

                for (t_ptr = s_com; *t_ptr; ++t_ptr)
                {
                    check_code_size();
                    *e_code++ = *t_ptr;
                }

                set_buf_break (bb_embedded_comment_end, paren_target);
                *e_code++ = ' ';
                *e_code = '\0'; /* null terminate code sect */
                parser_state_tos->want_blank = false;
                e_com = s_com;
            }
        }
        else if ((type_code != comment) &&
                 (type_code != cplus_comment) &&
                 !(settings.break_function_decl_args &&
                   (parser_state_tos->last_token == comma)) &&
                 !( (parser_state_tos->last_token == comma) &&
                    !settings.leave_comma))
        {
            /* preserve force_nl thru a comment but
             * cancel forced newline after newline, form feed, etc.
             * however, don't cancel if last thing seen was comma-newline
             * and -bc flag is on. */

            force_nl = false;
        }

        /* Main switch on type of token scanned */

        check_code_size();
        
        /* now, decide what to do with the token */

        handle_the_token(type_code, &scase, &force_nl, &sp_sw, &flushed_nl,
                         &hd_type, &dec_ind, &last_token_ends_sp, &file_exit_value,
                         can_break, &last_else, is_procname_definition);
        
        *e_code = '\0';         /* make sure code section is null terminated */

        if ((type_code != comment) &&
            (type_code != cplus_comment) &&
            (type_code != newline) &&
            (type_code != preesc) &&
            (type_code != form_feed))
        {
            parser_state_tos->last_token = type_code;
        }

        /* Now that we've put the token on the line (in most cases),
         * consider breaking the line because it's too long.
         *
         * Don't consider the cases of `unary_op', newlines,
         * declaration types (int, etc.), if, while, for,
         * identifiers (handled at the beginning of the loop),
         * periods, or preprocessor commands. */

        if ((settings.max_col > 0) && (buf_break != NULL))
        {
            if ( ( (type_code == binary_op) ||
                   (type_code == postop) ||
                   (type_code == question) ||
                   ((type_code == colon) && (scase || (squest <= 0))) ||
                   (type_code == semicolon) ||
                   (type_code == sp_nparen) ||
                   (type_code == sp_else) ||
                   ((type_code == ident) && (*token == '\"')) ||
                   (type_code == struct_delim) ||
                   (type_code == comma)) &&
                 (output_line_length () > settings.max_col))
            {
                break_line = 1;
            }
        }
    }                           /* end of main infinite loop */
}
#@+node:ekr.20200110014220.4: *4* @@test SyntaxSanitizer
from leo.core.leoBeautify import  SyntaxSanitizer
for child in p.subtree():
    child_s = child.b
    for keep in (True, False):
        # Setup.
        sanitizer = SyntaxSanitizer(c, keep)
        comment, result1 = sanitizer.comment_leo_lines(child)
        # Test basic round-tripping.
        result2 = sanitizer.uncomment_leo_lines(comment, child, s0=result1)
        assert child_s.rstrip() == result2.rstrip(), (
            f"Round-trip FAIL: keep: {keep}, {child.h}\n"
            f"{g.objToString(child_s, tag='child_s')}\n"
            f"{g.objToString(result1, tag='result1')}\n"
            f"{g.objToString(result2, tag='result2')}")
#@+node:ekr.20200110014220.5: *5* basic test
@language python
@
This is a doc part.
@c

def spam():
    if 1:
        # Regular comment.
        print('-----')
            # Indented comment.
    else:
        pass
#@+node:ekr.20200110014220.6: *5* @others & sections references
a = 1
<< section ref >>
b = 2

if 1:
    @others

# Note: section references will fail in if statements, because pass is not valid there:
    
    # if (
        # <section ref>
    # ):
        # pass
#@+node:ekr.20200110014220.7: *5* fast_at.scan_lines
@language python

def scan_lines(self, delims, first_lines, lines, path, start, test=False):
    '''Scan all lines of the file, creating vnodes.'''
    << init scan_lines >>
    << define dump_v >>
    i = 0 # To keep pylint happy.
    for i, line in enumerate(lines[start:]):
        # Order matters.
        << 1. common code for all lines >>
        << 2. short-circuit later tests >>
        << 3. handle @others >> # clears in_doc
        << 4. handle section refs >> # clears in_doc.
        # Order doesn't matter, but match more common sentinels first.
        << handle node_start >>
        << handle end of @doc & @code parts >>
        << handle @all >>
        << handle afterref >>
        << handle @first and @last >>
        << handle @comment >>
        << handle @delims >>
        << handle @raw >>
        << handle @-leo >>
        # These must be last, in this order.
        << Last 1. handle remaining @@ lines >>
        << Last 2. handle remaining @doc lines >>
        << Last 3. handle remaining @ lines >>
    else:
        # No @-leo sentinel
        return None, []
    # Handle @last lines.
    last_lines = lines[start+i:]
    if last_lines:
        last_lines = ['@last ' + z for z in last_lines]
        gnx2body[root_gnx] = gnx2body[root_gnx] + last_lines
    self.post_pass(gnx2body, gnx2vnode, root_v)
    return root_v, last_lines
#@+node:ekr.20200110014220.8: *6* << init scan_lines >>
#
# Simple vars...
afterref = False
    # A special verbatim line follows @afterref.
clone_v = None
    # The root of the clone tree.
    # When not None, we are scanning a clone and all it's descendants.
delim_start, delim_end = delims
    # The start/end delims.
doc_skip = (delim_start + '\n', delim_end + '\n')
    # To handle doc parts.
first_i = 0
    # Index into first array.
in_doc = False
    # True: in @doc parts.
in_raw = False
    # True: @raw seen.
is_cweb = delim_start == '@q@' and delim_end == '@>'
    # True: cweb hack in effect.
indent = 0 
    # The current indentation.
level_stack = []
    # Entries are (vnode, in_clone_tree)
n_last_lines = 0
    # The number of @@last directives seen.
root_seen = False
    # False: The next +@node sentinel denotes the root, regardless of gnx.
    # Needed to handle #1065 so reads will not create spurious child nodes.
sentinel = delim_start + '@'
    # Faster than a regex!
stack = []
    # Entries are (gnx, indent, body)
    # Updated when at+others, at+<section>, or at+all is seen.
verbline = delim_start + '@verbatim' + delim_end + '\n'
    # The spelling of at-verbatim sentinel
verbatim = False
    # True: the next line must be added without change.
#
# Init the data for the root node.
#

#
# Init the parent vnode for testing.
#
if self.test:
    root_gnx = gnx = 'root-gnx'
        # The node that we are reading.
        # start with the gnx for the @file node.
    gnx_head =  '<hidden top vnode>'
        # The headline of the root node.
    context = None
    parent_v = self.VNode(context=context, gnx=gnx)
    parent_v._headString = gnx_head
        # Corresponds to the @files node itself.
else:
    # Production.
    root_gnx = gnx = self.root.gnx
    context = self.c
    parent_v = self.root.v
root_v = parent_v
    # Does not change.
level_stack.append((root_v, False),)
#
# Init the gnx dict last.
#
gnx2vnode = self.gnx2vnode
    # Keys are gnx's, values are vnodes.
gnx2body = {}
    # Keys are gnxs, values are list of body lines.
gnx2vnode[gnx] = parent_v
    # Add gnx to the keys
gnx2body[gnx] = body = first_lines
    # Add gnx to the keys.
    # Body is the list of lines presently being accumulated.
#
# get the patterns.
after_pat, all_pat, code_pat, comment_pat, delims_pat,\
doc_pat, end_raw_pat, first_pat, last_pat, \
node_start_pat, others_pat, raw_pat, ref_pat = self.get_patterns(delims)
#@+node:ekr.20200110014220.9: *6* << define dump_v >>
def dump_v():
    '''Dump the level stack and v.'''
    print('----- LEVEL', level, v.h)
    print('       PARENT', parent_v.h)
    print('[')
    for i, data in enumerate(level_stack):
        v2, in_tree = data
        print('%2s %5s %s' % (i+1, in_tree, v2.h))
    print(']')
    print('PARENT.CHILDREN...')
    g.printObj([v3.h for v3 in parent_v.children])
    print('PARENTS...')
    g.printObj([v4.h for v4 in v.parents])
#@+node:ekr.20200110014220.10: *6* << 1. common code for all lines >>
if verbatim:
    # We are in raw mode, or other special situation.
    # Previous line was verbatim sentinel. Append this line as it is.
    if afterref:
        afterref = False
        if body: # a List of lines.
            body[-1] = body[-1].rstrip() + line
        else:
            body = [line]
        verbatim = False
    elif in_raw:
        m = end_raw_pat.match(line)
        if m:
            in_raw = False
            verbatim = False
        else:
             body.append(line)
             # Continue verbatim/raw mode.
    else:
        body.append(line)
        verbatim = False
    continue
if line == verbline: # <delim>@verbatim.
    verbatim = True
    continue
#
# Strip the line only once.
strip_line = line.strip()
#
# Undo the cweb hack.
if is_cweb and line.startswith(sentinel):
    line = line[:len(sentinel)] + line[len(sentinel):].replace('@@', '@')
# Adjust indentation.
if indent and line[:indent].isspace() and len(line) > indent:
    line = line[indent:]
#@+node:ekr.20200110014220.11: *6* << 2. short-circuit later tests >>
# This is valid because all following sections are either:
# 1. guarded by 'if in_doc' or
# 2. guarded by a pattern that matches the start of the sentinel.   
#
if not in_doc and not strip_line.startswith(sentinel):
    # lstrip() is faster than using a regex!
    body.append(line)
    continue
#@+node:ekr.20200110014220.12: *6* << 3. handle @others >>
m = others_pat.match(line)
if m:
    in_doc = False
    if m.group(2) == '+': # opening sentinel
        body.append('%s@others%s\n' % (m.group(1), m.group(3) or ''))
        stack.append((gnx, indent, body))
        indent += m.end(1) # adjust current identation
    else: # closing sentinel.
        # m.group(2) is '-' because the pattern matched.
        gnx, indent, body = stack.pop()
    continue
#@+node:ekr.20200110014220.13: *6* << 4. handle section refs >>
m = ref_pat.match(line)
if m:
    in_doc = False
    if m.group(2) == '+':
        # open sentinel.
        body.append(m.group(1) + g.angleBrackets(m.group(3)) + '\n')
        stack.append((gnx, indent, body))
        indent += m.end(1)
    else:
        # close sentinel.
        # m.group(2) is '-' because the pattern matched.
        gnx, indent, body = stack.pop()
    continue
#@+node:ekr.20200110014220.14: *6* << handle node_start >>
m = node_start_pat.match(line)
if m:
    in_doc, in_raw = False, False
    gnx, head = m.group(2), m.group(5)
    level = int(m.group(3)) if m.group(3) else 1 + len(m.group(4))
        # m.group(3) is the level number, m.group(4) is the number of stars.
    v = gnx2vnode.get(gnx)
    #
    # Case 1: The root @file node. Don't change the headline.
    if not root_seen:
        # Fix #1064: The node represents the root, regardless of the gnx!
        root_seen = True
        clone_v = None
        gnx2body[gnx] = body = []
        if not v:
            # Fix #1064.
            v = root_v
            # This message is annoying when using git-diff.
                # if gnx != root_gnx:
                    # g.es_print("using gnx from external file: %s" % (v.h), color='blue')
            gnx2vnode [gnx] = v
            v.fileIndex = gnx
        v.children = []
        continue
    #
    # Case 2: We are scanning the descendants of a clone.
    parent_v, clone_v = level_stack[level-2]
    if v and clone_v:
        # The last version of the body and headline wins..
        gnx2body[gnx] = body = []
        v._headString = head
        # Update the level_stack.
        level_stack = level_stack[:level-1]
        level_stack.append((v, clone_v),)
        # Always clear the children!
        v.children=[]
        parent_v.children.append(v)
        continue
    #
    # Case 3: we are not already scanning the descendants of a clone.
    if v:
        # The *start* of a clone tree. Reset the children.
        clone_v = v
        v.children = []
    else:
        # Make a new vnode.
        v = self.VNode(context=context, gnx=gnx)
    #
    # The last version of the body and headline wins.
    gnx2vnode[gnx] = v
    gnx2body[gnx] = body = []
    v._headString = head
    #
    # Update the stack.
    level_stack = level_stack[:level-1]
    level_stack.append((v, clone_v),)
    #
    # Update the links.
    assert v != root_v
    parent_v.children.append(v)
    v.parents.append(parent_v)
    # dump_v()
    continue
#@+node:ekr.20200110014220.15: *6* << handle end of @doc & @code parts >>
if in_doc:
    # When delim_end exists the doc block:
    # - begins with the opening delim, alonw on its own line
    # - ends with the closing delim, alone on its own line.
    # Both of these lines should be skipped
    if line in doc_skip:
        # doc_skip is (delim_start + '\n', delim_end + '\n')
        continue
    #
    # Check for @c or @code.
    m = code_pat.match(line)
    if m:
        in_doc = False 
        body.append('@code\n' if m.group(1) else '@c\n')
        continue
else:
    m = doc_pat.match(line)
    if m:
        # @+at or @+doc?
        doc = '@doc' if m.group(1) == 'doc' else '@'
        doc2 = m.group(2) or '' # Trailing text.
        if doc2:
            body.append('%s%s\n'%(doc, doc2))
        else:
            body.append(doc + '\n')
        # Enter @doc mode.
        in_doc = True
        continue
#@+node:ekr.20200110014220.16: *6* << handle @all >>
m = all_pat.match(line)
if m:
    # @all tells Leo's *write* code not to check for undefined sections.
    # Here, in the read code, we merely need to add it to the body.
    # Pushing and popping the stack may not be necessary, but it can't hurt.
    if m.group(2) == '+': # opening sentinel
        body.append('%s@all%s\n' % (m.group(1), m.group(3) or ''))
        stack.append((gnx, indent, body))
    else: # closing sentinel.
        # m.group(2) is '-' because the pattern matched.
        gnx, indent, body = stack.pop()
        gnx2body[gnx] = body
    continue
#@+node:ekr.20200110014220.17: *6* << handle afterref >>
m = after_pat.match(line)
if m:
    afterref = True
    verbatim = True
        # Avoid an extra test in the main loop.
    continue
#@+node:ekr.20200110014220.18: *6* << handle @first and @last >>
m = first_pat.match(line)
if m:
    if 0 <= first_i < len(first_lines):
        body.append('@first ' + first_lines[first_i])
        first_i += 1
    else:
        g.trace('\ntoo many @first lines: %s' %  path)
        print('@first is valid only at the start of @<file> nodes\n')
        g.printObj(first_lines, tag='first_lines')
        g.printObj(lines[start:i+2], tag='lines[start:i+2]')
    continue
m = last_pat.match(line)
if m:
    n_last_lines += 1
    continue
#@+node:ekr.20200110014220.19: *6* << handle @comment >>
# http://leoeditor.com/directives.html#part-4-dangerous-directives
m = comment_pat.match(line)
if m:
    # <1, 2 or 3 comment delims>
    delims = m.group(1).strip()
    # Whatever happens, retain the @delims line.
    body.append('@comment %s\n' % delims)
    delim1, delim2, delim3 = g.set_delims_from_string(delims)
        # delim1 is always the single-line delimiter.
    if delim1:
        delim_start, delim_end = delim1, ''
    else:
        delim_start, delim_end = delim2, delim3
    #
    # Within these delimiters:
    # - double underscores represent a newline.
    # - underscores represent a significant space,
    delim_start = delim_start.replace('__','\n').replace('_',' ')
    delim_end = delim_end.replace('__','\n').replace('_',' ')
    # Recalculate all delim-related values
    doc_skip = (delim_start + '\n', delim_end + '\n')
    is_cweb = delim_start == '@q@' and delim_end == '@>'
    sentinel = delim_start + '@'
    #
    # Recalculate the patterns.
    delims = delim_start, delim_end
    (
        after_pat, all_pat, code_pat, comment_pat, delims_pat,
        doc_pat, end_raw_pat, first_pat, last_pat,
        node_start_pat, others_pat, raw_pat, ref_pat
    ) = self.get_patterns(delims)
    continue
#@+node:ekr.20200110014220.20: *6* << handle @delims >>
m = delims_pat.match(line)
if m:
    # Get 1 or 2 comment delims
    # Whatever happens, retain the original @delims line.
    delims = m.group(1).strip()
    body.append('@delims %s\n' % delims)
    #
    # Parse the delims.
    delims_pat = re.compile(r'^([^ ]+)\s*([^ ]+)?')
    m2 = delims_pat.match(delims)
    if not m2:
        g.trace('Ignoring invalid @comment: %r' % line)
        continue
    delim_start = m2.group(1)
    delim_end = m2.group(2) or ''
    #
    # Within these delimiters:
    # - double underscores represent a newline.
    # - underscores represent a significant space,
    delim_start = delim_start.replace('__','\n').replace('_',' ')
    delim_end = delim_end.replace('__','\n').replace('_',' ')
    # Recalculate all delim-related values
    doc_skip = (delim_start + '\n', delim_end + '\n')
    is_cweb = delim_start == '@q@' and delim_end == '@>'
    sentinel = delim_start + '@'
    #
    # Recalculate the patterns
    delims = delim_start, delim_end
    (
        after_pat, all_pat, code_pat, comment_pat, delims_pat,
        doc_pat, end_raw_pat, first_pat, last_pat,
        node_start_pat, others_pat, raw_pat, ref_pat
    ) = self.get_patterns(delims)
    continue
#@+node:ekr.20200110014220.21: *6* << handle @raw >>
# http://leoeditor.com/directives.html#part-4-dangerous-directives
m = raw_pat.match(line)
if m:
    in_raw = True
    verbatim = True
        # Avoid an extra test in the main loop.
    continue
#@+node:ekr.20200110014220.22: *6* << handle @-leo >>
if line.startswith(delim_start + '@-leo'):
    i += 1
    break
#@+node:ekr.20200110014220.23: *6* << Last 1. handle remaining @@ lines >>
# @first, @last, @delims and @comment generate @@ sentinels,
# So this must follow all of those.
if line.startswith(delim_start + '@@'):
    ii = len(delim_start) + 1 # on second '@'
    jj = line.rfind(delim_end) if delim_end else -1
    body.append(line[ii:jj] + '\n')
    continue
#@+node:ekr.20200110014220.24: *6* << Last 2. handle remaining @doc lines >>
if in_doc:
    if delim_end:
        # doc lines are unchanged.
        body.append(line)
    else:
        # Doc lines start with start_delim + one blank.
        body.append(line[len(delim_start)+1:])
    continue
#@+node:ekr.20200110014220.25: *6* << Last 3. handle remaining @ lines >>
# Handle an apparent sentinel line.
# This *can* happen, as the result of the git-diff command.
#
# This assert verifies the short-circuit test.
assert strip_line.startswith(sentinel), (repr(sentinel), repr(line))
#
# This trace is less important, but interesting.
g.trace(f"{g.shortFileName(self.path)}: unexpected line: {line.strip()!r}")
body.append(line)
#@+node:ekr.20150530061745.1: *4* function: main & helpers
def main():
    """External entry point for Leo's beautifier."""
    t1 = time.process_time()
    base = g.os_path_abspath(os.curdir)
    files, options = scan_options()
    for path in files:
        path = g.os_path_finalize_join(base, path)
        beautify(options, path)
    print(f'beautified {len(files)} files in {time.process_time()-t1:4.2f} sec.')
#@+node:ekr.20150601170125.1: *5* beautify (stand alone)
def beautify(options, path):
    """Beautify the file with the given path."""
    fn = g.shortFileName(path)
    s, e = g.readFileIntoString(path)
    if not s:
        return
    print(f"beautifying {fn}")
    try:
        s1 = g.toEncodedString(s)
        node1 = ast.parse(s1, filename='before', mode='exec')
    except IndentationError:
        g.warning(f"IndentationError: can't check {fn}")
        return
    except SyntaxError:
        g.warning(f"SyntaxError: can't check {fn}")
        return
    readlines = g.ReadLinesClass(s).next
    tokens = list(tokenize.generate_tokens(readlines))
    x = PythonTokenBeautifier(c=None)
    # Compute the tokens.
    s2 = x.scan_all_tokens(s, tokens)
    try:
        s2_e = g.toEncodedString(s2)
        node2 = ast.parse(s2_e, filename='before', mode='exec')
    except IndentationError:
        g.warning(f"{fn}: IndentationError in result")
        g.es_print(f"{fn} will not be changed")
        g.printObj(s2, tag='RESULT')
        return
    except SyntaxError:
        g.warning(f"{fn}: Syntax error in result")
        g.es_print(f"{fn} will not be changed")
        g.printObj(s2, tag='RESULT')
        return
    except Exception:
        g.warning(f"{fn}: Unexpected exception creating the \"after\" parse tree")
        g.es_print(f"{fn} will not be changed")
        g.es_exception()
        g.printObj(s2, tag='RESULT')
        return
    ok = leoAst.compare_asts(node1, node2)
    if not ok:
        print(f"failed to beautify {fn}")
        return
    with open(path, 'wb') as f:
        f.write(s2_e)
#@+node:ekr.20150601162203.1: *5* scan_options (stand alone)
def scan_options():
    """Handle all options. Return a list of files."""
    # This automatically implements the --help option.
    usage = "usage: python -m leo.core.leoBeautify file1, file2, ..."
    parser = optparse.OptionParser(usage=usage)
    add = parser.add_option
    add(
        '-d',
        '--debug',
        action='store_true',
        dest='debug',
        help='print the list of files and exit',
    )
    # add('-k', '--keep-blank-lines', action='store_true', dest='keep',
        # help='keep-blank-lines')
    # Parse the options.
    options, files = parser.parse_args()
    if options.debug:
        # Print the list of files and exit.
        g.trace('files...', files)
        sys.exit(0)
    return files, options
#@+node:ekr.20191028141311.1: *4* test_FstringifyTokens
def test_FstringifyTokens(c, contents,
    dump=True,
    dump_input_tokens=False,
    dump_output_tokens=False,
):
    # pylint: disable=import-self
    import tokenize
    import leo.core.leoBeautify as leoBeautify
    # Tokenize.
    tokens = list(tokenize.tokenize(io.BytesIO(contents.encode('utf-8')).readline))
    # Create a list of input tokens (BeautifierTokens).
    x = leoBeautify.FstringifyTokens(c)
    x.dump_input_tokens = dump_input_tokens
    x.dump_output_tokens = dump_output_tokens
    # Scan the input tokens, creating, a string.
    results = x.scan_all_tokens(contents, tokens)
    # Show results.
    print('')
    show(contents, 'Contents', dump=dump)
    print('')
    show(results, 'Results', dump=dump)
#@+node:ekr.20191028140946.1: *4* test_NullTokenBeautifier
def test_NullTokenBeautifier(c, contents,
    dump=True,
    dump_input_tokens=False,
    dump_output_tokens=False,
):

    # pylint: disable=import-self
    import tokenize
    import leo.core.leoBeautify as leoBeautify
    # Tokenize.
    tokens = list(tokenize.tokenize(io.BytesIO(contents.encode('utf-8')).readline))
    # Untokenize.
    x = leoBeautify.NullTokenBeautifier(c)
    x.dump_input_tokens = dump_input_tokens
    x.dump_output_tokens = dump_output_tokens
    results = x.scan_all_tokens(contents, tokens)
    # Show results.
    show(contents, 'Contents', dump=dump)
    print('')
    show(results, 'Results', dump=dump)
    return contents == results
#@+node:ekr.20191029184028.1: *4* test_PythonTokenBeautifier
def test_PythonTokenBeautifier(c, contents,
    dump=True,
    dump_input_tokens=False,
    dump_output_tokens=False,
):

    # pylint: disable=import-self
    import tokenize
    import leo.core.leoBeautify as leoBeautify
    # Create 5-tuples.
    tokens = list(tokenize.tokenize(io.BytesIO(contents.encode('utf-8')).readline))
    # Beautify.
    x = leoBeautify.PythonTokenBeautifier(c)
    x.dump_input_tokens = dump_input_tokens
    x.dump_output_tokens = dump_output_tokens
    results = x.scan_all_tokens(contents, tokens)
    # Show results.
    print('')
    show(contents, 'Contents', dump)
    print('')
    show(results, 'Results', dump)
    return results.strip() == contents.strip()
#@+node:ekr.20200110015014.2: *4* These tests use only python's tokenize module
#@+node:ekr.20200110015014.3: *5* @@test bad input order 
from tokenize import Untokenizer
u = Untokenizer()
u.prev_row = 2
u.prev_col = 2
with self.assertRaises(ValueError) as cm:
    u.add_whitespace((1,3))
self.assertEqual(cm.exception.args[0],
    'start (1,3) precedes previous end (2,2)')
# raise if previous column in row
self.assertRaises(ValueError, u.add_whitespace, (2,1))
#@+node:ekr.20200110015014.4: *5* @@test backslash continuation
from tokenize import Untokenizer
import test.test_tokenize as tt
u = Untokenizer()
u.prev_row = 1
u.prev_col =  1
u.tokens = []
u.add_whitespace((2, 0))
self.assertEqual(u.tokens, ['\\\n'])
u.prev_row = 2
u.add_whitespace((4, 4))
self.assertEqual(u.tokens, ['\\\n', '\\\n\\\n', '    '])
tt.TestRoundtrip.check_roundtrip(self, 'a\n  b\n    c\n  \\\n  c\n')
#@+node:ekr.20200110015014.5: *5* @@test iter compat
from tokenize import untokenize, Untokenizer, NAME, ENCODING

u = Untokenizer()
token = (NAME, 'Hello')
tokens = [(ENCODING, 'utf-8'), token]
u.compat(token, iter([]))
self.assertEqual(u.tokens, ["Hello "])
u = Untokenizer()
self.assertEqual(u.untokenize(iter([token])), 'Hello ')
u = Untokenizer()
self.assertEqual(u.untokenize(iter(tokens)), 'Hello ')
self.assertEqual(u.encoding, 'utf-8')
self.assertEqual(untokenize(iter(tokens)), b'Hello ')
    # *not* u.untokenize.
#@+node:ekr.20150605175037.1: ** From leoCheck.py & checkerCommands.py
@first # -*- coding: utf-8 -*-
"""Experimental code checking for Leo."""
# To do:
# - Option to ignore defs without args if all calls have no args.
# * explain typical entries
import importlib
import leo.core.leoGlobals as g
import leo.core.leoAst as leoAst
importlib.reload(leoAst)
import ast
# import glob
import importlib
import os
import re
import time
@others
@language python
@tabwidth -4
@pagewidth 70
#@+node:ekr.20171207095816.1: *3* class ConventionChecker
class ConventionChecker:
    """
    A prototype of an extensible convention-checking tool.
    See: https://github.com/leo-editor/leo-editor/issues/632
    
    Here is the body of @button check-conventions:
    
        g.cls()
        if c.changed: c.save()
        
        import importlib
        import leo.core.leoCheck as leoCheck
        importlib.reload(leoCheck)
        
        fn = g.os_path_finalize_join(g.app.loadDir, '..', 'plugins', 'nodetags.py')
        leoCheck.ConventionChecker(c).check(fn=fn)
    """
    # pylint: disable=literal-comparison
        # What's wrong with `if self.test_kind is 'test'`?

    ignore = ('bool', 'dict', 'enumerate', 'list', 'tuple')
        # Things that look like function calls.

    @others
#@+node:ekr.20171210134449.1: *4* checker.Birth
def __init__(self, c):
    self.c = c
    self.class_name = None
    self.context_stack = []
        # Stack of ClassDef and FunctionDef nodes.
    # Rudimentary symbol tables...
    self.classes = self.init_classes()
    self.special_class_names = [
        'Commands', 'LeoGlobals', 'Position', 'String', 'VNode', 'VNodeBase',
    ]
    self.special_names_dict = self.init_special_names()
    # Debugging
    self.enable_trace = True
    self.file_name = None
    self.indent = 0 # For self.format.
    self.max_time = 0.0
    self.recursion_count = 0
    self.slowest_file = None
    self.stats = self.CCStats()
    # Other ivars...
    self.errors = 0
    self.line_number = 0
    self.pass_n = 0
    self.test_kind = None
    self.unknowns = {} # Keys are expression, values are (line, fn) pairs.
#@+node:ekr.20171209044610.1: *5* checker.init_classes
def init_classes(self):
    """
    Init the symbol tables with known classes.
    """
    return {
        # Pre-enter known classes.
        'Commands': {
            'ivars': {
                'p': self.Type('instance', 'Position'),
            },
            'methods': {},
        },
        'LeoGlobals': {
            'ivars': {}, # g.app, g.app.gui.
            'methods': {
                'trace': self.Type('instance', 'None')
            },
        },
        'Position': {
            'ivars': {
                'v': self.Type('instance', 'VNode'),
                'h': self.Type('instance', 'String'),
            },
            'methods': {},
        },
        'VNode': {
            'ivars': {
                'h': self.Type('instance', 'String'),
                # Vnode has no v instance!
            },
            'methods': {},
        },
        'VNodeBase': {
            'ivars': {},
            'methods': {},
        },
        'String': {
            'ivars': {},
            'methods': {}, # Possible?
        },
    }
    
#@+node:ekr.20171210133853.1: *5* checker.init_special_names
def init_special_names(self):
    """Init known special names."""
    t = self.Type
    return {
        'c': t('instance', 'Commands'),
        'c.p': t('instance', 'Position'),
        'g': t('instance', 'LeoGlobals'), # module?
        'p': t('instance', 'Position'),
        'v': t('instance', 'VNode'),
    }
#@+node:ekr.20171212015700.1: *4* checker.check & helpers (main entry)
def check(self):
    """
    The main entry point for the convention checker.

    A stand-alone version of the @button node that tested the
    ConventionChecker class.
    
    The check-conventions command in checkerCommands.py saves c and
    reloads the leoCheck module before instantiating this class and
    calling this method.
    """
    g.cls()
    c = self.c
    kind = 'production' # <----- Change only this line.
        # 'production', 'project', 'coverage', 'leo', 'lib2to3', 'pylint', 'rope'
    join = g.os_path_finalize_join
    loadDir = g.app.loadDir
    report_stats = True
    files_table = (
        # join(loadDir, 'leoCommands.py'),
        # join(loadDir, 'leoNodes.py'),
        join(loadDir, '..', 'plugins', 'qt_tree.py'),
    )
    # ===== Don't change anything below here =====
    if kind == 'files':
        for fn in files_table:
            self.check_file(fn=fn, trace_fn=True)
    elif kind == 'production':
        for p in g.findRootsWithPredicate(c, c.p, predicate=None):
            self.check_file(fn=g.fullPath(c, p), test_kind=kind, trace_fn=True)
    elif kind in ('project', 'coverage', 'leo', 'lib2to3', 'pylint', 'rope'):
        project_name = 'leo' if kind == 'project' else kind
        self.check_project(project_name)
    elif kind == 'test':
        self.test()
    else:
        g.trace('unknown kind', repr(kind))
    if report_stats:
        self.stats.report()
#@+node:ekr.20171207100432.1: *5* checker.check_file
def check_file(self, fn=None, s=None, test_kind=None, trace_fn=False):
    """Check the contents of fn or the string s."""
    # Get the source.
    if test_kind:
        self.test_kind = test_kind
    if fn:
        sfn = g.shortFileName(fn)
        if g.os_path_exists(fn):
            s, e = g.readFileIntoString(fn)
            if s:
                s = g.toEncodedString(s, encoding=e)
            else:
                g.trace('empty file:', sfn)
                return
        else:
            g.trace('file not found:', sfn)
            return
    elif s:
        sfn = '<string>'
    else:
        g.trace('no fn or s argument')
        return
    # Check the source
    if trace_fn:
        if fn:
            print(f"===== {sfn}")
        else:
            print('===== <string>\n%s\n----- </string>\n' % s.rstrip())
    t1 = time.process_time()
    node = ast.parse(s, filename='before', mode='exec')
    self.check_helper(fn=sfn, node=node, s=s)
    t2 = time.process_time()
    t_tot = t2-t1
    if t_tot > self.max_time:
        self.max_time = t_tot
        self.slowest_file = self.file_name
#@+node:ekr.20171214150828.1: *5* checker.check_helper
def check_helper(self, fn, node, s):

    cct = self.CCTraverser(controller=self)
    for n in 1, 2:
        if self.test_kind == 'test':
            g.trace('===== PASS', n)
        # Init this pass.
        self.file_name = fn
        self.indent = 0
        self.pass_n = n
        cct.visit(node)
    self.end_file()
#@+node:ekr.20171213013004.1: *5* checker.check_project
def check_project(self, project_name):
    
    trace_fn = True
    trace_skipped = False
    self.test_kind = 'project'
    fails_dict = {
        'coverage': ['cmdline.py',],
        'lib2to3': ['fixer_util.py', 'fix_dict.py', 'patcomp.py', 'refactor.py'],
        'leo': [], # All of Leo's core files pass.
        'pylint': [
            'base.py', 'classes.py', 'format.py',
            'logging.py', 'python3.py', 'stdlib.py', 
            'docparams.py', 'lint.py',
        ],
        'rope': ['objectinfo.py', 'objectdb.py', 'runmod.py',],
    }
    fails = fails_dict.get(project_name, [])
    utils = ProjectUtils()
    files = utils.project_files(project_name, force_all=False)
    if files:
        t1 = time.process_time()
        for fn in files:
            sfn = g.shortFileName(fn)
            if sfn in fails or fn in fails:
                if trace_skipped: print('===== skipping', sfn)
            else:
                self.check_file(fn=fn, trace_fn=trace_fn)
        t2 = time.process_time()
        print('%s files in %4.2f sec. max %4.2f sec in %s' % (
            len(files), (t2-t1), self.max_time, self.slowest_file))
        if self.errors:
            print(f"{self.errors} error{g.plural(self.errors)}")
    else:
        print(f"no files for project: {project_name}")
#@+node:ekr.20171208135642.1: *5* checker.end_file & helper
def end_file(self,trace_classes=False, trace_unknowns=False):
    
    # Do *not* clear self.classes.
    self.unknowns = {}
#@+node:ekr.20171212100005.1: *6* checker.trace_unknowns
def trace_unknowns(self):
    print('----- Unknown ivars...')
    d = self.unknowns
    max_key = max([len(key) for key in d ]) if d else 2
    for key, aList in sorted(d.items()):
        # Remove duplicates that vary only in line number.
        aList2, seen = [], []
        for data in aList:
            line, fn, s = data
            data2 = (key, fn, s)
            if data2 not in seen:
                seen.append(data2)
                aList2.append(data)
        for data in aList2:
            line, fn, s = data
            print('%*s %4s %s: %s' % (
                max_key, key, line, fn, g.truncate(s, 60)))
#@+node:ekr.20171212020013.1: *5* checker.test
tests = [
'''\
class TC:
    def __init__(self, c):
        c.tc = self
    def add_tag(self, p):
        print(p.v) # AttributeError if p is a vnode.

class Test:
    def __init__(self,c):
        self.c = c
        self.tc = self.c.tc
    def add_tag(self):
        p = self.c.p
        self.tc.add_tag(p.v) # WRONG: arg should be p.
''', # comma required!
]

def test(self):

    for s in self.tests:
        s = g.adjustTripleString(s, self.c.tab_width)
        self.check_file(s=s, test_kind='test', trace_fn=True)
    if self.errors:
        print(f"{self.errors} error{g.plural(self.errors)}")
#@+node:ekr.20171216063026.1: *4* checker.error, fail, note & log_line
def error(self, node, *args, **kwargs):
    
    self.errors += 1
    print('')
    print('Error: %s' % self.log_line(node, *args, **kwargs))
    print('')
    
def fail(self, node, *args, **kwargs):
    self.stats.inference_fails += 1
    print('')
    print('Inference failure: %s' % self.log_line(node, *args, **kwargs))
    print('')
    
def log_line(self, node=None, *args, **kwargs):
    # pylint: disable=keyword-arg-before-vararg
        # putting *args first is invalid in Python 2.x.
    return 'line: %s file: %s: %s' % (
        getattr(node, 'lineno', '??'),
        self.file_name or '<string>',
        ' '.join([z if isinstance(z, str) else repr(z) for z in args]),
    )
    
def note(self, node, *args, **kwargs):

    print('')
    print('Note: %s' % self.log_line(node, *args, **kwargs))
    print('')
#@+node:ekr.20171215080831.1: *4* checker.dump, format
def dump(self, node, annotate_fields=True, level=0, **kwargs):
    """Dump the node."""
    return leoAst.AstDumper().dump(node, level=level)

def format(self, node, *args, **kwargs):
    """Format the node and possibly its descendants, depending on args."""
    s = leoAst.AstFormatter().format(node, level=self.indent, *args, **kwargs)
    return s.rstrip()
#@+node:ekr.20171208142646.1: *4* checker.resolve & helpers
def resolve(self, node, name, context, trace=False):
    """Resolve name in the given context to a Type."""
    self.stats.resolve += 1
    assert isinstance(name, str), (repr(name), g.callers())
    if context:
        if context.kind in ('error', 'unknown'):
            result = context
        elif name == 'self':
            if context.name:
                result = self.Type('instance', context.name)
            else:
                g.trace('===== NO OBJECT NAME')
                result = self.Type('error', 'no object name')
        elif context.kind in ('class', 'instance'):
            result = self.resolve_ivar(node, name, context)
        else:
            result = self.Type('error', f"unknown kind: {context.kind}")
    else:
        result = self.Type('error', f"unbound name: {name}")
    return result
#@+node:ekr.20171208134737.1: *5* checker.resolve_call
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def resolve_call(self, node):
    """Resolve the head of the call's chain to a Type."""
    assert self.pass_n == 2
    self.stats.resolve_call += 1
    chain = self.get_chain(node.func)
    if chain:
        func = chain.pop()
        if isinstance(func, ast.Name):
            func = func.id
        assert isinstance(func, str), repr(func)
    if chain:
        assert isinstance(chain[0], ast.Name), repr(chain[0])
        chain[0] = chain[0].id
        # args = ','.join([self.format(z) for z in node.args])
        self.recursion_count = 0
        if self.class_name:
            context = self.Type('instance', self.class_name)
        else:
            context = self.Type('module', self.file_name)
        result = self.resolve_chain(node, chain, context)
    else:
        result = self.Type('unknown', 'empty chain')
    assert isinstance(result, self.Type), repr(result)
    return result
#@+node:ekr.20171209034244.1: *5* checker.resolve_chain
def resolve_chain(self, node, chain, context, trace=False):
    """Resolve the chain to a Type."""
    self.stats.resolve_chain += 1
    name = '<no name>'
    for obj in chain:
        name = obj.id if isinstance(obj, ast.Name) else obj
        assert isinstance(name, str), (repr(name), g.callers())
        context = self.resolve(node, name, context, trace=trace)
    assert isinstance(context, self.Type), repr(context)
    return context
#@+node:ekr.20171208173323.1: *5* checker.resolve_ivar & helpers
def resolve_ivar(self, node, ivar, context):
    """Resolve context.ivar to a Type."""
    assert self.pass_n == 2, repr(self.pass_n)
    self.stats.resolve_ivar += 1
    class_name = 'Commands' if context.name == 'c' else context.name
    self.recursion_count += 1
    if self.recursion_count > 20:
        self.report_unbounded_recursion(node, class_name, ivar, context)
        return self.Type('error', 'recursion')
    the_class = self.classes.get(class_name)
    if not the_class:
        return self.Type('error', f"no class {ivar}")
    ivars = the_class.get('ivars')
    methods = the_class.get('methods')
    if ivar == 'self':
        return self.Type('instance', class_name)
    if methods.get(ivar):
        return self.Type('func', ivar)
    if ivars.get(ivar):
        val = ivars.get(ivar)
        if isinstance(val, self.Type):
            return val
        # Check for pre-defined special names.
        for special_name, special_obj in self.special_names_dict.items():
            tail = val[len(special_name):]
            if val == special_name:
                return special_obj
            if val.startswith(special_name) and tail.startswith('.'):
                # Resovle the rest of the tail in the found context.
                return self.resolve_chain(node, tail[1:], special_obj)
        # Avoid recursion .
        head = val.split('.')
        if ivar in (val, head[0]):
            return self.Type('unknown', ivar)
        for name2 in head:
            old_context = context
            context = self.resolve(node, name2, context)
            if 0: g.trace('recursive %s: %r --> %r' % (name2, old_context, context))
        if 0: g.trace('END RECURSIVE: %r', context)
        return context
    if ivar in self.special_names_dict:
        val = self.special_names_dict.get(ivar)
        return val
    # Remember the unknown.
    self.remember_unknown_ivar(ivar)
    return self.Type('error', f"no member {ivar}")
#@+node:ekr.20171217102701.1: *6* checker.remember_unknown_ivar
def remember_unknown_ivar(self, ivar):

    d = self.unknowns
    aList = d.get(ivar, [])
    data = (self.line_number, self.file_name)
    aList.append(data)
    # tag:setter (data describing unknown ivar)
    d[ivar] = aList
    # self.error(node, 'No member:', ivar)
    return self.Type('error', 'no member %s' % ivar)
#@+node:ekr.20171217102055.1: *6* checker.report_unbounded_recursion
def report_unbounded_recursion(self, node, class_name, ivar, context):
    
    the_class = self.classes.get(class_name)
    self.error(node, 'UNBOUNDED RECURSION: %r %r\nCallers: %s' % (
        ivar, context, g.callers()))
    if 0:
        g.trace('CLASS DICT: Commands')
        g.printDict(self.classes.get('Commands'))
    if 0:
        g.trace('CLASS DICT', class_name)
        g.printDict(the_class)
#@+node:ekr.20171209065852.1: *5* checker_check_signature & helpers
def check_signature(self, node, func, args, signature):
    
    self.stats.check_signature += 1
    if signature[0] == 'self':
        signature = signature[1:]
    result = 'ok'
    for i, arg in enumerate(args):
        if i < len(signature):
            result = self.check_arg(node, func, args, arg, signature[i])
            if result == 'fail':
                self.fail(node, '\n%s(%s) incompatible with %s(%s)' % (
                    func, ','.join(args),
                    func, ','.join(signature),
                ))
                break
    if result == 'ok':
        self.stats.sig_ok += 1
    elif result == 'fail':
        self.stats.sig_fail += 1
    else:
        assert result == 'unknown'
        self.stats.sig_unknown += 1
#@+node:ekr.20171212034531.1: *6* checker.check_arg (Finish)
def check_arg(self, node, func, args, call_arg, sig_arg):
    """
    Check call_arg and sig_arg with arg (a list).
    
    To do: check keyword args.
    """
    return self.check_arg_helper(node, func, call_arg, sig_arg)

#@+node:ekr.20171212035137.1: *6* checker.check_arg_helper
def check_arg_helper(self, node, func, call_arg, sig_arg):

    special_names_dict = self.special_names_dict
    if call_arg == sig_arg or sig_arg in (None, 'None'):
        # Match anything against a default value of None.
        return 'ok'
    # Resolve the call_arg if possible.
    chain = call_arg.split('.')
    if len(chain) > 1:
        head, tail = chain[0], chain[1:]
        if head in special_names_dict:
            context = special_names_dict.get(head)
            context = self.resolve_chain(node, tail, context)
            if context.kind == 'error':
                # Caller will report the error.
                return 'unknown'
            if sig_arg in special_names_dict:
                sig_class = special_names_dict.get(sig_arg)
                return self.compare_classes(
                    node, call_arg, sig_arg, context, sig_class)
    if sig_arg in special_names_dict and call_arg in special_names_dict:
        sig_class = special_names_dict.get(sig_arg)
        call_class = special_names_dict.get(call_arg)
        return self.compare_classes(
            node, call_arg, sig_arg, call_class, sig_class)
    return 'unknown'
#@+node:ekr.20171212044621.1: *6* checker.compare_classes
def compare_classes(self, node, arg1, arg2, class1, class2):

    if class1 == class2:
        self.stats.sig_infer_ok += 1
        return 'ok'
    # The caller reports the failure.
    # self.error(node, 'FAIL', arg1, arg2, class1, class2)
    self.stats.sig_infer_fail += 1
    return 'fail'
#@+node:ekr.20171215074959.1: *4* checker.Visitors & helpers
#@+node:ekr.20171215074959.2: *5* checker.Assign & helpers
def before_Assign(self, node):
    
    s = self.format(node)
    if self.test_kind == 'test': print(s)
    if self.pass_n == 1:
        return
    self.stats.assignments += 1
    for target in node.targets:
        chain = self.get_chain(target)
        if len(chain) == 2:
            var1, var2 = chain
            assert isinstance(var1, ast.Name), repr(var1)
            assert isinstance(var2, str), repr(var2)
            name = var1.id
            if name == 'self':
                self.do_assn_to_self(node, name, var2)
            elif name in self.special_names_dict:
                self.do_assn_to_special(node, name, var2)
#@+node:ekr.20171215074959.4: *6* checker.do_assn_to_self
def do_assn_to_self(self, node, var1, var2):

    assert self.pass_n == 2
    assert var1 == 'self'
    class_name = self.class_name
    if not class_name:
        self.note(node, 'SKIP: no class name', self.format(node))
        return
    if class_name in self.special_class_names:
        # self.note(node, 'SKIP: not special', self.format(node))
        return
    d = self.classes.get(class_name)
    assert d is not None, class_name
    ivars = d.get('ivars')
    ivars[var2] = self.format(node.value)
    d['ivars'] = ivars
#@+node:ekr.20171215074959.3: *6* checker.do_assn_to_special
def do_assn_to_special(self, node, var1, var2):

    assert self.pass_n == 2
    assert var1 in self.special_names_dict, (repr(var1))
    class_name = self.class_name
    t = self.special_names_dict.get(var1)
    if not t:
        if 0: self.note(node, 'not special', var1, self.format(node).strip())
        return
    # Do not set members within the class itself.
    if t.kind == 'instance' and t.name == class_name:
        if 0: self.note(node, 'SKIP', var1, class_name)
        return
    # Resolve val, if possible.
    context = self.Type(
        'instance' if class_name else 'module',
        class_name or self.file_name,
    )
    self.recursion_count = 0
    value_s = self.format(node.value)
    resolved_type = self.resolve(node, value_s, context, trace=False)
    assert isinstance(resolved_type, self.Type), repr(resolved_type)
    if 0:
        self.note(node, f"context {context} : {value_s} ==> {resolved_type}")
    # Update var1's dict, not class_name's dict.
    d = self.classes.get(t.name)
    ivars = d.get('ivars')
    # tag:setter ivar1.ivar2 = Type
    ivars[var2] = resolved_type
    d['ivars'] = ivars
#@+node:ekr.20171215074959.5: *5* checker.Call
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def before_Call(self, node):

    if self.test_kind == 'test':
        print(self.format(node))
    if self.pass_n == 1:
        return
    self.stats.calls += 1
    context = self.resolve_call(node)
    assert isinstance(context, self.Type)
    if context.kind != 'instance':
        return
    instance = self.classes.get(context.name)
    if not instance:
        return
    chain = self.get_chain(node.func)
    func = chain[-1]
    d = instance.get('methods')
    signature = d.get(func)
    if not signature:
        return
    if isinstance(signature, self.Type):
        pass # Already checked?
    else:
        args = [self.format(z) for z in node.args]
        signature = signature.split(',')
        self.check_signature(node, func, args, signature)
#@+node:ekr.20171215074959.7: *5* checker.ClassDef
def before_ClassDef(self, node):

    s = self.format(node, print_body=False)
    if self.test_kind == 'test': print(s)
    self.indent += 1
    self.context_stack.append(node)
    self.class_name = name = node.name
    if self.pass_n == 1:
        self.stats.classes += 1
        if name not in self.special_class_names:
            # tag:setter Init the class's dict.
            self.classes [name] = {'ivars': {}, 'methods': {}}

def after_ClassDef(self, node):

    self.indent -= 1
    if 0 and self.pass_n == 1:
        g.trace(node, self.show_stack())
        print(f"----- END class {self.class_name}. class dict...")
        g.printDict(self.classes.get(self.class_name))
    #
    # This code must execute in *both* passes.
    top = self.context_stack.pop()
    assert node == top, (node, top)
    # Set the class name
    self.class_name = None
    for node2 in reversed(self.context_stack):
        if isinstance(node2, ast.ClassDef):
            self.class_name = node2.name
            break
#@+node:ekr.20171215074959.9: *5* checker.FunctionDef
def before_FunctionDef(self, node):

    s = self.format(node, print_body=False)
    if self.test_kind == 'test': print(s)
    self.indent += 1
    self.context_stack.append(node)
    if self.pass_n == 1:
        self.stats.defs += 1
        if self.class_name not in self.special_class_names:
            if self.class_name in self.classes:
                the_class = self.classes.get(self.class_name)
                methods = the_class.get('methods')
                # tag:setter function-name=stringized-args
                methods [node.name] = self.format(node.args)
            # This is not an error.
            # else: g.error(node 'no class', node.name)

def after_FunctionDef(self, node):

    self.indent -= 1
    top = self.context_stack.pop()
    assert node == top, (node, top)
#@+node:ekr.20171216110107.1: *5* checker.get_chain
def get_chain(self,node):
    """Scan node for a chain of names."""
    chain, node1 = [], node
    while not isinstance(node, ast.Name):
        if isinstance(node, ast.Attribute):
            assert isinstance(node.attr, str), repr(node.attr)
            chain.append(node.attr)
            node = node.value
        else:
            name = node.__class__.__name__
            if name not in (
                'BoolOp', # c.config.getString('stylesheet') or ''.strip
                'Call', # c1.rootPosition().h = whatever
                'Dict', # {}.whatever.
                'Subscript', # d[x] = whatever
                'Str', # ''.join(), etc
                'Tuple', # (hPos,vPos) = self.getScroll()
            ):
                self.note(node1, '(get_chain) target %s:\n%s' % (
                    name, self.format(node1)))
            return []
    if isinstance(node, ast.Name):
        chain.append(node)
        return list(reversed(chain))
    return []
#@+node:ekr.20171215082648.1: *5* checker.show_stack
def show_stack(self):

    return g.listToString([
        '%15s %s' % (node.__class__.__name__, node.name)
            for node in self.context_stack
        ])
#@+node:ekr.20171212101613.1: *4* class CCStats
class CCStats:
    """
    A basic statistics class.  Use this way:
        
        stats = Stats()
        stats.classes += 1
        stats.defs += 1
        stats.report()
    """
    # Big sigh: define these to placate pylint.
    assignments = 0
    calls = 0
    check_signature = 0
    classes = 0
    defs = 0
    inference_fails = 0
    resolve = 0
    resolve_call = 0
    resolve_chain = 0
    resolve_ivar = 0
    sig_fail = 0
    sig_infer_fail = 0
    sig_infer_ok = 0
    sig_ok = 0
    sig_unknown = 0
        
    def report(self):
        aList = [z for z in dir(self) if not z.startswith('_') and z != 'report']
        n = max([len(z) for z in aList])
        for ivar in aList:
            print('%*s: %s' % (n, ivar, getattr(self, ivar)))
    
#@+node:ekr.20171214151001.1: *4* class CCTraverser (AstFullTraverser)
class CCTraverser (leoAst.AstFullTraverser):
    
    """A traverser class that *only* calls controller methods."""

    def __init__(self, controller):

        super().__init__()
        self.cc = controller
    
    def visit(self, node):
        """
        Visit a *single* ast node.
        Visitors are responsible for visiting children!
        """
        name = node.__class__.__name__
        assert isinstance(node, ast.AST), repr(node)
        before_method = getattr(self.cc, 'before_'+name, None)
        if before_method:
            before_method(node)
        do_method = getattr(self, 'do_'+name, None)
        do_method(node)
        after_method = getattr(self.cc, 'after_'+name, None)
        if after_method:
            after_method(node)
#@+node:ekr.20171209030742.1: *4* class Type
class Type:
    """A class to hold all type-related data."""

    kinds = ('error', 'class', 'func', 'instance', 'module', 'unknown')
    
    def __init__(self, kind, name, source=None, tag=None):

        assert kind in self.kinds, repr(kind)
        self.kind = kind
        self.name=name
        self.source = source
        self.tag = tag
        
    def __repr__(self):

        return f"<{self.kind}: {self.name}>"
        
    def __eq__(self, other):
        
        return self.kind == other.kind and self.name == other.name
#@+node:ekr.20160109102859.1: *3* class Context
class Context:
    """
    Context class (NEW)

    Represents a binding context: module, class or def.

    For any Ast context node N, N.cx is a reference to a Context object.
    """
    @others
#@+node:ekr.20160109103533.1: *4* Context.ctor
def __init__ (self, fn, kind, name, node, parent_context):
    """Ctor for Context class."""
    self.fn = fn
    self.kind = kind
    self.name = name
    self.node = node
    self.parent_context = parent_context
    # Name Data...
    self.defined_names = set()
    self.global_names = set()
    self.imported_names = set()
    self.nonlocal_names = set() # To do.
    self.st = {}
        # Keys are names seen in this context, values are defining contexts.
    self.referenced_names = set()
    # Node lists. Entries are Ast nodes...
    self.inner_contexts_list = []
    self.minor_contexts_list = []
    self.assignments_list = []
    self.calls_list = []
    self.classes_list = []
    self.defs_list = []
    self.expressions_list = []
    self.returns_list = []
    self.statements_list = []
    self.yields_list = []
    # Add this context to the inner context of the parent context.
    if parent_context:
        parent_context.inner_contexts_list.append(self)
#@+node:ekr.20160109134527.1: *4* Context.define_name
def define_name(self, name):
    """Define a name in this context."""
    self.defined_names.add(name)
    if name in self.referenced_names:
        self.referenced_names.remove(name)
#@+node:ekr.20160109143040.1: *4* Context.global_name
def global_name(self, name):
    """Handle a global name in this context."""
    self.global_names.add(name)
    # Not yet.
        # Both Python 2 and 3 generate SyntaxWarnings when a name
        # is used before the corresponding global declarations.
        # We can make the same assumpution here:
        # give an *error* if an STE appears in this context for the name.
        # The error indicates that scope resolution will give the wrong result.
        # e = cx.st.d.get(name)
        # if e:
            # self.u.error(f"name {name!r} used prior to global declaration")
            # # Add the name to the global_names set in *this* context.
            # # cx.global_names.add(name)
        # # Regardless of error, bind the name in *this* context,
        # # using the STE from the module context.
        # cx.st.d[name] = module_e
#@+node:ekr.20160109144139.1: *4* Context.import_name
def import_name(self, module, name):

    if True and name == '*':
        g.trace('From x import * not ready yet')
    else:
        self.imported_names.add(name)
#@+node:ekr.20160109145526.1: *4* Context.reference_name
def reference_name(self, name):

    self.referenced_names.add(name)
#@+node:ekr.20160108105958.1: *3* class Pass1 (AstFullTraverser)
class Pass1 (leoAst.AstFullTraverser): # V2

    """ Pass1 does the following:

    1. Creates Context objects and injects them into the new_cx field of
       ast.Class, ast.FunctionDef and ast.Lambda nodes.

    2. Calls the following Context methods: cx.define/global/import/reference_name.
       These methods update lists used later to bind names to objects.
    """
    # pylint: disable=no-member
        # Stats class defines __setattr__
        # This is a known limitation of pylint.

    @others
#@+node:ekr.20160108105958.2: *4*  p1.ctor
def __init__(self, fn):

    super().__init__()
    self.fn = fn
    # Abbreviations...
    self.stats = Stats()
    self.u = ProjectUtils()
    self.format = leoAst.AstFormatter.format
    # Present context...
    self.context = None
    self.in_attr = False
        # True: traversing inner parts of an AST.Attribute tree.
    self.module_context = None
    self.parent = None
#@+node:ekr.20160108105958.3: *4*  p1.run (entry point)
def run (self,root):

    self.visit(root)
#@+node:ekr.20160109125654.1: *4*  p1.visit
def visit(self, node):
    """Visit a *single* ast node.  Visitors are responsible for visiting children!"""
    assert isinstance(node, ast.AST), node.__class__.__name__
    # Visit the children with the new parent.
    old_parent = self.parent
    self.parent = node
    method_name = 'do_' + node.__class__.__name__
    method = getattr(self, method_name)
    method(node)
    self.parent = old_parent
#@+node:ekr.20160108105958.11: *4* p1.visitors
#@+node:ekr.20160109134854.1: *5* Contexts
#@+node:ekr.20160108105958.8: *6* p1.def_args_helper
# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def def_args_helper (self,cx,node):

    assert self.kind(node) == 'arguments'
    self.visit_list(node.args)
    self.visit_list(node.defaults)
    for field in ('vararg','kwarg'): # node.field is a string.
        name = getattr(node,field,None)
        if name:
            # e = cx.st.define_name(name)
            self.stats.n_param_names += 1
#@+node:ekr.20160108105958.16: *6* p1.ClassDef
# ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

def do_ClassDef (self,node):

    # pylint: disable=arguments-differ
    old_cx = self.context
    name = node.name
    # Define the class name in the old context.
    old_cx.define_name(name)
    # Visit bases in the old context.
    # bases = self.visit_list(node.bases)
    new_cx = Context(
        fn=None,
        kind='class',
        name=name,
        node=node,
        parent_context=old_cx)
    setattr(node,'new_cx',new_cx)
    # Visit the body in the new context.
    self.context = new_cx
    self.visit_list(node.body)
    self.context = old_cx
    # Stats.
    old_cx.classes_list.append(new_cx)
#@+node:ekr.20160108105958.19: *6* p1.FunctionDef
# 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#    expr? returns)

def do_FunctionDef (self,node):
    # pylint: disable=arguments-differ
    # Define the function/method name in the old context.
    old_cx = self.context
    name = node.name
    old_cx.define_name(name)
    # Create the new context.
    new_cx = Context(
        fn=None,
        kind='def',
        name=name,
        node=node,
        parent_context=old_cx)
    setattr(node,'new_cx',new_cx) # Bug fix.
    # Visit in the new context...
    self.context = new_cx
    self.def_args_helper(new_cx,node.args)
    self.visit_list(node.body)
    self.context = old_cx
    # Stats
    old_cx.defs_list.append(new_cx)
#@+node:ekr.20160108105958.23: *6* p1.Interactive
def do_Interactive(self,node):

    assert False,'Interactive context not supported'
#@+node:ekr.20160108105958.24: *6* p1.Lambda
def do_Lambda (self,node):

    # Synthesize a lambda name in the old context.
    # This name must not conflict with split names of the form name@n.
    old_cx = self.context
    name = f"Lambda@@{self.stats.n_lambdas}"
    # Define a Context for the 'lambda' variables.
    new_cx = Context(
        fn=None,
        kind='lambda',
        name=name,
        node=node,
        parent_context=old_cx)
    setattr(node,'new_cx',new_cx)
    # Evaluate expression in the new context.
    self.context = new_cx
    self.def_args_helper(new_cx,node.args)
    self.visit(node.body)
    self.context = old_cx
    # Stats...
    self.stats.n_lambdas += 1
#@+node:ekr.20160108105958.26: *6* p1.Module
def do_Module (self,node):

    # Not yet: Get the module context from the global dict if possible.
    new_cx = Context(
        fn=self.fn,
        kind='module',
        name=None,
        node=node,
        parent_context=None)
    self.context = new_cx
    self.visit_list(node.body)
    self.context = None
#@+node:ekr.20160109135022.1: *5* Expressions
#@+node:ekr.20160108105958.13: *6* p1.Attribute (Revise)
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self,node):

    # Visit...
    # cx = self.context
    old_attr, self.in_attr = self.in_attr, True
    # ctx = self.kind(node.ctx)
    self.visit(node.value)
    # self.visit(node.ctx)
    self.in_attr = old_attr
    if not self.in_attr:
        base_node = node
        kind = self.kind(base_node)
        if kind in ('Builtin','Name'):
            # base_name = base_node.id
            pass
        elif kind in ('Dict','List','Num','Str','Tuple',):
            pass
        elif kind in ('BinOp','UnaryOp'):
            pass
        else:
            assert False,kind
    # Stats...
    self.stats.n_attributes += 1
#@+node:ekr.20160108105958.17: *6* p1.Expr
# Expr(expr value)

def do_Expr(self,node):

    # Visit...
    cx = self.context
    self.visit(node.value)
    # Stats...
    self.stats.n_expressions += 1
    cx.expressions_list.append(node)
    cx.statements_list.append(node)
#@+node:ekr.20160108105958.27: *6* p1.Name (REWRITE)
def do_Name(self,node):

    cx  = self.context
    ctx = self.kind(node.ctx)
    name = node.id
    # def_flag,ref_flag=False,False

    if ctx in ('AugLoad','AugStore','Load'):
        # Note: AugStore does *not* define the symbol.
        cx.reference_name(name)
        self.stats.n_load_names += 1
    elif ctx == 'Store':
        # if name not in cx.global_names:
        self.stats.n_store_names += 1
    elif ctx == 'Param':
        self.stats.n_param_refs += 1
    else:
        assert ctx == 'Del',ctx
        self.stats.n_del_names += 1
#@+node:ekr.20160109140648.1: *5* Imports
#@+node:ekr.20160108105958.21: *6* p1.Import
@ From Guido:

import x            -->  x = __import__('x')
import x as y       -->  y = __import__('x')
import x.y.z        -->  x = __import__('x.y.z')
import x.y.z as p   -->  p = __import__('x.y.z').y.z
@c

def do_Import(self,node):
    """
    Add the imported file to u.files_list if needed
    and create a context for the file.
    """
    cx = self.context
    cx.statements_list.append(node)
    # e_list, names = [],[]
    for fn,asname in self.get_import_names(node):
        self.resolve_import_name(fn)
        # Not yet.
        # # Important: do *not* analyze modules not in the files list.
        # if fn2:
            # mname = self.u.module_name(fn2)
            # if g.shortFileName(fn2) in self.u.files_list:
                # if mname not in self.u.module_names:
                    # self.u.module_names.append(mname)
            # def_name = asname or mname
            # names.append(def_name)
            # e = cx.st.define_name(def_name) # sets e.defined.
            # cx.imported_symbols_list.append(def_name)
            # e_list.append(e)

            # # Add the constant type to the list of types for the *variable*.
            # mod_cx = self.u.modules_dict.get(fn2) or LibraryModuleContext(self.u,fn2)
            # e.types_cache[''] = mod_cx.module_type
            # # self.u.stats.n_imports += 1

    # for e in e_list:
        # e.defs_list.append(node)
        # e.refs_list.append(node)
#@+node:ekr.20160108105958.22: *6* p1.ImportFrom
@ From Guido:

from p.q import x       -->  x = __import__('p.q', fromlist=['x']).x
from p.q import x as y  -->  y = __import__('p.q', fromlist=['x']).x
from ..x.y import z     -->  z = __import('x.y', level=2, fromlist=['z']).z

All these equivalences are still somewhat approximate; __import__
isn't looked up the way other variables are looked up (it is taken
from the current builtins), and if the getattr operation in the "from"
versions raises AttributeError that is translated into ImportError.

There's also a subtlety where "import x.y" implies that y must be a
submodule/subpackage of x, whereas in "from x import y" it may be
either a submodule/subpackage or a plain attribute (e.g. a class,
function or some other variable).
@c

def do_ImportFrom(self,node):
    """
    Add the imported file to u.files_list if needed
    and add the imported symbols to the *present* context.
    """
    cx = self.context
    cx.statements_list.append(node)
    self.resolve_import_name(node.module)
    for fn,asname in self.get_import_names(node):
        fn2 = asname or fn
        cx.import_name(fn2)
#@+node:ekr.20160108105958.9: *6* p1.get_import_names
def get_import_names (self,node):
    """Return a list of the the full file names in the import statement."""
    result = []
    for ast2 in node.names:

        if self.kind(ast2) == 'alias':
            data = ast2.name,ast2.asname
            result.append(data)
        else:
            g.trace('unsupported kind in Import.names list',self.kind(ast2))
    return result
#@+node:ekr.20160108105958.10: *6* p1.resolve_import_name
def resolve_import_name (self,spec):
    """Return the full path name corresponding to the import spec."""
    if not spec:
        return ''
    # This may not work for leading dots.
    aList = spec.split('.')
    path = None
    # paths = None
    name = 'no name'
    for name in aList:
        try:
            pass
            ### Not ready. Old code:
                # f,path,description = imp.find_module(name,paths)
                # if not path: break
                # paths = [path]
                # if f: f.close()
        except ImportError:
            # Important: imports can fail due to Python version.
            # Thus, such errors are not necessarily searious.
            path = None
            break
    if not path:
        return ''
    if path.endswith('.pyd'):
        return ''
    return path
#@+node:ekr.20160108105958.29: *5* Operators... To be deleted???
# operator = Add | BitAnd | BitOr | BitXor | Div
# FloorDiv | LShift | Mod | Mult | Pow | RShift | Sub |

def do_Add(self,node):       setattr(node,'op_name','+')
def do_BitAnd(self,node):    setattr(node,'op_name','&')
def do_BitOr(self,node):     setattr(node,'op_name','|')
def do_BitXor(self,node):    setattr(node,'op_name','^')
def do_Div(self,node):       setattr(node,'op_name','/')
def do_FloorDiv(self,node):  setattr(node,'op_name','//')
def do_LShift(self,node):    setattr(node,'op_name','<<')
def do_Mod(self,node):       setattr(node,'op_name','%')
def do_Mult(self,node):      setattr(node,'op_name','*')
def do_Pow(self,node):       setattr(node,'op_name','**')
def do_RShift(self,node):    setattr(node,'op_name','>>')
def do_Sub(self,node):       setattr(node,'op_name','-')

# boolop = And | Or
def do_And(self,node):       setattr(node,'op_name',' and ')
def do_Or(self,node):        setattr(node,'op_name',' or ')

# cmpop = Eq | Gt | GtE | In |
# Is | IsNot | Lt | LtE | NotEq | NotIn
def do_Eq(self,node):        setattr(node,'op_name','==')
def do_Gt(self,node):        setattr(node,'op_name','>')
def do_GtE(self,node):       setattr(node,'op_name','>=')
def do_In(self,node):        setattr(node,'op_name',' in ')
def do_Is(self,node):        setattr(node,'op_name',' is ')
def do_IsNot(self,node):     setattr(node,'op_name',' is not ')
def do_Lt(self,node):        setattr(node,'op_name','<')
def do_LtE(self,node):       setattr(node,'op_name','<=')
def do_NotEq(self,node):     setattr(node,'op_name','!=')
def do_NotIn(self,node):     setattr(node,'op_name',' not in ')

# unaryop = Invert | Not | UAdd | USub
def do_Invert(self,node):   setattr(node,'op_name','~')
def do_Not(self,node):      setattr(node,'op_name',' not ')
def do_UAdd(self,node):     setattr(node,'op_name','+')
def do_USub(self,node):     setattr(node,'op_name','-')
#@+node:ekr.20160109134929.1: *5* Minor contexts
#@+node:ekr.20160109130719.1: *6* p1.comprehension (to do)
# comprehension (expr target, expr iter, expr* ifs)

def do_comprehension(self, node):

    # Visit...
    self.visit(node.target) # A name.
    self.visit(node.iter) # An attribute.
    for z in node.ifs:
        self.visit(z)
#@+node:ekr.20160108105958.18: *6* p1.For
# For(expr target, expr iter, stmt* body, stmt* orelse)

def do_For(self,node):

    # Visit...
    cx = self.context
    self.visit(node.target)
    self.visit(node.iter)
    for z in node.body:
        self.visit(z)
    for z in node.orelse:
        self.visit(z)
    # Stats...
    self.stats.n_fors += 1
    cx.statements_list.append(node)
    cx.assignments_list.append(node)
#@+node:ekr.20160108105958.30: *6* p1.With
def do_With(self,node):

    # Visit...
    cx = self.context
    self.visit(node.context_expr)
    if node.optional_vars:
        self.visit(node.optional_vars)
    for z in node.body:
        self.visit(z)
    # Stats...
    self.stats.n_withs += 1
    cx.statements_list.append(node)
#@+node:ekr.20160109135003.1: *5* Statements
#@+node:ekr.20160108105958.12: *6* p1.Assign
def do_Assign(self,node):

    # Visit...
    for z in node.targets:
        self.visit(z)
    self.visit(node.value)
    # Stats...
    cx = self.context
    self.stats.n_assignments += 1
    cx.assignments_list.append(node)
    cx.statements_list.append(node)
#@+node:ekr.20160108105958.14: *6* p1.AugAssign
# AugAssign(expr target, operator op, expr value)

def do_AugAssign(self,node):

    # Visit...
    self.visit(node.target)
    self.visit(node.value)
    # Stats...
    cx = self.context
    self.stats.n_assignments += 1
    cx.assignments_list.append(node)
    cx.statements_list.append(node)
#@+node:ekr.20160108105958.15: *6* p1.Call
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self,node):

    # Visit...
    self.visit(node.func)
    for z in node.args:
        self.visit(z)
    for z in node.keywords:
        self.visit(z)
    if getattr(node, 'starargs', None):
        self.visit(node.starargs)
    if getattr(node, 'kwargs', None):
        self.visit(node.kwargs)
    # Stats...
    cx = self.context
    self.stats.n_calls += 1
    cx.calls_list.append(node)
#@+node:ekr.20160108105958.20: *6* p1.Global
def do_Global(self,node):

    # Visit
    cx = self.context
    for name in node.names:
        cx.global_name(name)
    # Stats...
    cx.statements_list.append(node)
    self.stats.n_globals += 1
#@+node:ekr.20160108105958.28: *6* p1.Return
def do_Return(self,node):

    # Visit...
    if node.value:
        self.visit(node.value)
    # Stats...
    self.stats.n_returns += 1
    cx = self.context
    cx.returns_list.append(node)
    cx.statements_list.append(node)
#@+node:ekr.20150525123715.1: *3* class ProjectUtils
class ProjectUtils:
    """A class to compute the files in a project."""
    # To do: get project info from @data nodes.
    @others
#@+node:ekr.20150525123715.2: *4* pu.files_in_dir
def files_in_dir(self, theDir, recursive=True, extList=None, excludeDirs=None):
    """
    Return a list of all Python files in the directory.
    Include all descendants if recursiveFlag is True.
    Include all file types if extList is None.
    """
    # import glob
    import os
    # if extList is None: extList = ['.py']
    if excludeDirs is None: excludeDirs = []
    result = []
    if recursive:
        for root, dirs, files in os.walk(theDir):
            for z in files:
                fn = g.os_path_finalize_join(root, z)
                junk, ext = g.os_path_splitext(fn)
                if not extList or ext in extList:
                    result.append(fn)
            if excludeDirs and dirs:
                for z in dirs:
                    if z in excludeDirs:
                        dirs.remove(z)
    else:
        for ext in extList:
            result.extend(g.glob_glob(f"{theDir}.*{ext}"))
    return sorted(list(set(result)))
#@+node:ekr.20150525123715.3: *4* pu.get_project_directory
def get_project_directory(self, name):
    # Ignore everything after the first space.
    i = name.find(' ')
    if i > -1:
        name = name[: i].strip()
    leo_path, junk = g.os_path_split(__file__)
    d = {
        # Change these paths as required for your system.
        'coverage': r'C:\Python26\Lib\site-packages\coverage-3.5b1-py2.6-win32.egg\coverage',
        'leo': r'C:\leo.repo\leo-editor\leo\core',
        'lib2to3': r'C:\Python26\Lib\lib2to3',
        'pylint': r'C:\Python26\Lib\site-packages\pylint',
        'rope': r'C:\Python26\Lib\site-packages\rope-0.9.4-py2.6.egg\rope\base',
        'test': g.os_path_finalize_join(g.app.loadDir, '..', 'test-proj'),
    }
    dir_ = d.get(name.lower())
    if not dir_:
        g.trace(f"bad project name: {name}")
    if not g.os_path_exists(dir_):
        g.trace('directory not found:' % (dir_))
    return dir_ or ''
#@+node:ekr.20171213071416.1: *4* pu.leo_core_files
def leo_core_files(self):
    """Return all the files in Leo's core."""
    loadDir = g.app.loadDir
    # Compute directories.
    commands_dir = g.os_path_finalize_join(loadDir, '..', 'commands')
    plugins_dir = g.os_path_finalize_join(loadDir, '..', 'plugins')
    # Compute files.
    core_files = g.glob_glob('%s%s%s' % (loadDir, os.sep, '*.py'))
    for exclude in ['format-code.py',]:
        core_files = [z for z in core_files if not z.endswith(exclude)]
    command_files = g.glob_glob(f"{commands_dir}{os.sep}{'*.py'}")
    plugins_files = g.glob_glob(f"{plugins_dir}{os.sep}{'qt_*.py'}")
    # Compute the result.
    files = core_files + command_files + plugins_files
    files = [z for z in files if not z.endswith('__init__.py')]
    return files
#@+node:ekr.20150525123715.4: *4* pu.project_files
@nobeautify

def project_files(self, name, force_all=False):
    """Return a list of all files in the named project."""
    # Ignore everything after the first space.
    i = name.find(' ')
    if i > -1:
        name = name[: i].strip()
    leo_path, junk = g.os_path_split(__file__)
    if name == 'leo':
        # Get the leo files directly.
        return self.leo_core_files()
    # Import the appropriate module.
    try:
        m = importlib.import_module(name, name)
        theDir = g.os_path_dirname(m.__file__)
    except ImportError:
        g.trace('package not found', name)
        return []
    d = {
        'coverage': (['.py'], ['.bzr', 'htmlfiles']),
        'lib2to3':  (['.py'], ['tests']),
        'pylint':   (['.py'], ['.bzr', 'test']),
        'rope':     (['.py'], ['.bzr']),
    }
    data = d.get(name.lower())
    if not data:
        g.trace(f"bad project name: {name}")
        return []
    extList, excludeDirs = data
    files = self.files_in_dir(theDir,
        recursive=True,
        extList=extList,
        excludeDirs=excludeDirs,
    )
    if files:
        if g.app.runningAllUnitTests and len(files) > 1 and not force_all:
            return [files[0]]
    if not files:
        g.trace(f"no files found for {name} in {theDir}")
    if g.app.runningAllUnitTests and len(files) > 1 and not force_all:
        return [files[0]]
    return files
#@+node:ekr.20171213155537.1: *3* class NewShowData
class NewShowData:
    """The driver class for analysis project."""
    assigns_d = {}
    calls_d = {}
    classes_d = {}
    defs_d = {}
    returns_d = {}

    @others
#@+node:ekr.20171213160214.1: *4* sd.analyze
def analyze(self, fn, root):
    
    ast_d = {
        ast.Assign: self.assigns_d,
        ast.AugAssign: self.assigns_d,
        ast.Call: self.calls_d,
        ast.ClassDef: self.classes_d,
        ast.FunctionDef: self.defs_d,
        ast.Return: self.returns_d, 
    }
    fn = g.shortFileName(fn)
    for d in ast_d.values():
        d[fn] = []
    for node in ast.walk(root):
        d = ast_d.get(node.__class__)
        if d is not None:
            d[fn].append(self.format(node))
#@+node:ekr.20171214040822.1: *4* sd.dump
def dump(self, fn, root):
    
    suppress = [
        'arg', 'arguments', 'comprehension', 'keyword',
        'Attribute', 'BinOp', 'BoolOp', 'Dict', 'IfExp', 'Index',
        'Load', 'List', 'ListComp', 'Name', 'NameConstant', 'Num',
        'Slice', 'Store', 'Str', 'Subscript', 'Tuple', 'UnaryOp',
    ]
    # statements = ['Assign', 'AugAssign', 'Call', 'Expr', 'If', 'Return',]
    errors = set()
    fn = g.shortFileName(fn)
    for node in ast.walk(root):
        name = node.__class__.__name__
        if name not in suppress:
            try:
                print('%15s: %s' % (name, self.format(node,strip=False)))
            except AttributeError:
                errors.add(name)
    g.trace('errors', sorted(errors))
    # g.printList(sorted(errors))
#@+node:ekr.20171213163216.1: *4* sd.format
def format(self, node, strip=True):
    
    class Formatter(leoAst.AstFormatter):
        level = 0
    
    s = Formatter().visit(node)
    line1 = g.splitLines(s)[0]
    line1 = line1.strip() if strip else line1.rstrip()
    return g.truncate(line1, 80)
#@+node:ekr.20171213155537.3: *4* sd.run
def run(self, files, dump=False, show_results=True):
    """Process all files"""
    t1 = time.time()
    for fn in files:
        s, e = g.readFileIntoString(fn)
        if s:
            print('=====', g.shortFileName(fn))
            s1 = g.toEncodedString(s)
            root = ast.parse(s1, filename='before', mode='exec')
            if dump:
                self.dump(fn, root)
            else:
                self.analyze(fn, root)
        else:
            g.trace('skipped', g.shortFileName(fn))
    t2 = time.time()
    if show_results:
        self.show_results()
    g.trace('done: %s files in %4.1f sec.' % (len(files), (t2 - t1)))
#@+node:ekr.20171213155537.7: *4* sd.show_results
def show_results(self):
    """Print a summary of the test results."""
    table = (
        ('assignments', self.assigns_d),
        ('calls', self.calls_d),
        ('classes', self.classes_d),
        ('defs', self.defs_d),
        ('returns', self.returns_d),
    )
    for name, d in table:
        print(f"{name}...")
        g.printDict({key: sorted(set(d.get(key))) for key in d})
#@+node:ekr.20171213174732.1: *4* sd.visit
def visit(self, node, types):
    if isinstance(node, types):
        yield self.format(node)
#@+node:ekr.20150604164113.1: *3* class ShowData
class ShowData:
    """The driver class for analysis project."""
    @others
#@+node:ekr.20150604165500.1: *4*  ctor
def __init__(self, c):
    """Ctor for ShowData controller class."""
    self.c = c
    self.files = None
    # Data.
    self.assigns_d = {}
    self.calls_d = {}
    self.classes_d = {}
    self.context_stack = []
    self.defs_d = {}
    self.returns_d = {}
    # Statistics
    self.n_matches = 0
    self.n_undefined_calls = 0
    self.tot_lines = 0
    self.tot_s = 0
#@+node:ekr.20150604163903.1: *4* run & helpers
def run(self, files):
    """Process all files"""
    self.files = files
    t1 = time.time()
    for fn in files:
        s, e = g.readFileIntoString(fn)
        if s:
            self.tot_s += len(s)
            g.trace('%8s %s' % ("{:,}".format(len(s)), g.shortFileName(fn)))
                # Print len(s), with commas.
            # Fast, accurate:
            # 1.9 sec for parsing.
            # 2.5 sec for Null AstFullTraverer traversal.
            # 2.7 sec to generate all strings.
            # 3.8 sec to generate all reports.
            s1 = g.toEncodedString(s)
            self.tot_lines += len(g.splitLines(s))
                # Adds less than 0.1 sec.
            node = ast.parse(s1, filename='before', mode='exec')
            ShowDataTraverser(self, fn).visit(node)
            # elif 0: # Too slow, too clumsy: 3.3 sec for tokenizing
                # readlines = g.ReadLinesClass(s).next
                # for token5tuple in tokenize.generate_tokens(readlines):
                    # pass
            # else: # Inaccurate. 2.2 sec to generate all reports.
                # self.scan(fn, s)
        else:
            g.trace('skipped', g.shortFileName(fn))
    t2 = time.time()
        # Get the time exlusive of print time.
    self.show_results()
    g.trace('done: %4.1f sec.' % (t2 - t1))
#@+node:ekr.20150605054921.1: *4* scan & helpers (a prototype: no longer used)
if 0:
    # The excellent prototype code, fast, easy but inaccurate.
    # It was a roadmap for the ShowDataTraverser class.

    # Regex patterns (were defined in the ctor)
    r_class = r'class[ \t]+([a-z_A-Z][a-z_A-Z0-9]*).*:'
    r_def = r'def[ \t]+([a-z_A-Z][a-z_A-Z0-9]*)[ \t]*\((.*)\)'
    r_return = r'(return[ \t].*)$'
    r_call = r'([a-z_A-Z][a-z_A-Z0-9]*)[ \t]*\(([^)]*)\)'
    r_all = re.compile(r'|'.join([r_class, r_def, r_return, r_call,]))

    def scan(self, fn, s):
        lines = g.splitLines(s)
        self.tot_lines += len(lines)
        for i, s in enumerate(lines):
            m = re.search(self.r_all, s)
            if m and not s.startswith('@'):
                self.match(fn, i, m, s)
#@+node:ekr.20150605063318.1: *5* match
def match(self, fn, i, m, s):
    """Handle the next match."""
    self.n_matches += 1
    indent = g.skip_ws(s, 0)
    # Update the context and enter data.
    if g.match_word(s, indent, 'def'):
        self.update_context(fn, indent, 'def', s)
        for i, name in enumerate(m.groups()):
            if name:
                aList = self.defs_d.get(name, [])
                def_tuple = self.context_stack[: -1], s
                aList.append(def_tuple)
                self.defs_d[name] = aList
                break
    elif g.match_word(s, indent, 'class'):
        self.update_context(fn, indent, 'class', s)
        for i, name in enumerate(m.groups()):
            if name:
                aList = self.classes_d.get(name, [])
                class_tuple = self.context_stack[: -1], s
                aList.append(class_tuple)
                self.classes_d[name] = aList
    elif s.find('return') > -1:
        context, name = self.context_names()
        j = s.find('#')
        if j > -1: s = s[: j]
        s = s.strip()
        if s:
            aList = self.returns_d.get(name, [])
            return_tuple = context, s
            aList.append(return_tuple)
            self.returns_d[name] = aList
    else:
        # A call.
        for i, name in enumerate(m.groups()):
            if name:
                context2, context1 = self.context_names()
                j = s.find('#')
                if j > -1:
                    s = s[: j]
                s = s.strip().strip(',').strip()
                if s:
                    aList = self.calls_d.get(name, [])
                    call_tuple = context2, context1, s
                    aList.append(call_tuple)
                    self.calls_d[name] = aList
                break
#@+node:ekr.20150605074749.1: *5* update_context
def update_context(self, fn, indent, kind, s):
    """Update context info when a class or def is seen."""
    while self.context_stack:
        fn2, kind2, indent2, s2 = self.context_stack[-1]
        if indent <= indent2:
            self.context_stack.pop()
        else:
            break
    context_tuple = fn, kind, indent, s
    self.context_stack.append(context_tuple)
    self.context_indent = indent
#@+node:ekr.20150604164546.1: *4* show_results & helpers
def show_results(self):
    """Print a summary of the test results."""
    make = True
    multiple_only = False # True only show defs defined in more than one place.
    c = self.c
    result = ['@killcolor\n']
    for name in sorted(self.defs_d):
        aList = self.defs_d.get(name, [])
        if len(aList) > 1 or not multiple_only: # not name.startswith('__') and (
            self.show_defs(name, result)
            self.show_calls(name, result)
            self.show_returns(name, result)
    self.show_undefined_calls(result)
    # Put the result in a new node.
    format = (
        'files: %s lines: %s chars: %s classes: %s\n'
        'defs: %s calls: %s undefined calls: %s returns: %s'
    )
    summary = format % (
        # g.plural(self.files),
        len(self.files),
        "{:,}".format(self.tot_lines),
        "{:,}".format(self.tot_s),
        "{:,}".format(len(self.classes_d.keys())),
        "{:,}".format(len(self.defs_d.keys())),
        "{:,}".format(len(self.calls_d.keys())),
        "{:,}".format(self.n_undefined_calls),
        "{:,}".format(len(self.returns_d.keys())),
    )
    result.insert(1, summary)
    result.extend(['', summary])
    if c and make:
        last = c.lastTopLevel()
        p2 = last.insertAfter()
        p2.h = 'global signatures'
        p2.b = '\n'.join(result)
        c.redraw(p=p2)
    print(summary)
#@+node:ekr.20150605160218.1: *5* show_calls
def show_calls(self, name, result):
    aList = self.calls_d.get(name, [])
    if not aList:
        return
    result.extend(['', f"    {len(aList)} call{g.plural(aList)}..."])
    w = 0
    calls = sorted(set(aList))
    for call_tuple in calls:
        context2, context1, s = call_tuple
        w = max(w, len(context2 or '') + len(context1 or ''))
    for call_tuple in calls:
        context2, context1, s = call_tuple
        pad = w - (len(context2 or '') + len(context1 or ''))
        if context2:
            result.append('%s%s::%s: %s' % (
                ' ' * (8 + pad), context2, context1, s))
        else:
            result.append('%s%s: %s' % (
                ' ' * (10 + pad), context1, s))
#@+node:ekr.20150605155601.1: *5* show_defs
def show_defs(self, name, result):
    aList = self.defs_d.get(name, [])
    name_added = False
    w = 0
    # Calculate the width
    for def_tuple in aList:
        context_stack, s = def_tuple
        if context_stack:
            fn, kind, context_s = context_stack[-1]
            w = max(w, len(context_s))
    for def_tuple in aList:
        context_stack, s = def_tuple
        if not name_added:
            name_added = True
            result.append('\n%s' % name)
            result.append(f"    {len(aList)} definition{g.plural(aList)}...")
        if context_stack:
            fn, kind, context_s = context_stack[-1]
            def_s = s.strip()
            pad = w - len(context_s)
            result.append('%s%s: %s' % (' ' * (8 + pad), context_s, def_s))
        else:
            result.append('%s%s' % (' ' * 4, s.strip()))
#@+node:ekr.20150605160341.1: *5* show_returns
def show_returns(self, name, result):
    aList = self.returns_d.get(name, [])
    if not aList:
        return
    result.extend(['', f"    {len(aList)} return{g.plural(aList)}..."])
    w, returns = 0, sorted(set(aList))
    for returns_tuple in returns:
        context, s = returns_tuple
        w = max(w, len(context or ''))
    for returns_tuple in returns:
        context, s = returns_tuple
        pad = w - len(context)
        result.append('%s%s: %s' % (' ' * (8 + pad), context, s))
#@+node:ekr.20150606092147.1: *5* show_undefined_calls
def show_undefined_calls(self, result):
    """Show all calls to undefined functions."""
    call_tuples = []
    for s in self.calls_d:
        i = 0
        while True:
            progress = i
            j = s.find('.', i)
            if j == -1:
                name = s[i:].strip()
                call_tuple = name, s
                call_tuples.append(call_tuple)
                break
            else:
                i = j + 1
            assert progress < i
    undef = []
    for call_tuple in call_tuples:
        name, s = call_tuple
        if name not in self.defs_d:
            undef.append(call_tuple)
    undef = list(set(undef))
    result.extend(['', f"{len(undef)} undefined call{g.plural(undef)}..."])
    self.n_undefined_calls = len(undef)
    # Merge all the calls for name.
    # There may be several with different s values.
    results_d = {}
    for undef_tuple in undef:
        name, s = undef_tuple
        calls = self.calls_d.get(s, [])
        aList = results_d.get(name, [])
        for call_tuple in calls:
            aList.append(call_tuple)
        results_d[name] = aList
    # Print the final results.
    for name in sorted(results_d):
        calls = results_d.get(name)
        result.extend(['', f"{name} {len(calls)} call{g.plural(calls)}..."])
        w = 0
        for call_tuple in calls:
            context2, context1, s = call_tuple
            if context2:
                w = max(w, 2 + len(context2) + len(context1))
            else:
                w = max(w, len(context1))
        for call_tuple in calls:
            context2, context1, s = call_tuple
            pad = w - (len(context2) + len(context1))
            if context2:
                result.append('%s%s::%s: %s' % (
                    ' ' * (2 + pad), context2, context1, s))
            else:
                result.append('%s%s: %s' % (
                    ' ' * (2 + pad), context1, s))
#@+node:ekr.20150605140911.1: *4* context_names
def context_names(self):
    """Return the present context name."""
    if self.context_stack:
        result = []
        for stack_i in -1, -2:
            try:
                fn, kind, indent, s = self.context_stack[stack_i]
            except IndexError:
                result.append('')
                break
            s = s.strip()
            assert kind in ('class', 'def'), kind
            i = g.skip_ws(s, 0)
            i += len(kind)
            i = g.skip_ws(s, i)
            j = g.skip_c_id(s, i)
            result.append(s[i: j])
        return reversed(result)
    return ['', '']
#@+node:ekr.20150606024455.1: *3* class ShowDataTraverser (AstFullTraverser)
class ShowDataTraverser(leoAst.AstFullTraverser):
    """
    Add data about classes, defs, returns and calls to controller's
    dictionaries.
    """

    def __init__(self, controller, fn):
        """Ctor for ShopDataTraverser class."""
        super().__init__()
        module_tuple = g.shortFileName(fn), 'module', g.shortFileName(fn)
            # fn, kind, s.
        self.context_stack = [module_tuple]
        self.controller = controller
        self.fn = g.shortFileName(fn)
        self.formatter = leoAst.AstFormatter()
            # leoAst.AstPatternFormatter()
    @others
#@+node:ekr.20150609053332.1: *4* sd.Helpers
#@+node:ekr.20150606035006.1: *5* sd.context_names
def context_names(self):
    """Return the present context names."""
    result = []
    n = len(self.context_stack)
    for i in n - 1, n - 2:
        if i >= 0:
            fn, kind, s = self.context_stack[i]
            assert kind in ('class', 'def', 'module'), kind
            if kind == 'module':
                result.append(s.strip())
            else:
                # Append the name following the class or def.
                i = g.skip_ws(s, 0)
                i += len(kind)
                i = g.skip_ws(s, i)
                j = g.skip_c_id(s, i)
                result.append(s[i: j])
        else:
            result.append('')
            break
    return reversed(result)
#@+node:ekr.20150609053010.1: *5* sd.format
def format(self, node, level, *args, **kwargs):
    """Return the formatted version of an Ast Node."""
    return self.formatter.format(node, level, *args, **kwargs).strip()
#@+node:ekr.20150606024455.62: *4* sd.visit
def visit(self, node):
    """
    Visit a *single* ast node. Visitors must visit their children
    explicitly.
    """
    method = getattr(self, 'do_' + node.__class__.__name__)
    method(node)

def visit_children(self, node):
    """Override to ensure this method is never called."""
    assert False, 'must visit children explicitly'
#@+node:ekr.20150609052952.1: *4* sd.Visitors
#@+node:ekr.20150607200422.1: *5* sd.Assign
def do_Assign(self, node):
    """Handle an assignment statement: Assign(expr* targets, expr value)"""
    value = self.format(self.visit(node.value), self.level)
    assign_tuples = []
    for target in node.targets:
        target = self.format(self.visit(target), self.level)
        s = '%s=%s' % (target, value)
        context2, context1 = self.context_names()
        assign_tuple = context2, context1, s
        assign_tuples.append(assign_tuple)
        aList = self.controller.assigns_d.get(target, [])
        aList.extend(assign_tuples)
        self.controller.calls_d[target] = aList
#@+node:ekr.20150607200439.1: *5* sd.AugAssign
def do_AugAssign(self, node):
    """
    Handle an augmented assignement:
    AugAssign(expr target, operator op, expr value).
    """
    target = self.format(self.visit(node.target), self.level)
    s = '%s=%s' % (target, self.format(self.visit(node.value), self.level))
    context2, context1 = self.context_names()
    assign_tuple = context2, context1, s
    aList = self.controller.assigns_d.get(target, [])
    aList.append(assign_tuple)
    self.controller.calls_d[target] = aList
#@+node:ekr.20150606024455.16: *5* sd.Call
def do_Call(self, node):
    """
    Handle a call statement:
    Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)
    """
    # Update data.
    s = self.format(node, self.level)
    name = self.format(node.func, self.level)
    context2, context1 = self.context_names()
    call_tuple = context2, context1, s
    aList = self.controller.calls_d.get(name, [])
    aList.append(call_tuple)
    self.controller.calls_d[name] = aList
    # Visit.
    self.visit(node.func)
    for z in node.args:
        self.visit(z)
    for z in node.keywords:
        self.visit(z)
    if getattr(node, 'starargs', None):
        self.visit(node.starargs)
    if getattr(node, 'kwargs', None):
        self.visit(node.kwargs)
#@+node:ekr.20150606024455.3: *5* sd.ClassDef
def do_ClassDef(self, node):
    """
    Handle a class defintion:
    ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)
    """
    # pylint: disable=arguments-differ
    # Format.
    if node.bases:
        bases = [self.format(z, self.level) for z in node.bases]
        s = 'class %s(%s):' % (node.name, ','.join(bases))
    else:
        s = 'class %s:' % node.name
    # Enter the new context.
    context_tuple = self.fn, 'class', s
    self.context_stack.append(context_tuple)
    # Update data.
    class_tuple = self.context_stack[: -1], s
    aList = self.controller.classes_d.get(node.name, [])
    aList.append(class_tuple)
    self.controller.classes_d[node.name] = aList
    # Visit.
    for z in node.bases:
        self.visit(z)
    for z in node.body:
        self.visit(z)
    for z in node.decorator_list:
        self.visit(z)
    # Leave the context.
    self.context_stack.pop()
#@+node:ekr.20150606024455.4: *5* sd.FunctionDef
def do_FunctionDef(self, node):
    """
    Visit a function defintion:
    FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
    """
    # pylint: disable=arguments-differ
    # Format.
    args = self.format(node.args, self.level) if node.args else ''
    s = 'def %s(%s):' % (node.name, args)
    # Enter the new context.
    context_tuple = self.fn, 'def', s
    self.context_stack.append(context_tuple)
    # Update data.
    def_tuple = self.context_stack[: -1], s
    aList = self.controller.defs_d.get(node.name, [])
    aList.append(def_tuple)
    self.controller.defs_d[node.name] = aList
    # Visit.
    for z in node.decorator_list:
        self.visit(z)
    self.visit(node.args)
    for z in node.body:
        self.visit(z)
    # Leave the context.
    self.context_stack.pop()
#@+node:ekr.20150606024455.55: *5* sd.Return
def do_Return(self, node):
    """Handle a 'return' statement: Return(expr? value)"""
    # Update data.
    s = self.format(node, self.level)
    context, name = self.context_names()
    aList = self.controller.returns_d.get(name, [])
    return_tuple = context, s
    aList.append(return_tuple)
    self.controller.returns_d[name] = aList
    # Visit.
    if node.value:
        self.visit(node.value)
#@+node:ekr.20171211163833.1: *3* class Stats
class Stats:
    """
    A basic statistics class.  Use this way:
        
        stats = Stats()
        stats.classes += 1
        stats.defs += 1
        stats.report()
    """

    d = {}
    
    def __getattr__(self, name):
        return self.d.get(name, 0)
        
    def __setattr__(self, name, val):
        self.d[name] = val
        
    def report(self):
        if self.d:
            n = max([len(key) for key in self.d])
            for key, val in sorted(self.d.items()):
                print('%*s: %s' % (n, key, val))
        else:
            print('no stats')
#@+node:ekr.20171211061816.1: *3* top-level test functions
#@+node:ekr.20150704135836.1: *4* testShowData (leoCheck.py)
def test(c, files):
    r"""
    A stand-alone version of @button show-data.  Call as follows:

        import leo.core.leoCheck as leoCheck
        files = (
            [
                # r'c:\leo.repo\leo-editor\leo\core\leoNodes.py',
            ] or
            leoCheck.ProjectUtils().project_files('leo')
        )
        leoCheck.test(files)
    """
    # pylint: disable=import-self
    import leo.core.leoCheck as leoCheck
    leoCheck.ShowData(c=c).run(files)
#@+node:ekr.20171211055756.1: *3* checkConventions (checkerCommands.py)
@g.command('check-conventions')
@g.command('cc')
def checkConventions(event):
    """Experimental script to test Leo's convensions."""
    c = event.get('c')
    if c:
        if c.changed: c.save()
        import importlib
        import leo.core.leoCheck as leoCheck
        importlib.reload(leoCheck)
        leoCheck.ConventionChecker(c).check()
#@+node:ekr.20200219073706.1: ** From leoTest.py
#@+node:ekr.20120220070422.10420: *3* Top-level functions (leoTest)
#@+node:ekr.20051104075904.97: *4* leoTest.py: factorial (a test of doctests)
# Some of these will fail now for Python 2.x.

def factorial(n):
    """Return the factorial of n, an exact integer >= 0.

    If the result is small enough to fit in an int, return an int.
    Else return a long.

    >>> [factorial(n) for n in range(6)]
    [1, 1, 2, 6, 24, 120]
    >>> factorial(30)
    265252859812191058636308480000000
    >>> factorial(-1)
    Traceback (most recent call last):
        ...
    ValueError: n must be >= 0

    Factorials of floats are OK, but the float must be an exact integer:
    >>> factorial(30.1)
    Traceback (most recent call last):
        ...
    ValueError: n must be exact integer
    >>> factorial(30.0)
    265252859812191058636308480000000

    It must also not be ridiculously large:
    >>> factorial(1e100)
    Traceback (most recent call last):
        ...
    OverflowError: n too large
    """
    import math
    if not n >= 0:
        raise ValueError("n must be >= 0")
    if math.floor(n) != n:
        raise ValueError("n must be exact integer")
    if n + 1 == n:  # catch a value like 1e300
        raise OverflowError("n too large")
    result = 1
    factor = 2
    while factor <= n:
        try:
            result *= factor
        except OverflowError:
            result = int(factor)
        factor += 1
    return result
#@-all
#@@nosearch
#@-leo
