#@+leo-ver=5-thin
#@+node:ekr.20170302123956.1: * @file ../doc/leoAttic.txt
# This is Leo's final resting place for dead code.
# New in Leo 6.7.5. The attic will contain only code retired in the present release.

#@@language python
#@@killbeautify
#@+all
#@+node:ekr.20240322064529.1: ** retire .cmd scripts
#@+node:ekr.20240322064529.2: *3* beautify-leo.cmd
@language batch
@echo off
cd %~dp0..\..

echo beautify-leo

call py -m leo.core.leoAst --orange --verbose leo\core
call py -m leo.core.leoAst --orange --verbose leo\commands
call py -m leo.core.leoAst --orange --verbose leo\plugins
call py -m leo.core.leoAst --orange --verbose leo\modes
#@+node:ekr.20240322064529.3: *3* beautify-leo-force.cmd
@language batch
@echo off
cd %~dp0..\..

echo beautify-leo

call py -m leo.core.leoAst --orange --force --verbose leo\core
call py -m leo.core.leoAst --orange --force --verbose leo\commands

rem It's ok to beautify everything:

call py -m leo.core.leoAst --orange --verbose leo\plugins
call py -m leo.core.leoAst --orange --verbose leo\modes

rem call py -m leo.core.leoAst --orange --force --verbose leo\plugins\importers
rem call py -m leo.core.leoAst --orange --force --verbose leo\plugins\writers
#@+node:ekr.20240322064529.4: *3* blacken-leo.cmd
@language batch
@echo off
cd %~dp0..\..

rem not recommended!
echo black leo.core
call py -m black --skip-string-normalization leo\core
#@+node:ekr.20240322064529.5: *3* flake8-leo.cmd
@language batch
@echo off
cd %~dp0..\..

rem: See leo-editor/setup.cfg for defaults.

echo flake8-leo
py -m flake8 %*
#@+node:ekr.20240322064529.6: *3* full-test-leo.cmd
@language batch
@echo off
cls
cd %~dp0..\..

rem Run all of Leo's pre-commit tests.

call tbo.cmd --all --beautified --report --write
call python312 -m unittest
call ruff-leo.cmd
call mypy-leo.cmd
echo Done!
#@+node:ekr.20240322064529.7: *3* make-leo.cmd
@language batch
@echo off
cls
rem -a: write all files  (make clean)
cd %~dp0..\..
cd leo\doc\html

echo.
echo sphinx-build -a (make clean)
echo.
sphinx-build -M html . _build -a
#@+node:ekr.20240322064529.8: *3* mypy-leo.cmd
@language batch
@echo off
cd %~dp0..\..

rem See leo-editor/.mypy.ini for exclusions!
rem Always use the fast (official) version of mypy.

echo mypy-leo
py -m mypy --debug-cache leo %*
#@+node:ekr.20240322064529.9: *3* pylint-leo.cmd
@language batch
@echo off
cd %~dp0..\..

echo pylint-leo
time /T
call py -m pylint leo --extension-pkg-allow-list=PyQt6.QtCore,PyQt6.QtGui,PyQt6.QtWidgets %*
time /T
#@+node:ekr.20240322064529.10: *3* reindent-leo.cmd
@language batch
@echo off
cd %~dp0..\..

:: Save path to reindent.py to a file .leo\reindent-path.txt
call py %~dp0\find-reindent.py

set PATH_FILE=%USERPROFILE%\.leo\reindent-path.txt
set /P "REINDENT_PATH="< %PATH_FILE%

:: echo %REINDENT_PATH%

if "%REINDENT_PATH%"=="" goto no_reindent

echo reindent-leo

rem echo reindent leo/core
call py %REINDENT_PATH% -r leo\core
rem echo reindent leo/commands
call py %REINDENT_PATH% -r leo\commands
rem echo reindent leo/plugins/importers
call py %REINDENT_PATH% -r leo\plugins\importers
rem echo reindent leo/plugins/commands
call py %REINDENT_PATH% leo\plugins\qt_commands.py
call py %REINDENT_PATH% leo\plugins\qt_events.py
call py %REINDENT_PATH% leo\plugins\qt_frame.py
call py %REINDENT_PATH% leo\plugins\qt_gui.py
call py %REINDENT_PATH% leo\plugins\qt_idle_time.py
call py %REINDENT_PATH% leo\plugins\qt_text.py
call py %REINDENT_PATH% leo\plugins\qt_tree.py
rem echo reindent leo/plugins/writers
call py %REINDENT_PATH% -r leo\plugins\writers
rem echo reindent leo/unittests
call py %REINDENT_PATH% -r leo\unittests
rem echo reindent official plugins.
call py %REINDENT_PATH% leo\plugins\indented_languages.py
goto done

:no_reindent
echo Cannot find reindent.py, skipping reindentation

:done
#@+node:ekr.20240322064529.11: *3* test-leo.cmd
@language batch
@echo off
cd %~dp0..\..

call reindent-leo.cmd

echo test-leo
py -m unittest %*
#@+node:ekr.20240322064529.12: *3* test-one-leo.cmd
@language batch
@echo off
cls
cd %~dp0..\..

echo test-one-leo
call py -m unittest leo.unittests.core.test_leoGlobals.TestGlobals.test_g_handleScriptException
#@+node:ekr.20240322064529.13: *3* tbo.cmd
@language batch

@echo off
cls
cd %~dp0..\..

rem Use leoTokens.py to beautify all files.

IF [%1]==[-h] goto help
IF [%1]==[--help] goto help

:tbo:

echo tbo [%*]
call python312 -m leo.core.leoTokens leo\core %*
call python312 -m leo.core.leoTokens leo\commands %*
call python312 -m leo.core.leoTokens leo\plugins\importers %*
call python312 -m leo.core.leoTokens leo\plugins\writers %*
call python312 -m leo.core.leoTokens leo\modes %*

call python312 -m leo.core.leoTokens leo\unittests\core %*
call python312 -m leo.core.leoTokens leo\unittests\commands %*
call python312 -m leo.core.leoTokens leo\unittests\plugins %*
call python312 -m leo.core.leoTokens leo\unittests\misc_tests %*
goto done

:help:
call python312 -m leo.core.leoTokens  --help

:done:
#@+node:ekr.20240326032226.1: ** retire commands in leoAst.py
See #3843: https://github.com/leo-editor/leo-editor/issues/3843
#@+node:ekr.20200702114522.1: *3*  leoAst.py: top-level commands
# Don't bother covering top-level commands.
if 1:  # pragma: no cover
    @others
#@+node:ekr.20200702114557.1: *4* command: fstringify_command
def fstringify_command(files: list[str]) -> None:
    """
    Entry point for --fstringify.

    Fstringify the given file, overwriting the file.
    """
    if not check_g():
        return
    for filename in files:
        if os.path.exists(filename):
            print(f"fstringify {filename}")
            Fstringify().fstringify_file_silent(filename)
        else:
            print(f"file not found: {filename}")
#@+node:ekr.20200702121222.1: *4* command: fstringify_diff_command
def fstringify_diff_command(files: list[str]) -> None:
    """
    Entry point for --fstringify-diff.

    Print the diff that would be produced by fstringify.
    """
    if not check_g():
        return
    for filename in files:
        if os.path.exists(filename):
            print(f"fstringify-diff {filename}")
            Fstringify().fstringify_file_diff(filename)
        else:
            print(f"file not found: {filename}")
#@+node:ekr.20200702115002.1: *4* command: orange_command (leoAst.py)
def orange_command(
    arg_files: list[str], files: list[str], settings: Settings = None,
) -> None:

    if not check_g():
        return
    t1 = time.process_time()
    any_changed = 0
    for filename in files:
        if os.path.exists(filename):
            # print(f"orange {filename}")
            changed = Orange(settings).beautify_file(filename)
            if changed:
                any_changed += 1
        else:
            print(f"file not found: {filename}")
    t2 = time.process_time()
    if any_changed or Orange(settings).verbose:
        n, files_s = any_changed, ','.join(arg_files)
        print(f"orange: {t2-t1:3.1f} sec. changed {n} file{g.plural(n)} in {files_s}")
#@+node:ekr.20200702121315.1: *4* command: orange_diff_command
def orange_diff_command(files: list[str], settings: Settings = None) -> None:

    if not check_g():
        return
    for filename in files:
        if os.path.exists(filename):
            print(f"orange-diff {filename}")
            Orange(settings).beautify_file_diff(filename)
        else:
            print(f"file not found: {filename}")
#@+node:ekr.20200107175223.1: *3* 2.2: BaseTest.beautify
def beautify(self, contents, tokens, tree, filename=None, max_join_line_length=None, max_split_line_length=None):
    """
    BaseTest.beautify.
    """
    t1 = get_time()
    if not contents:
        return ''  # pragma: no cover
    if not filename:
        filename = g.callers(2).split(',')[0]
    orange = Orange()
    result_s = orange.beautify(contents, filename, tokens, tree,
        max_join_line_length=max_join_line_length,
        max_split_line_length=max_split_line_length)
    t2 = get_time()
    self.update_times('22: beautify', t2 - t1)
    self.code_list = orange.code_list
    return result_s
#@+node:ekr.20200107165250.1: *3* class Orange
class Orange:  # Orange is the new Black.
    """
    This class is deprecated. Use the TokenBasedOrange class in leoTokens.py

    This class is a demo of the TokenOrderGenerator class.

    This is a predominantly a *token-based* beautifier. However,
    orange.do_op, orange.colon, and orange.possible_unary_op use the parse
    tree to provide context that would otherwise be difficult to deduce.
    """
    # This switch is really a comment. It will always be false.
    # It marks the code that simulates the operation of the black tool.
    black_mode = False

    # Patterns...
    nobeautify_pat = re.compile(r'\s*#\s*pragma:\s*no\s*beautify\b|#\s*@@nobeautify')

    # Patterns from FastAtRead class, specialized for python delims.
    node_pat = re.compile(r'^(\s*)#@\+node:([^:]+): \*(\d+)?(\*?) (.*)$')  # @node
    start_doc_pat = re.compile(r'^\s*#@\+(at|doc)?(\s.*?)?$')  # @doc or @
    at_others_pat = re.compile(r'^(\s*)#@(\+|-)others\b(.*)$')  # @others

    # Doc parts end with @c or a node sentinel. Specialized for python.
    end_doc_pat = re.compile(r"^\s*#@(@(c(ode)?)|([+]node\b.*))$")
    @others
#@+node:ekr.20200107165250.2: *4* orange.ctor
def __init__(self, settings: Settings = None):
    """Ctor for Orange class."""
    if settings is None:
        settings = {}
    valid_keys = (
        'allow_joined_strings',
        'force',
        'max_join_line_length',
        'max_split_line_length',
        'orange',
        'tab_width',
        'verbose',
    )
    # For mypy...
    self.kind: str = ''
    # Default settings...
    self.allow_joined_strings = False  # EKR's preference.
    self.force = False
    self.max_join_line_length = 88
    self.max_split_line_length = 88
    self.tab_width = 4
    self.verbose = False
    # Override from settings dict...
    for key in settings:  # pragma: no cover
        value = settings.get(key)
        if key in valid_keys and value is not None:
            setattr(self, key, value)
        else:
            g.trace(f"Unexpected setting: {key} = {value!r}")
#@+node:ekr.20200107165250.51: *4* orange.push_state
def push_state(self, kind: str, value: Union[int, str] = None) -> None:
    """Append a state to the state stack."""
    state = ParseState(kind, value)
    self.state_stack.append(state)
#@+node:ekr.20200107165250.8: *4* orange: Entries & helpers
#@+node:ekr.20200107173542.1: *5* orange.beautify (main token loop)
def oops(self) -> None:  # pragma: no cover
    g.trace(f"Unknown kind: {self.kind}")

def beautify(self,
    contents: str,
    filename: str,
    tokens: list[Token],
    tree: Optional[Node] = None,
    max_join_line_length: Optional[int] = None,
    max_split_line_length: Optional[int] = None,
) -> str:
    """
    The main line. Create output tokens and return the result as a string.

    beautify_file and beautify_file_def call this method.
    """
    # Config overrides
    if max_join_line_length is not None:
        self.max_join_line_length = max_join_line_length
    if max_split_line_length is not None:
        self.max_split_line_length = max_split_line_length
    # State vars...
    self.curly_brackets_level = 0  # Number of unmatched '{' tokens.
    self.decorator_seen = False  # Set by do_name for do_op.
    self.in_arg_list = 0  # > 0 if in an arg list of a def.
    self.in_fstring = False  # True: scanning an f-string.
    self.level = 0  # Set only by do_indent and do_dedent.
    self.lws = ''  # Leading whitespace.
    self.paren_level = 0  # Number of unmatched '(' tokens.
    self.square_brackets_stack: list[bool] = []  # A stack of bools, for self.word().
    self.state_stack: list["ParseState"] = []  # Stack of ParseState objects.
    self.val = None  # The input token's value (a string).
    self.verbatim = False  # True: don't beautify.
    #
    # Init output list and state...
    self.code_list: list[OutputToken] = []  # The list of output tokens.
    self.tokens = tokens  # The list of input tokens.
    self.tree = tree
    self.add_token('file-start', '')
    self.push_state('file-start')
    for token in tokens:
        self.token = token
        self.kind, self.val, self.line = token.kind, token.value, token.line
        if self.verbatim:
            self.do_verbatim()
        elif self.in_fstring:
            self.continue_fstring()
        else:
            func = getattr(self, f"do_{token.kind}", self.oops)
            func()
    # Any post pass would go here.
    return output_tokens_to_string(self.code_list)
#@+node:ekr.20200107172450.1: *5* orange.beautify_file (entry)
def beautify_file(self, filename: str) -> bool:  # pragma: no cover
    """
    Orange: Beautify the the given external file.

    Return True if the file was changed.
    """
    self.filename = filename
    # Annotate the tokens.
    tog = TokenOrderGenerator()
    contents, encoding, tokens, tree = tog.init_from_file(filename)
    if not contents or not tokens or not tree:
        return False  # Not an error.
    # Beautify.
    try:
        results = self.beautify(contents, filename, tokens, tree)  # type:ignore
    except BeautifyError:
        return False  # #2578.
    # Something besides newlines must change.
    if regularize_nls(contents) == regularize_nls(results):
        return False
    if 0:  # This obscures more import error messages.
        show_diffs(contents, results, filename=filename)
    # Write the results
    print(f"Beautified: {g.shortFileName(filename)}")
    write_file(filename, results, encoding=encoding)
    return True
#@+node:ekr.20200107172512.1: *5* orange.beautify_file_diff (entry)
def beautify_file_diff(self, filename: str) -> bool:  # pragma: no cover
    """
    Orange: Print the diffs that would result from the orange-file command.

    Return True if the file would be changed.
    """
    tag = 'diff-beautify-file'
    self.filename = filename

    if 1:  ### Legacy: use parse trees.
        tog = TokenOrderGenerator()
        contents, encoding, tokens, tree = tog.init_from_file(filename)
        if not contents or not tokens or not tree:
            print(f"{tag}: Can not beautify: {filename}")
            return False

    # Beautify
    results = self.beautify(contents, filename, tokens, tree)
    # Something besides newlines must change.
    if regularize_nls(contents) == regularize_nls(results):
        print(f"{tag}: Unchanged: {filename}")
        return False
    # Show the diffs.
    show_diffs(contents, results, filename=filename)
    return True
#@+node:ekr.20240104093833.1: *5* orange.init_tokens_from_file
def init_tokens_from_file(self, filename: str) -> tuple[
    str, str, list[Token]
]:  # pragma: no cover
    """
    Create the list of tokens for the given file.
    Return (contents, encoding, tokens).
    """
    self.level = 0
    self.filename = filename
    contents, encoding = g.readFileIntoString(filename)
    if not contents:
        return None, None, None
    self.tokens = tokens = self.make_tokens(contents)
    return contents, encoding, tokens
#@+node:ekr.20240104123947.1: *5* orange.make_tokens
def make_tokens(self, contents: str) -> list[Token]:
    """
    Return a list (not a generator) of Token objects corresponding to the
    list of 5-tuples generated by tokenize.tokenize.

    Perform consistency checks and handle all exceptions.
    """

    def check(contents: str, tokens: list[Token]) -> bool:
        result = tokens_to_string(tokens)
        ok = result == contents
        if not ok:
            print('\nRound-trip check FAILS')
            print('Contents...\n')
            g.printObj(contents)
            print('\nResult...\n')
            g.printObj(result)
        return ok

    try:
        five_tuples = tokenize.tokenize(
            io.BytesIO(contents.encode('utf-8')).readline)
    except Exception:
        print('make_tokens: exception in tokenize.tokenize')
        g.es_exception()
        return None
    tokens = Tokenizer().create_tokens(contents, five_tuples)
    assert check(contents, tokens)
    return tokens
#@+node:ekr.20200107165250.13: *4* orange: Input token handlers
#@+node:ekr.20200107165250.14: *5* orange.do_comment
in_doc_part = False

comment_pat = re.compile(r'^(\s*)#[^@!# \n]')

def do_comment(self) -> None:
    """Handle a comment token."""
    val = self.val
    #
    # Leo-specific code...
    if self.node_pat.match(val):
        # Clear per-node state.
        self.in_doc_part = False
        self.verbatim = False
        self.decorator_seen = False
        # Do *not clear other state, which may persist across @others.
            # self.curly_brackets_level = 0
            # self.in_arg_list = 0
            # self.level = 0
            # self.lws = ''
            # self.paren_level = 0
            # self.square_brackets_stack = []
            # self.state_stack = []
    else:
        # Keep track of verbatim mode.
        if self.beautify_pat.match(val):
            self.verbatim = False
        elif self.nobeautify_pat.match(val):
            self.verbatim = True
        # Keep trace of @doc parts, to honor the convention for splitting lines.
        if self.start_doc_pat.match(val):
            self.in_doc_part = True
        if self.end_doc_pat.match(val):
            self.in_doc_part = False
    #
    # General code: Generate the comment.
    self.clean('blank')
    entire_line = self.line.lstrip().startswith('#')
    if entire_line:
        self.clean('hard-blank')
        self.clean('line-indent')
        # #1496: No further munging needed.
        val = self.line.rstrip()
        # #3056: Insure one space after '#' in non-sentinel comments.
        #        Do not change bang lines or '##' comments.
        if m := self.comment_pat.match(val):
            i = len(m.group(1))
            val = val[:i] + '# ' + val[i + 1 :]
    else:
        # Exactly two spaces before trailing comments.
        val = '  ' + self.val.rstrip()
    self.add_token('comment', val)
#@+node:ekr.20200107165250.15: *5* orange.do_encoding
def do_encoding(self) -> None:
    """
    Handle the encoding token.
    """
    pass
#@+node:ekr.20200107165250.16: *5* orange.do_endmarker
def do_endmarker(self) -> None:
    """Handle an endmarker token."""
    # Ensure exactly one blank at the end of the file.
    self.clean_blank_lines()
    self.add_token('line-end', '\n')
#@+node:ekr.20231215212951.1: *5* orange.do_fstring_start & continue_fstring
def do_fstring_start(self) -> None:
    """Handle the 'fstring_start' token. Enter f-string mode."""
    self.in_fstring = True
    self.add_token('verbatim', self.val)

def continue_fstring(self) -> None:
    """
    Put the next token in f-fstring mode.
    Exit f-string mode if the token is 'fstring_end'.
    """
    self.add_token('verbatim', self.val)
    if self.kind == 'fstring_end':
        self.in_fstring = False
#@+node:ekr.20200107165250.18: *5* orange.do_indent & do_dedent & helper
# Note: other methods use self.level.

def do_dedent(self) -> None:
    """Handle dedent token."""
    self.level -= 1
    self.lws = self.level * self.tab_width * ' '
    self.line_indent()
    if self.black_mode:  # pragma: no cover (black)
        state = self.state_stack[-1]
        if state.kind == 'indent' and state.value == self.level:
            self.state_stack.pop()
            state = self.state_stack[-1]
            if state.kind in ('class', 'def'):
                self.state_stack.pop()
                self.handle_dedent_after_class_or_def(state.kind)

def do_indent(self) -> None:
    """Handle indent token."""
    # #2578: Refuse to beautify files containing leading tabs or unusual indentation.
    consider_message = 'consider using python/Tools/scripts/reindent.py'
    if '\t' in self.val:  # pragma: no cover
        message = f"Leading tabs found: {self.filename}"
        print(message)
        print(consider_message)
        raise BeautifyError(message)
    if (len(self.val) % self.tab_width) != 0:  # pragma: no cover
        message = f" Indentation error: {self.filename}"
        print(message)
        print(consider_message)
        raise BeautifyError(message)
    new_indent = self.val
    old_indent = self.level * self.tab_width * ' '
    if new_indent > old_indent:
        self.level += 1
    elif new_indent < old_indent:  # pragma: no cover (defensive)
        g.trace('\n===== can not happen', repr(new_indent), repr(old_indent))
    self.lws = new_indent
    self.line_indent()
#@+node:ekr.20200220054928.1: *6* orange.handle_dedent_after_class_or_def
def handle_dedent_after_class_or_def(self, kind: str) -> None:  # pragma: no cover (black)
    """
    Insert blank lines after a class or def as the result of a 'dedent' token.

    Normal comment lines may precede the 'dedent'.
    Insert the blank lines *before* such comment lines.
    """
    #
    # Compute the tail.
    i = len(self.code_list) - 1
    tail: list[OutputToken] = []
    while i > 0:
        t = self.code_list.pop()
        i -= 1
        if t.kind == 'line-indent':
            pass
        elif t.kind == 'line-end':
            tail.insert(0, t)
        elif t.kind == 'comment':
            # Only underindented single-line comments belong in the tail.
            #@verbatim
            # @+node comments must never be in the tail.
            single_line = self.code_list[i].kind in ('line-end', 'line-indent')
            lws = len(t.value) - len(t.value.lstrip())
            underindent = lws <= len(self.lws)
            if underindent and single_line and not self.node_pat.match(t.value):
                # A single-line comment.
                tail.insert(0, t)
            else:
                self.code_list.append(t)
                break
        else:
            self.code_list.append(t)
            break
    #
    # Remove leading 'line-end' tokens from the tail.
    while tail and tail[0].kind == 'line-end':
        tail = tail[1:]
    #
    # Put the newlines *before* the tail.
    # For Leo, always use 1 blank lines.
    n = 1  # n = 2 if kind == 'class' else 1
    # Retain the token (intention) for debugging.
    self.add_token('blank-lines', n)
    for _i in range(0, n + 1):
        self.add_token('line-end', '\n')
    if tail:
        self.code_list.extend(tail)
    self.line_indent()
#@+node:ekr.20200107165250.20: *5* orange.do_name
def do_name(self) -> None:
    """Handle a name token."""
    name = self.val
    if self.black_mode and name in ('class', 'def'):  # pragma: no cover (black)
        # Handle newlines before and after 'class' or 'def'
        self.decorator_seen = False
        state = self.state_stack[-1]
        if state.kind == 'decorator':
            # Always do this, regardless of @bool clean-blank-lines.
            self.clean_blank_lines()
            # Suppress split/join.
            self.add_token('hard-newline', '\n')
            self.add_token('line-indent', self.lws)
            self.state_stack.pop()
        else:
            # Always do this, regardless of @bool clean-blank-lines.
            self.blank_lines(2 if name == 'class' else 1)
        self.push_state(name)
        # For trailing lines after inner classes/defs.
        self.push_state('indent', self.level)
        self.word(name)
        return
    #
    # Leo mode...
    if name in ('class', 'def'):
        self.word(name)
    elif name in (
        'and', 'elif', 'else', 'for', 'if', 'in', 'not', 'not in', 'or', 'while'
    ):
        self.word_op(name)
    else:
        self.word(name)
#@+node:ekr.20200107165250.21: *5* orange.do_newline & do_nl
def do_newline(self) -> None:
    """Handle a regular newline."""
    self.line_end()

def do_nl(self) -> None:
    """Handle a continuation line."""
    self.line_end()
#@+node:ekr.20200107165250.22: *5* orange.do_number
def do_number(self) -> None:
    """Handle a number token."""
    self.blank()
    self.add_token('number', self.val)
#@+node:ekr.20200107165250.23: *5* orange.do_op & helper
def do_op(self) -> None:
    """Handle an op token."""
    val = self.val
    if val == '.':
        self.clean('blank')
        prev = self.code_list[-1]
        # #2495 & #2533: Special case for 'from .'
        if prev.kind == 'word' and prev.value == 'from':
            self.blank()
        self.add_token('op-no-blanks', val)
    elif val == '@':
        if self.black_mode:  # pragma: no cover (black)
            if not self.decorator_seen:
                self.blank_lines(1)
                self.decorator_seen = True
        self.clean('blank')
        self.add_token('op-no-blanks', val)
        self.push_state('decorator')
    elif val == ':':
        # Treat slices differently.
        self.colon(val)
    elif val in ',;':
        # Pep 8: Avoid extraneous whitespace immediately before
        # comma, semicolon, or colon.
        self.clean('blank')
        self.add_token('op', val)
        self.blank()
    elif val in '([{':
        # Pep 8: Avoid extraneous whitespace immediately inside
        # parentheses, brackets or braces.
        self.lt(val)
    elif val in ')]}':
        # Ditto.
        self.rt(val)
    elif val == '=':
        self.do_equal_op(val)
    elif val in '~+-':
        self.possible_unary_op(val)
    elif val == '*':
        self.star_op()
    elif val == '**':
        self.star_star_op()
    else:
        # Pep 8: always surround binary operators with a single space.
        # '==','+=','-=','*=','**=','/=','//=','%=','!=','<=','>=','<','>',
        # '^','~','*','**','&','|','/','//',
        # Pep 8: If operators with different priorities are used,
        # consider adding whitespace around the operators with the lowest priorities.
        self.blank()
        self.add_token('op', val)
        self.blank()
#@+node:ekr.20230115141629.1: *6* orange.do_equal_op
# Keys: token.index of '=' token. Values: count of ???s
arg_dict: dict[int, int] = {}

dump_flag = True

def do_equal_op(self, val: str) -> None:

    if 0:
        token = self.token
        g.trace(
            f"token.index: {token.index:2} paren_level: {self.paren_level} "
            f"token.equal_sign_spaces: {int(token.equal_sign_spaces)} "
            # f"{token.node.__class__.__name__}"
        )
        # dump_tree(self.tokens, self.tree)
    if self.token.equal_sign_spaces:
        self.blank()
        self.add_token('op', val)
        self.blank()
    else:
        # Pep 8: Don't use spaces around the = sign when used to indicate
        #        a keyword argument or a default parameter value.
        #        However, hen combining an argument annotation with a default value,
        #        *do* use spaces around the = sign
        self.clean('blank')
        self.add_token('op-no-blanks', val)
#@+node:ekr.20200107165250.24: *5* orange.do_string
def do_string(self) -> None:
    """Handle a 'string' token."""
    # Careful: continued strings may contain '\r'
    val = regularize_nls(self.val)
    self.add_token('string', val)
    self.blank()
#@+node:ekr.20200210175117.1: *5* orange.do_verbatim
beautify_pat = re.compile(
    r'#\s*pragma:\s*beautify\b|#\s*@@beautify|#\s*@\+node|#\s*@[+-]others|#\s*@[+-]<<')

def do_verbatim(self) -> None:
    """
    Handle one token in verbatim mode.
    End verbatim mode when the appropriate comment is seen.
    """
    kind = self.kind
    #
    # Careful: tokens may contain '\r'
    val = regularize_nls(self.val)
    if kind == 'comment':
        if self.beautify_pat.match(val):
            self.verbatim = False
        val = val.rstrip()
        self.add_token('comment', val)
        return
    if kind == 'indent':
        self.level += 1
        self.lws = self.level * self.tab_width * ' '
    if kind == 'dedent':
        self.level -= 1
        self.lws = self.level * self.tab_width * ' '
    self.add_token('verbatim', val)
#@+node:ekr.20200107165250.25: *5* orange.do_ws
def do_ws(self) -> None:
    """
    Handle the "ws" pseudo-token.

    Put the whitespace only if if ends with backslash-newline.
    """
    val = self.val
    # Handle backslash-newline.
    if '\\\n' in val:
        self.clean('blank')
        self.add_token('op-no-blanks', val)
        return
    # Handle start-of-line whitespace.
    prev = self.code_list[-1]
    inner = self.paren_level or self.square_brackets_stack or self.curly_brackets_level
    if prev.kind == 'line-indent' and inner:
        # Retain the indent that won't be cleaned away.
        self.clean('line-indent')
        self.add_token('hard-blank', val)
#@+node:ekr.20200107165250.26: *4* orange: Output token generators
#@+node:ekr.20200118145044.1: *5* orange.add_line_end
def add_line_end(self) -> OutputToken:
    """Add a line-end request to the code list."""
    # This may be called from do_name as well as do_newline and do_nl.
    assert self.token.kind in ('newline', 'nl'), self.token.kind
    self.clean('blank')  # Important!
    self.clean('line-indent')
    t = self.add_token('line-end', '\n')
    # Distinguish between kinds of 'line-end' tokens.
    t.newline_kind = self.token.kind
    return t
#@+node:ekr.20200107170523.1: *5* orange.add_token
def add_token(self, kind: str, value: Any) -> OutputToken:
    """Add an output token to the code list."""
    tok = OutputToken(kind, value)
    tok.index = len(self.code_list)
    self.code_list.append(tok)
    return tok
#@+node:ekr.20200107165250.27: *5* orange.blank
def blank(self) -> None:
    """Add a blank request to the code list."""
    prev = self.code_list[-1]
    if prev.kind not in (
        'blank',
        'blank-lines',
        'file-start',
        'hard-blank',  # Unique to orange.
        'line-end',
        'line-indent',
        'lt',
        'op-no-blanks',
        'unary-op',
    ):
        self.add_token('blank', ' ')
#@+node:ekr.20200107165250.29: *5* orange.blank_lines (black only)
def blank_lines(self, n: int) -> None:  # pragma: no cover (black)
    """
    Add a request for n blank lines to the code list.
    Multiple blank-lines request yield at least the maximum of all requests.
    """
    self.clean_blank_lines()
    prev = self.code_list[-1]
    if prev.kind == 'file-start':
        self.add_token('blank-lines', n)
        return
    for _i in range(0, n + 1):
        self.add_token('line-end', '\n')
    # Retain the token (intention) for debugging.
    self.add_token('blank-lines', n)
    self.line_indent()
#@+node:ekr.20200107165250.30: *5* orange.clean
def clean(self, kind: str) -> None:
    """Remove the last item of token list if it has the given kind."""
    prev = self.code_list[-1]
    if prev.kind == kind:
        self.code_list.pop()
#@+node:ekr.20200107165250.31: *5* orange.clean_blank_lines
def clean_blank_lines(self) -> bool:
    """
    Remove all vestiges of previous blank lines.

    Return True if any of the cleaned 'line-end' tokens represented "hard" newlines.
    """
    cleaned_newline = False
    table = ('blank-lines', 'line-end', 'line-indent')
    while self.code_list[-1].kind in table:
        t = self.code_list.pop()
        if t.kind == 'line-end' and getattr(t, 'newline_kind', None) != 'nl':
            cleaned_newline = True
    return cleaned_newline
#@+node:ekr.20200107165250.32: *5* orange.colon
def colon(self, val: str) -> None:
    """Handle a colon."""

    def is_expr(node: Node) -> bool:
        """True if node is any expression other than += number."""
        if isinstance(node, (ast.BinOp, ast.Call, ast.IfExp)):
            return True
        num_node = ast.Num if g.python_version_tuple < (3, 12, 0) else ast.Constant
        return (
            isinstance(node, ast.UnaryOp)
            and not isinstance(node.operand, num_node)
        )

    node = self.token.node
    self.clean('blank')
    if not isinstance(node, ast.Slice):
        self.add_token('op', val)
        self.blank()
        return
    # A slice.
    lower = getattr(node, 'lower', None)
    upper = getattr(node, 'upper', None)
    step = getattr(node, 'step', None)
    if any(is_expr(z) for z in (lower, upper, step)):
        prev = self.code_list[-1]
        if prev.value not in '[:':
            self.blank()
        self.add_token('op', val)
        self.blank()
    else:
        self.add_token('op-no-blanks', val)
#@+node:ekr.20200107165250.33: *5* orange.line_end
def line_end(self) -> None:
    """Add a line-end request to the code list."""
    # This should be called only be do_newline and do_nl.
    node, token = self.token.statement_node, self.token
    assert token.kind in ('newline', 'nl'), (token.kind, g.callers())
    # Create the 'line-end' output token.
    self.add_line_end()
    # Attempt to split the line.
    was_split = self.split_line(node, token)
    # Attempt to join the line only if it has not just been split.
    if not was_split and self.max_join_line_length > 0:
        self.join_lines(node, token)
    # Add the indentation for all lines
    # until the next indent or unindent token.
    self.line_indent()
#@+node:ekr.20200107165250.40: *5* orange.line_indent
def line_indent(self) -> None:
    """Add a line-indent token."""
    self.clean('line-indent')  # Defensive. Should never happen.
    self.add_token('line-indent', self.lws)
#@+node:ekr.20200107165250.41: *5* orange.lt & rt
#@+node:ekr.20200107165250.42: *6* orange.lt
def lt(self, val: str) -> None:
    """Generate code for a left paren or curly/square bracket."""
    assert val in '([{', repr(val)
    if val == '(':
        self.paren_level += 1
    elif val == '[':
        self.square_brackets_stack.append(False)
    else:
        self.curly_brackets_level += 1
    self.clean('blank')
    prev = self.code_list[-1]
    if prev.kind in ('op', 'word-op'):
        self.blank()
        self.add_token('lt', val)
    elif prev.kind == 'word':
        # Only suppress blanks before '(' or '[' for non-keywords.
        if val == '{' or prev.value in ('if', 'else', 'return', 'for'):
            self.blank()
        elif val == '(':
            self.in_arg_list += 1
        self.add_token('lt', val)
    else:
        self.clean('blank')
        self.add_token('op-no-blanks', val)
#@+node:ekr.20200107165250.43: *6* orange.rt
def rt(self, val: str) -> None:
    """Generate code for a right paren or curly/square bracket."""
    assert val in ')]}', repr(val)
    if val == ')':
        self.paren_level -= 1
        self.in_arg_list = max(0, self.in_arg_list - 1)
    elif val == ']':
        self.square_brackets_stack.pop()
    else:
        self.curly_brackets_level -= 1
    self.clean('blank')
    self.add_token('rt', val)
#@+node:ekr.20200107165250.45: *5* orange.possible_unary_op & unary_op
def possible_unary_op(self, s: str) -> None:
    """Add a unary or binary op to the token list."""
    node = self.token.node
    self.clean('blank')
    if isinstance(node, ast.UnaryOp):
        self.unary_op(s)
    else:
        self.blank()
        self.add_token('op', s)
        self.blank()

def unary_op(self, s: str) -> None:
    """Add an operator request to the code list."""
    assert s and isinstance(s, str), repr(s)
    self.clean('blank')
    prev = self.code_list[-1]
    if prev.kind == 'lt':
        self.add_token('unary-op', s)
    else:
        self.blank()
        self.add_token('unary-op', s)
#@+node:ekr.20200107165250.46: *5* orange.star_op
def star_op(self) -> None:
    """Put a '*' op, with special cases for *args."""
    val = '*'
    node = self.token.node
    self.clean('blank')
    if isinstance(node, ast.arguments):
        self.blank()
        self.add_token('op', val)
        return  # #2533
    if self.paren_level > 0:
        prev = self.code_list[-1]
        if prev.kind == 'lt' or (prev.kind, prev.value) == ('op', ','):
            self.blank()
            self.add_token('op', val)
            return
    self.blank()
    self.add_token('op', val)
    self.blank()
#@+node:ekr.20200107165250.47: *5* orange.star_star_op
def star_star_op(self) -> None:
    """Put a ** operator, with a special case for **kwargs."""
    val = '**'
    node = self.token.node
    self.clean('blank')
    if isinstance(node, ast.arguments):
        self.blank()
        self.add_token('op', val)
        return  # #2533
    if self.paren_level > 0:
        prev = self.code_list[-1]
        if prev.kind == 'lt' or (prev.kind, prev.value) == ('op', ','):
            self.blank()
            self.add_token('op', val)
            return
    self.blank()
    self.add_token('op', val)
    self.blank()
#@+node:ekr.20200107165250.48: *5* orange.word & word_op
def word(self, s: str) -> None:
    """Add a word request to the code list."""
    assert s and isinstance(s, str), repr(s)
    node = self.token.node
    if isinstance(node, ast.ImportFrom) and s == 'import':  # #2533
        self.clean('blank')
        self.add_token('blank', ' ')
        self.add_token('word', s)
    elif self.square_brackets_stack:
        # A previous 'op-no-blanks' token may cancel this blank.
        self.blank()
        self.add_token('word', s)
    elif self.in_arg_list > 0:
        self.add_token('word', s)
        self.blank()
    else:
        self.blank()
        self.add_token('word', s)
        self.blank()

def word_op(self, s: str) -> None:
    """Add a word-op request to the code list."""
    assert s and isinstance(s, str), repr(s)
    self.blank()
    self.add_token('word-op', s)
    self.blank()
#@+node:ekr.20200118120049.1: *4* orange: Split/join
#@+node:ekr.20200107165250.34: *5* orange.split_line & helpers
def split_line(self, node: Node, token: Token) -> bool:
    """
    Split token's line, if possible and enabled.

    Return True if the line was broken into two or more lines.
    """
    assert token.kind in ('newline', 'nl'), repr(token)
    # Return if splitting is disabled:
    if self.max_split_line_length <= 0:  # pragma: no cover (user option)
        return False
    # Return if the node can't be split.
    if not is_long_statement(node):
        return False
    # Find the *output* tokens of the previous lines.
    line_tokens = self.find_prev_line()
    line_s = ''.join([z.to_string() for z in line_tokens])
    # Do nothing for short lines.
    if len(line_s) < self.max_split_line_length:
        return False
    # Return if the previous line has no opening delim: (, [ or {.
    if not any(z.kind == 'lt' for z in line_tokens):  # pragma: no cover (defensive)
        return False
    prefix = self.find_line_prefix(line_tokens)
    # Calculate the tail before cleaning the prefix.
    tail = line_tokens[len(prefix) :]
    # Cut back the token list: subtract 1 for the trailing line-end.
    self.code_list = self.code_list[: len(self.code_list) - len(line_tokens) - 1]
    # Append the tail, splitting it further, as needed.
    self.append_tail(prefix, tail)
    # Add the line-end token deleted by find_line_prefix.
    self.add_token('line-end', '\n')
    return True
#@+node:ekr.20200107165250.35: *6* orange.append_tail
def append_tail(self, prefix: list[OutputToken], tail: list[OutputToken]) -> None:
    """Append the tail tokens, splitting the line further as necessary."""
    tail_s = ''.join([z.to_string() for z in tail])
    if len(tail_s) < self.max_split_line_length:
        # Add the prefix.
        self.code_list.extend(prefix)
        # Start a new line and increase the indentation.
        self.add_token('line-end', '\n')
        self.add_token('line-indent', self.lws + ' ' * 4)
        self.code_list.extend(tail)
        return
    # Still too long.  Split the line at commas.
    self.code_list.extend(prefix)
    # Start a new line and increase the indentation.
    self.add_token('line-end', '\n')
    self.add_token('line-indent', self.lws + ' ' * 4)
    open_delim = Token(kind='lt', value=prefix[-1].value)
    value = open_delim.value.replace('(', ')').replace('[', ']').replace('{', '}')
    close_delim = Token(kind='rt', value=value)
    delim_count = 1
    lws = self.lws + ' ' * 4
    for i, t in enumerate(tail):
        if t.kind == 'op' and t.value == ',':
            if delim_count == 1:
                # Start a new line.
                self.add_token('op-no-blanks', ',')
                self.add_token('line-end', '\n')
                self.add_token('line-indent', lws)
                # Kill a following blank.
                if i + 1 < len(tail):
                    next_t = tail[i + 1]
                    if next_t.kind == 'blank':
                        next_t.kind = 'no-op'
                        next_t.value = ''
            else:
                self.code_list.append(t)
        elif t.kind == close_delim.kind and t.value == close_delim.value:
            # Done if the delims match.
            delim_count -= 1
            if delim_count == 0:
                # Start a new line
                self.add_token('op-no-blanks', ',')
                self.add_token('line-end', '\n')
                self.add_token('line-indent', self.lws)
                self.code_list.extend(tail[i:])
                return
            lws = lws[:-4]
            self.code_list.append(t)
        elif t.kind == open_delim.kind and t.value == open_delim.value:
            delim_count += 1
            lws = lws + ' ' * 4
            self.code_list.append(t)
        else:
            self.code_list.append(t)
    g.trace('BAD DELIMS', delim_count)  # pragma: no cover
#@+node:ekr.20200107165250.36: *6* orange.find_prev_line
def find_prev_line(self) -> list[OutputToken]:
    """Return the previous line, as a list of tokens."""
    line = []
    for t in reversed(self.code_list[:-1]):
        if t.kind in ('hard-newline', 'line-end'):
            break
        line.append(t)
    return list(reversed(line))
#@+node:ekr.20200107165250.37: *6* orange.find_line_prefix
def find_line_prefix(self, token_list: list[OutputToken]) -> list[OutputToken]:
    """
    Return all tokens up to and including the first lt token.
    Also add all lt tokens directly following the first lt token.
    """
    result = []
    for t in token_list:
        result.append(t)
        if t.kind == 'lt':
            break
    return result
#@+node:ekr.20200107165250.39: *5* orange.join_lines
def join_lines(self, node: Node, token: Token) -> None:
    """
    Join preceding lines, if possible and enabled.
    token is a line_end token. node is the corresponding ast node.
    """
    if self.max_join_line_length <= 0:  # pragma: no cover (user option)
        return
    assert token.kind in ('newline', 'nl'), repr(token)
    if token.kind == 'nl':
        return
    # Scan backward in the *code* list,
    # looking for 'line-end' tokens with tok.newline_kind == 'nl'
    nls = 0
    i = len(self.code_list) - 1
    t = self.code_list[i]
    assert t.kind == 'line-end', repr(t)
    # Not all tokens have a newline_kind ivar.
    assert t.newline_kind == 'newline'
    i -= 1
    while i >= 0:
        t = self.code_list[i]
        if t.kind == 'comment':
            # Can't join.
            return
        if t.kind == 'string' and not self.allow_joined_strings:
            # An EKR preference: don't join strings, no matter what black does.
            # This allows "short" f-strings to be aligned.
            return
        if t.kind == 'line-end':
            if getattr(t, 'newline_kind', None) == 'nl':
                nls += 1
            else:
                break  # pragma: no cover
        i -= 1
    # Retain at the file-start token.
    if i <= 0:
        i = 1
    if nls <= 0:  # pragma: no cover (rare)
        return
    # Retain line-end and and any following line-indent.
    # Required, so that the regex below won't eat too much.
    while True:
        t = self.code_list[i]
        if t.kind == 'line-end':
            if getattr(t, 'newline_kind', None) == 'nl':  # pragma: no cover (rare)
                nls -= 1
            i += 1
        elif self.code_list[i].kind == 'line-indent':
            i += 1
        else:
            break  # pragma: no cover (defensive)
    if nls <= 0:  # pragma: no cover (defensive)
        return
    # Calculate the joined line.
    tail = self.code_list[i:]
    tail_s = output_tokens_to_string(tail)
    tail_s = re.sub(r'\n\s*', ' ', tail_s)
    tail_s = tail_s.replace('( ', '(').replace(' )', ')')
    tail_s = tail_s.rstrip()
    # Don't join the lines if they would be too long.
    if len(tail_s) > self.max_join_line_length:  # pragma: no cover (defensive)
        return
    # Cut back the code list.
    self.code_list = self.code_list[:i]
    # Add the new output tokens.
    self.add_token('string', tail_s)
    self.add_token('line-end', '\n')
#@+node:ekr.20200107174645.1: *3* class TestOrange (BaseTest)
class TestOrange(BaseTest):
    """
    Tests for the Orange class.

    **Important**: All unit tests assume that black_mode is False.
                   That is, unit tests assume that no blank lines
                   are ever inserted or deleted.
    """
    @others
#@+node:ekr.20200115201823.1: *4* TestOrange.blacken
def blacken(self, contents, line_length=None):
    """Return the results of running black on contents"""
    if not black:
        self.skipTest('Requires Black')  # pragma: no cover
    # Suppress string normalization!
    try:
        mode = black.FileMode()
        mode.string_normalization = False
        if line_length is not None:
            mode.line_length = line_length
    except TypeError:  # pragma: no cover
        self.skipTest('Requires later version of Black')
    return black.format_str(contents, mode=mode)
#@+node:ekr.20230115150916.1: *4* TestOrange.test_annotations
def test_annotations(self):

    table = (
    # Case 0.
    '''
def annotated_f(s: str = None, x=None) -> None:
    pass
''',
    )
    for i, contents in enumerate(table):
        contents, tokens, tree = self.make_data(contents)
        expected = self.blacken(contents).strip() + '\n'
        results = self.beautify(contents, tokens, tree)
        self.assertEqual(results, expected)

#@+node:ekr.20200219114415.1: *4* TestOrange.test_at_doc_part
def test_at_doc_part(self):

    line_length = 40  # For testing.
    contents = """
@ Line 1
Line 2
@c

print('hi')
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents.rstrip() + '\n'
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    self.assertEqual(results, expected)
#@+node:ekr.20200116102345.1: *4* TestOrange.test_backslash_newline
def test_backslash_newline(self):
    """
    This test is necessarily different from black, because orange doesn't
    delete semicolon tokens.
    """
    contents = r"""
print(a);\
print(b)
print(c); \
print(d)
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents.rstrip() + '\n'
    # expected = self.blacken(contents).rstrip() + '\n'
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200219145639.1: *4* TestOrange.test_blank_lines_after_function
def test_blank_lines_after_function(self):

    contents = """
# Comment line 1.
# Comment line 2.

def spam():
    pass
    # Properly indented comment.

# Comment line3.
# Comment line4.
a = 2
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200220050758.1: *4* TestOrange.test_blank_lines_after_function_2
def test_blank_lines_after_function_2(self):

    contents = """
# Leading comment line 1.
# Leading comment lines 2.

def spam():
    pass

# Trailing comment line.
a = 2
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200220053212.1: *4* TestOrange.test_blank_lines_after_function_3
def test_blank_lines_after_function_3(self):

    # From leoAtFile.py.
    contents = """
def writeAsisNode(self, p):
    print('1')

    def put(s):
        print('2')

    # Trailing comment 1.
    # Trailing comment 2.
    print('3')
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200228074455.1: *4* TestOrange.test_bug_1429
def test_bug_1429(self):

    contents = r'''
def get_semver(tag):
    """bug 1429 docstring"""
    try:
        import semantic_version
        version = str(semantic_version.Version.coerce(tag, partial=True))
            # tuple of major, minor, build, pre-release, patch
            # 5.6b2 --> 5.6-b2
    except(ImportError, ValueError) as err:
        print('\n', err)
        print("""*** Failed to parse Semantic Version from git tag '{0}'.
        Expecting tag name like '5.7b2', 'leo-4.9.12', 'v4.3' for releases.
        This version can't be uploaded to PyPi.org.""".format(tag))
        version = tag
    return version
'''
    contents, tokens, tree = self.make_data(contents)
    expected = contents.strip() + '\n'
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=0, max_split_line_length=0)
    self.assertEqual(results, expected)
#@+node:ekr.20210318055702.1: *4* TestOrange.test_bug_1851
def test_bug_1851(self):

    contents = r'''
def foo(a1):
    pass
'''
    contents, tokens, tree = self.make_data(contents)
    expected = contents.strip() + '\n'
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=0, max_split_line_length=0)
    self.assertEqual(results, expected)
#@+node:ekr.20200209152745.1: *4* TestOrange.test_comment_indented
def test_comment_indented(self):

    line_length = 40  # For testing.
    table = (
"""
if 1:
    pass
        # An indented comment.
""",
"""
table = (
    # Indented comment.
)
"""
    )

    fails = 0
    for contents in table:
        contents, tokens, tree = self.make_data(contents)
        expected = contents
        if 0:
            dump_contents(contents)
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!r}\n"
            f"  expected: {expected!r}\n"
            f"       got: {results!r}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    assert not fails, fails
#@+node:ekr.20230117043931.1: *4* TestOrange.test_comment_space_after_delim
def test_comment_space_after_delim(self):

    line_length = 40  # For testing.
    table = (
        # Test 1.
        (
            """#No space after delim.\n""",
            """# No space after delim.\n""",
        ),
        # Test 2.  Don't change bang lines.
        (
            """#! /usr/bin/env python\n""",
            """#! /usr/bin/env python\n""",
        ),
        # Test 3.  Don't change ### comments.
        (
            """### To do.\n""",
            """### To do.\n""",
        ),
    )
    fails = 0
    for contents, expected in table:
        contents, tokens, tree = self.make_data(contents)
        if 0:
            dump_contents(contents)
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!r}\n"
            f"  expected: {expected!r}\n"
            f"       got: {results!r}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    assert not fails, fails
#@+node:ekr.20200210120455.1: *4* TestOrange.test_decorator
def test_decorator(self):

    table = (
    # Case 0.
    """
@my_decorator(1)
def func():
    pass
""",
    # Case 1.
    """
if 1:
    @my_decorator
    def func():
        pass
""",
    # Case 2.
    '''
@g.commander_command('promote')
def promote(self, event=None, undoFlag=True):
    """Make all children of the selected nodes siblings of the selected node."""
''',
    )
    for i, contents in enumerate(table):
        contents, tokens, tree = self.make_data(contents)
        expected = self.prep(contents)
        results = self.beautify(contents, tokens, tree)
        if results != expected:
            g.trace('Fail:', i)  # pragma: no cover
        self.assertEqual(results, expected)
#@+node:ekr.20200211094614.1: *4* TestOrange.test_dont_delete_blank_lines
def test_dont_delete_blank_lines(self):

    line_length = 40  # For testing.
    contents = """
class Test:

    def test_func():

        pass

    a = 2
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents.rstrip() + '\n'
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    self.assertEqual(results, expected)
#@+node:ekr.20200116110652.1: *4* TestOrange.test_function_defs
def test_function_defs(self):

    table = (
    # Case 0.
    """
def f1(a=2 + 5):
    pass
""",
    # Case 2
     """
def f1():
    pass
""",
    # Case 3.
    """
def f1():
    pass
""",
    # Case 4.
    '''
def should_kill_beautify(p):
    """Return True if p.b contains @killbeautify"""
    return 'killbeautify' in g.get_directives_dict(p)
''',
    )
    for i, contents in enumerate(table):
        contents, tokens, tree = self.make_data(contents)
        expected = self.blacken(self.prep(contents))
        results = self.beautify(contents, tokens, tree)
        self.assertEqual(results, expected)
#@+node:ekr.20200116104031.1: *4* TestOrange.test_join_and_strip_condition
def test_join_and_strip_condition(self):

    contents = self.prep(
    """
        if (
            a == b or
            c == d
        ):
            pass
    """)
    expected = self.prep(
    """
        if (a == b or c == d):
            pass
    """)
    contents, tokens, tree = self.make_data(contents)
    expected = self.prep(expected)
    # Black also removes parens, which is beyond our scope at present.
        # expected = self.blacken(contents, line_length=40)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200208041446.1: *4* TestOrange.test_join_leading_whitespace
def test_join_leading_whitespace(self):

    line_length = 40  # For testing.
    table = (
                        # 1234567890x1234567890x1234567890x1234567890x
"""
if 1:
    print('4444',
        '5555')
""",
"""
if 1:
    print('4444', '5555')\n""",
    )
    fails = 0
    for contents in table:
        contents, tokens, tree = self.make_data(contents)
        if 0:
            dump_contents(contents)
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        expected = contents
        # expected = self.blacken(contents, line_length=line_length)
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!r}\n"
            f"  expected: {expected!r}\n"
            f"       got: {results!r}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    assert not fails, fails
#@+node:ekr.20200121093134.1: *4* TestOrange.test_join_lines
def test_join_lines(self):

    # Except where noted, all entries are expected values....
    line_length = 40  # For testing.
    table = (
        # 1234567890x1234567890x1234567890x1234567890x
        """print('4444',\n    '5555')""",
        """print('4444', '5555')\n""",
    )
    fails = 0
    for contents in table:
        contents, tokens, tree = self.make_data(contents)
        if 0:
            dump_contents(contents)
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        expected = contents
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!r}\n"
            f"  expected: {expected!r}\n"
            f"    orange: {results!r}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    self.assertEqual(fails, 0)
#@+node:ekr.20200210051900.1: *4* TestOrange.test_join_suppression
def test_join_suppression(self):

    contents = self.prep("""
        class T:
            a = 1
            print(
               a
            )
    """)
    expected = self.prep("""
        class T:
            a = 1
            print(a)
    """)
    contents, tokens, tree = self.make_data(contents)
    expected = self.prep(expected)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200207093606.1: *4* TestOrange.test_join_too_long_lines
def test_join_too_long_lines(self):

    # Except where noted, all entries are expected values....
    line_length = 40  # For testing.
    table = (
                        # 1234567890x1234567890x1234567890x1234567890x
        (
            """print('aaaaaaaaaaaa',\n    'bbbbbbbbbbbb', 'cccccccccccccccc')""",
            """print('aaaaaaaaaaaa',\n    'bbbbbbbbbbbb', 'cccccccccccccccc')\n""",
        ),
    )
    fails = 0
    for contents, expected in table:
        contents, tokens, tree = self.make_data(contents)
        if 0:
            dump_contents(contents)
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!r}\n"
            f"  expected: {expected!r}\n"
            f"       got: {results!r}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    assert not fails, fails
#@+node:ekr.20220327131225.1: *4* TestOrange.test_leading_stars
def test_leading_stars(self):

    # #2533.
    contents = """
        def f(
            arg1,
            *args,
            **kwargs
        ):
            pass
    """.strip() + '\n'

    expected = """
        def f(arg1, *args, **kwargs):
            pass
    """.strip() + '\n'
    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(expected, results)
#@+node:ekr.20200108075541.1: *4* TestOrange.test_leo_sentinels
def test_leo_sentinels_1(self):

    # Careful: don't put a sentinel into the file directly.
    # That would corrupt leoAst.py.
    sentinel = '#@+node:ekr.20200105143308.54: ** test'
    contents = f"""
{sentinel}
def spam():
    pass
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents.rstrip() + '\n'
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200209155457.1: *4* TestOrange.test_leo_sentinels_2
def test_leo_sentinels_2(self):

    # Careful: don't put a sentinel into the file directly.
    # That would corrupt leoAst.py.
    sentinel = '#@+node:ekr.20200105143308.54: ** test'
    contents = f"""
{sentinel}
class TestClass:
    pass
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents.rstrip() + '\n'
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200108082833.1: *4* TestOrange.test_lines_before_class
def test_lines_before_class(self):

    contents = """
a = 2
class aClass:
    pass
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200110014220.86: *4* TestOrange.test_multi_line_pet_peeves
def test_multi_line_pet_peeves(self):

    contents = """
if x == 4: pass
if x == 4 : pass
print (x, y); x, y = y, x
print (x , y) ; x , y = y , x
if(1):
    pass
elif(2):
    pass
while(3):
    pass
"""
    # At present Orange doesn't split lines...
    expected = """
if x == 4: pass
if x == 4: pass
print(x, y); x, y = y, x
print(x, y); x, y = y, x
if (1):
    pass
elif (2):
    pass
while (3):
    pass
"""
    contents, tokens, tree = self.make_data(contents)
    expected = self.adjust_expected(expected)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200110014220.95: *4* TestOrange.test_one_line_pet_peeves
def test_one_line_pet_peeves(self):

    # See https://peps.python.org/pep-0008/#pet-peeves
    # See https://peps.python.org/pep-0008/#other-recommendations

    tag = 'test_one_line_pet_peeves'
    # Except where noted, all entries are expected values....
    if 0:
        # Test fails or recents...
        table = (
            # """a[: 1 if True else 2 :]""",
            """a[:-1]""",
        )
    else:
        table = (
            # Assignments...
            # Slices (colons)...
            """a[:-1]""",
            """a[: 1 if True else 2 :]""",
            """a[1 : 1 + 2]""",
            """a[lower:]""",
            """a[lower::]""",
            """a[:upper]""",
            """a[:upper:]""",
            """a[::step]""",
            """a[lower:upper:]""",
            """a[lower:upper:step]""",
            """a[lower + offset : upper + offset]""",
            """a[: upper_fn(x) :]""",
            """a[: upper_fn(x) : step_fn(x)]""",
            """a[:: step_fn(x)]""",
            """a[: upper_fn(x) :]""",
            """a[: upper_fn(x) : 2 + 1]""",
            """a[:]""",
            """a[::]""",
            """a[1:]""",
            """a[1::]""",
            """a[:2]""",
            """a[:2:]""",
            """a[::3]""",
            """a[1:2]""",
            """a[1:2:]""",
            """a[:2:3]""",
            """a[1:2:3]""",
            # * and **, inside and outside function calls.
            """a = b * c""",
            # Now done in test_star_star_operator
            # """a = b ** c""",  # Black has changed recently.
            """f(*args)""",
            """f(**kwargs)""",
            """f(*args, **kwargs)""",
            """f(a, *args)""",
            """f(a=2, *args)""",
            # Calls...
            """f(-1)""",
            """f(-1 < 2)""",
            """f(1)""",
            """f(2 * 3)""",
            """f(2 + name)""",
            """f(a)""",
            """f(a.b)""",
            """f(a=2 + 3, b=4 - 5, c= 6 * 7, d=8 / 9, e=10 // 11)""",
            """f(a[1 + 2])""",
            """f({key: 1})""",
            """t = (0,)""",
            """x, y = y, x""",
            # Dicts...
            """d = {key: 1}""",
            """d['key'] = a[i]""",
            # Trailing comments: expect two spaces.
            """whatever # comment""",
            """whatever  # comment""",
            """whatever   # comment""",
            # Word ops...
            """v1 = v2 and v3 if v3 not in v4 or v5 in v6 else v7""",
            """print(v7 for v8 in v9)""",
            # Unary ops...
            """v = -1 if a < b else -2""",
            # Returns...
            """return -1""",
        )
    fails = 0
    for i, contents in enumerate(table):
        description = f"{tag} part {i}"
        contents, tokens, tree = self.make_data(contents, description=description)
        expected = self.blacken(contents)
        results = self.beautify(contents, tokens, tree, filename=description)
        if results != expected:  # pragma: no cover
            fails += 1
            print('')
            print(
                f"TestOrange.test_one_line_pet_peeves: FAIL {fails}\n"
                f"  contents: {contents.rstrip()}\n"
                f"     black: {expected.rstrip()}\n"
                f"    orange: {results.rstrip() if results else 'None'}")
    self.assertEqual(fails, 0)
#@+node:ekr.20220327135448.1: *4* TestOrange.test_relative_imports
def test_relative_imports(self):

    # #2533.
    contents = self.prep(
    """
        from .module1 import w
        from . module2 import x
        from ..module1 import y
        from .. module2 import z
        from . import a
        from.import b
        from leo.core import leoExternalFiles
        import leo.core.leoGlobals as g
    """)

    expected = self.prep(
    """
        from .module1 import w
        from .module2 import x
        from ..module1 import y
        from ..module2 import z
        from . import a
        from . import b
        from leo.core import leoExternalFiles
        import leo.core.leoGlobals as g
    """)

    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(expected, results)
#@+node:ekr.20200210050646.1: *4* TestOrange.test_return
def test_return(self):

    contents = """return []"""
    expected = self.blacken(contents)
    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200107174742.1: *4* TestOrange.test_single_quoted_string
def test_single_quoted_string(self):

    contents = """print('hi')"""
    # blacken suppresses string normalization.
    expected = self.blacken(contents)
    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200117180956.1: *4* TestOrange.test_split_lines
def test_split_lines(self):

    line_length = 40  # For testing.
    table = (
    # 1234567890x1234567890x1234567890x1234567890x
        """
if 1:
    print('1111111111', '2222222222', '3333333333')
""",
"""print('aaaaaaaaaaaaa', 'bbbbbbbbbbbbbb', 'cccccc')""",
"""print('aaaaaaaaaaaaa', 'bbbbbbbbbbbbbb', 'cccccc', 'ddddddddddddddddd')""",
    )
    fails = 0
    for contents in table:
        contents, tokens, tree = self.make_data(contents)
        if 0:
            dump_tokens(tokens)
            # dump_tree(tokens, tree)
        expected = self.blacken(contents, line_length=line_length)
        results = self.beautify(contents, tokens, tree,
            max_join_line_length=line_length,
            max_split_line_length=line_length,
        )
        message = (
            f"\n"
            f"  contents: {contents!s}\n"
            f"     black: {expected!s}\n"
            f"    orange: {results!s}")
        if results != expected:  # pragma: no cover
            fails += 1
            print(f"Fail: {fails}\n{message}")
    self.assertEqual(fails, 0)
#@+node:ekr.20200210073227.1: *4* TestOrange.test_split_lines_2
def test_split_lines_2(self):

    line_length = 40  # For testing.

    # Different from how black handles things.
    contents = """
if not any([z.kind == 'lt' for z in line_tokens]):
    return False
"""

    expected = self.prep(
    """
        if not any(
            [z.kind == 'lt' for z in line_tokens]):
            return False
    """)

    fails = 0
    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    message = (
        f"\n"
        f"  contents: {contents!r}\n"
        f"  expected: {expected!r}\n"
        f"       got: {results!r}")
    if results != expected:  # pragma: no cover
        fails += 1
        print(f"Fail: {fails}\n{message}")
    self.assertEqual(fails, 0)
#@+node:ekr.20200219144837.1: *4* TestOrange.test_split_lines_3
def test_split_lines_3(self):

    line_length = 40  # For testing.
    # Different from how black handles things.
    contents = """print('eee', ('fffffff, ggggggg', 'hhhhhhhh', 'iiiiiii'), 'jjjjjjj', 'kkkkkk')"""

    # This is a bit different from black, but it's good enough for now.
    expected = self.prep(
    """
        print(
            'eee',
            ('fffffff, ggggggg', 'hhhhhhhh', 'iiiiiii'),
            'jjjjjjj',
            'kkkkkk',
        )
    """)
    fails = 0
    contents, tokens, tree = self.make_data(contents)
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    message = (
        f"\n"
        f"  contents: {contents!r}\n"
        f"  expected: {expected!r}\n"
        f"       got: {results!r}")
    if results != expected:  # pragma: no cover
        fails += 1
        print(f"Fail: {fails}\n{message}")
    self.assertEqual(fails, 0)
#@+node:ekr.20220401191253.1: *4* TestOrange.test_star_star_operator
def test_star_star_operator(self):
    # Was tested in pet peeves, but this is more permissive.
    contents = """a = b ** c"""
    contents, tokens, tree = self.make_data(contents)
    # Don't rely on black for this test.
    # expected = self.blacken(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200119155207.1: *4* TestOrange.test_sync_tokens
def test_sync_tokens(self):

    contents = """if x == 4: pass"""
    # At present Orange doesn't split lines...
    expected = """if x == 4: pass"""
    contents, tokens, tree = self.make_data(contents)
    expected = self.adjust_expected(expected)
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200209161226.1: *4* TestOrange.test_ternary
def test_ternary(self):

    contents = """print(2 if name == 'class' else 1)"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected)
#@+node:ekr.20200211093359.1: *4* TestOrange.test_verbatim
def test_verbatim(self):

    line_length = 40  # For testing.

    contents = self.prep("""
@nobeautify

def addOptionsToParser(self, parser, trace_m):

    add = parser.add_option

    def add_bool(option, help, dest=None):
        add(option, action='store_true', dest=dest, help=help)

    add_bool('--diff',          'use Leo as an external git diff')
    # add_bool('--dock',          'use a Qt dock')
    add_bool('--fullscreen',    'start fullscreen')
    add_bool('--init-docks',    'put docks in default positions')
    # Multiple bool values.
    add('-v', '--version', action='store_true',
        help='print version number and exit')

# From leoAtFile.py
noDirective     =  1 # not an at-directive.
allDirective    =  2 # at-all (4.2)
docDirective    =  3 # @doc.

@beautify
""")
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    self.assertEqual(results, expected, msg=contents)
#@+node:ekr.20200211094209.1: *4* TestOrange.test_verbatim_with_pragma
def test_verbatim_with_pragma(self):

    line_length = 40  # For testing.
    contents = """
# pragma: no beautify

def addOptionsToParser(self, parser, trace_m):

    add = parser.add_option

    def add_bool(option, help, dest=None):
        add(option, action='store_true', dest=dest, help=help)

    add_bool('--diff',          'use Leo as an external git diff')
    # add_bool('--dock',          'use a Qt dock')
    add_bool('--fullscreen',    'start fullscreen')
    add_other('--window-size',  'initial window size (height x width)', m='SIZE')
    add_other('--window-spot',  'initial window position (top x left)', m='SPOT')
    # Multiple bool values.
    add('-v', '--version', action='store_true',
        help='print version number and exit')

# pragma: beautify
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree,
        max_join_line_length=line_length,
        max_split_line_length=line_length,
    )
    self.assertEqual(results, expected, msg=contents)
#@+node:ekr.20200729083027.1: *4* TestOrange.verbatim2
def test_verbatim2(self):

    contents = """
@beautify
@nobeautify
@ Starts doc part
More doc part.
The @c ends the doc part.
@c
"""
    contents, tokens, tree = self.make_data(contents)
    expected = contents
    results = self.beautify(contents, tokens, tree)
    self.assertEqual(results, expected, msg=contents)
#@+node:ekr.20240326032825.1: *3* command methods in Fstringify class
#@+node:ekr.20200103054101.1: *4* fs.fstringify_file (entry)
def fstringify_file(self, filename: str) -> bool:  # pragma: no cover
    """
    Fstringify.fstringify_file.

    The entry point for the fstringify-file command.

    f-stringify the given external file with the Fstrinfify class.

    Return True if the file was changed.
    """
    tag = 'fstringify-file'
    self.filename = filename
    self.silent = False
    tog = TokenOrderGenerator()
    try:
        contents, encoding, tokens, tree = tog.init_from_file(filename)
        if not contents or not tokens or not tree:
            print(f"{tag}: Can not fstringify: {filename}")
            return False
        results = self.fstringify(contents, filename, tokens, tree)
    except Exception as e:
        print(e)
        return False
    # Something besides newlines must change.
    changed = regularize_nls(contents) != regularize_nls(results)
    status = 'Wrote' if changed else 'Unchanged'
    print(f"{tag}: {status:>9}: {filename}")
    if changed:
        write_file(filename, results, encoding=encoding)
    return changed
#@+node:ekr.20200103065728.1: *4* fs.fstringify_file_diff (entry)
def fstringify_file_diff(self, filename: str) -> bool:  # pragma: no cover
    """
    Fstringify.fstringify_file_diff.

    The entry point for the diff-fstringify-file command.

    Print the diffs that would result from the fstringify-file command.

    Return True if the file would be changed.
    """
    tag = 'diff-fstringify-file'
    self.filename = filename
    self.silent = False
    tog = TokenOrderGenerator()
    try:
        contents, encoding, tokens, tree = tog.init_from_file(filename)
        if not contents or not tokens or not tree:
            return False
        results = self.fstringify(contents, filename, tokens, tree)
    except Exception as e:
        print(e)
        return False
    # Something besides newlines must change.
    changed = regularize_nls(contents) != regularize_nls(results)
    if changed:
        show_diffs(contents, results, filename=filename)
    else:
        print(f"{tag}: Unchanged: {filename}")
    return changed
#@+node:ekr.20200112060218.1: *4* fs.fstringify_file_silent (entry)
def fstringify_file_silent(self, filename: str) -> bool:  # pragma: no cover
    """
    Fstringify.fstringify_file_silent.

    The entry point for the silent-fstringify-file command.

    fstringify the given file, suppressing all but serious error messages.

    Return True if the file would be changed.
    """
    self.filename = filename
    self.silent = True
    tog = TokenOrderGenerator()
    try:
        contents, encoding, tokens, tree = tog.init_from_file(filename)
        if not contents or not tokens or not tree:
            return False
        results = self.fstringify(contents, filename, tokens, tree)
    except Exception as e:
        print(e)
        return False
    # Something besides newlines must change.
    changed = regularize_nls(contents) != regularize_nls(results)
    status = 'Wrote' if changed else 'Unchanged'
    # Write the results.
    print(f"{status:>9}: {filename}")
    if changed:
        write_file(filename, results, encoding=encoding)
    return changed
#@+node:ekr.20240326031704.1: *3* Docstring relating to commands
@language rest
@wrap

See also leoTokens.py. It defines a Python beautifier that uses only
Python's tokenize module.

This commands in this file require Python 3.9 or above.

**Stand-alone operation**

usage:
    python -m leo.core.leoAst --help
    python -m leo.core.leoAst --fstringify [ARGS] PATHS
    python -m leo.core.leoAst --fstringify-diff [ARGS] PATHS
    python -m leo.core.leoAst --orange [ARGS] PATHS
    python -m leo.core.leoAst --orange-diff [ARGS] PATHS
    python -m leo.core.leoAst --py-cov [ARGS]
    python -m leo.core.leoAst --pytest [ARGS]
    python -m leo.core.leoAst --unittest [ARGS]

examples:
    python -m leo.core.leoAst --orange --force --verbose PATHS
    python -m leo.core.leoAst --py-cov "-f TestOrange"
    python -m leo.core.leoAst --pytest "-f TestOrange"
    python -m leo.core.leoAst --unittest TestOrange

positional arguments:
  PATHS              directory or list of files

optional arguments:
  -h, --help         show this help message and exit
  --force            operate on all files. Otherwise operate only on modified files
  --fstringify       leonine fstringify
  --fstringify-diff  show fstringify diff
  --orange           leonine text formatter (Orange is the new Black)
  --orange-diff      show orange diff
  --py-cov           run pytest --cov on leoAst.py
  --pytest           run pytest on leoAst.py
  --unittest         run unittest on leoAst.py
  --verbose          verbose output

#@+node:ekr.20231114133501.1: *3* function: get_modified_files
def get_modified_files(repo_path: str) -> list[str]:
    """Return the modified files in the given repo."""
    if not repo_path:
        return []
    old_cwd = os.getcwd()
    os.chdir(repo_path)
    try:
        # We are not checking the return code here, so:
        # pylint: disable=subprocess-run-check
        result = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True)
        if result.returncode != 0:
            print("Error running git command")
            return []
        modified_files = []
        for line in result.stdout.split('\n'):
            if line.startswith((' M', 'M ', 'A ', ' A')):
                modified_files.append(line[3:])
        return [os.path.abspath(z) for z in modified_files]
    finally:
        os.chdir(old_cwd)
#@+node:ekr.20200702102239.1: *3* function: main (leoAst.py) & helper
def main() -> None:  # pragma: no cover
    """Run commands specified by sys.argv."""
    args, settings_dict, arg_files = scan_ast_args()
    # Finalize arguments.
    cwd = os.getcwd()
    # Calculate requested files.
    requested_files: list[str] = []
    for path in arg_files:
        if path.endswith('.py'):
            requested_files.append(os.path.join(cwd, path))
        else:
            root_dir = os.path.join(cwd, path)
            requested_files.extend(glob.glob(f'{root_dir}**{os.sep}*.py', recursive=True))
    if not requested_files:
        print(f"No files in {arg_files!r}")
        return
    files: list[str]
    if args.force:
        # Handle all requested files.
        files = requested_files
    else:
        # Handle only modified files.
        modified_files = get_modified_files(cwd)
        files = [z for z in requested_files if os.path.abspath(z) in modified_files]
    if not files:
        return
    if args.verbose:
        kind = (
            'fstringify' if args.f else
            'fstringify-diff' if args.fd else
            'orange' if args.o else
            'orange-diff' if args.od else
            None
        )
        if kind and kind != 'orange':
            n = len(files)
            n_s = f" {n:>3} file" if n == 1 else f"{n:>3} files"
            print(f"{kind}: {n_s} in {', '.join(arg_files)}")
    # Do the command.
    if args.f:
        fstringify_command(files)
    if args.fd:
        fstringify_diff_command(files)
    if args.o:
        orange_command(arg_files, files, settings_dict)
    if args.od:
        orange_diff_command(files, settings_dict)
#@+node:ekr.20220404062739.1: *4* function: scan_ast_args
def scan_ast_args() -> tuple[Any, dict[str, Any], list[str]]:
    description = textwrap.dedent("""\
        Execute fstringify or beautify commands contained in leoAst.py.
    """)
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('PATHS', nargs='*', help='directory or list of files')
    group = parser.add_mutually_exclusive_group(required=False)  # Don't require any args.
    add = group.add_argument
    add('--fstringify', dest='f', action='store_true',
        help='fstringify PATHS')
    add('--fstringify-diff', dest='fd', action='store_true',
        help='fstringify diff PATHS')
    add('--orange', dest='o', action='store_true',
        help='beautify PATHS')
    add('--orange-diff', dest='od', action='store_true',
        help='diff beautify PATHS')
    # New arguments.
    add2 = parser.add_argument
    add2('--allow-joined', dest='allow_joined', action='store_true',
        help='allow joined strings')
    add2('--max-join', dest='max_join', metavar='N', type=int,
        help='max unsplit line length (default 0)')
    add2('--max-split', dest='max_split', metavar='N', type=int,
        help='max unjoined line length (default 0)')
    add2('--tab-width', dest='tab_width', metavar='N', type=int,
        help='tab-width (default -4)')
    # Newer arguments.
    add2('--force', dest='force', action='store_true',
        help='force beautification of all files')
    add2('--verbose', dest='verbose', action='store_true',
        help='verbose (per-file) output')
    # Create the return values, using EKR's prefs as the defaults.
    parser.set_defaults(
        allow_joined=False,
        force=False,
        max_join=0,
        max_split=0,
        recursive=False,
        tab_width=4,
        verbose=False
    )
    args: Any = parser.parse_args()
    files = args.PATHS
    # Create the settings dict, ensuring proper values.
    settings_dict: dict[str, Any] = {
        'allow_joined_strings': bool(args.allow_joined),
        'force': bool(args.force),
        'max_join_line_length': abs(args.max_join),
        'max_split_line_length': abs(args.max_split),
        'tab_width': abs(args.tab_width),  # Must be positive!
        'verbose': bool(args.verbose),
    }
    return args, settings_dict, files
#@+node:ekr.20230913144248.1: ** retire g.SherlockTracer
# I am going to leave this class in the attic indefinitely.
# It might be useful as the base for other classes.
#@+node:ekr.20121128031949.12605: *3* class g.SherlockTracer
class SherlockTracer:
    """
    A stand-alone tracer class with many of Sherlock's features.

    This class should work in any environment containing the re, os and sys modules.

    The arguments in the pattern lists determine which functions get traced
    or which stats get printed. Each pattern starts with "+", "-", "+:" or
    "-:", followed by a regular expression::

    "+x"  Enables tracing (or stats) for all functions/methods whose name
          matches the regular expression x.
    "-x"  Disables tracing for functions/methods.
    "+:x" Enables tracing for all functions in the **file** whose name matches x.
    "-:x" Disables tracing for an entire file.

    Enabling and disabling depends on the order of arguments in the pattern
    list. Consider the arguments for the Rope trace::

    patterns=['+.*','+:.*',
        '-:.*\\lib\\.*','+:.*rope.*','-:.*leoGlobals.py',
        '-:.*worder.py','-:.*prefs.py','-:.*resources.py',])

    This enables tracing for everything, then disables tracing for all
    library modules, except for all rope modules. Finally, it disables the
    tracing for Rope's worder, prefs and resources modules.

    Being able to zero in on the code of interest can be a big help in
    studying other people's code. This is a non-invasive method: no tracing
    code needs to be inserted anywhere.

    Usage:

    g.SherlockTracer(patterns).run()
    """
    @others
#@+node:ekr.20121128031949.12602: *4* sherlock.__init__
def __init__(
    self,
    patterns: list[Any],
    indent: bool = True,
    show_args: bool = True,
    show_return: bool = True,
    verbose: bool = True,
) -> None:
    """SherlockTracer ctor."""
    self.bad_patterns: list[str] = []  # List of bad patterns.
    self.indent = indent  # True: indent calls and returns.
    self.contents_d: dict[str, list] = {}  # Keys are file names, values are file lines.
    self.n = 0  # The frame level on entry to run.
    self.stats: dict[str, dict] = {}  # Keys are full file names, values are dicts.
    self.patterns: list[Any] = None  # A list of regex patterns to match.
    self.pattern_stack: list[str] = []
    self.show_args = show_args  # True: show args for each function call.
    self.show_return = show_return  # True: show returns from each function.
    self.trace_lines = True  # True: trace lines in enabled functions.
    self.verbose = verbose  # True: print filename:func
    self.set_patterns(patterns)
    try:  # Don't assume g.app exists.
        from leo.core.leoQt import QtCore
        if QtCore:
            # pylint: disable=no-member
            QtCore.pyqtRemoveInputHook()
    except Exception:
        pass
#@+node:ekr.20140326100337.16844: *4* sherlock.__call__
def __call__(self, frame: Any, event: Any, arg: Any) -> Any:
    """Exists so that self.dispatch can return self."""
    return self.dispatch(frame, event, arg)
#@+node:ekr.20140326100337.16846: *4* sherlock.bad_pattern
def bad_pattern(self, pattern: Any) -> None:
    """Report a bad Sherlock pattern."""
    if pattern not in self.bad_patterns:
        self.bad_patterns.append(pattern)
        print(f"\nignoring bad pattern: {pattern}\n")
#@+node:ekr.20140326100337.16847: *4* sherlock.check_pattern
def check_pattern(self, pattern: str) -> bool:
    """Give an error and return False for an invalid pattern."""
    try:
        for prefix in ('+:', '-:', '+', '-'):
            if pattern.startswith(prefix):
                re.match(pattern[len(prefix) :], 'xyzzy')
                return True
        self.bad_pattern(pattern)
        return False
    except Exception:
        self.bad_pattern(pattern)
        return False
#@+node:ekr.20121128031949.12609: *4* sherlock.dispatch
def dispatch(self, frame: Any, event: Any, arg: Any) -> Any:
    """The dispatch method."""
    if event == 'call':
        self.do_call(frame, arg)
    elif event == 'return' and self.show_return:
        self.do_return(frame, arg)
    elif event == 'line' and self.trace_lines:
        self.do_line(frame, arg)
    # Queue the SherlockTracer instance again.
    return self
#@+node:ekr.20121128031949.12603: *4* sherlock.do_call & helper
def do_call(self, frame: Any, unused_arg: Any) -> None:
    """Trace through a function call."""
    frame1 = frame
    code = frame.f_code
    file_name = code.co_filename
    locals_ = frame.f_locals
    function_name = code.co_name
    try:
        full_name = self.get_full_name(locals_, function_name)
    except Exception:
        full_name = function_name
    if not self.is_enabled(file_name, full_name, self.patterns):
        # 2020/09/09: Don't touch, for example, __ methods.
        return
    n = 0  # The number of callers of this def.
    while frame:
        frame = frame.f_back
        n += 1
    indent = ' ' * max(0, n - self.n) if self.indent else ''
    path = f"{os.path.basename(file_name):>20}" if self.verbose else ''
    leadin = '+' if self.show_return else ''
    args_list = self.get_args(frame1)
    if self.show_args and args_list:
        args_s = ','.join(args_list)
        args_s2 = f"({args_s})"
        if len(args_s2) > 100:
            print(f"{path}:{indent}{leadin}{full_name}")
            g.printObj(args_list, indent=len(indent) + 22)
        else:
            print(f"{path}:{indent}{leadin}{full_name}{args_s2}")
    else:
        print(f"{path}:{indent}{leadin}{full_name}")
    # Always update stats.
    d = self.stats.get(file_name, {})
    d[full_name] = 1 + d.get(full_name, 0)
    self.stats[file_name] = d
#@+node:ekr.20130111185820.10194: *5* sherlock.get_args
def get_args(self, frame: Any) -> list[str]:
    """Return a list of string "name=val" for each arg in the function call."""
    code = frame.f_code
    locals_ = frame.f_locals
    name = code.co_name
    n = code.co_argcount
    if code.co_flags & 4:
        n = n + 1
    if code.co_flags & 8:
        n = n + 1
    result = []
    for i in range(n):
        name = code.co_varnames[i]
        if name != 'self':
            arg = locals_.get(name, '*undefined*')
            if arg:
                if isinstance(arg, (list, tuple)):
                    val_s = ','.join([self.show(z) for z in arg if self.show(z)])
                    val = f"[{val_s}]"
                elif isinstance(arg, str):
                    val = arg
                else:
                    val = self.show(arg)
                if val:
                    result.append(f"{name}={val}")
    return result
#@+node:ekr.20140402060647.16845: *4* sherlock.do_line (not used)
bad_fns: list[str] = []

def do_line(self, frame: Any, arg: Any) -> None:
    """print each line of enabled functions."""
    if 1:
        return
    code = frame.f_code
    file_name = code.co_filename
    locals_ = frame.f_locals
    name = code.co_name
    full_name = self.get_full_name(locals_, name)
    if not self.is_enabled(file_name, full_name, self.patterns):
        return
    n = frame.f_lineno - 1  # Apparently, the first line is line 1.
    d = self.contents_d
    lines = d.get(file_name)
    if not lines:
        print(file_name)
        try:
            with open(file_name) as f:
                s = f.read()
        except Exception:
            if file_name not in self.bad_fns:
                self.bad_fns.append(file_name)
                print(f"open({file_name}) failed")
            return
        lines = g.splitLines(s)
        d[file_name] = lines
    line = lines[n].rstrip() if n < len(lines) else '<EOF>'
    if 0:
        print(f"{name:3} {line}")
    else:
        print(f"{g.shortFileName(file_name)} {n} {full_name} {line}")
#@+node:ekr.20130109154743.10172: *4* sherlock.do_return & helper
def do_return(self, frame: Any, arg: Any) -> None:  # Arg *is* used below.
    """Trace a return statement."""
    code = frame.f_code
    fn = code.co_filename
    locals_ = frame.f_locals
    name = code.co_name
    self.full_name = self.get_full_name(locals_, name)
    if not self.is_enabled(fn, self.full_name, self.patterns):
        return
    n = 0
    while frame:
        frame = frame.f_back
        n += 1
    path = f"{os.path.basename(fn):>20}" if self.verbose else ''
    if name and name == '__init__':
        try:
            ret1 = locals_ and locals_.get('self', None)
            self.put_ret(ret1, n, path)
        except NameError:
            self.put_ret(f"<{ret1.__class__.__name__}>", n, path)
    else:
        self.put_ret(arg, n, path)
#@+node:ekr.20220605141445.1: *5* sherlock.put_ret
def put_ret(self, arg: Any, n: int, path: str) -> None:
    """Print arg, the value returned by a "return" statement."""
    indent = ' ' * max(0, n - self.n + 1) if self.indent else ''
    try:
        if isinstance(arg, types.GeneratorType):
            ret = '<generator>'
        elif isinstance(arg, (tuple, list)):
            ret_s = ','.join([self.show(z) for z in arg])
            if len(ret_s) > 40:
                g.printObj(arg, indent=len(indent))
                ret = ''
            else:
                ret = f"[{ret_s}]"
        elif arg:
            ret = self.show(arg)
            if len(ret) > 100:
                ret = f"\n    {ret}"
        else:
            ret = '' if arg is None else repr(arg)
        print(f"{path}:{indent}-{self.full_name} -> {ret}")
    except Exception:
        exctype, value = sys.exc_info()[:2]
        try:  # Be extra careful.
            arg_s = f"arg: {arg!r}"
        except Exception:
            arg_s = ''  # arg.__class__.__name__
        print(
            f"{path}:{indent}-{self.full_name} -> "
            f"{exctype.__name__}, {value} {arg_s}"
        )
#@+node:ekr.20121128111829.12185: *4* sherlock.fn_is_enabled
def fn_is_enabled(self, func: Any, patterns: list[str]) -> bool:
    """Return True if tracing for the given function is enabled."""
    if func in self.ignored_functions:
        return False

    def ignore_function() -> None:
        if func not in self.ignored_functions:
            self.ignored_functions.append(func)
            print(f"Ignore function: {func}")
    #
    # New in Leo 6.3. Never trace dangerous functions.
    table = (
        '_deepcopy.*',
        # Unicode primitives.
        'encode\b', 'decode\b',
        # System functions
        '.*__next\b',
        '<frozen>', '<genexpr>', '<listcomp>',
        # '<decorator-gen-.*>',
        'get\b',
        # String primitives.
        'append\b', 'split\b', 'join\b',
        # File primitives...
        'access_check\b', 'expanduser\b', 'exists\b', 'find_spec\b',
        'abspath\b', 'normcase\b', 'normpath\b', 'splitdrive\b',
    )
    g.trace('=====', func)
    for z in table:
        if re.match(z, func):
            ignore_function()
            return False
    #
    # Legacy code.
    try:
        enabled, pattern = False, None
        for pattern in patterns:
            if pattern.startswith('+:'):
                if re.match(pattern[2:], func):
                    enabled = True
            elif pattern.startswith('-:'):
                if re.match(pattern[2:], func):
                    enabled = False
        return enabled
    except Exception:
        self.bad_pattern(pattern)
        return False
#@+node:ekr.20130112093655.10195: *4* sherlock.get_full_name
def get_full_name(self, locals_: Any, name: str) -> str:
    """Return class_name::name if possible."""
    full_name = name
    try:
        user_self = locals_ and locals_.get('self', None)
        if user_self:
            full_name = user_self.__class__.__name__ + '::' + name
    except Exception:
        pass
    return full_name
#@+node:ekr.20121128111829.12183: *4* sherlock.is_enabled
ignored_files: list[str] = []  # List of files.
ignored_functions: list[str] = []  # List of files.

def is_enabled(
    self,
    file_name: str,
    function_name: str,
    patterns: list[str] = None,
) -> bool:
    """Return True if tracing for function_name in the given file is enabled."""
    #
    # New in Leo 6.3. Never trace through some files.
    if not os:
        return False  # Shutting down.
    base_name = os.path.basename(file_name)
    if base_name in self.ignored_files:
        return False

    def ignore_file() -> None:
        if base_name not in self.ignored_files:
            self.ignored_files.append(base_name)

    def ignore_function() -> None:
        if function_name not in self.ignored_functions:
            self.ignored_functions.append(function_name)

    if f"{os.sep}lib{os.sep}" in file_name:
        ignore_file()
        return False
    if base_name.startswith('<') and base_name.endswith('>'):
        ignore_file()
        return False
    #
    # New in Leo 6.3. Never trace dangerous functions.
    table = (
        '_deepcopy.*',
        # Unicode primitives.
        'encode\b', 'decode\b',
        # System functions
        '.*__next\b',
        '<frozen>', '<genexpr>', '<listcomp>',
        # '<decorator-gen-.*>',
        'get\b',
        # String primitives.
        'append\b', 'split\b', 'join\b',
        # File primitives...
        'access_check\b', 'expanduser\b', 'exists\b', 'find_spec\b',
        'abspath\b', 'normcase\b', 'normpath\b', 'splitdrive\b',
    )
    for z in table:
        if re.match(z, function_name):
            ignore_function()
            return False
    #
    # Legacy code.
    enabled = False
    if patterns is None:
        patterns = self.patterns
    for pattern in patterns:
        try:
            if pattern.startswith('+:'):
                if re.match(pattern[2:], file_name):
                    enabled = True
            elif pattern.startswith('-:'):
                if re.match(pattern[2:], file_name):
                    enabled = False
            elif pattern.startswith('+'):
                if re.match(pattern[1:], function_name):
                    enabled = True
            elif pattern.startswith('-'):
                if re.match(pattern[1:], function_name):
                    enabled = False
            else:
                self.bad_pattern(pattern)
        except Exception:
            self.bad_pattern(pattern)
    return enabled
#@+node:ekr.20121128111829.12182: *4* sherlock.print_stats
def print_stats(self, patterns: list[str] = None) -> None:
    """Print all accumulated statisitics."""
    print('\nSherlock statistics...')
    if not patterns:
        patterns = ['+.*', '+:.*',]
    for fn in sorted(self.stats.keys()):
        d = self.stats.get(fn)
        if self.fn_is_enabled(fn, patterns):
            result = sorted(d.keys())  # type:ignore
        else:
            result = [key for key in sorted(d.keys())  # type:ignore
                if self.is_enabled(fn, key, patterns)]
        if result:
            print('')
            fn = fn.replace('\\', '/')
            parts = fn.split('/')
            print('/'.join(parts[-2:]))
            for key in result:
                print(f"{d.get(key):4} {key}")
#@+node:ekr.20121128031949.12614: *4* sherlock.run
# Modified from pdb.Pdb.set_trace.

def run(self, frame: Any = None) -> None:
    """Trace from the given frame or the caller's frame."""
    print("SherlockTracer.run:patterns:\n%s" % '\n'.join(self.patterns))
    if frame is None:
        frame = sys._getframe().f_back
    # Compute self.n, the number of frames to ignore.
    self.n = 0
    while frame:
        frame = frame.f_back
        self.n += 1
    # Pass self to sys.settrace to give easy access to all methods.
    sys.settrace(self)
#@+node:ekr.20140322090829.16834: *4* sherlock.push & pop
def push(self, patterns: list[str]) -> None:
    """Push the old patterns and set the new."""
    self.pattern_stack.append(self.patterns)  # type:ignore
    self.set_patterns(patterns)
    print(f"SherlockTracer.push: {self.patterns}")

def pop(self) -> None:
    """Restore the pushed patterns."""
    if self.pattern_stack:
        self.patterns = self.pattern_stack.pop()  # type:ignore
        print(f"SherlockTracer.pop: {self.patterns}")
    else:
        print('SherlockTracer.pop: pattern stack underflow')
#@+node:ekr.20140326100337.16845: *4* sherlock.set_patterns
def set_patterns(self, patterns: list[str]) -> None:
    """Set the patterns in effect."""
    self.patterns = [z for z in patterns if self.check_pattern(z)]
#@+node:ekr.20140322090829.16831: *4* sherlock.show
def show(self, item: Any) -> str:
    """return the best representation of item."""
    if not item:
        return repr(item)
    if isinstance(item, dict):
        return 'dict'
    if isinstance(item, str):
        s = repr(item)
        if len(s) <= 20:
            return s
        return s[:17] + '...'
    s = repr(item)
    # A Hack for mypy:
    if s.startswith("<object object"):
        s = "_dummy"
    return s
#@+node:ekr.20121128093229.12616: *4* sherlock.stop
def stop(self) -> None:
    """Stop all tracing."""
    sys.settrace(None)
#@+node:ekr.20240324061253.1: ** retire Qt5 plugins & files
#@+node:tbrown.20171028115144.3: *3* @@@file ../plugins/editpane/pandownview.py
<< pandownview imports >>
@others
@language python
@tabwidth -4
#@+node:tbrown.20171028115505.1: *4* << pandownview imports >>
"""Markdown view using Pandoc.

There could also be a more generic Pandoc view that handles more input
languages, but this just does markdown.
"""
from subprocess import Popen, PIPE

from leo.core import leoGlobals as g
assert g
# from leo.core.leoQt import QtCore, QtGui, QtWidgets, QtConst

# FIXME: for now, prefer the older WebKit over WebEngine.  WebEngine is
# probably superior, but needs --disable-web-security passed to the
# QApplication to load local images without a server.
try:
    from leo.plugins.editpane.webkitview import LEP_WebKitView as HtmlView
except ImportError:
    from leo.plugins.editpane.webengineview import LEP_WebEngineView as HtmlView

from leo.plugins.editpane.plaintextview import LEP_PlainTextView as TextView

#@+node:tbrown.20171028115505.2: *4* to_html
def to_html(text, from_='markdown'):
    """to_html - convert to HTML

    Args:
        text (str): markdown text to convert

    Returns:
        str: html
    """

    cmd = f"pandoc --smart --standalone --mathjax --from {from_} --to html"
    cmd = cmd.split()
    proc = Popen(cmd, stdin=PIPE, stdout=PIPE)
    out, err = proc.communicate(text)
    return out

# see if Pandoc's installed

try:
    to_html("test")
except:  # pylint: disable=raise-missing-from
    raise ImportError
#@+node:tbrown.20171028115505.3: *4* class LEP_PanDownView
class LEP_PanDownView(HtmlView):
    """LEP_MarkdownView -
    """
    lep_type = "MARKDOWN"
    lep_name = "PanDoc Markdown View"
    from_fmt = 'markdown'
    @others
#@+node:tbrown.20171028115505.4: *5* __init__
def __init__(self, c=None, lep=None, *args, **kwargs):
    """set up"""
    super().__init__(c=c, lep=lep, *args, **kwargs)
    self.c = c
    self.lep = lep
#@+node:tbrown.20171028115505.5: *5* new_text
def new_text(self, text):
    """new_text - update for new text

    Args:
        text (str): new text
    """
    self.setHtml(to_html(text, from_=self.from_fmt))
#@+node:tbrown.20171028115505.6: *5* update_text
def update_text(self, text):
    """update_text - update for current text

    Args:
        text (str): current text
    """
    # h = self.horizontalScrollBar().value()
    # v = self.verticalScrollBar().value()
    self.new_text(text)
    # self.horizontalScrollBar().setValue(h)
    # self.verticalScrollBar().setValue(v)
#@+node:tbrown.20171028115505.7: *4* class LEP_PanDownHtmlView
class LEP_PanDownHtmlView(TextView):
    """LEP_PanDownHtmlView - view the HTML for markdown from PanDoc
    """
    lep_type = "MARKDOWN-HTML"
    lep_name = "PanDoc Markdown Html View"
    from_fmt = 'markdown'
    @others
#@+node:tbrown.20171028115505.8: *5* __init__
def __init__(self, c=None, lep=None, *args, **kwargs):
    """set up"""
    super().__init__(c=c, lep=lep, *args, **kwargs)
    self.c = c
    self.lep = lep
#@+node:tbrown.20171028115505.9: *5* new_text
def new_text(self, text):
    """new_text - update for new text

    Args:
        text (str): new text
    """
    self.setPlainText(to_html(text, from_=self.from_fmt))
#@+node:tbrown.20171128074654.1: *4* class LEP_PanRstView
class LEP_PanRstView(LEP_PanDownView):
    """LEP_PanDownView -
    """
    lep_type = "RST"
    lep_name = "PanDoc rst View"
    from_fmt = 'rst'
#@+node:tbrown.20171128074707.1: *4* class LEP_PanRstHtmlView
class LEP_PanRstHtmlView(LEP_PanDownHtmlView):
    """LEP_PanDownHtmlView -
    """
    lep_type = "RST-HTML"
    lep_name = "PanDoc rst Html View"
    from_fmt = 'rst'
#@+node:tbrown.20171028115143.2: *3* @@@file ../plugins/editpane/webengineview.py
@nosearch

<< webengineview imports >>
@others
@language python
@tabwidth -4
#@+node:tbrown.20171028115459.1: *4* << webengineview imports >>
# EKR: Use QtWebKitWidgets instead of QtWebEngineWidgets
# TNB: No, there are two HTML viewers, this one must be QtWebEngineWidgets
#      it's ok if it fails to load
# pylint: disable=no-name-in-module
### from PyQt5 import QtWebEngineWidgets

### from leo.core.leoQt import QtWebKitWidgets
from leo.core import leoGlobals as g
assert g
#@+node:tbrown.20171028115459.2: *4* class LEP_WebEngineView
class LEP_WebEngineView(QtWebEngineWidgets.QWebEngineView):
    """LEP_PlainTextView - simplest possible LeoEditorPane viewer
    """
    lep_type = "HTML"
    lep_name = "Web Engine View"
    @others
#@+node:tbrown.20171028115459.3: *5* __init__
def __init__(self, c=None, lep=None, *args, **kwargs):
    """set up"""
    super().__init__(*args, **kwargs)
    self.c = c
    self.lep = lep
#@+node:tbrown.20171028115459.4: *5* new_text
def new_text(self, text):
    """new_text - update for new text

    :param str text: new text
    """
    # see https://stackoverflow.com/questions/36609489,
    # widget grabs focus on .setHTML()
    self.setEnabled(False)
    self.setHtml(text)
    self.setEnabled(True)
#@+node:tbrown.20171028115459.5: *5* update_text
def update_text(self, text):
    """update_text - update for current text

    :param str text: current text
    """
    # h = self.horizontalScrollBar().value()
    # v = self.verticalScrollBar().value()
    self.new_text(text)
    # self.horizontalScrollBar().setValue(h)
    # self.verticalScrollBar().setValue(v)
#@+node:tbrown.20171028115143.1: *3* @@@file ../plugins/editpane/webkitview.py
<< webkitview imports >>
@others
@language python
@tabwidth -4
#@+node:tbrown.20171028115457.1: *4* << webkitview imports >> (webkitview.py)
import os
from leo.core import leoGlobals as g
assert g
from leo.core.leoQt import QtWebKit QtWebKitWidgets
if not QtWebKitWidgets or 'engine' in g.os_path_basename(
    QtWebKitWidgets.__file__).lower():
    # not loading webkit view, webengine masquerading as webkit
    raise ImportError
#@+node:tbrown.20171028115457.2: *4* _path_from_pos
def _path_from_pos(c, p):
    """_path_from_pos - get folder for position

    FIXME: should be in Leo core somewhere.

    Args:
        p (position): position

    Returns:
        str: path
    """
    p = p.copy()

    def atfile(p):
        word0 = p.h.split()[0]
        return (
            word0 in g.app.atFileNames | set(['@auto']) or
            word0.startswith('@auto-')
        )

    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    while c.positionExists(p):
        if atfile(p):  # see if it's a @<file> node of some sort
            nodepath = p.h.split(None, 1)[-1]
            nodepath = g.os_path_join(path, nodepath)
            if not g.os_path_isdir(nodepath):  # remove filename
                nodepath = g.os_path_dirname(nodepath)
            if g.os_path_isdir(nodepath):  # append if it's a directory
                path = nodepath
            break
        p.moveToParent()

    return path
#@+node:tbrown.20171028115457.3: *4* class LEP_WebKitView
class LEP_WebKitView(QtWebKitWidgets.QWebView):
    """LEP_WebKitView - Web Kit View
    """
    lep_type = "HTML"
    lep_name = "Web Kit View"
    @others
#@+node:tbrown.20171028115457.4: *5* __init__
def __init__(self, c=None, lep=None, *args, **kwargs):
    """set up"""
    super().__init__(*args, **kwargs)
    self.c = c
    self.lep = lep

    # enable inspector
    try:
        QtWebKit.QWebSettings.globalSettings().setAttribute(
          QtWebKit.QWebSettings.DeveloperExtrasEnabled, True)
    except AttributeError:
        # leoQt substitutes QtWebEngine for QtWebKit
        # if QtWebKit isn't available, causing this to fail
        pass
#@+node:tbrown.20171028115457.5: *5* new_text
def new_text(self, text):
    """new_text - update for new text

    Args:
        text (str): new text
    """
    owd = os.getcwd()
    path = _path_from_pos(self.c, self.c.p)
    g.es("FIXME: _path_from_pos() in WebKitView - not self.c.p")
    os.chdir(path)
    g.es(path)
    self.setHtml(text)
    os.chdir(owd)
#@+node:tbrown.20171028115457.6: *5* update_text
def update_text(self, text):
    """update_text - update for current text

    Args:
        text (str): current text
    """
    self.new_text(text)
#@+node:ville.20120604212857.4215: *3* @@@file ../plugins/notebook.py
""" QML Notebook

Edit several nodes at once, in a pannable "notebook" view.

Use <Alt-x>nb-<tab> to see the list of commands.
"""
from typing import Any
from leo.core import leoGlobals as g
from leo.core.leoQt import QtCore, QtGui  ### QtDeclarative
#
# Fail fast, right after all imports.
g.assertUi('qt')  # May raise g.UiTypeException, caught by the plugins manager.

controllers: dict[str, Any] = {}  # keys are c.hash(), values are NavControllers

@others
#@+node:ville.20120604212857.4219: *4* init
def init():
    """Return True if the plugin has loaded successfully."""
    ok = g.app.gui.guiName() == "qt"
    if ok:
        g.registerHandler('after-create-leo-frame', onCreate)
        g.plugin_signon(__name__)
    return ok
#@+node:ville.20120604212857.4231: *4* onCreate
def onCreate(tag, keys):
    """notebook.py onCreate"""
    global controllers
    c = keys.get('c')
    if c:
        h = c.hash()
        nb = controllers.get(h)
        if not nb:
            controllers[h] = NbController(c)
#@+node:ville.20120604212857.4227: *4* class ModelWrapper
class ModelWrapper:
    @others
#@+node:ville.20120604212857.4228: *5* __init__
def __init__(self, fieldlist):
    """Ctor for ModelWrapper class."""
    self.rolenames = rn = {}
    self.roleids = ri = {}
    for n, f in enumerate(fieldlist):
        rid = n + 100
        rn[rid] = f
        ri[f] = rid
    self.model = mo = QtGui.QStandardItemModel()
    try:
        mo.setRoleNames(rn)
    except AttributeError:
        pass
#@+node:ville.20120604212857.4229: *5* mkitem
def mkitem(self, d):
    """ dict with field->value """
    si = QtGui.QStandardItem()
    for k, v in d.items():
        rid = self.roleids[k]
        si.setData(v, rid)
    return si
#@+node:ville.20120604212857.4237: *4* class NbController
class NbController:
    @others
#@+node:ville.20120604212857.4241: *5* __init__ (NBController, notebook.py)
def __init__(self, c):
    """Ctor for NbController class."""
    self.c = c
    self.gnxcache = {}
    self.mw = ModelWrapper(["h", "b", "gnx", "level", "style"])
    try:
        # pylint: disable=import-error, no-name-in-module
        from PyQt5.QtQuick import QQuickView
        self.view = view = QQuickView()
    except Exception:  #1746.
        self.view = view = QtDeclarative.QDeclarativeView()
    ctx = view.rootContext()

    @g.command("nb-all")
    def nb_all_f(event):
        self.add_all_nodes()
        self.view.show()

    @g.command("nb-subtree")
    def nb_subtree_f(event):
        p = self.c.p
        self.add_subtree(p)
        self.view.show()

    ctx.setContextProperty("nodesModel", self.mw.model)
    path = g.os_path_join(g.computeLeoDir(), 'plugins', 'qmlnb', 'qml', 'leonbmain.qml')
    view.setSource(QtCore.QUrl(path))
    mode = view.SizeRootObjectToView
    view.setResizeMode(mode)
    # Display the user interface and allow the user to interact with it.
    view.hide()
    view.setGeometry(100, 100, 800, 600)
    c.dummy = view
#@+node:ville.20120604212857.4239: *5* add_all_nodes
def add_all_nodes(self):
    self.mw.model.clear()
    for p in self.c.all_positions():
        self.addNode(p)
#@+node:ville.20120604212857.4240: *5* add_subtree
def add_subtree(self, pos):
    self.mw.model.clear()
    for p in pos.self_and_subtree():
        self.addNode(p)

#@+node:ville.20120604212857.4238: *5* addNode
def addNode(self, p, styling=None):
    if styling is None:
        styling = {}
    v = p.v
    d = {
        "h": v.h,
        "b": v.b,
        "gnx": v.gnx,
        "level": p.level(),
    }
    d.update(styling)
    self.gnxcache[v.gnx] = v
    si = self.mw.mkitem(d)
    self.mw.model.appendRow(si)
#@+node:tbrown.20130813134319.11942: *3* @@@file ../plugins/richtext.py
@nosearch

<< docstring >>
<< imports >>
@others
@language python
@tabwidth -4
#@+node:tbrown.20130813134319.14333: *4* << docstring >> (richtext.py)
"""
richtext.py - Rich text editing
===============================

This plugin allows you to use CKEditor__ to edit rich text
in Leo.  Text is stored as HTML in Leo nodes.

__ http://ckeditor.com/

``richtext.py`` provides these ``Alt-X`` commands (also available from
Plugins -> richtext menu):

  cke-text-close
    Close the rich text editor, unhide the regular editor.
  cke-text-open
    Open the rich text editor, hide the regular editor.
  cke-text-switch
    Switch between regular and rich text editor.
  cke-text-toggle-autosave
    Toggle autosaving of changes when you leave a node.
    Be careful not to convert plain text (e.g. source code) to rich
    text unintentionally.  As long as you make no edits, the original
    text will not be changed.

Unless autosaving is enabled, you must confirm saving of edits
each time you edit a node with the rich text editor.

``@rich`` in the headline or first few lines (1000 characters) of a node or its
ancestors will automatically open the rich text editor. ``@norich`` cancels this
action.  Manually opened editors are not affected.

``richtext.py`` uses these ``@settings``:

  @bool richtext_cke_autosave = False
    Set this to True for rich text edits to be saved automatically.

    *BE CAREFUL* - plain-text nodes will be converted to rich text
    without confirmation if you edit them in rich text mode when
    this is True.

  @data richtext_cke_config Configuration info. for CKEditor, see
    http://docs.ckeditor.com/#!/guide/dev_configuration the content of this node
    is the javascript object passed to ``CKEDITOR.replace()`` as it's second
    argument. The version supplied in LeoSettings.leo sets up a sensible
    toolbar. To enable *all* CKEditor toolbar features copy this setting to
    myLeoSettings.leo and remove the default content, i.e. make this node blank,
    then CKEditor will generate a toolbar with all available features.

To make a button to toggle the editor on and off, use::

    @button rich
      c.doCommandByName('cke-text-switch')

"""
#@+node:tbrown.20130813134319.14335: *4* << imports >> (richtext.py)
import time
from urllib.parse import unquote
from leo.core import leoGlobals as g
from leo.core.leoQt import QtCore, QtWidgets  ###, QtWebKitWidgets, QtWebKit
#
# Fail fast, right after all imports.
g.assertUi('qt')  # May raise g.UiTypeException, caught by the plugins manager.
#
# Alias.
### real_webkit = QtWebKit and 'engine' not in g.os_path_basename(QtWebKit.__file__).lower()
real_webkit = False
#@+node:tbrown.20130813134319.14337: *4* init (richtext.py)
def init():
    """Return True if the plugin has loaded successfully."""
    if not QtWebKit:
        return False
    name = g.app.gui.guiName()
    ok = name == 'qt'
    if ok:
        g.registerHandler('after-create-leo-frame', onCreate)
        g.registerHandler('select3', at_rich_check)
        g.plugin_signon(__name__)
    elif name != 'nullGui':
        print('richtext.py plugin not loading because gui is not Qt')
    return ok
#@+node:tbrown.20130813134319.5691: *4* class CKEEditor
class CKEEditor(QtWidgets.QWidget):  # type:ignore
    @others
#@+node:tbrown.20130813134319.7225: *5* __init__ & reloadSettings (CKEEditor)
def __init__(self, *args, **kwargs):

    self.c = kwargs['c']
    del kwargs['c']
    super().__init__(*args, **kwargs)
    # were we opened by an @ rich node? Calling code will set
    self.at_rich = False
    # are we being closed by leaving an @ rich node? Calling code will set
    self.at_rich_close = False
    # read settings.
    self.reloadSettings()
    # load HTML template
    template_path = g.os_path_join(g.computeLeoDir(), 'plugins', 'cke_template.html')
    self.template = open(template_path).read()
    path = g.os_path_join(g.computeLeoDir(), 'external', 'ckeditor')
    self.template = self.template.replace(
        '[CKEDITOR]', QtCore.QUrl.fromLocalFile(path).toString())
    # make widget containing QWebView
    self.setLayout(QtWidgets.QVBoxLayout())
    self.layout().setSpacing(0)
    self.layout().setContentsMargins(0, 0, 0, 0)
    ###
        # # enable inspector, if this really is QtWebKit
        # if real_webkit:
            # QtWebKit.QWebSettings.globalSettings().setAttribute(
                # QtWebKit.QWebSettings.DeveloperExtrasEnabled, True)
    self.webview = QtWebKitWidgets.QWebView()
    self.layout().addWidget(self.webview)
    g.registerHandler('select3', self.select_node)
    g.registerHandler('unselect1', self.unselect_node)
    # load current node
    self.select_node('', {'c': self.c, 'new_p': self.c.p})

def reloadSettings(self):
    c = self.c
    c.registerReloadSettings(self)
    # read autosave preference
    if not hasattr(self.c, '_ckeeditor_autosave'):
        auto = self.c.config.getBool("richtext-cke-autosave") or False
        self.c._ckeeditor_autosave = auto
        if auto:
            g.es("NOTE: automatic saving of rich text edits")
    # load config
    self.config = self.c.config.getData("richtext_cke_config")
    if self.config:
        self.config = '\n'.join(self.config).strip()
#@+node:tbrown.20130813134319.7226: *5* select_node
def select_node(self, tag, kwargs):
    c = kwargs['c']
    if c != self.c:
        return

    p = kwargs['new_p']

    self.v = p.v  # to ensure unselect_node is working on the right node
    # currently (20130814) insert doesn't trigger unselect/select, but
    # even if it did, this would be safest

    data = self.template
    if p.b.startswith('<'):  # already rich text, probably
        content = p.b
        self.was_rich = True
    else:
        self.was_rich = p.b.strip() == ''
        # put anything except whitespace in a <pre/>
        content = "<pre>%s</pre>" % p.b if not self.was_rich else ''

    data = data.replace('[CONTENT]', content)

    # replace textarea with CKEditor, with or without config.
    if self.config:
        data = data.replace('[CONFIG]', ', ' + self.config)
    else:
        data = data.replace('[CONFIG]', '')

    # try and make the path for URL evaluation relative to the node's path
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if p.h.startswith('@'):  # see if it's a @<file> node of some sort
        nodepath = p.h.split(None, 1)[-1]
        nodepath = g.os_path_join(path, nodepath)
        if not g.os_path_isdir(nodepath):  # remove filename
            nodepath = g.os_path_dirname(nodepath)
        if g.os_path_isdir(nodepath):  # append if it's a directory
            path = nodepath

    self.webview.setHtml(data, QtCore.QUrl.fromLocalFile(path + "/"))
#@+node:tbrown.20130813134319.7228: *5* unselect_node
def unselect_node(self, tag, kwargs):

    c = kwargs['c']
    if c != self.c:
        return None
    # read initial content and request and wait for final content
    frame = self.webview.page().mainFrame()
    ele = frame.findFirstElement("#initial")
    text = str(ele.toPlainText()).strip()
    if text == '[empty]':
        return None  # no edit
    frame.evaluateJavaScript('save_final();')
    ele = frame.findFirstElement("#final")
    for attempt in range(10):  # wait for up to 1 second
        new_text = str(ele.toPlainText()).strip()
        if new_text == '[empty]':
            time.sleep(0.1)
            continue
        break
    if new_text == '[empty]':
        print("Didn't get new text")
        return None
    text = unquote(str(text))
    new_text = unquote(str(new_text))
    if new_text != text:
        if self.c._ckeeditor_autosave:
            ans = 'yes'
        else:
            text = "Save edits?"
            if not self.was_rich:
                text += " *converting plain text to rich*"
            ans = g.app.gui.runAskYesNoCancelDialog(
                self.c,
                "Save edits?",
                text
            )
        if ans == 'yes':
            c.vnode2position(self.v).b = new_text
            c.redraw()  # but node has content marker still doesn't appear?
        elif ans == 'cancel':
            return 'STOP'
        else:
            pass  # discard edits
    return None
#@+node:tbrown.20130813134319.7229: *5* close
def close(self):
    if self.c and not self.at_rich_close:
        # save changes?
        self.unselect_node('', {'c': self.c, 'old_p': self.c.p})
    self.c = None
    g.unregisterHandler('select3', self.select_node)
    g.unregisterHandler('unselect1', self.unselect_node)
    return QtWidgets.QWidget.close(self)
#@+node:tbrown.20130813134319.5694: *4* class CKEPaneProvider
class CKEPaneProvider:
    ns_id = '_add_cke_pane'

    def __init__(self, c):
        self.c = c
        # Careful: we may be unit testing.
        if hasattr(c, 'free_layout'):
            splitter = c.free_layout.get_top_splitter()
            if splitter:
                splitter.register_provider(self)

    def ns_provides(self):
        return [('Rich text CKE editor', self.ns_id)]

    def ns_provide(self, id_):
        if id_ == self.ns_id:
            w = CKEEditor(c=self.c)
            return w
        return None

    def ns_provider_id(self):
        # used by register_provider() to unregister previously registered
        # providers of the same service
        return self.ns_id
#@+node:tbrown.20130813134319.14339: *4* onCreate
def onCreate(tag, key):

    c = key.get('c')

    CKEPaneProvider(c)
#@+node:tbrown.20130814090427.22458: *4* at_rich_check
def at_rich_check(tag, key):

    p = key.get('new_p')

    do = 'close'
    for nd in p.self_and_parents():
        if '@norich' in nd.h or '@norich' in nd.b[:1000]:
            do = 'close'
            break
        if '@rich' in nd.h or '@rich' in nd.b[:1000]:
            do = 'open'
            break

    if do == 'close':
        cmd_CloseEditor(key, at_rich=True)
    elif do == 'open':
        cmd_OpenEditor(key, at_rich=True)
#@+node:tbrown.20130813134319.5692: *4* @g.command('cke-text-open')
@g.command('cke-text-open')
def cmd_OpenEditor(event=None, at_rich=False):
    """Open the rich text editor, hide the regular editor."""
    c = event.get('c')
    splitter = c.free_layout.get_top_splitter()
    rte = splitter.find_child(CKEEditor, '')
    if rte:
        if not at_rich:
            g.es("CKE Editor appears to be open already")
        return
    body = splitter.find_child(QtWidgets.QWidget, 'bodyFrame')
    w = CKEEditor(c=c)
    w.at_rich = at_rich
    splitter = body.parent()
    splitter.replace_widget(body, w)
#@+node:tbrown.20130813134319.5693: *4* @g.command('cke-text-close')
@g.command('cke-text-close')
def cmd_CloseEditor(event=None, at_rich=False):
    """Close the rich text editor, unhide the regular editor."""
    c = event.get('c')
    splitter = c.free_layout.get_top_splitter()
    if not splitter:
        return
    rte = splitter.find_child(CKEEditor, '')
    if not rte:
        if not at_rich:
            g.es("No editor open")
        return
    if at_rich and not rte.at_rich:
        # don't close manually opened editor
        return
    body = splitter.get_provided('_leo_pane:bodyFrame')
    splitter = rte.parent()
    rte.at_rich_close = True
    splitter.replace_widget(rte, body)
#@+node:tbrown.20130813134319.7233: *4* @g.command('cke-text-switch')
@g.command('cke-text-switch')
def cmd_SwitchEditor(event):
    """Switch between regular and rich text editor."""
    c = event.get('c')
    splitter = c.free_layout.get_top_splitter()
    rte = splitter.find_child(CKEEditor, '')
    if not rte:
        cmd_OpenEditor(event)
    else:
        cmd_CloseEditor(event)
#@+node:tbrown.20130813134319.7231: *4* @g.command('cke-text-toggle-autosave')
@g.command('cke-text-toggle-autosave')
def cmd_ToggleAutosave(event):
    """
    Toggle autosaving of changes when you leave a node.

    Be careful not to convert plain text (e.g. source code) to rich
    text unintentionally.  As long as you make no edits, the original
    text will not be changed.
    """
    c = event.get('c')
    c._ckeeditor_autosave = not c._ckeeditor_autosave
    g.es("Rich text autosave " +
         ("ENABLED" if c._ckeeditor_autosave else "disabled"))
#@+node:ekr.20210407010914.1: *3* @@@file leoQt5.py
@nosearch

"""Import wrapper for pyQt5"""

# pylint: disable=import-error,no-name-in-module,unused-import

# Required imports
from PyQt5 import Qt
from PyQt5 import QtCore
from PyQt5 import QtGui
from PyQt5 import QtWidgets
from PyQt5.QtCore import QUrl
from PyQt5.QtCore import pyqtSignal as Signal
from PyQt5.QtGui import QCloseEvent
QtConst = QtCore.Qt
printsupport = Qt
qt_version = QtCore.QT_VERSION_STR
assert Qt and QtCore and QtGui and QtWidgets  # For pyflakes.
assert QCloseEvent and QUrl and Signal  # For pyflakes.
# Optional imports: Import this before creating the GUI.
try:
    # pylint: disable=ungrouped-imports
    from PyQt5 import QtWebEngineWidgets
    assert QtWebEngineWidgets
    has_WebEngineWidgets = True
except ImportError:
    # print('No Qt5 QtWebEngineWidgets')
    has_WebEngineWidgets = False
try:
    import PyQt5.QtDeclarative as QtDeclarative
except ImportError:
    QtDeclarative = None
try:
    import PyQt5.phonon as phonon
    phonon = phonon.Phonon
except ImportError:
    phonon = None
try:
    from PyQt5 import QtMultimedia
except ImportError:
    QtMultimedia = None
try:
    from PyQt5 import Qsci
except ImportError:
    Qsci = None
try:
    import PyQt5.QtSvg as QtSvg
except ImportError:
    QtSvg = None
try:
    from PyQt5 import uic
except ImportError:
    uic = None
try:
    from PyQt5 import QtWebKit
except ImportError:
    # 2016/07/13: Reinhard: Support pyqt 5.6...
    try:
        from PyQt5 import QtWebEngineCore as QtWebKit
    except ImportError:
        QtWebKit = None
try:
    import PyQt5.QtWebKitWidgets as QtWebKitWidgets
except ImportError:
    try:
        # https://groups.google.com/d/msg/leo-editor/J_wVIzqQzXg/KmXMxJSAAQAJ
        # Reinhard: Support pyqt 5.6...
        # used by viewrendered(2|3).py, bigdash.py, richtext.py.
        import PyQt5.QtWebEngineWidgets as QtWebKitWidgets  # type:ignore
        QtWebKitWidgets.QWebView = QtWebKitWidgets.QWebEngineView
        QtWebKit.QWebSettings = QtWebKitWidgets.QWebEngineSettings
        QtWebKitWidgets.QWebPage = QtWebKitWidgets.QWebEnginePage
    except ImportError:
        QtWebKitWidgets = None
#
# Default enum values. These apply to both Qt4 and Qt5
Alignment = QtCore.Qt
ButtonRole = QtWidgets.QMessageBox
ContextMenuPolicy = QtCore.Qt
ControlType = QtWidgets.QSizePolicy
DialogCode = QtWidgets.QDialog
DropAction = QtCore.Qt
EndEditHint = QtWidgets.QAbstractItemDelegate
FocusPolicy = QtCore.Qt
FocusReason = QtCore.Qt
Format = QtGui.QImage
GlobalColor = QtCore.Qt
Icon = QtWidgets.QMessageBox
Information = QtWidgets.QMessageBox
ItemFlag = QtCore.Qt  # 2347
ItemDataRole = QtCore.Qt  # 2347
Key = QtCore.Qt
KeyboardModifier = QtCore.Qt
Modifier = QtCore.Qt
MouseButton = QtCore.Qt
MoveMode = QtGui.QTextCursor
MoveOperation = QtGui.QTextCursor
Orientation = QtCore.Qt
Policy = QtWidgets.QSizePolicy
QAction = QtWidgets.QAction
QActionGroup = QtWidgets.QActionGroup
QStyle = QtWidgets.QStyle
ScrollBarPolicy = QtCore.Qt
SelectionBehavior = QtWidgets.QAbstractItemView
SelectionMode = QtWidgets.QAbstractItemView
Shadow = QtWidgets.QFrame
Shape = QtWidgets.QFrame
SizeAdjustPolicy = QtWidgets.QComboBox
SliderAction = QtWidgets.QAbstractSlider
SolidLine = QtCore.Qt.SolidLine
StandardButton = QtWidgets.QDialogButtonBox
StandardPixmap = QtWidgets.QStyle
Style = QtGui.QFont
TextInteractionFlag = QtCore.Qt
TextOption = QtGui.QTextOption
ToolBarArea = QtCore.Qt
Type = QtCore.QEvent
UnderlineStyle = QtGui.QTextCharFormat
if has_WebEngineWidgets:
    QWebEngineSettings = QtWebEngineWidgets.QWebEngineSettings
    WebEngineAttribute = QtWebEngineWidgets.QWebEngineSettings
else:
    QWebEngineSettings = None  # type:ignore
    WebEngineAttribute = None  # type:ignore

Weight = QtGui.QFont
WindowType = QtCore.Qt
WindowState = QtCore.Qt
WidgetAttribute = QtCore.Qt  # #2347
WrapMode = QtGui.QTextOption
#@+node:ekr.20210407011013.1: *3* @@@file leoQt6.py
@nosearch

"""
Import wrapper for pyQt6.

For Qt6, plugins are responsible for loading all optional modules.

"""

# pylint: disable=unused-import,no-name-in-module,c-extension-no-member,import-error

# Required imports
from typing import Any
from PyQt6 import QtCore, QtGui, QtWidgets
from PyQt6.QtCore import Qt, QUrl
from PyQt6.QtGui import QAction, QActionGroup, QCloseEvent
from PyQt6.QtCore import pyqtSignal as Signal
#
# For pyflakes.
assert QtCore and QtGui and QtWidgets
assert QAction and QActionGroup
assert QCloseEvent
assert Qt and QUrl and Signal
#
# Standard abbreviations.
QtConst = Qt
qt_version = QtCore.QT_VERSION_STR
#
# Optional imports: #2005
# Must import this before creating the GUI
has_WebEngineWidgets = False
try:
    from PyQt6 import QtWebEngineWidgets
    from PyQt6 import QtWebEngineCore  # included with PyQt6-WebEngine
    assert QtWebEngineWidgets
    has_WebEngineWidgets = True
except ImportError:
    # 2866: This message pollutes leoserver.py.
        # print('No Qt6 QtWebEngineWidgets')
        # print('pip install PyQt6-WebEngine')
    pass

try:
    from PyQt6 import QtPrintSupport as printsupport
except Exception:
    printsupport = None

try:
    from PyQt6 import Qsci
except ImportError:
    Qsci = None
try:
    import PyQt6.QtSvg as QtSvg
except ImportError:
    QtSvg = None
try:
    from PyQt6 import uic
except ImportError:
    uic = None
#
# #2005: Do not import these by default. All of these *do* work.
if 0:
    try:
        from PyQt6 import QtDesigner
    except Exception:
        QtDesigner = None
    try:
        from PyQt6 import QtOpenGL
    except Exception:
        QtOpenGL = None
    try:
        from PyQt6 import QtMultimedia
    except ImportError:
        QtMultimedia = None
    try:
        from PyQt6 import QtNetwork
    except Exception:
        QtNetwork = None
#
# Enumerations, with (sheesh) variable spellings.
try:
    # New spellings (6.1+): mostly singular.
    Alignment = Qt.AlignmentFlag
    ControlType = QtWidgets.QSizePolicy.ControlType
    DropAction = Qt.DropAction
    ItemFlag = Qt.ItemFlag
    KeyboardModifier = Qt.KeyboardModifier
    Modifier = Qt.Modifier
    MouseButton = Qt.MouseButton
    Orientation = Qt.Orientation
    StandardButton = QtWidgets.QDialogButtonBox.StandardButton
    TextInteractionFlag = Qt.TextInteractionFlag
    ToolBarArea = Qt.ToolBarArea
    WidgetAttribute = Qt.WidgetAttribute  # #2347
    WindowType = Qt.WindowType
    WindowState = Qt.WindowState
except AttributeError:
    # Old spellings (6.0): mostly plural.
    Alignment = Qt.Alignment  # type:ignore
    ControlType = QtWidgets.QSizePolicy.ControlTypes  # type:ignore
    DropAction = Qt.DropActions  # type:ignore
    ItemFlag = Qt.ItemFlags  # type:ignore
    KeyboardModifier = Qt.KeyboardModifiers  # type:ignore
    Modifier = Qt.Modifiers  # type:ignore
    MouseButton = Qt.MouseButtons  # type:ignore
    Orientation = Qt.Orientations  # type:ignore
    StandardButton = QtWidgets.QDialog.StandardButtons  # type:ignore
    TextInteractionFlag = Qt.TextInteractionFlags  # type:ignore
    ToolBarArea = Qt.ToolBarAreas  # type:ignore
    WindowType = Qt.WindowFlags  # type:ignore
    WindowState = Qt.WindowStates  # type:ignore
#
# Other enums.
ButtonRole = QtWidgets.QMessageBox.ButtonRole
ContextMenuPolicy = Qt.ContextMenuPolicy
DialogCode = QtWidgets.QDialog.DialogCode
EndEditHint = QtWidgets.QAbstractItemDelegate.EndEditHint
FocusPolicy = Qt.FocusPolicy
FocusReason = Qt.FocusReason
Format = QtGui.QImage.Format
GlobalColor = Qt.GlobalColor
Icon = QtWidgets.QMessageBox.Icon
Information = Icon.Information
ItemDataRole = Qt.ItemDataRole  # 2347
Key = Qt.Key
MoveMode = QtGui.QTextCursor.MoveMode
MoveOperation = QtGui.QTextCursor.MoveOperation
Policy = QtWidgets.QSizePolicy.Policy
ScrollBarPolicy = Qt.ScrollBarPolicy
SelectionBehavior = QtWidgets.QAbstractItemView.SelectionBehavior
SelectionMode = QtWidgets.QAbstractItemView.SelectionMode
Shadow = QtWidgets.QFrame.Shadow
Shape = QtWidgets.QFrame.Shape
SizeAdjustPolicy = QtWidgets.QComboBox.SizeAdjustPolicy
SliderAction = QtWidgets.QAbstractSlider.SliderAction
SolidLine = Qt.PenStyle.SolidLine
StandardPixmap = QtWidgets.QStyle.StandardPixmap
Style = QtGui.QFont.Style
TextOption = QtGui.QTextOption
Type = QtCore.QEvent.Type
UnderlineStyle = QtGui.QTextCharFormat.UnderlineStyle
QWebEngineSettings: Any
WebEngineAttribute: Any
if has_WebEngineWidgets:
    QWebEngineSettings = QtWebEngineCore.QWebEngineSettings
    WebEngineAttribute = QWebEngineSettings.WebAttribute
else:
    QWebEngineSettings = None
    WebEngineAttribute = None

Weight = QtGui.QFont.Weight
WrapMode = QtGui.QTextOption.WrapMode
#@-all
#@@nosearch
#@-leo
