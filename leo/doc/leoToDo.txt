#@+leo-ver=5-thin
#@+node:ekr.20100119205347.6015: * @thin ../doc/leoToDo.txt
#@+all
#@+node:ekr.20100109214940.6225: ** 4.8 to do
4.8 vim, cleanups, your mission...
#@+node:ekr.20100223123910.5836: *3* First
#@+node:ekr.20100204052559.5791: *4* Make TOC sidebar collapsible
@nocolor-node
@wrap

http://groups.google.com/group/leo-editor/browse_thread/thread/abe236a45b0511c7

http://www.google.com/url?sa=t&source=web&ct=res&cd=4&ved=0CBYQFjAD&url=http%3A%2F%2Fbugs.python.org%2Fissue3143&ei=bW5oS-eQIJDalAfqlYyGCA&usg=AFQjCNGyhpE3wZ2jvfwA0dwjCfoAxleDRQ&sig2=2CRD7hNMmx1NzFHMyOq_cQ

includes code for the CSS stylesheet (sidebar.js) to do make the sidebar collapsable.

EKR:

1. Place sidebar.js in leo\doc\html\_build\html\_static

2. Add the following line in the <head> section of all .html files in leo\doc\html\_build\html:

    <script type="text/javascript" src="sidebar.js"></script>

Now the sidebar is collapsable. Mousing over the divider shows a << icon. When
the sidebar is collapsed, mousing over the left edge shows a >> button.

The question is, how to do this automatically?
#@+node:ekr.20100707124440.5870: *4* Fix at-root unit tests
#@+node:ekr.20100521090440.5888: *4* Fix tangle/untangle problems
#@+node:ekr.20100521130114.5903: *5* Allow @root only in headlines
@nocolor-node

I just finished reviewing Chapter 5, and some of its text, if not
downright wrong, is at best confusing, because it was written assuming
use of @root, and then perhaps modified to be less wrong - sometimes.
Before I launch on a significant rewrite, I'd like to know the plans
and timeframe for the revision to @root behavior.

Is it a matter only of @root becoming valid only in headers and not in
the body?  E.g., are there any changes to body section definitions,
e.g.,

+ headline
@c
commentary
@
<<section extension>>=
   more lines
   added to section extension

?  I.e., what's the full spec for the new behavior?

What's more likely to happen first:

(a) I rewrite the chapter to assume @file behavior (approx. two
weeks).
(b) Edward renews interest in changing @root (? days) and fixes it (2
days?)
(c) I get a spec for the new behavior of @root (? days) and attempt to
implement it myself (20 days?) then rewrite chapter 5 (one week; less
to change because I can leave in @root).

Reasons you'll have to wait longer for me than you might otherwise
expect: 1. Edward is more familiar with the code. 2 I've got
concurrent projects. 3. My strongest languages are perl, /bin/sh, C
and only then {python,ruby,lisp,objective-C,C++,erlang,...} 4.
Edward's probably smarter than I am ;-)

#@+node:ekr.20100507084415.5757: *5* Fix @root-code/doc bug
#@+node:ekr.20031218072017.1380: *6* g.Directive utils...
# New in Leo 4.6:
# g.findAtTabWidthDirectives, g.findLanguageDirectives and
# g.get_directives_dict use re module for faster searching.
#@+node:EKR.20040504150046.4: *7* g.comment_delims_from_extension
def comment_delims_from_extension(filename):

    """
    Return the comment delims corresponding to the filename's extension.

    >>> import leo.core.leoGlobals as g
    >>> g.comment_delims_from_extension(".py")
    ('#', '', '')

    >>> g.comment_delims_from_extension(".c")
    ('//', '/*', '*/')

    >>> g.comment_delims_from_extension(".html")
    ('', '<!--', '-->')

    """

    if filename.startswith('.'):
        # Python 2.6 changes how splitext works.
        root,ext = None,filename
    else:
        root, ext = os.path.splitext(filename)
    if ext == '.tmp':
        root, ext = os.path.splitext(root)

    language = g.app.extension_dict.get(ext[1:])
    if ext:
        return g.set_delims_from_language(language)
    else:
        g.trace("unknown extension: %s, filename: %s, root: %s" % (
            repr(ext),repr(filename),repr(root)))
        return '','',''
#@+node:ekr.20071109165315: *7* g.stripPathCruft
def stripPathCruft (path):

    '''Strip cruft from a path name.'''

    if not path:
        return path # Retain empty paths for warnings.

    if len(path) > 2 and (
        (path[0]=='<' and path[-1] == '>') or
        (path[0]=='"' and path[-1] == '"') or
        (path[0]=="'" and path[-1] == "'")
    ):
        path = path[1:-1].strip()

    # We want a *relative* path, not an absolute path.
    return path
#@+node:ekr.20090214075058.8: *7* g.findAtTabWidthDirectives (must be fast)
g_tabwidth_pat = re.compile(r'(^@tabwidth)',re.MULTILINE)

def findTabWidthDirectives(c,p):

    '''Return the language in effect at position p.'''

    if c is None:
        return # c may be None for testing.

    w = None
    # 2009/10/02: no need for copy arg to iter
    for p in p.self_and_parents():
        if w: break
        for s in p.h,p.b:
            if w: break
            anIter = g_tabwidth_pat.finditer(s)
            for m in anIter:
                word = m.group(0)
                i = m.start(0)
                j = g.skip_ws(s,i + len(word))
                junk,w = g.skip_long(s,j)
                if w == 0: w = None
    return w
#@+node:ekr.20090214075058.6: *7* g.findLanguageDirectives (must be fast)
g_language_pat = re.compile(r'(^@language)',re.MULTILINE)

def findLanguageDirectives(c,p):

    '''Return the language in effect at position p.'''

    trace = False and not g.unitTesting

    if c is None:
        return # c may be None for testing. 
    if c.target_language:
        language = c.target_language.lower()
    else:
        language = 'python'
    found = False
    # 2009/10/02: no need for copy arg to iter.
    for p in p.self_and_parents():
        if found: break
        for s in p.h,p.b:
            if found: break
            anIter = g_language_pat.finditer(s)
            for m in anIter:
                word = m.group(0)
                i = m.start(0)
                j = i + len(word)
                k = g.skip_line(s,j)
                language = s[j:k].strip()
                found = True

    if trace: g.trace(language)
    return language
#@+node:ekr.20031218072017.1385: *7* g.findReference
# Called from the syntax coloring method that colorizes section references.

def findReference(c,name,root):

    '''Find the section definition for name.

    If a search of the descendants fails,
    and an ancestor is an @root node,
    search all the descendants of the @root node.
    '''

    for p in root.subtree():
        assert(p!=root)
        if p.matchHeadline(name) and not p.isAtIgnoreNode():
            return p

    # New in Leo 4.7: expand the search for @root trees.
    for p in root.self_and_parents():
        d = g.get_directives_dict(p)
        if 'root' in d:
            for p2 in p.subtree():
                if p2.matchHeadline(name) and not p2.isAtIgnoreNode():
                    return p2

    # g.trace("not found:",name,root)
    return c.nullPosition()
#@+node:ekr.20090214075058.9: *7* g.get_directives_dict (must be fast)
# The caller passes [root_node] or None as the second arg.
# This allows us to distinguish between None and [None].

g_noweb_root = re.compile('<'+'<'+'*'+'>'+'>'+'=',re.MULTILINE)

def get_directives_dict(p,root=None):

    """Scan p for @directives found in globalDirectiveList.

    Returns a dict containing the stripped remainder of the line
    following the first occurrence of each recognized directive"""

    trace = False and not g.unitTesting
    verbose = False
    if trace: g.trace('*'*20,p.h)

    if root: root_node = root[0]
    d = {}

    # Do this every time so plugins can add directives.
    pat = g.compute_directives_re()
    directives_pat = re.compile(pat,re.MULTILINE)

    # The headline has higher precedence because it is more visible.
    for kind,s in (('head',p.h),('body',p.b)):
        anIter = directives_pat.finditer(s)
        for m in anIter:
            word = m.group(0)[1:] # Omit the @
            i = m.start(0)
            if word.strip() not in d:
                j = i + 1 + len(word)
                k = g.skip_line(s,j)
                val = s[j:k].strip()
                if j < len(s) and s[j] not in (' ','\t','\n'):
                    # g.es_print('invalid character after directive',s[max(0,i-1):k-1],color='red')
                    # if trace:g.trace(word,repr(val),s[i:i+20])
                    pass # Not a valid directive: just ignore it.
                else:
                    directive_word = word.strip()
                    if directive_word in ('root-doc', 'root-code'):
                        d['root'] = val # in addition to optioned version
                    d[directive_word] = val
                    if trace: g.trace(word.strip(),kind,repr(val))
                    # A special case for @path in the body text of @<file> nodes.
                    # Don't give an actual warning: just set some flags.
                    if kind == 'body' and word.strip() == 'path' and p.isAnyAtFileNode():
                        g.app.atPathInBodyWarning = p.h
                        d['@path_in_body'] = p.h
                        if trace: g.trace('@path in body',p.h)

    if root:
        anIter = g_noweb_root.finditer(p.b)
        for m in anIter:
            if root_node:
                d["root"]=0 # value not immportant
            else:
                g.es('%s= may only occur in a topmost node (i.e., without a parent)' % (
                    g.angleBrackets('*')))
            break

    if trace and verbose: g.trace('%4d' % (len(p.h) + len(p.b)),g.callers(5))
    return d
#@+node:ekr.20090214075058.10: *8* compute_directives_re
def compute_directives_re ():

    '''Return an re pattern which will match all Leo directives.'''

    global globalDirectiveList

    aList = ['^@%s' % z for z in globalDirectiveList
                if z != 'others']

    if 0: # 2010/02/01
        # The code never this, and this regex is broken
        # because it can confuse g.get_directives_dict.
        # @others can have leading whitespace.
        aList.append(r'^\s@others\s')

    return '|'.join(aList)
#@+node:ekr.20080827175609.1: *7* g.get_directives_dict_list (must be fast)
def get_directives_dict_list(p1):

    """Scans p and all its ancestors for directives.

    Returns a list of dicts containing pointers to
    the start of each directive"""

    trace = False and not g.unitTesting

    if trace: time1 = g.getTime()

    result = []

    if p1:
        p1 = p1.copy()
        for p in p1.self_and_parents():
            if p.hasParent(): root = None
            else:             root = [p.copy()]
            result.append(g.get_directives_dict(p,root=root))

        if trace:
            n = len(p1.h) + len(p1.b)
            g.trace('%4d %s' % (n,g.timeSince(time1)))

    return result
#@+node:ekr.20031218072017.1386: *7* g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@+node:ekr.20080827175609.52: *7* g.scanAtCommentAndLanguageDirectives
def scanAtCommentAndAtLanguageDirectives(aList):

    '''Scan aList for @comment and @language directives.

    @comment should follow @language if both appear in the same node.'''

    lang = None

    for d in aList:

        comment = d.get('comment')
        language = d.get('language')

        # Important: assume @comment follows @language.
        if language:
            # if g.unitTesting: g.trace('language',language)
            lang,delim1,delim2,delim3 = g.set_language(language,0)

        if comment:
            # if g.unitTesting: g.trace('comment',comment)
            delim1,delim2,delim3 = g.set_delims_from_string(comment)

        if comment or language:
            delims = delim1,delim2,delim3
            return {'language':lang,'comment':comment,'delims':delims}

    return None
#@+node:ekr.20080827175609.32: *7* g.scanAtEncodingDirectives
def scanAtEncodingDirectives(aList):

    '''Scan aList for @encoding directives.'''

    for d in aList:
        encoding = d.get('encoding')
        if encoding and g.isValidEncoding(encoding):
            # g.trace(encoding)
            return encoding
        elif encoding and not g.app.unitTesting:
            g.es("invalid @encoding:",encoding,color="red")

    return None
#@+node:ekr.20080827175609.53: *7* g.scanAtHeaderDirectives
def scanAtHeaderDirectives(aList):

    '''scan aList for @header and @noheader directives.'''

    for d in aList:
        if d.get('header') and d.get('noheader'):
            g.es_print("conflicting @header and @noheader directives",color='red')
#@+node:ekr.20080827175609.33: *7* g.scanAtLineendingDirectives
def scanAtLineendingDirectives(aList):

    '''Scan aList for @lineending directives.'''

    for d in aList:

        e = d.get('lineending')
        if e in ("cr","crlf","lf","nl","platform"):
            lineending = g.getOutputNewline(name=e)
            return lineending
        # else:
            # g.es("invalid @lineending directive:",e,color="red")

    return None
#@+node:ekr.20080827175609.34: *7* g.scanAtPagewidthDirectives
def scanAtPagewidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @pagewidth directives.'''

    for d in aList:
        s = d.get('pagewidth')
        if s is not None:
            i, val = g.skip_long(s,0)
            if val != None and val > 0:
                # g.trace(val)
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @pagewidth",s,color="red")

    return None
#@+node:ekr.20100507084415.5760: *7* g.scanAtRootDirectives
def scanAtRootDirectives(aList):

    '''Scan aList for @root directives.'''

    for d in aList:
        s = d.get('root')
        if s is not None:
            i, mode = g.scanAtRootOptions(s,0)
            g.trace(mode)
            return mode

    return None
#@+node:ekr.20031218072017.3154: *7* g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    # g.trace(mode,g.callers(3))

    return i,mode
#@+node:ekr.20031218072017.3155: *8* << scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','\n','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@+node:ekr.20080827175609.37: *7* g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
def scanAtTabwidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @tabwidth directives.'''

    for d in aList:
        s = d.get('tabwidth')
        if s is not None:
            junk,val = g.skip_long(s,0)
            if val not in (None,0):
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @tabwidth",s,color="red")
    return None

def scanAllAtTabWidthDirectives(c,p):

    '''Scan p and all ancestors looking for @tabwidth directives.'''

    if c and p:
        aList = g.get_directives_dict_list(p)
        val = g.scanAtTabwidthDirectives(aList)
        ret = g.choose(val is None,c.tab_width,val)
    else:
        ret = None
    # g.trace(ret,p and p.h,ret)
    return ret
#@+node:ekr.20080831084419.4: *7* g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@+node:ekr.20080901195858.4: *7* g.scanDirectives  (for compatibility only)
def scanDirectives(c,p=None):

    return c.scanAllDirectives(p)
#@+node:ekr.20040715155607: *7* g.scanForAtIgnore
def scanForAtIgnore(c,p):

    """Scan position p and its ancestors looking for @ignore directives."""

    if g.app.unitTesting:
        return False # For unit tests.

    for p in p.self_and_parents():
        d = g.get_directives_dict(p)
        if 'ignore' in d:
            return True

    return False
#@+node:ekr.20040712084911.1: *7* g.scanForAtLanguage
def scanForAtLanguage(c,p):

    """Scan position p and p's ancestors looking only for @language and @ignore directives.

    Returns the language found, or c.target_language."""

    # Unlike the code in x.scanAllDirectives, this code ignores @comment directives.

    if c and p:
        for p in p.self_and_parents():
            d = g.get_directives_dict(p)
            if 'language' in d:
                z = d["language"]
                language,delim1,delim2,delim3 = g.set_language(z,0)
                return language

    return c.target_language
#@+node:ekr.20041123094807: *7* g.scanForAtSettings
def scanForAtSettings(p):

    """Scan position p and its ancestors looking for @settings nodes."""

    for p in p.self_and_parents():
        h = p.h
        h = g.app.config.canonicalizeSettingName(h)
        if h.startswith("@settings"):
            return True

    return False
#@+node:ekr.20031218072017.1382: *7* g.set_delims_from_language
# Returns a tuple (single,start,end) of comment delims

def set_delims_from_language(language):

    trace = False and not g.unitTesting

    val = g.app.language_delims_dict.get(language)
    # if language.startswith('huh'): g.pdb()

    if val:
        delim1,delim2,delim3 = g.set_delims_from_string(val)
        if trace: g.trace(repr(language),
            repr(delim1),repr(delim2),repr(delim3),g.callers(5))
        if delim2 and not delim3:
            return '',delim1,delim2
        else: # 0,1 or 3 params.
            return delim1,delim2,delim3
    else:
        return '','','' # Indicate that no change should be made
#@+node:ekr.20031218072017.1383: *7* g.set_delims_from_string
def set_delims_from_string(s):

    """Returns (delim1, delim2, delim2), the delims following the @comment directive.

    This code can be called from @language logic, in which case s can point at @comment"""

    # Skip an optional @comment
    tag = "@comment"
    i = 0
    if g.match_word(s,i,tag):
        i += len(tag)

    count = 0 ; delims = ['','','']
    while count < 3 and i < len(s):
        i = j = g.skip_ws(s,i)
        while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        if j == i: break
        delims[count] = s[j:i] or ''
        count += 1

    # 'rr 09/25/02
    if count == 2: # delims[0] is always the single-line delim.
        delims[2] = delims[1]
        delims[1] = delims[0]
        delims[0] = ''

    # 7/8/02: The "REM hack": replace underscores by blanks.
    # 9/25/02: The "perlpod hack": replace double underscores by newlines.
    for i in range(0,3):
        if delims[i]:
            delims[i] = delims[i].replace("__",'\n').replace('_',' ')

    return delims[0], delims[1], delims[2]
#@+node:ekr.20031218072017.1384: *7* g.set_language
def set_language(s,i,issue_errors_flag=False):

    """Scan the @language directive that appears at s[i:].

    The @language may have been stripped away.

    Returns (language, delim1, delim2, delim3)
    """

    tag = "@language"
    # g.trace(g.get_line(s,i))
    assert(i != None)
    # assert(g.match_word(s,i,tag))
    if g.match_word(s,i,tag):
        i += len(tag)
    # Get the argument.
    i = g.skip_ws(s, i)
    j = i ; i = g.skip_c_id(s,i)
    # Allow tcl/tk.
    arg = s[j:i].lower()
    if app.language_delims_dict.get(arg):
        language = arg
        delim1, delim2, delim3 = g.set_delims_from_language(language)
        return language, delim1, delim2, delim3

    if issue_errors_flag:
        g.es("ignoring:",g.get_line(s,i))

    return None, None, None, None,
#@+node:ekr.20081001062423.9: *7* g.setDefaultDirectory & helpers
# This is a refactoring, used by leoImport.scanDefaultDirectory and
# atFile.scanDefaultDirectory

def setDefaultDirectory(c,p,importing=False):

    ''' Compute a default directory by scanning @path directives.
    Return (default_dir,error_message).'''

    if not p: return '',''
    default_dir,error = g.getAbsPathFromNode(c,p),''

    if not default_dir:
        default_dir,error = g.getPathFromDirectives(c,p)

    if c and c.frame and not default_dir and not error:
        default_dir = g.findDefaultDirectory(c)

    if not default_dir and not importing and not error:
        # This should never happen: c.openDirectory should be a good last resort.
        error = "No absolute directory specified anywhere."

    return default_dir, error
#@+node:ekr.20081001062423.10: *8* g.getAbsPathFromNode
# An absolute path in an @file node over-rides everything else.
# A relative path gets appended to the relative path by the open logic.

def getAbsPathFromNode(c,p,name=''): # Name is for unit testing.

    default_dir = ''
    if p:
        name = p.anyAtFileNodeName()

    if name:
        theDir = g.os_path_dirname(name)
        if theDir and g.os_path_isabs(theDir):
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)

    return default_dir
#@+node:ekr.20081001062423.11: *8* g.getPathFromDirectives
def getPathFromDirectives(c,p):

    '''Scan for @path directives.'''

    trace = False and not g.unitTesting
    default_dir = '' ; error = ''
    if not p: return default_dir,error
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if path:
        base = g.getBaseDirectory(c) # returns "" on error.
        path = c.os_path_finalize_join(base,path)
        if g.os_path_exists(path):
            default_dir = path
        else:
            default_dir = g.makeAllNonExistentDirectories(path,c=c)
            if not default_dir:
                error = "invalid @path: %s" % path

    return default_dir,error
#@+node:ekr.20081001062423.12: *8* g.findDefaultDirectory (major change)
# This code is executed if no valid absolute path was specified in
# the @file node or in an @path directive.

def findDefaultDirectory(c):

    '''Attempt to find a suitable default directory.'''

    default_dir = ''

    # Check that c.openDirectory and c.frame.openDirectory are in synch.
    if c.openDirectory != c.frame.openDirectory:
        g.trace('***can not happen: c.openDirectory != c.frame.openDirectory')
        g.trace('c.openDirectory',c.openDirectory)
        g.trace('c.frame.openDirectory',c.frame.openDirectory)

    if not g.os_path_isabs(c.openDirectory):
        g.trace('*** can not happen: relative c.openDirectory',c.openDirectory)

    for theDir in (c.openDirectory,g.getBaseDirectory(c)):
        if theDir and g.os_path_isabs(theDir): # Errors may result in relative or invalid path.
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)
            if default_dir: break

    return default_dir
#@+node:ekr.20100507084415.5758: *6* Report
@nocolor-node

Whereas the @root directive in a body works (for some value of works; I'm still
clarifying for myself - it doesn't work the way Leo of October 2002 did),
@root-doc and @root-code always elicit a message:

----- The outline contains no roots
looking for a parent to tangle...
tangle complete
 CancelOk
#@+node:ekr.20080923124254.16: *6* tangle.scanAllDirectives
def scanAllDirectives(self,p):

    """Scan vnode p and p's ancestors looking for directives,
    setting corresponding tangle ivars and globals.
    """

    c = self.c
    self.init_directive_ivars()
    if p:
        s = p.b
        << Collect @first attributes >>

    table = (
        ('encoding',    self.encoding,  g.scanAtEncodingDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives), 
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    lang_dict = {'language':None,'delims':None}
    self.parent_language_comment_settings(p,lang_dict)

    # Post process.
    lineending      = d.get('lineending')
    if lineending:
        self.output_newline = lineending
    self.encoding             = d.get('encoding')
    self.language             = lang_dict.get('language')
    self.init_delims          = lang_dict.get('delims')
    self.page_width           = d.get('pagewidth')
    self.tangle_directory     = d.get('path')
    self.tab_width            = d.get('tabwidth')

    # Handle the print-mode directives.
    self.print_mode = None
    for d in aList:
        for key in ('verbose','terse','quiet','silent'):
            if d.get(key) is not None:
                self.print_mode = key ; break
        if self.print_mode: break
    if not self.print_mode: self.print_mode = 'verbose'

    # g.trace(self.tangle_directory)

    # For unit testing.
    return {
        "encoding"  : self.encoding,
        "language"  : self.language,
        "lineending": self.output_newline,
        "pagewidth" : self.page_width,
        "path"      : self.tangle_directory,
        "tabwidth"  : self.tab_width,
    }
#@+node:ekr.20080923124254.17: *7* << Collect @first attributes >>
@
Stephen P. Schaefer 9/13/2002: Add support for @first. Unlike other
root attributes, does *NOT* inherit from parent nodes.
@c

tag = "@first"
sizeString = len(s) # DTHEIN 13-OCT-2002: use to detect end-of-string
i = 0
while 1:
    # DTHEIN 13-OCT-2002: directives must start at beginning of a line
    if not g.match_word(s,i,tag):
        i = g.skip_line(s,i)
    else:
        i = i + len(tag)
        j = i = g.skip_ws(s,i)
        i = g.skip_to_end_of_line(s,i)
        if i>j:
            self.first_lines += s[j:i] + '\n'
        i = g.skip_nl(s,i)
    if i >= sizeString:  # DTHEIN 13-OCT-2002: get out when end of string reached
        break
#@+node:ekr.20031218072017.3475: *6* tanglePass1
#@+node:ekr.20031218072017.3594: *6* setRootFromHeadline
def setRootFromHeadline (self,p):

    s = p.h

    if s[0:5] == "@root":
        i,self.start_mode = g.scanAtRootOptions(s,0)
        i = g.skip_ws(s,i)

        if i < len(s): # Non-empty file name.
            # self.root_name must be set later by token_type().
            self.root = s[i:]
            # implement headline @root (but create unit tests first):
            # arguments: name, is_code, is_doc
            # st_enter_root_name(self.root, False, False)
#@+node:ekr.20031218072017.1259: *6* setRootFromText
@ This code skips the file name used in @root directives.

File names may be enclosed in < and > characters, or in double quotes.
If a file name is not enclosed be these delimiters it continues until
the next newline.
@c
def setRootFromText(self,s,report_errors=True):

    # g.trace(s)
    self.root_name = None
    i,self.start_mode = g.scanAtRootOptions(s,0)
    i = g.skip_ws(s,i)

    if i >= len(s): return i
    # Allow <> or "" as delimiters, or a bare file name.
    if s[i] == '"':
        i += 1 ; delim = '"'
    elif s[i] == '<':
        i += 1 ; delim = '>'
    else: delim = '\n'

    root1 = i # The name does not include the delimiter.
    while i < len(s) and s[i] != delim and not g.is_nl(s,i):
        i += 1
    root2 = i

    if delim != '\n' and not g.match(s,i,delim):
        if report_errors:
            g.scanError("bad filename in @root " + s[:i])
    else:
        self.root_name = s[root1:root2].strip()
    return i
#@+node:ekr.20031218072017.3154: *6* g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    # g.trace(mode,g.callers(3))

    return i,mode
#@+node:ekr.20031218072017.3155: *7* << scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','\n','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@+node:ekr.20031218072017.3599: *6* token_type
def token_type(self,s,i,report_errors=True):

    """This method returns a code indicating the apparent kind of token at the position i.

    The caller must determine whether section definiton tokens are valid.

    returns (kind, end) and sets global root_name using setRootFromText().
    end is only valid for kind in (section_ref, section_def, at_root)."""

    kind = plain_line ; end = -1
    << set token_type in noweb mode >>
    if kind == at_other :
        << set kind for directive >>
    # g.trace(kind,g.get_line(s,i))
    return kind, end
#@+node:ekr.20031218072017.3600: *7* << set token_type in noweb mode >>
if g.match(s,i,"<<"):
    i, kind, end = self.skip_section_name(s,i)
    if kind == bad_section_name:
        kind = plain_line # not an error.
    elif kind == at_root:
        assert(self.head_root == None)
        if self.head_root:
            self.setRootFromText(self.head_root,report_errors)
        else:
            kind = bad_section_name # The warning has been given.
elif g.match(s,i,"@ ") or g.match(s,i,"@\t") or g.match(s,i,"@\n"):
    # 10/30/02: Only @doc starts a noweb doc part in raw cweb mode.
    kind = g.choose(self.raw_cweb_flag,plain_line,at_doc)
elif g.match(s,i,"@@"): kind = at_at
elif i < len(s) and s[i] == '@': kind = at_other
else: kind = plain_line
#@+node:ekr.20031218072017.3602: *7* << set kind for directive >>
# This code will return at_other for any directive other than those listed.

if g.match_word(s,i,"@c"):
    # 10/30/02: Only @code starts a code section in raw cweb mode.
    kind = g.choose(self.raw_cweb_flag,plain_line,at_code)
else:
    for name, theType in [
        ("@chapter", at_chapter),
        ("@code", at_code),
        ("@doc", at_doc),
        ("@root", at_root),
        ("@section", at_section) ]:
        if g.match_word(s,i,name):
            kind = theType ; break

if self.raw_cweb_flag and kind == at_other:
    # 10/30/02: Everything else is plain text in raw cweb mode.
    kind = plain_line

if kind == at_root:
    end = self.setRootFromText(s[i:],report_errors)
#@+node:sps.20100618004337.20865: *6* tanglePass1
# Traverses the tree whose root is given, handling each headline and associated body text.

def tanglePass1(self,p_in,delims):

    """The main routine of tangle pass 1"""

    p = self.p = p_in.copy() # self.p used by update_def in untangle
#    g.trace(p)
    self.setRootFromHeadline(p)
    theDict = g.get_directives_dict(p,[self.head_root])
    if ('ignore' in theDict):
        return
    self.scanAllDirectives(p) # calls init_directive_ivars.
    # Scan the headline and body text.
    # @language and @comment are not recognized in headlines
    self.skip_headline(p)
    delims = self.skip_body(p, delims)
    if self.errors + g.app.scanErrors >= max_errors:
        self.warning("----- Halting Tangle: too many errors")
    elif p.hasChildren():
        p.moveToFirstChild()
        self.tanglePass1(p,delims)
        while p.hasNext() and (self.errors + g.app.scanErrors < max_errors):
            p.moveToNext()
            self.tanglePass1(p,delims)
#@+node:ekr.20100521090440.5889: *5* Fix untangle problem with @unit
@nocolor-node

Thanks for quick answer! But I have still some questions.


2010/3/11 Edward K. Ream <edreamleo@gmail.com>

    [...]Something like this:

    @unit
       @root x.h
           << functions defined in x.c >>

       @root x.c
            << functions defined in x.c >> +=
                void f1(void);

            void f1 (void) { << the actual code }


There are no delimiters (section definitions) between the lines above?


    So after tangling x.h will contain:
       void f1(void);
       void f2(void);


Tangling seems to be ok. But there are Big problems with untangling.
Without @unit only the first @root is untangled.
But now, with @unit, I got an error:
'''

untangling...

----- The outline contains no roots

untangle complete

'''


I hope it's only a bug, not the feature :)
#@+node:ekr.20100521090440.5885: *4* Fix mac unicode crasher
#@+node:ekr.20100521090440.5886: *5* Report
@nocolor-node

I put the following in qtGui.py after

# Last minute-munges to keysym.

    if sys.platform.startswith('darwin'):
        darwinmap = {
            'Alt-Key-5': '[',
            'Alt-Key-6': ']',
            'Alt-Key-7': '|',
            'Alt-slash': '\\',
            'Alt-Key-8': '{',
            'Alt-Key-9': '}',
            'Alt-e': 'â‚¬',
            'Alt-l': '@',
        }
        if tkKey in darwinmap:
            tkKey = stroke = darwinmap[tkKey]

It works quite reasonabe. Sometimes (not really well reproducable)
following message appears:

/Users/tst/Leo-4.7-final/leo/core/leoKeys.py:3363: UnicodeWarning:
Unicode equal comparison failed to convert both arguments to Unicode -
interpreting them as being unequal
  if k.abortAllModesKey and stroke == k.abortAllModesKey:
/Users/scalet/Leo-4.7-final/leo/core/leoKeys.py:2521: UnicodeWarning:
Unicode equal comparison failed to convert both arguments to Unicode -
interpreting them as being unequal
  if k.abortAllModesKey and stroke == k.abortAllModesKey: # 'Control-
g'

nonetheless the special characters were inserted as expected.

I think all this is quite a hack, but ... thanks for the hack, most
important for me it's working for now. 
#@+node:ekr.20100421104119.5753: *4* Fix @shadow IndexError crash
#@+node:ekr.20100521130114.5904: *4* Plugins documentation thread
@nocolor-node

We want better docs, automatically, and a way to update @enabled-plugins.

http://groups.google.com/group/leo-editor/browse_thread/thread/b409aac6ca8cd33b
#@+node:ekr.20100522090453.5912: *4* Fix bugs with @verbatim, @raw and @end_raw
@nocolor-node

> In the @file family of derived files (@thin, @nosent, etc.)  (i.e.,
> not @root), you can prevent any interpretation of the immediately
> following line with the "@verbatim" directive

This is not true, although it might appear to be true.

There is an @verbatim *sentinel*, but no @verbatim *directive*.

For example, I have just verified that the following does not work:

@verbatim
<< undefined ref >>

@raw and @end_raw do work as described.

There appear to be several bugs in this area:

1. Leo probably should warn that @verbatim does not exist as a
directive, although technically Leo is supposed to write anything that
looks like a sentinel but isn't "verbatim".

2. Leo does appear to read @raw and @end_raw properly in @thin files,
but Leo improperly issues the (red) log message,
converting @file format in @thin test_verbatim_sentinel.py
#@+node:ekr.20100220190251.5616: *4* Fix rst bug?
# See handleCodeMode
#@+node:ekr.20100220190251.5617: *5* report
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/c212814815c92aac

The indentation of the second @doc causes the doc part to look like
a continuation of the code:: directive.

It's not clear whether this bug is worth fixing, and it's not clear whether
there would be side effects of any potential fix.

The simplest fix appears to be in handleCodeMode.
#@+node:ekr.20100220204150.5627: *5* @@rst hello.html
@ @rst-options
verbose=True
code_mode=True
show_doc_parts_as_paragraphs=True
number_code_lines=True
write_intermediate_file=True
@c

#@+node:ekr.20100220204150.5628: *6* Greet the world
@
Greet the world, politely
@c

g.es ("Hello, world")

@
    Was that polite enough?
    Indentation.
@c
#@+node:ekr.20100221142603.5620: *4* Fix bug 524890: Incomplete derived file
@nocolor-node

This is the @others bug

1. Create the following tree

Instead of the expected test1.c file of:

Content (clone)
Content (clone)

I got just:

Content (clone)
#@+node:ekr.20100221142603.5625: *5* @@shadow clone-bug-test.py@
# This buglet has been around for a long long time.
# It's not clear what Leo can do to fix it.
# In the meantime, don't put clones under two different
# @others directives :-)

<< A >>
<< B >>
@others
# end
#@+node:ekr.20100221142603.5626: *6* << a >>
# Node a
@others
#@+node:ekr.20100221142603.5629: *7* clone
# Content (clone)
#@+node:ekr.20100221142603.5628: *6* << b >>
# Node b
@others
#@+node:ekr.20100221142603.5629: *7* clone
# Content (clone)
#@+node:ekr.20100223133351.5998: *4* show-invisibles doesn't work for blank lines
#@+node:ekr.20081208102356.1: *4* Threading colorizer doesn't handle multiple body editors
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5be7a099b299327e

> Tk only colorizes one body editor, and if you delete that editor it
> colorizes no editor.

Thanks for this report.  This is a problem, never noticed until now,
with the threading colorizer.  A workaround is to disable the
threading colorizer plugin. 
#@+node:ekr.20100131161507.6303: *4* Unit tests that all commands have docstrings
# Just make the test.  It doesn't have to pass.
#@+node:ekr.20080603052650.466: *3* Fix vim problems
@nocolor

All problems appear to be easy.

http://groups.google.com/group/leo-editor/browse_thread/thread/141690c553bfde55

Vim mode users: your top 3 complaints, please
#@+node:ekr.20100521090440.5887: *4* Generalize minibuffer code
Just playing with part of a template system, the (partial) mock up for
"range()" is:

def tabStopNaming (event=None):

  stateName = 'naming'
  k = c.k
  state = k.getState(stateName)

  help = ('start-value -- optional, -> fill-in or tab eliminate.  ',
           'end-value -- required, -> fill-in.  ',
           'step -- optional, ->fill-in or tab to eliminate.  ')
  tabStop = ('start-value', 'end-value', 'step')

  if state == 0:
      k.setLabelBlue(help[0],protect=True)
      k.getArg(event,stateName,1,tabStopNaming)
      # g.es('does this ever executed?') # yes, imediately!
  else:
      k.clearState()
      g.es_print('%s : %s' % (tabStop[0], k.arg))
      k.setLabelBlue('')

tabStopNaming()

=====================================================
This is hardwired for the first parameter.  Things I need to expand
this:

1. put in a variable that cycles through the tabStops

2. In this mock up, you are entering the parameters in the minibuffer,
a more advanced version would collect each keypress and put it in the
body at the current tabStop, a tab would finalize the entry and
advance to the next stop, no text other than the 'help', ends up in
the minibuffer.

Sinc I'm only modifying existing code without real understanding of
what Leo is doing, andy guidance would be appreciated.

Tom

=======================

Thanks for this work.  You obviously understand the present code well
enough to play with it.

Generalizing the minibuffer code would be a good thing to do.  I
suppose we could define some kind of language that would create, or
rather simulate, hand-written code.  In a sense, @mode nodes are
intended to do this also.

As I look at leoKeys.py again I'll keep this example in the back of my
mind as something that it would be good to support more easily.

Edward
#@+node:ekr.20100210102224.5744: *4* Notes for key bindings
@nocolor-node

Requirements:
    - Existing bindings must still be valid.
    - But @mode does not have to remain.

Think data:
    - Drive binding by tables.
    *** Design these tables first.
    - Table design should be flixible.
      It can change without affecting user.

keySequence class?
    - Represents a sequence of keystrokes.

bufferMode class?
    - Might encapsulate directives, etc.

bindHelper class?
    - Would mediate various aspects of binding.
    - c.bindHelper or k.bindHelper?
#@+node:ekr.20060927173836.6: *4* Don't abort mode if there are problems with bindings
# Or give a better message.
#@+node:ekr.20100113075303.6270: *4* Easiest vim problems
#@+node:ekr.20100112051224.6229: *5* (vim) Binding Arrow keys (fixed?)
Binding arrow keys, with or without Shift, Ctrl, Alt, and their combinations, to
commands or @mode nodes have no effect.
#@+node:ekr.20100112051224.6239: *5* Displaying mode help
@nocolor-node

The "--> mode-help" command has the following issues related to the
display of the "Help" tab:

1. Key label always capitalized.

Vim commands are mapped to both lower-case and upper-case keys but always appear
mapped to upper-case keys within the "Help" tab.

2. Layout of tab's contents.

To improve readability and better support narrow tab cards, display the mode's
label without the "enter-" and "-mode" text and place the key label before the
mode label.

For example, the following entries would change from::
    enter-vi-delete-line-mode d
    enter-vi-delete-to-begin-of-word-mode b
to::
    d : vi-delete-line
    b : vi-delete-to-begin-of-word
#@+node:ekr.20100112051224.6225: *5* Repeat last cursor movement command
Support the ';' key: repeat the last "To character" or "Find character" command.
#@+node:ekr.20090629183608.8445: *5* Cursors (easiest)
Vi normally uses two different "current character" designators depending on the
current state.

Insert state:

In the Insert state, a vertical bar is placed between two characters to indicate
where the next key will be inserted. Leo's cursor is of this type.

Command state: 

In the Command state, vi expects that the cursor is highlighting a current
character and provides commands to enter the insert state or paste text either
before or after that current character. Leo's vi emulation currently does not
support a "current character" cursor. As a result, inserting and pasting before
or after is replaced by inserting or pasting "at" the current cursor location.
For example, the 'i' and 'a' command are both mapped to enter the insert state
at the current cursor location.
#@+node:ekr.20100112051224.6231: *5* Undo command (fixed?)
Using the "undo" command (key 'u') to undo a change to a node's headline text
only works correctly after another node has been selected. It appears that
changes made to a node's headline text are not recorded in Leo's change history
until the edited node has lost focus.
#@+node:ekr.20100113075303.6271: *4* Mode-oriented bindings
#@+node:ekr.20100112051224.6228: *5* Binding numeric keys (modes-oriented bindings)
Mapping a number to a command or an @mode node works but can not be used as it
prevents the number from being entered as text while in Vi's insert state.
#@+node:ekr.20100112051224.6230: *5* Binding 'bksp' key (mode-oriented bindings)
Binding 'bksp' key to back-char to move back a character in command mode
prevents 'bksp' from deleting characters in text edit mode.
#@+node:ekr.20080616110054.2: *4* Support vim dot command
The ability to repeat the last editing related command by pressing the period
key is not supported and there is no workaround in place.

Binding keys within nodes:

Some commands can be "easily" repeated by having the command's mode
bind itself to the period key.  This is not currently working.

Support commands requesting input:

Add companion commands that reuse input.  For example, a zap-to-
character-again command could exist which will reuse the key entered
in the last zap-to-character command.  With this support, the mode
that performs the initial command would assign the period key to a
companion mode that is identical to the initial mode but with the zap-
to-character command replaced by the zap-to-character-again command.

Commands requiring companion commands are:
  zap-to-character
  find-character
  backward-find-character
  (Any others?)

Notes:

- The copy of the character should be saved somewhere that does NOT affect the
  contents of the clipboard.

- The same or a separate storage location can be used for all commands to retain
  a copy of the character entered by the user. It doesn't matter since only the
  last command is assigned to the period key to be re-executed.
#@+node:ekr.20100113075303.6272: *4* Argument handling
#@+node:ekr.20100112051224.6222: *5* Commands requesting user input (hard?)
Commands requesting user input must be the last command executed within an @mode
node. This prevents the implementation of commands such as "yank to <character>"
that requires a "copy to clipboard" operation after the "find-character"
command.
#@+node:ekr.20100112051224.6226: *5* Range prefix to commands (k.getArgs)
The ability to specify a numeric range prefix is not supported. For example,
entering "3dd" will not delete the next three lines and "20G" will not move the
cursor to the 20th line in the file.

#@+node:ekr.20100112051224.6227: *5* Range prefix to objects (k.getArgs)
The ability to specify a numeric range prefix to an object is not supported. For
example, the "d2fx" command should Delete up to and including the 2nd Found "x"
character.
#@+node:ekr.20100112051224.6223: *4* Editing node headlines using @mode nodes
Commands modifying or selecting headline text do not work correctly within a
@mode node.

This eliminates accurate implementation of vi's delete/change/substitute/yank
object commands. As a workaround, the commands are currently written to only
select the text. The user must perform the subsequent delete, change,
substitute, and yank.
#@+node:ekr.20100112051224.6246: *4* Missing commands
#@+node:ekr.20100112051224.6232: *5* Toggle case command
Leo provides support for switching to upper or lower case but no method exists
to toggle between cases (used by Vi's "~" command).

#@+node:ekr.20100112051224.6233: *5* Replace current character command
Vi's "r" command allows user to replace the current character with the next
entered character.
#@+node:ekr.20100112051224.6234: *5* Move current line
Vi has a collection of "z<movement>" commands that will move the
current line to the top, middle, and bottom of the screen.  They are
not supported in Leo.
#@+node:ekr.20100112051224.6235: *5* Move buffer up/down
Vi maps keys to scroll the text up/down one line and by half the
number of visible lines.  Leo does not support this.

#@+node:ekr.20100112051224.6236: *5* Word-related commands
Vi supports two types of words in its commands:

1. Words that consist of only a subset of the character set and
2. words that consist of all characters except the space and tab characters.

Leo's always considers a word to consist of a subset of characters
although some word related commands include different characters
than others.
#@+node:ekr.20100112051224.6237: *5* Forward and backward by sentences
Leo's sentence related functions:

- do not stop at empty lines.
- do not skip periods within words.
- do not stop at sentences ending in non-periods.
- do not stop at the end or beginning of the buffer.

Note: see forwardSentenceHelper and backSentenceHelper functions.
#@+node:ekr.20100112051224.6238: *5* Focus to body pane
Leo functions exist which unconditionally set focus to the body pane
regardless of the active pane.

For example, bracket matching commands ("%" key) do not work within
a node's headline text.  Instead, the command is performed on the
node's body text.
#@+node:ekr.20090629183608.8446: *5* Notes about commands
Yank vs. Yank:
Vi's "yank" commands copy the selected text TO the clipboard.
Leo's "yank" commands insert text FROM the clipboard.

copy-text in modes:
Leo's copy-text command does not work within a mode.  As a result,
all "copy to clipboard" capability is being implemented using the
kill-<object> command followed by Leo's "yank" command to put the
text back.

paste-text in modes:
The paste-text command does not work within an @mode node.  Leo's
"yank" command is used instead.

delete-node does not copy node to clipboard:
A copy-node command is issued to copy the node to the clipboard
followed by the delete-node command.
#@+node:ekr.20100521090440.5890: *3* Cleanups: first
#@+node:ekr.20100223123910.5930: *4* recentFilesController
@
The present operation of recent files is surprising.

Recent files should be a global list, managed by a single controller.
#@+node:ekr.20100219083854.5616: *4* Simplify i/o
#@+node:ekr.20100211125418.11612: *5* Revise g.readFileIntoString
@nocolor-node

- Create g.readFileWithUnknownEncodingIntoString.
    - Only this function should return ok,e.

- g.readFileIntoString should assume utf-8, and support explicit encodings.

We also need the following functions:

- g.openFileForReading.
- g.openFileForWriting.
#@+node:ekr.20100209224508.5744: *5* Calls to .write
@nocolor-node

All these could be considered potential Python 3.x bugs.  Most are not.

It is likely invalid to create an input or output stream which could be either binary or not.

For example, we probably can not choose between "w" and "wb" (or "r" and "rb" at runtime.)
#@+node:ekr.20031218072017.1470: *6* put (leoFileCommands)
def put (self,s):

    '''Put string s to self.outputFile. All output eventually comes here.'''

    # Improved code: self.outputFile (a cStringIO object) always exists.
    # g.trace(g.callers(1),repr(s))
    if s:
        self.putCount += 1
        if not g.isPython3:
            s = g.toEncodedString(s,self.leo_file_encoding,reportErrors=True)
        self.outputFile.write(s)

def put_dquote (self):
    self.put('"')

def put_dquoted_bool (self,b):
    if b: self.put('"1"')
    else: self.put('"0"')

def put_flag (self,a,b):
    if a:
        self.put(" ") ; self.put(b) ; self.put('="1"')

def put_in_dquotes (self,a):
    self.put('"')
    if a: self.put(a) # will always be True if we use backquotes.
    else: self.put('0')
    self.put('"')

def put_nl (self):
    self.put("\n")

def put_tab (self):
    self.put("\t")

def put_tabs (self,n):
    while n > 0:
        self.put("\t")
        n -= 1
#@+node:ekr.20100119145629.6111: *6* writeToFileHelper & helpers
def writeToFileHelper (self,fileName,toOPML):

    c = self.c ; toZip = c.isZipped
    ok,backupName = self.createBackupFile(fileName)
    if not ok: return False
    fileName,theActualFile = self.createActualFile(fileName,toOPML,toZip)
    self.mFileName = fileName
    self.outputFile = StringIO() # Always write to a string.

    try:
        if toOPML:
            self.putToOPML()
        else:
            self.putLeoFile()
        s = self.outputFile.getvalue()
        g.app.write_Leo_file_string = s # 2010/01/19: always set this.
        if toZip:
            self.writeZipFile(s)
        else:
            if g.isPython3:
                s = bytes(s,self.leo_file_encoding,'replace')
            theActualFile.write(s)
            theActualFile.close()
            c.setFileTimeStamp(fileName)
            # raise AttributeError # To test handleWriteLeoFileException.
            # Delete backup file.
            if backupName and g.os_path_exists(backupName):
                self.deleteFileWithMessage(backupName,'backup')
        return True
    except Exception:
        self.handleWriteLeoFileException(
            fileName,backupName,theActualFile)
        return False
#@+node:ekr.20100119145629.6106: *7* createActualFile
def createActualFile (self,fileName,toOPML,toZip):

    c = self.c

    if toOPML and not self.mFileName.endswith('opml'):
        fileName = self.mFileName + '.opml'

    if toZip:
        self.toString = True
        theActualFile = None
    else:
        try:
            # 2010/01/21: always write in binary mode.
            theActualFile = open(fileName,'wb')
        except IOError:
            theActualFile = None

    return fileName,theActualFile
#@+node:ekr.20031218072017.3047: *7* createBackupFile
def createBackupFile (self,fileName):

    '''
        Create a closed backup file and copy the file to it,
        but only if the original file exists.
    '''

    c = self.c

    if g.os_path_exists(fileName):
        # backupName = g.os_path_join(g.app.loadDir,fileName+'.bak')

        fd,backupName = tempfile.mkstemp(text=False)
        f = open(fileName,'rb') # rb is essential.
        s = f.read()
        f.close()

        try:
            try:
                os.write(fd,s)
            finally:
                os.close(fd)
            ok = True
        except Exception:
            g.es('exception creating backup file',color='red')
            g.es_exception()
            ok,backupName = False,None

        if not ok and self.read_only:
            g.es("read only",color="red")
    else:
        ok,backupName = True,None

    return ok,backupName
#@+node:ekr.20100119145629.6108: *7* handleWriteLeoFileException
def handleWriteLeoFileException(self,fileName,backupName,theActualFile):

    c = self.c

    g.es("exception writing:",fileName)
    g.es_exception(full=True)

    if theActualFile:
        theActualFile.close()

    # Delete fileName.
    if fileName and g.os_path_exists(fileName):
        self.deleteFileWithMessage(fileName,'')

    # Rename backupName to fileName.
    if backupName and g.os_path_exists(backupName):
        g.es("restoring",fileName,"from",backupName)

        # No need to create directories when restoring.
        g.utils_rename(c,backupName,fileName)
    else:
        g.trace('backup file does not exist!',
            repr(backupName),color='red')
#@+node:ekr.20031218072017.1149: *6* << Write s into newFileName >>
try:
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    theFile = open(newFileName,mode)
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    theFile.write(s)
    theFile.close()
    if not g.unitTesting:
        g.es("created:",newFileName)
except Exception:
    g.es("exception creating:",newFileName)
    g.es_exception()
#@+node:ekr.20080713091247.1: *6* x.replaceFileWithString
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    trace = False and not g.unitTesting
    x = self
    exists = g.os_path_exists(fn)

    if exists:
        # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s2 is None:
            return False
        if s == s2:
            if not g.unitTesting: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            x.error('not written: %s directory not found' % fn)
        return False

    # Replace the file.
    try:
        f = open(fn,'wb')
        f.write(g.toEncodedString(s))
        if trace: g.trace('fn',fn,
            '\nlines...\n%s' %(g.listToString(g.splitLines(s))),
            '\ncallers',g.callers(4))
        f.close()
        if not g.unitTesting:
            # g.trace('created:',fn,g.callers())
            if exists:  g.es('wrote:',fn)
            else:       g.es('created:',fn)
        return True
    except IOError:
        x.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20080712150045.1: *6* replaceFileWithString (atFile)
def replaceFileWithString (self,fn,s):

    '''Replace the file with s if s is different from theFile's contents.

    Return True if theFile was changed.
    '''

    at = self ; testing = g.app.unitTesting

    # g.trace('fn',fn,'s','\n',s)
    # g.trace(g.callers())

    exists = g.os_path_exists(fn)

    if exists: # Read the file.  Return if it is the same.
        s2,e = g.readFileIntoString(fn)
        if s is None:
            return False
        if s == s2:
            if not testing: g.es('unchanged:',fn)
            return False

    # Issue warning if directory does not exist.
    theDir = g.os_path_dirname(fn)
    if theDir and not g.os_path_exists(theDir):
        if not g.unitTesting:
            g.es('not written: %s directory not found' % fn,color='red')
        return False

    # Replace
    try:
        f = open(fn,'wb')
        if g.isPython3:
            s = g.toEncodedString(s,encoding=self.encoding)
        f.write(s)
        f.close()
        if not testing:
            if exists:
                g.es('wrote:    ',fn)
            else:
                # g.trace('created:',fn,g.callers())
                g.es('created:',fn)
        return True
    except IOError:
        at.error('unexpected exception writing file: %s' % (fn))
        g.es_exception()
        return False
#@+node:ekr.20070115135502: *6* writeScriptFile
def writeScriptFile (self,script):

    # Get the path to the file.
    c = self
    path = c.config.getString('script_file_path')
    if path:
        isAbsPath = os.path.isabs(path)
        driveSpec, path = os.path.splitdrive(path)
        parts = path.split('/')
        # xxx bad idea, loadDir is often read only!
        path = g.app.loadDir
        if isAbsPath:
            # make the first element absolute
            parts[0] = driveSpec + os.sep + parts[0]
        allParts = [path] + parts
        path = c.os_path_finalize_join(*allParts)
    else:
        path = c.os_path_finalize_join(
            g.app.homeLeoDir,'scriptFile.py')                    

    # Write the file.
    try:
        if g.isPython3:
            # Use the default encoding.
            f = open(path,encoding='utf-8',mode='w')
        else:
            f = open(path,'w')
        f.write(script)
        f.close()
    except Exception:
        g.es_exception()
        g.es("Failed to write script to %s" % path)
        # g.es("Check your configuration of script_file_path, currently %s" %
            # c.config.getString('script_file_path'))
        path = None

    return path
#@+node:ekr.20090502071837.94: *6* write (leoRst)
def write (self,s,theFile=None):

    if theFile is None:
        theFile = self.outputFile

    if g.isPython3:
        if g.is_binary_file(theFile):
            s = self.encode(s)
    else:
        s = self.encode(s)

    theFile.write(s)
#@+node:ekr.20090502071837.64: *6* writeSpecialTree
def writeSpecialTree (self,p,toString,justOneFile):

    c = self.c
    isHtml = self.ext in ('.html','.htm')
    if isHtml and not SilverCity:
        if not self.silverCityWarningGiven:
            self.silverCityWarningGiven = True
            g.es('SilverCity not present so no syntax highlighting')

    self.initWrite(p)
        # was encoding=g.choose(isHtml,'utf-8','iso-8859-1'))
    self.outputFile = StringIO()
    self.writeTree(p)
    self.source = self.outputFile.getvalue()
    self.outputFile = None

    if not toString:
        # Compute this here for use by intermediate file.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)

        # Create the directory if it doesn't exist.
        theDir, junk = g.os_path_split(self.outputFileName)
        theDir = c.os_path_finalize(theDir)
        if not g.os_path_exists(theDir):
            ok = g.makeAllNonExistentDirectories(theDir,c=c,force=False)
            if not ok:
                g.es_print('did not create:',theDir,color='red')
                return False

        if self.getOption('write_intermediate_file'):
            ext = self.getOption('write_intermediate_extension')
            name = self.outputFileName.rsplit('.',1)[0] + ext 
            if g.isPython3: # 2010/04/21
                f = open(name,'w',encoding=self.encoding)
            else:
                f = open(name,'w')
            f.write(self.source)
            f.close()
            self.report(name)

    try:
        output = self.writeToDocutils(self.source)
        ok = output is not None
    except Exception:
        g.pr('Exception in docutils')
        g.es_exception()
        ok = False

    if ok:
        if isHtml:
            import re
            idxTitle = output.find('<title></title>')
            if idxTitle > -1:
                m = re.search('<h1>([^<]*)</h1>', output)
                if not m:
                    m = re.search('<h1><[^>]+>([^<]*)</a></h1>', output)
                if m:
                    output = output.replace(
                        '<title></title>',
                        '<title>%s</title>' % m.group(1)
                    )


        if toString:
            self.stringOutput = output
        else:
            # Write the file to the directory containing the .leo file.
            f = open(self.outputFileName,'w')
            f.write(output)
            f.close()
            self.http_endTree(self.outputFileName, p, justOneFile=justOneFile)

    return ok
#@+node:ekr.20100203050306.5937: *6* c.createOpenWithTempFile
def createOpenWithTempFile (self,p,ext):

    trace = False and not g.unitTesting
    c = self ; f = None

    # May be over-ridden by mod_tempfname plugin.
    fn = c.openWithTempFilePath(p,ext)

    try:
        if g.os_path_exists(fn):
            g.es('recreating:  ',g.shortFileName(fn),color='red')
        else:
            g.es('creating:  ',g.shortFileName(fn),color='blue')
        f = open(fn,'w')
        # Convert s to whatever encoding is in effect.
        d = c.scanAllDirectives(p)
        encoding = d.get('encoding',None)
        if encoding == None:
            encoding = c.config.default_derived_file_encoding
        if g.isPython3: # 2010/02/09
            s = p.b
        else:
            s = g.toEncodedString(p.b,encoding,reportErrors=True) 
        f.write(s)
        f.flush()
        f.close()
        try:
            time = g.os_path_getmtime(fn)
            if time: g.es('time: ',time)
        except:
            time = None

        # Remove previous entry from app.openWithFiles if it exists.
        for d in g.app.openWithFiles[:]:
            if p.v == d.get('v'):
                if trace: g.trace('removing',d.get('path'))
                g.app.openWithFiles.remove(d)

        d = {
            # Used by app.destroyOpenWithFilesForFrame.
            'c':c,
            # Used here and by app.destroyOpenWithFileWithDict.
            'path':fn,
            # Used by c.testForConflicts.
            'body':s,
            'encoding':encoding,
            'time':time,
            # Used by the open_with plugin.
            'p':p.copy(),
            # Used by c.openWithHelper, and below.
            'v':p.v,
        }
        g.app.openWithFiles.append(d)
        return fn
    except:
        if f: f.close()
        g.es('exception creating temp file',color='red')
        g.es_exception()
        return None
#@+node:ekr.20031218072017.1982: *6* << attempt to create leoID.txt >>
for theDir in (homeLeoDir,globalConfigDir,loadDir):
    # N.B. We would use the _working_ directory if theDir is None!
    if theDir:
        try:
            fn = g.os_path_join(theDir,tag)
            f = open(fn,'w')
            f.write(g.app.leoID)
            f.close()
            if g.os_path_exists(fn):
                g.es_print('',tag,'created in',theDir,color='red')
                return
        except IOError:
            pass

        g.es('can not create',tag,'in',theDir,color='red')
#@+node:ekr.20041005105605.155: *6* << Write p's headline if it starts with @@ >>
s = p.h

if g.match(s,0,"@@"):
    s = s[2:]
    if s and len(s) > 0:
        s = g.toEncodedString(s,at.encoding,reportErrors=True) # 3/7/03
        at.outputFile.write(s)
#@+node:ekr.20041005105605.204: *6* os
def os (self,s):

    """Write a string to the output stream.

    All output produced by leoAtFile module goes here."""

    trace = False and not g.unitTesting
    at = self ; tag = self.underindentEscapeString
    f = at.outputFile

    if s and f:
        try:
            if s.startswith(tag):
                junk,s = self.parseUnderindentTag(s)
            # Bug fix: this must be done last.
            s = g.toEncodedString(s,at.encoding,reportErrors=True)
            if trace: g.trace(repr(s),g.callers(5))
            f.write(s)
        except Exception:
            at.exception("exception writing:" + s)
#@+node:ekr.20070915142635: *6* writeFileFromNode
def writeFileFromNode (self,event=None):

    # If node starts with @read-file-into-node, use the full path name in the headline.
    # Otherwise, prompt for a file name.

    c = self ; p = c.p
    c.endEditing()

    h = p.h.rstrip()
    s = p.b
    tag = '@read-file-into-node'

    if h.startswith(tag):
        fileName = h[len(tag):].strip()
    else:
        fileName = None

    if not fileName:
        filetypes = [("All files", "*"),("Python files","*.py"),("Leo files", "*.leo"),]
        fileName = g.app.gui.runSaveFileDialog(
            initialfile=None,
            title='Write File From Node',
            filetypes=filetypes,
            defaultextension=None)
    if fileName:
        try:
            theFile = open(fileName,'w')
            g.chdir(fileName)
        except IOError:
            theFile = None
        if theFile:
            if s.startswith('@nocolor\n'):
                s = s[len('@nocolor\n'):]
            theFile.write(s)
            theFile.flush()
            g.es_print('wrote:',fileName,color='blue')
            theFile.close()
        else:
            g.es('can not write %s',fileName,color='red')
#@+node:ekr.20050424131051: *6* writeRecentFilesFileHelper
def writeRecentFilesFileHelper (self,fileName):

    # g.trace(g.toUnicode(fileName))

    # Don't update the file if it begins with read-only.
    theFile = None
    try:
        theFile = open(fileName)
        lines = theFile.readlines()
        if lines and self.munge(lines[0])=='readonly':
            # g.trace('read-only: %s' %fileName)
            return False
    except IOError:
        # The user may have erased a file.  Not an error.
        if theFile: theFile.close()

    theFile = None
    try:
        if g.isPython3:
            theFile = open(fileName,encoding='utf-8',mode='w')
        else:
            theFile = open(fileName,mode='w')
        if self.recentFiles:
            s = '\n'.join(self.recentFiles)
        else:
            s = '\n'
        if not g.isPython3:
            s = g.toEncodedString(s,reportErrors=True)
        theFile.write(s)

    except IOError:
        if 1: # The user may have erased a file.  Not an error.
            g.es_print('error writing',fileName,color='red')
            g.es_exception()
            return False

    except Exception:
        g.es('unexpected exception writing',fileName,color='red')
        g.es_exception()
        if g.unitTesting: raise
        return False

    if theFile:
        theFile.close()
        return True
    else:
        return False
#@+node:ekr.20050920084036.24: *6* writeAbbreviations
def writeAbbreviations (self,event):

    '''Write abbreviations to a file.'''

    fileName = g.app.gui.runSaveFileDialog(
        initialfile = None,
        title='Write Abbreviations',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    if not fileName: return

    try:
        f = open(fileName,'w')
        for x in self.abbrevs:
            f.write('%s=%s\n' % (x,self.abbrevs[x]))
        f.close()
    except IOError:
        g.es('can not create',fileName)
#@+node:ekr.20050920084036.170: *6* saveFile
def saveFile (self,event):

    '''Prompt for the name of a file and put the body text of the selected node into it..'''

    w = self.editWidget(event)
    if not w: return

    fileName = g.app.gui.runSaveFileDialog(
        initialfile = None,
        title='save-file',
        filetypes = [("Text","*.txt"), ("All files","*")],
        defaultextension = ".txt")

    if not fileName: return

    try:
        s = w.getAllText()
        f = open(fileName,'w')
        f.write(s)
        f.close()
    except IOError:
        g.es('can not create',fileName)
#@+node:ekr.20051025071455.37: *6* add (spellTab)
def add(self,event=None):
    """Add the selected suggestion to the dictionary."""

    if not self.currentWord: return

    # g.trace(self.currentWord)

    try:
        f = None
        try:
            # Rewrite the dictionary in alphabetical order.
            f = open(self.dictionaryFileName, "r")
            words = f.readlines()
            f.close()
            words = [word.strip() for word in words]
            words.append(self.currentWord)
            words.sort()
            f = open(self.dictionaryFileName, "w")
            for word in words:
                f.write("%s\n" % g.toEncodedString(word,reportErrors=True))
            f.flush()
            f.close()
            if 1:
                s = 'Spell: added %s' % self.currentWord
                self.messages.append(s)
            else: # Too distracting.
                g.es("adding ", color= "blue", newline= False) 
                g.es('','%s' % self.currentWord)
        except IOError:
            g.es("can not add",self.currentWord,"to dictionary",color="red")
    finally:
        if f: f.close()

    self.dictionary[self.currentWord.lower()] = 0
    self.tab.onFindButton()
#@+node:ekr.20041012091252: *6* rawPrint
def rawPrint (self,s):

    if self.old:
        self.old.write(s+'\n')
    else:
        g.pr(s)
#@+node:ekr.20031218072017.1462: *6* exportHeadlines
def exportHeadlines (self,fileName):

    c = self.c ; nl = g.u(self.output_newline)
    p = c.p
    if not p: return
    self.setEncoding()
    firstLevel = p.level()
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return
    for p in p.self_and_subtree():
        head = p.moreHead(firstLevel,useVerticalBar=True)
        s = g.toEncodedString(head + nl,self.encoding,reportErrors=True)
        theFile.write(s)
    theFile.close()
#@+node:ekr.20031218072017.1147: *6* flattenOutline
def flattenOutline (self,fileName):

    c = self.c ; nl = g.u(self.output_newline)
    p = c.currentVnode()
    if not p: return
    self.setEncoding()
    firstLevel = p.level()

    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return

    for p in p.self_and_subtree():
        head = p.moreHead(firstLevel)
        s = g.toEncodedString(head + nl,encoding=self.encoding,reportErrors=True)
        theFile.write(s)
        body = p.moreBody() # Inserts escapes.
        if len(body) > 0:
            s = g.toEncodedString(body + nl,self.encoding,reportErrors=True)
            theFile.write(s)
    theFile.close()
#@+node:ekr.20031218072017.1148: *6* outlineToWeb
def outlineToWeb (self,fileName,webType):

    c = self.c ; nl = self.output_newline
    current = c.p
    if not current: return
    self.setEncoding()
    self.webType = webType
    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    try:
        theFile = open(fileName,mode)
    except IOError:
        g.es("can not open",fileName,color="blue")
        leoTest.fail()
        return

    self.treeType = "@file"
    # Set self.treeType to @root if p or an ancestor is an @root node.
    for p in current.parents():
        flag,junk = g.is_special(p.b,0,"@root")
        if flag:
            self.treeType = "@root"
            break
    for p in current.self_and_subtree():
        s = self.convertVnodeToWeb(p)
        if len(s) > 0:
            s = g.toEncodedString(s,self.encoding,reportErrors=True)
            theFile.write(s)
            if s[-1] != '\n': theFile.write(nl)
    theFile.close()
#@+node:ekr.20031218072017.1464: *6* weave
def weave (self,filename):

    c = self.c ; nl = self.output_newline
    p = c.p
    if not p: return
    self.setEncoding()
    << open filename to f, or return >>
    for p in p.self_and_subtree():
        s = p.b
        s2 = s.strip()
        if s2 and len(s2) > 0:
            f.write("-" * 60) ; f.write(nl)
            << write the context of p to f >>
            f.write("-" * 60) ; f.write(nl)
            s = g.toEncodedString(s,self.encoding,reportErrors=True)
            f.write(s.rstrip() + nl)
    f.flush()
    f.close()
#@+node:ekr.20031218072017.1150: *7* << open filename to f, or return >>
try:
    # 10/14/02: support for output_newline setting.
    mode = c.config.output_newline
    mode = g.choose(mode=="platform",'w','wb')
    f = open(filename,mode)
    if not f: return
except Exception:
    g.es("exception opening:",filename)
    g.es_exception()
    return
#@+node:ekr.20031218072017.1465: *7* << write the context of p to f >>
# write the headlines of p, p's parent and p's grandparent.
context = [] ; p2 = p.copy() ; i = 0
while i < 3:
    i += 1
    if not p2: break
    context.append(p2.h)
    p2.moveToParent()

context.reverse()
indent = ""
for line in context:
    f.write(indent)
    indent += '\t'
    line = g.toEncodedString(line,self.encoding,reportErrors=True)
    f.write(line)
    f.write(nl)
#@+node:ekr.20031218072017.1465: *6* << write the context of p to f >>
# write the headlines of p, p's parent and p's grandparent.
context = [] ; p2 = p.copy() ; i = 0
while i < 3:
    i += 1
    if not p2: break
    context.append(p2.h)
    p2.moveToParent()

context.reverse()
indent = ""
for line in context:
    f.write(indent)
    indent += '\t'
    line = g.toEncodedString(line,self.encoding,reportErrors=True)
    f.write(line)
    f.write(nl)
#@+node:ekr.20090502071837.61: *6* writeNormalTree
def writeNormalTree (self,p,toString=False):

    self.initWrite(p)

    # Always write to a string first.
    self.outputFile = StringIO()
    self.writeTree(p)
    self.source = self.stringOutput = self.outputFile.getvalue()

    # Copy to a file if requested.
    if not toString:
        # Comput the output file name *after* calling writeTree.
        self.outputFileName = self.computeOutputFileName(self.outputFileName)
        self.outputFile = open(self.outputFileName,'w')
        self.outputFile.write(self.stringOutput)
        self.outputFile.close()

    return True
#@+node:ekr.20080822065427.4: *6* show_error_lines
def show_error_lines (self,lines,fileName):

    for line in lines:
        g.es_print(line)

    if False: # Only for major debugging.
        try:
            f1 = open(fileName, "w")
            for line in lines:
                f1.write(g.toEncodedString(line))
            f1.close()
        except IOError:
            g.es_exception()
            g.es_print('can not open',fileName)
#@+node:ekr.20031218072017.1488: *6* oblank, oblanks, os, otab, otabs (Tangle)
def oblank (self):
    self.oblanks(1)

def oblanks (self,n):
    if abs(n) > 0:
        s = g.toEncodedString(' ' * abs(n),encoding=self.encoding)
        self.output_file.write(s)

def onl(self):
    s = self.output_newline
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    self.output_file.write(s)

def os (self,s):
    s = s.replace('\r','\n')
    s = g.toEncodedString(s,self.encoding,reportErrors=True)
    self.output_file.write(s)

def otab (self):
    self.otabs(1)

def otabs (self,n):
    if abs(n) > 0:
        s = g.toEncodedString('\t' * abs(n),self.encoding,reportErrors=True)
        self.output_file.write(s)
#@+node:ekr.20031218072017.3650: *6* show
def show (self,s):

    # g.pr(s)
    if self.outputFile:
        s = g.toEncodedString(s + '\n')
        self.outputFile.write(s)
    elif self.c:
        g.es(s)
    else:
        g.pr(s)
        g.pr('')
#@+node:ekr.20100202145902.6106: *4* Init all settings in c.initConfigSettings
@nocolor-node

To do:

- remove most of the logic in configSettings.__init__.
- Move config ivars to the commander.
#@+node:ekr.20100130042842.6404: *5* Reading settings (do not delete)
Here are the calls to g.app.getxxx

# runLeo.createFrame
fileName = g.app.config.getString(c=None,setting='default_leo_file')

# c.configSettings.initIvar
# Why not init these settings by hand???
val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

# g.es and g.es_print
keys['color'] = g.app.config.getColor(None,"log_error_color") or 'red'

# leoPlugins.loadHandlers
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')
s = g.app.config.getEnabledPlugins()

# leoPlugins.loadOnePlugin
verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

#@+node:ekr.20041120064303: *6* readSettingsFiles & helpers (g.app.config)
def readSettingsFiles (self,fileName,verbose=True):

    trace = False and not g.unitTesting
    seen = []
    self.write_recent_files_as_needed = False # Will be set later.
    << define localDirectory, localConfigFile & myLocalConfigFile >>

    if trace: g.trace(g.callers(5))
    table = (
        (self.globalConfigFile,False),
        (self.homeFile,False),
        (localConfigFile,False),
        (self.myGlobalConfigFile,False),
        (self.myHomeConfigFile,False),
        (self.machineConfigFile,False),
        (myLocalConfigFile,False),
        # New in Leo 4.6: the -c file is in *addition* to other config files.
        (g.app.oneConfigFilename,False),
        (fileName,True),
    )

    # Init settings from leoSettings.leo and myLeoSettings.leo files.
    for path,localFlag in table:
        if path:
            path = g.os_path_realpath(g.os_path_finalize(path))
            # Bug fix: 6/3/08: make sure we mark files seen no matter how they are specified.
        isZipped = path and zipfile.is_zipfile(path)
        isLeo = isZipped or (path and path.endswith('.leo'))
        if isLeo and path and path.lower() not in seen and g.os_path_exists(path):
            seen.append(path.lower())
            if verbose and not g.app.unitTesting and not self.silent and not g.app.batchMode:
                s = 'reading settings in %s' % path
                # This occurs early in startup, so use the following instead of g.es_print.
                if not g.isPython3:
                    s = g.toEncodedString(s,'ascii')
                g.es_print(s,color='blue')
            c = self.openSettingsFile(path)
            if c:
                self.updateSettings(c,localFlag)
                g.app.destroyWindow(c.frame)
                self.write_recent_files_as_needed = c.config.getBool(
                    'write_recent_files_as_needed')
                if 0:
                    # This is useless. setIvarsFromSettings does nothing
                    # until the self.inited flag is True.
                    g.trace('?' * 20,c)
                    self.setIvarsFromSettings(c)
    self.readRecentFiles(localConfigFile)
    # self.createMyLeoSettingsFile(myLocalConfigFile)
    self.inited = True
    self.setIvarsFromSettings(None)
#@+node:ekr.20061028082834: *7* << define localDirectory, localConfigFile & myLocalConfigFile >>
# This can't be done in initSettingsFiles because
# the local directory does not yet exist.
localDirectory = g.os_path_dirname(fileName)

#  Set the local leoSettings.leo file.
localConfigFile = g.os_path_join(localDirectory,'leoSettings.leo')
if not g.os_path_exists(localConfigFile):
    localConfigFile = None

# Set the local myLeoSetting.leo file.
myLocalConfigFile = g.os_path_join(localDirectory,'myLeoSettings.leo')
if not g.os_path_exists(myLocalConfigFile):
    myLocalConfigFile = None
#@+node:ekr.20041117085625: *7* openSettingsFile
def openSettingsFile (self,path):

    theFile,isZipped = g.openLeoOrZipFile(path)
    if not theFile: return None

    # Similar to g.openWithFileName except it uses a null gui.
    # Changing g.app.gui here is a major hack.
    oldGui = g.app.gui
    g.app.gui = leoGui.nullGui("nullGui")
    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=path,relativeFileName=None,
        initEditCommanders=False,updateRecentFiles=False)
    frame.log.enable(False)
    c.setLog()
    g.app.lockLog()
    ok = frame.c.fileCommands.open(
        theFile,path,readAtFileNodesFlag=False,silent=True) # closes theFile.
    g.app.unlockLog()
    c.openDirectory = frame.openDirectory = g.os_path_dirname(path)
    g.app.gui = oldGui
    return ok and c
#@+node:ekr.20051013161232: *7* updateSettings
def updateSettings (self,c,localFlag):

    d = self.readSettings(c,localFlag)

    if d:
        d['_hash'] = theHash = c.hash()
        if localFlag:
            self.localOptionsDict[theHash] = d
        else:
            self.localOptionsList.insert(0,d)

    if 0: # Good trace.
        if localFlag:
            g.trace(c.fileName())
            g.trace(d and list(d.keys()))
#@+node:ekr.20041118104831.2: *6* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118084146.1: *6* set (g.app.config) To be deleted??
def set (self,c,setting,kind,val):

    '''Set the setting.  Not called during initialization.'''

    trace = False and not g.unitTesting
    found = False ;  key = self.munge(setting)
    if trace: g.trace(setting,kind,val)

    if c:
        d = self.localOptionsDict.get(c.hash())
        if d: found = True

    if not found:
        theHash = c.hash()
        for d in self.localOptionsList:
            hash2 = d.get('_hash')
            if theHash == hash2:
                found = True ; break

    if not found:
        d = self.dictList [0]

    d[key] = g.Bunch(setting=setting,kind=kind,val=val,tag='setting')

    if 0:
        dkind = d.get('_hash','<no hash: %s>' % c.hash())
        g.trace(dkind,setting,kind,val)
#@+node:ekr.20041118104240: *6* initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@+node:ekr.20041228042224: *6* setIvarsFromSettings (g.app.config)
def setIvarsFromSettings (self,c):

    '''Init g.app.config ivars or c's ivars from settings.

    - Called from readSettingsFiles with c = None to init g.app.config ivars.
    - Called from c.__init__ to init corresponding commmander ivars.'''

    trace = False and not g.unitTesting
    verbose = True

    # Ingore temporary commanders created by readSettingsFiles.
    if self.inited:
        if trace:
            if c:
                g.trace('=' * 10, 'inited',c.shortFileName(),g.callers(4))
            else:
                tag = '<no c: called at end of readSettingsFiles>'
                g.trace('=' * 10, 'inited',tag,g.callers(1))
    else:
        if trace and verbose: g.trace('*' * 10,'not inited.  do nothing')
        return

    d = self.ivarsDict
    keys = list(d.keys())
    keys.sort()
    for key in keys:
        if key != '_hash':
            bunch = d.get(key)
            if bunch:
                ivar = bunch.ivar # The actual name of the ivar.
                kind = bunch.kind
                val = self.get(c,key,kind) # Don't use bunch.val!
                if c:
                    if trace: g.trace("%20s %s = %s" % (
                        g.shortFileName(c.mFileName),ivar,val))
                    setattr(c,ivar,val)
                else:
                    if trace: g.trace("%20s %s = %s" % (
                        'g.app.config',ivar,val))
                    setattr(self,ivar,val)
#@+node:ekr.20100130042842.9008: *5*  Notes
@nocolor-node

colorizeAnyLanguage.
    g.app.config.defaultFontFamily

c.scanAtPathDirectives:
    relative_path_base_directory:

** Methods that write recent files:
    recentFileMessageWritten (Probabaly ok)

c.configSettings.__init__:

** copies these ivars by hand.
    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize
** calls initIvar and initEncoding to copy other ivars.

g.makeAllNonExistentDirectories:
    # Uses one or the other, depending on the c arg.
    c.create_nonexistent_directories
    g.app.config.create_nonexistent_directories

g.getOutputNewline:
    # Uses one or the other, depending on the c arg.
    c.config.output_newline
    g.app.config.output_newline

g.doHook:
    g.app.config.use_plugins

loadOnePlugin:
    g.app.config.enabledPluginsFileName

leoGui.getFontFromParams:
    g.app.config.defaultFont

k.addModeCommands and several other methods use:
    g.app.config.modeCommandsDict
#@+node:ekr.20100130042842.9010: *6* at_root_bodies_start_in_doc_mode
@nocolor-node

at_root_bodies_start_in_doc_mode

c.scanAtRootDirectives
    should use c.config.getBool instead of the weird code.

g.scanAtRootOptions
    Why doesn't this use c.config ivars??
    Actually, this should be tangle.scanAtRootOptions.  We know c!

leoImport.convertVnodeToWeb:
    Uses c.config.at_root_bodies_start_in_doc_mode
#@+node:ekr.20080828103146.12: *7* c.scanAtRootDirectives
# Called only by scanColorDirectives.

def scanAtRootDirectives(self,aList):

    '''Scan aList for @root-code and @root-doc directives.'''

    c = self

    # To keep pylint happy.
    tag = 'at_root_bodies_start_in_doc_mode'
    start_in_doc = hasattr(c.config,tag) and getattr(c.config,tag)

    # New in Leo 4.6: dashes are valid in directive names.
    for d in aList:
        if 'root-code' in d:
            return 'code'
        elif 'root-doc' in d:
            return 'doc'
        elif 'root' in d:
            return g.choose(start_in_doc,'doc','code')

    return None
#@+node:ekr.20031218072017.3154: *7* g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    # g.trace(mode,g.callers(3))

    return i,mode
#@+node:ekr.20031218072017.3155: *8* << scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','\n','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@+node:ekr.20100131161507.6302: *6* Replace all of these by config.get methods
c.config.default_at_auto_file_encoding
c.config.default_derived_file_encoding
#@+node:ekr.20100202145902.6108: *6* code
#@+node:ekr.20031218072017.1880: *7* colorizeAnyLanguage & allies
def colorizeAnyLanguage (self,p,leading=None,trailing=None):

    """Color the body pane either incrementally or non-incrementally"""

    c = self.c ; w = c.frame.body.bodyCtrl

    if not c.config.getBool('use_syntax_coloring'):
        # There have been reports of this trace causing crashes.
        # Certainly it is not necessary.
        # g.trace('no coloring')
        return

    if self.killFlag:
        self.removeAllTags()
        return
    try:
        # g.trace('incremental',self.incremental)
        << initialize ivars & tags >>
        g.doHook("init-color-markup",colorer=self,p=self.p,v=self.p)
        if self.incremental and (
            << all state ivars match >> ):
            << incrementally color the text >>
        else:
            << non-incrementally color the text >>
        << update state ivars >>
        return "ok" # for testing.
    except:
        << set state ivars to "unknown" >>
        if self.c:
            g.es_exception()
        else:
            import traceback ; traceback.print_exc()
        return "error" # for unit testing.
#@+node:ekr.20031218072017.1602: *8* << initialize ivars & tags >> colorizeAnyLanguage
# Copy the arguments.
self.p = p

# Get the body text, converted to unicode.
self.allBodyText = w.getAllText()
sel = w.getInsertPoint()
start,end = g.convertPythonIndexToRowCol(self.allBodyText,sel)
start += 1 # Simulate the old 1-based Tk scheme.  self.index undoes this hack.
# g.trace('new',start,end)

if self.language: self.language = self.language.lower()
# g.trace(self.count,self.p)
# g.trace(body.tag_names())

if not self.incremental:
    self.removeAllTags()
    # self.removeAllImages()

<< configure fonts >>
<< configure tags >>
<< configure language-specific settings >>

self.hyperCount = 0 # Number of hypertext tags
self.count += 1
lines = self.allBodyText.split('\n')
#@+node:ekr.20060829084924: *9* << configure fonts >> (revise,maybe)
# Get the default body font.
defaultBodyfont = self.fonts.get('default_body_font')
if not defaultBodyfont:
    defaultBodyfont = c.config.getFontFromParams(
        "body_text_font_family", "body_text_font_size",
        "body_text_font_slant",  "body_text_font_weight",
        c.config.defaultBodyFontSize)
    self.fonts['default_body_font'] = defaultBodyfont

# Configure fonts.
w = c.frame.body.bodyCtrl
keys = sorted(default_font_dict)
for key in keys:
    option_name = default_font_dict[key]
    # First, look for the language-specific setting, then the general setting.
    for name in ('%s_%s' % (self.language,option_name),(option_name)):
        font = self.fonts.get(name)
        if font:
            # g.trace('found',name,id(font))
            w.tag_config(key,font=font)
            break
        else:
            family = c.config.get(name + '_family','family')
            size   = c.config.get(name + '_size',  'size')   
            slant  = c.config.get(name + '_slant', 'slant')
            weight = c.config.get(name + '_weight','weight')
            if family or slant or weight or size:
                family = family or g.app.config.defaultFontFamily
                size   = size or str(c.config.defaultBodyFontSize)
                slant  = slant or 'roman'
                weight = weight or 'normal'
                font = c.config.getFontFromParams(family,size,slant,weight)
                # Save a reference to the font so it 'sticks'.
                self.fonts[name] = font 
                # g.trace(key,name,family,size,slant,weight,id(font))
                w.tag_config(key,font=font)
                break
    else: # Neither the general setting nor the language-specific setting exists.
        if len(list(self.fonts.keys())) > 1: # Restore the default font.
            # g.trace('default',key)
            w.tag_config(key,font=defaultBodyfont)
#@+node:ekr.20031218072017.1603: *9* << configure tags >>
# g.trace('configure tags',self.c.frame.body.bodyCtrl)

for name in default_colors_dict:
    option_name,default_color = default_colors_dict[name]
    option_color = c.config.getColor(option_name)
    color = g.choose(option_color,option_color,default_color)
    # g.trace(name,color)
    # Must use foreground, not fg.
    try:
        c.frame.body.tag_configure(name, foreground=color)
    except: # Recover after a user error.
        c.frame.body.tag_configure(name, foreground=default_color)

underline_undefined = c.config.getBool("underline_undefined_section_names")
use_hyperlinks      = c.config.getBool("use_hyperlinks")
self.use_hyperlinks = use_hyperlinks

# underline=var doesn't seem to work.
if 0: # use_hyperlinks: # Use the same coloring, even when hyperlinks are in effect.
    c.frame.body.tag_configure("link",underline=1) # defined
    c.frame.body.tag_configure("name",underline=0) # undefined
else:
    c.frame.body.tag_configure("link",underline=0)
    if underline_undefined:
        c.frame.body.tag_configure("name",underline=1)
    else:
        c.frame.body.tag_configure("name",underline=0)

# 8/4/02: we only create tags for whitespace when showing invisibles.
if self.showInvisibles:
    for name,option_name,default_color in (
        ("blank","show_invisibles_space_background_color","Gray90"),
        ("tab",  "show_invisibles_tab_background_color",  "Gray80")):
        option_color = c.config.getColor(option_name)
        color = g.choose(option_color,option_color,default_color)
        try:
            c.frame.body.tag_configure(name,background=color)
        except: # Recover after a user error.
            c.frame.body.tag_configure(name,background=default_color)

# 11/15/02: Colors for latex characters.  Should be user options...

if 1: # Alas, the selection doesn't show if a background color is specified.
    c.frame.body.tag_configure("latexModeBackground",foreground="black")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue")
    c.frame.body.tag_configure("latexBackground",foreground="black")
    c.frame.body.tag_configure("latexKeyword",foreground="blue")
else: # Looks cool, and good for debugging.
    c.frame.body.tag_configure("latexModeBackground",foreground="black",background="seashell1")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue",background="seashell1")
    c.frame.body.tag_configure("latexBackground",foreground="black",background="white")
    c.frame.body.tag_configure("latexKeyword",foreground="blue",background="white")

# Tags for wiki coloring.
if self.showInvisibles:
    c.frame.body.tag_configure("elide",background="yellow")
else:
    c.frame.body.tag_configure("elide",elide="1")
c.frame.body.tag_configure("bold",font=self.bold_font)
c.frame.body.tag_configure("italic",font=self.italic_font)
c.frame.body.tag_configure("bolditalic",font=self.bolditalic_font)
for name in self.color_tags_list:
    c.frame.body.tag_configure(name,foreground=name)
#@+node:ekr.20031218072017.370: *9* << configure language-specific settings >> colorizer
# Define has_string, keywords, single_comment_start, block_comment_start, block_comment_end.

if self.language == "cweb": # Use C comments, not cweb sentinel comments.
    delim1,delim2,delim3 = g.set_delims_from_language("c")
elif self.comment_string:
    delim1,delim2,delim3 = g.set_delims_from_string(self.comment_string)
elif self.language == "plain": # 1/30/03
    delim1,delim2,delim3 = None,None,None
else:
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)

self.single_comment_start = delim1
self.block_comment_start = delim2
self.block_comment_end = delim3

# A strong case can be made for making this code as fast as possible.
# Whether this is compatible with general language descriptions remains to be seen.
self.case_sensitiveLanguage = self.language not in case_insensitiveLanguages
self.has_string = self.language != "plain"
if self.language == "plain":
    self.string_delims = ()
elif self.language in ("elisp","html"):
    self.string_delims = ('"')
else:
    self.string_delims = ("'",'"')
self.has_pp_directives = self.language in ("c","csharp","cweb","latex")

# The list of languages for which keywords exist.
# Eventually we might just use language_delims_dict.keys()
languages = [
    "actionscript","ada","c","csharp","css","cweb","elisp","html","java","latex","lua",
    "pascal","perl","perlpod","php","plsql","python","rapidq","rebol","ruby","shell","tcltk"]

self.keywords = []
if self.language == "cweb":
    for i in self.c_keywords:
        self.keywords.append(i)
    for i in self.cweb_keywords:
        self.keywords.append(i)
else:
    for name in languages:
        if self.language==name: 
            # g.trace("setting keywords for",name)
            self.keywords = getattr(self, name + "_keywords")

# Color plain text unless we are under the control of @nocolor.
# state = g.choose(self.flag,"normal","nocolor")
state = self.setFirstLineState()

if 1: # 10/25/02: we color both kinds of references in cweb mode.
    self.lb = "<<"
    self.rb = ">>"
else:
    self.lb = g.choose(self.language == "cweb","@<","<<")
    self.rb = g.choose(self.language == "cweb","@>",">>")
#@+node:ekr.20031218072017.1881: *8* << all state ivars match >>
self.flag == self.last_flag and
self.last_language == self.language
#@+node:ekr.20031218072017.1882: *8* << incrementally color the text >>
@ Each line has a starting state. The starting state for the first line
is always "normal".

We need remember only self.lines and self.states between colorizing.
It is not necessary to know where the text comes from, only what the
previous text was! We must always colorize everything when changing
nodes, even if all lines match, because the context may be different.

We compute the range of lines to be recolored by comparing leading
lines and trailing lines of old and new text. All other lines (the
middle lines) must be colorized, as well as any trailing lines whose
states may have changed as the result of changes to the middle lines.
@c

if self.trace: g.trace("incremental",self.language)

# 6/30/03: make a copies of everything
old_lines = self.lines[:]
old_states = self.states[:]
new_lines = lines[:]
new_states = []

new_len = len(new_lines)
old_len = len(old_lines)

if new_len == 0:
    self.states = []
    self.lines = []
    return

# Bug fix: 11/21/02: must test against None.
if leading != None and trailing != None:
    # g.pr("leading,trailing:",leading,trailing)
    leading_lines = leading
    trailing_lines = trailing
else:
    << compute leading, middle & trailing lines >>

middle_lines = new_len - leading_lines - trailing_lines
# g.pr("middle lines", middle_lines)

<< clear leading_lines if middle lines involve @color or @recolor  >>
<< initialize new states >>
<< colorize until the states match >>
#@+node:ekr.20031218072017.1883: *9* << compute leading, middle & trailing  lines >>
@ The leading lines are the leading matching lines. The trailing lines
are the trailing matching lines. The middle lines are all other new
lines. We will color at least all the middle lines. There may be no
middle lines if we delete lines.
@c

min_len = min(old_len,new_len)

i = 0
while i < min_len:
    if old_lines[i] != new_lines[i]:
        break
    i += 1
leading_lines = i

if leading_lines == new_len:
    # All lines match, and we must color _everything_.
    # (several routine delete, then insert the text again,
    # deleting all tags in the process).
    # g.pr("recolor all")
    leading_lines = trailing_lines = 0
else:
    i = 0
    while i < min_len - leading_lines:
        if old_lines[old_len-i-1] != new_lines[new_len-i-1]:
            break
        i += 1
    trailing_lines = i
#@+node:ekr.20031218072017.1884: *9* << clear leading_lines if middle lines involve @color or @recolor  >>
@ 11/19/02: Changing @color or @nocolor directives requires we recolor
all leading states as well.
@c

if trailing_lines == 0:
    m1 = new_lines[leading_lines:]
    m2 = old_lines[leading_lines:]
else:
    m1 = new_lines[leading_lines:-trailing_lines]
    m2 = old_lines[leading_lines:-trailing_lines]
m1.extend(m2) # m1 now contains all old and new middle lines.
if m1:
    for s in m1:
        ### s = g.toUnicode(s)
        i = g.skip_ws(s,0)
        if g.match_word(s,i,"@color") or g.match_word(s,i,"@nocolor"):
            leading_lines = 0
            break
#@+node:ekr.20031218072017.1885: *9* << initialize new states >>
# Copy the leading states from the old to the new lines.
i = 0
while i < leading_lines and i < old_len: # 12/8/02
    new_states.append(old_states[i])
    i += 1

# We know the starting state of the first middle line!
if middle_lines > 0 and i < old_len:
    new_states.append(old_states[i])
    i += 1

# Set the state of all other middle lines to "unknown".
first_trailing_line = max(0,new_len - trailing_lines)
while i < first_trailing_line:
    new_states.append("unknown")
    i += 1

# Copy the trailing states from the old to the new lines.
i = max(0,old_len - trailing_lines)
while i < old_len and i < len(old_states):
    new_states.append(old_states[i])
    i += 1

# 1/8/03: complete new_states by brute force.
while len(new_states) < new_len:
    new_states.append("unknown")
#@+node:ekr.20031218072017.1886: *9* << colorize until the states match >>
# Colorize until the states match.
# All middle lines have "unknown" state, so they will all be colored.

# Start in the state _after_ the last leading line, which may be unknown.
i = leading_lines
while i > 0:
    if i < old_len and i < new_len:
        state = new_states[i]
        # assert(state!="unknown") # This can fail.
        break
    else:
        i -= 1

if i == 0:
    # Color plain text unless we are under the control of @nocolor.
    # state = g.choose(self.flag,"normal","nocolor")
    state = self.setFirstLineState()
    new_states[0] = state

# The new_states[] will be "unknown" unless the lines match,
# so we do not need to compare lines here.
while i < new_len:
    self.line_index = i + 1
    state = self.colorizeLine(new_lines[i],state)
    i += 1
    # Set the state of the _next_ line.
    if i < new_len and state != new_states[i]:
        new_states[i] = state
    else: break

# Update the ivars
self.states = new_states
self.lines = new_lines
#@+node:ekr.20031218072017.1887: *8* << non-incrementally color the text >>
if self.trace: g.trace("non-incremental",self.language)

self.line_index = 1 # The Tk line number for indices, as in n.i
for s in lines:
    state = self.colorizeLine(s,state)
    self.line_index += 1
#@+node:ekr.20031218072017.1888: *8* << update state ivars >>
self.last_flag = self.flag
self.last_language = self.language
#@+node:ekr.20031218072017.1889: *8* << set state ivars to "unknown" >>
self.last_flag = "unknown"
self.last_language = "unknown"
#@+node:ekr.20080828103146.15: *7* c.scanAtPathDirectives
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@+node:ekr.20041118104831.2: *7* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20031218072017.3119: *7* g.makeAllNonExistentDirectories
# This is a generalization of os.makedir.

def makeAllNonExistentDirectories (theDir,c=None,force=False,verbose=True):

    """Attempt to make all non-existent directories"""

    trace = False and not g.unitTesting
    testing = False # True: don't actually make the directories.

    if force:
        create = True # Bug fix: g.app.config will not exist during startup.
    elif c:
        create = c.config and c.config.create_nonexistent_directories
    else:
        create = (g.app and g.app.config and
            g.app.config.create_nonexistent_directories)

    if c: theDir = g.os_path_expandExpression(theDir,c=c)

    dir1 = theDir = g.os_path_normpath(theDir)

    ok = g.os_path_isdir(dir1) and g.os_path_exists(dir1)
    if ok:
        return ok
    elif not force and not create:
        if trace:
            g.trace('did not create: force and create are both false')
        return ok

    if trace:
        g.trace('\n',theDir,'\n',g.callers(4))
        # g.trace('c exists: %s force: %s create: %s dir: %s' % (
            # c is not None,force,create,theDir))

    # Split theDir into all its component parts.
    paths = []
    while len(theDir) > 0:
        head,tail=g.os_path_split(theDir)
        if len(tail) == 0:
            paths.append(head)
            break
        else:
            paths.append(tail)
            theDir = head
    path = ""
    paths.reverse()
    if trace: g.trace('paths:',paths)
    for s in paths:
        path = g.os_path_join(path,s)
        if not g.os_path_exists(path):
            try:
                if testing:
                    g.trace('***making',path)
                else:
                    os.mkdir(path)
                if verbose and not testing and not g.app.unitTesting:
                    # g.trace('***callers***',g.callers(5))
                    g.es_print("created directory:",path,color='red')
            except Exception:
                # g.trace(g.callers())
                if verbose: g.es_print("exception creating directory:",path,color='red')
                g.es_exception()
                return None
    return dir1 # All have been created.
#@+node:ekr.20031218072017.1386: *7* g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@+node:ekr.20031218072017.1596: *7* g.doHook
@ This global function calls a hook routine.  Hooks are identified by the tag param.
Returns the value returned by the hook routine, or None if the there is an exception.

We look for a hook routine in three places:
1. c.hookFunction
2. app.hookFunction
3. leoPlugins.doPlugins()
We set app.hookError on all exceptions.  Scripts may reset app.hookError to try again.
@c

def doHook(tag,*args,**keywords):

    trace = False ; verbose = False

    if g.app.killed or g.app.hookError: # or (g.app.gui and g.app.gui.isNullGui):
        return None

    if args:
        # A minor error in Leo's core.
        g.pr("***ignoring args param.  tag = %s" % tag)

    if not g.app.config.use_plugins:
        if tag in ('open0','start1'):
            s = "Plugins disabled: use_plugins is 0 in a leoSettings.leo file."
            g.es_print(s,color="blue")
        return None

    # Get the hook handler function.  Usually this is doPlugins.
    c = keywords.get("c")
    f = (c and c.hookFunction) or g.app.hookFunction

    if trace and (verbose or tag != 'idle'):
        g.trace('tag',tag,'f',f and f.__name__)

    if not f:
        import leo.core.leoPlugins as leoPlugins
        g.app.hookFunction = f = leoPlugins.doPlugins

    try:
        # Pass the hook to the hook handler.
        # g.pr('doHook',f.__name__,keywords.get('c'))
        return f(tag,keywords)
    except Exception:
        g.es_exception()
        g.app.hookError = True # Supress this function.
        g.app.idleTimeHook = False # Supress idle-time hook
        return None # No return value
#@+node:ekr.20041113113140: *7* loadOnePlugin
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.endswith('.py'):
        moduleName = 'leo.plugins.' + moduleOrFileName [:-3]
    else:
        moduleName = moduleOrFileName
    #moduleName = g.shortFileName(moduleName)

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    #plugins_path = g.os_path_finalize_join(g.app.loadDir,"..","plugins")
    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)
    #result = g.importFromPath(moduleName,plugins_path,pluginName=moduleName,verbose=True)
    #print "imp", moduleName
    try:
        toplevel = __import__(moduleName)
        # need to look up through sys.modules, __import__ returns toplevel package
        result = sys.modules[moduleName]

    except Exception as e:
        g.es_print('exception importing plugin ' + moduleName,color='red')
        g.es_exception()
        result = None

    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@+node:ekr.20061031131434.100: *7* addModeCommands (enterModeCallback)
def addModeCommands (self):

    '''Add commands created by @mode settings to c.commandsDict and k.inverseCommandsDict.'''

    k = self ; c = k.c
    d = g.app.config.modeCommandsDict # Keys are command names: enter-x-mode.

    # Create the callback functions and update c.commandsDict and k.inverseCommandsDict.
    for key in d:

        def enterModeCallback (event=None,name=key):
            k.enterNamedMode(event,name)

        c.commandsDict[key] = f = enterModeCallback
        k.inverseCommandsDict [f.__name__] = key
        # g.trace('leoCommands %24s = %s' % (f.__name__,key))
#@+node:ekr.20041118104831.1: *5* class configSettings (leoCommands)
class configSettings:

    """A class to hold config settings for commanders."""

    @others
#@+node:ekr.20041118104831.2: *6* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118104240: *6* initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@+node:ekr.20041118104414: *6* initEncoding
def initEncoding (self,key):

    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.encodingIvarsDict.get(key)
    encodingName = bunch.ivar
    encoding = g.app.config.get(c,encodingName,kind='string')

    # New in 4.4b3: use the global setting as a last resort.
    if encoding:
        # g.trace('c.configSettings',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)
    else:
        encoding = getattr(g.app.config,encodingName)
        # g.trace('g.app.config',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)

    if encoding and not g.isValidEncoding(encoding):
        g.es("bad", "%s: %s" % (encodingName,encoding))
#@+node:ekr.20041118053731: *6* Getters (c.configSettings)
def get (self,setting,theType):
    '''A helper function: return the commander's setting, checking the type.'''
    return g.app.config.get(self.c,setting,theType)

def getAbbrevDict (self):
    '''return the commander's abbreviation dictionary.'''
    return g.app.config.getAbbrevDict(self.c)

def getBool (self,setting,default=None):
    '''Return the value of @bool setting, or the default if the setting is not found.'''
    return g.app.config.getBool(self.c,setting,default=default)

def getButtons (self):
    '''Return a list of tuples (x,y) for common @button nodes.'''
    return g.app.config.atCommonButtonsList # unusual.

def getColor (self,setting):
    '''Return the value of @color setting.'''
    return g.app.config.getColor(self.c,setting)

def getCommands (self):
    '''Return the list of tuples (headline,script) for common @command nodes.'''
    return g.app.config.atCommonCommandsList # unusual.

def getData (self,setting):
    '''Return a list of non-comment strings in the body text of @data setting.'''
    return g.app.config.getData(self.c,setting)

def getDirectory (self,setting):
    '''Return the value of @directory setting, or None if the directory does not exist.'''
    return g.app.config.getDirectory(self.c,setting)

def getFloat (self,setting):
    '''Return the value of @float setting.'''
    return g.app.config.getFloat(self.c,setting)

def getFontFromParams (self,family,size,slant,weight,defaultSize=12):

    '''Compute a font from font parameters.

    Arguments are the names of settings to be use.
    Default to size=12, slant="roman", weight="normal".

    Return None if there is no family setting so we can use system default fonts.'''

    return g.app.config.getFontFromParams(self.c,
        family, size, slant, weight, defaultSize = defaultSize)

def getInt (self,setting):
    '''Return the value of @int setting.'''
    return g.app.config.getInt(self.c,setting)

def getLanguage (self,setting):
    '''Return the value of @string setting.

    The value of this setting should be a language known to Leo.'''
    return g.app.config.getLanguage(self.c,setting)

def getMenusList (self):
    '''Return the list of entries for the @menus tree.'''
    return g.app.config.getMenusList(self.c) # Changed in Leo 4.5.

def getOpenWith (self):
    '''Return a list of dictionaries corresponding to @openwith nodes.'''
    return g.app.config.getOpenWith(self.c)

def getRatio (self,setting):
    '''Return the value of @float setting.
    Warn if the value is less than 0.0 or greater than 1.0.'''
    return g.app.config.getRatio(self.c,setting)

def getRecentFiles (self):
    '''Return the list of recently opened files.'''
    return g.app.config.getRecentFiles()

def getShortcut (self,shortcutName):
    '''Return the tuple (rawKey,accel) for shortcutName in @shortcuts tree.'''
    return g.app.config.getShortcut(self.c,shortcutName)

def getSettingSource(self,setting):
    '''return the name of the file responsible for setting.'''
    return g.app.config.getSettingSource(self.c,setting)

def getString (self,setting):
    '''Return the value of @string setting.'''
    return g.app.config.getString(self.c,setting)
#@+node:ekr.20041118195812: *6* Setters... (c.configSettings)
def setRecentFiles (self,files):
    '''Update the recent files list.'''
    # Append the files to the global list.
    g.app.config.appendToRecentFiles(files)
#@+node:ekr.20100219083854.5615: *4* Improve caching
#@+node:ekr.20100209160132.5770: *5* cache notes
@nocolor-node

Top-level folder are direct subfolders of .leo/db.
Top-level folders represent file *locations* not file contents.
Exception: the top-level "globals" folder represents minor data.

Only two files are ever needed in a top-level folder:

contents_<key>: the contents of the file.
data_<key>: a dict representing the "minor data" of the file:
    <globals> element stuff, expansion bits, etc.

We write contents_<key> only once.
By definition, its contents never changes, since the contents generates the key.
We can write data_<key> as many times as we like.

To do:
- Simplify or even eliminate the path-manipulation code in PickleShareDB.
- Use g.makeAllNonExistentDirectories to make top-level directories.
- Clear cache should clear all top-level directories.
#@+node:ekr.20100209114432.5751: *6* Cache expansion bits
# Simplify the structure of the cache: put more into the "minor" files.
#@+node:ekr.20100211095442.6201: *5* cache notes 2
@nocolor-node

1. Memory does leak, and that's not ok with me.  And I want just two
files per top-level directory.

2. Strange things can happen with caching, as just happened to me when
I restored qtui_generate.py mistakenly deleted from leo/test.  There
is an @auto node for this file in qtGui.py, and I got improper 'can
not open' messages for this file.

3. It is troubling that the present caching scheme does not use the
full path to a file, only the basename.  This means that two identical
files in two different places will use the same cache entries.  I've
been wondering for the last several days about whether this could
cause problems.  I don't know for sure, but I am uncomfortable.

4. I want the clear-cache and clear-all-caches commands to do what
they say: get rid of everything.  Among other things, this is good for
debugging and recovering from cache problems.

#@+node:ekr.20100223075705.5635: *5* Don't write expansion bits
#@+node:ekr.20100210163813.5748: *5* Caching buglets?
@nocolor-node

This is a recent bug, but imo it has uncovered some other caching buglets. These
buglets are not big enough to delay Leo 4.7, but the new caching scheme would
ensure they never bite.

1. The code that computes what I have been calling the top-level directory is dubious::

    dbdirname = join(g.app.homeLeoDir,'db',
            '%s_%s' % (bname,hashlib.md5(fn).hexdigest()))

The problem is that bname is only the base name of the cached file, not a name
(or key) that depends on the full path. Thus, two copies of the same file in the
same place will be cached in the same directory. Is this ominous?

2. It's not clear what caching to do with the save-to command.
#@+node:ekr.20100225102636.5627: *5* Use the string returned by cacher
# It should be possible to avoid duplicate reads.
#@+node:ekr.20100206074650.5844: *3* Cleanups & features: next
#@+node:ekr.20100223123910.5835: *4* Improve python importer
#@+node:ekr.20070703122141.65: *5* << class baseScannerClass >>
class baseScannerClass (scanUtility):

    '''The base class for all import scanner classes.
    This class contains common utility methods.'''

    @others
#@+node:ekr.20070703122141.66: *6* baseScannerClass.__init__
def __init__ (self,importCommands,atAuto,language):

    ic = importCommands

    self.atAuto = atAuto
    self.c = c = ic.c

    self.atAutoWarnsAboutLeadingWhitespace = c.config.getBool('at_auto_warns_about_leading_whitespace')
    self.classId = None # The identifier containing the class tag: 'class', 'interface', 'namespace', etc.
    self.codeEnd = None
        # The character after the last character of the class, method or function.
        # An error will be given if this is not a newline.
    self.encoding = ic.encoding
    self.errors = 0
    ic.errors = 0
    self.errorLines = []
    self.escapeSectionRefs = True
    self.extraIdChars = ''
    self.fileName = ic.fileName # The original filename.
    self.fileType = ic.fileType # The extension,  '.py', '.c', etc.
    self.file_s = '' # The complete text to be parsed.
    self.fullChecks = c.config.getBool('full_import_checks')
    self.functionSpelling = 'function' # for error message.
    self.importCommands = ic
    self.indentRefFlag = None # None, True or False.
    self.isRst = False
    self.language = language
    self.lastParent = None # The last generated parent node (used only by rstScanner).
    self.methodName = ic.methodName # x, as in < < x methods > > =
    self.methodsSeen = False
    self.mismatchWarningGiven = False
    self.output_newline = ic.output_newline # = c.config.getBool('output_newline')
    self.output_indent = 0 # The minimum indentation presently in effect.
    self.root = None # The top-level node of the generated tree.
    self.rootLine = ic.rootLine # '' or @root + self.fileName
    self.sigEnd = None # The index of the end of the signature.
    self.sigId = None # The identifier contained in the signature, i.e., the function or method name.
    self.sigStart = None
        # The start of the line containing the signature.
        # An error will be given if something other than whitespace precedes the signature.
    self.startSigIndent = None
    self.tab_width = None # Set in run: the tab width in effect in the c.currentPosition.
    self.tab_ws = '' # Set in run: the whitespace equivalent to one tab.
    self.trace = False or ic.trace # = c.config.getBool('trace_import')
    self.treeType = ic.treeType # '@root' or '@file'
    self.webType = ic.webType # 'cweb' or 'noweb'

    # Compute language ivars.
    delim1,junk,junk = g.set_delims_from_language(language)
    self.comment_delim = delim1

    # May be overridden in subclasses.
    self.anonymousClasses = [] # For Delphi Pascal interfaces.
    self.blockCommentDelim1 = None
    self.blockCommentDelim2 = None
    self.blockCommentDelim1_2 = None
    self.blockCommentDelim2_2 = None
    self.blockDelim1 = '{'
    self.blockDelim2 = '}'
    self.blockDelim2Cruft = [] # Stuff that can follow .blockDelim2.
    self.classTags = ['class',] # tags that start a tag.
    self.functionTags = []
    self.hasClasses = True
    self.hasFunctions = True
    self.lineCommentDelim = None
    self.lineCommentDelim2 = None
    self.outerBlockDelim1 = None
    self.outerBlockDelim2 = None
    self.outerBlockEndsDecls = True
    self.sigHeadExtraTokens = [] # Extra tokens valid in head of signature.
    self.sigFailTokens = []
        # A list of strings that abort a signature when seen in a tail.
        # For example, ';' and '=' in C.

    self.strict = False # True if leading whitespace is very significant.
#@+node:ekr.20070808115837: *6* Checking
#@+node:ekr.20070703122141.102: *7* check
def check (self,unused_s,unused_parent):

    '''Make sure the generated nodes are equivalent to the original file.

    1. Regularize and check leading whitespace.
    2. Check that a trial write produces the original file.

    Return True if the nodes are equivalent to the original file.
    '''

    if self.fullChecks and self.treeType == '@file':
        return self.checkTrialWrite()
    else:
        return True
#@+node:ekr.20070703122141.104: *7* checkTrialWrite (baseScannerClass)
def checkTrialWrite (self,s1=None,s2=None):

    '''Return True if a trial write produces the original file.'''

    # s1 and s2 are for unit testing.
    c = self.c ; at = c.atFileCommands
    if s1 is None and s2 is None:
        if self.isRst:
            outputFile = StringIO()
            c.rstCommands.writeAtAutoFile(self.root,self.fileName,outputFile,trialWrite=True)
            s1,s2 = self.file_s,outputFile.getvalue()
        else:
            at.write(self.root,
                nosentinels=True,thinFile=False,
                scriptWrite=False,toString=True)
            s1,s2 = self.file_s, at.stringOutput

    s1 = g.toUnicode(s1,self.encoding)
    s2 = g.toUnicode(s2,self.encoding)

    # Make sure we have a trailing newline in both strings.
    s1 = s1.replace('\r','')
    s2 = s2.replace('\r','')
    if not s1.endswith('\n'): s1 = s1 + '\n'
    if not s2.endswith('\n'): s2 = s2 + '\n'

    if s1 == s2: return True

    lines1 = g.splitLines(s1)
    lines2 = g.splitLines(s2)

    if self.isRst:
        lines1 = self.adjustRstLines(lines1)
        lines2 = self.adjustRstLines(lines2)

    n1,n2 = len(lines1), len(lines2)
    ok = True ; bad_i = 0
    for i in range(max(n1,n2)):
        ok = self.compareHelper(lines1,lines2,i,self.strict)
        if not ok:
            bad_i = i
            break

    if g.app.unitTesting:
        d = g.app.unitTestDict
        # g.trace('expected',d.get('expectedMismatchLine'),'actual',d.get('actualMismatchLine'))
        ok = d.get('expectedMismatchLine') == d.get('actualMismatchLine')
        # Unit tests do not generate errors unless the mismatch line does not match.
        if not ok: d['fail'] = g.callers() # 2008/10/3

    if not ok:
        self.reportMismatch(lines1,lines2,bad_i)

    return ok
#@+node:ekr.20070730093735: *7* compareHelper & helpers
def compareHelper (self,lines1,lines2,i,strict):

    '''Compare lines1[i] and lines2[i].
    strict is True if leading whitespace is very significant.'''



    def pr(*args,**keys): #compareHelper
        g.es_print(color='blue',*args,**keys)

    def pr_mismatch(i,line1,line2):
        g.es_print('first mismatched line at line',str(i+1))
        g.es_print('original line: ',line1)
        g.es_print('generated line:',line2)

    d = g.app.unitTestDict
    expectedMismatch = g.app.unitTesting and d.get('expectedMismatchLine')
    enableWarning = not self.mismatchWarningGiven and self.atAutoWarnsAboutLeadingWhitespace
    messageKind = None

    if i >= len(lines1):
        if i != expectedMismatch or not g.unitTesting:
            pr('extra lines')
            for line in lines2[i:]:
                pr(repr(line))
        d ['actualMismatchLine'] = i
        return False

    if i >= len(lines2):
        if i != expectedMismatch or not g.unitTesting:
            g.es_print('missing lines')
            for line in lines2[i:]:
                g.es_print('',repr(line))
        d ['actualMismatchLine'] = i
        return False

    line1,line2 = lines1[i],lines2[i]

    if line1 == line2:
        return True # An exact match.
    elif not line1.strip() and not line2.strip():
        return True # Blank lines compare equal.
    elif self.isRst and self.compareRstUnderlines(line1,line2):
        return True
    elif strict:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(
            s1 == s2 and self.startsComment(s1,0) and self.startsComment(s2,0),
            'comment','error')
    else:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(s1==s2,'warning','error')

    if g.unitTesting:
        d ['actualMismatchLine'] = i+1
        ok = i+1 == expectedMismatch
        if not ok:  pr_mismatch(i,line1,line2)
        return ok
    elif strict:
        if enableWarning:
            self.mismatchWarningGiven = True
            if messageKind == 'comment':
                self.warning('mismatch in leading whitespace before comment')
            else:
                self.error('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind == 'comment' # Only mismatched comment lines are valid.
    else:
        if enableWarning:
            self.mismatchWarningGiven = True
            self.checkLeadingWhitespace(line1)
            self.warning('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind in ('comment','warning') # Only errors are invalid.
#@+node:ekr.20091227115606.6468: *8* adjustRstLines
def adjustRstLines(self,lines):

    '''Ignore newlines.

    This fudge allows the rst code generators to insert needed newlines freely.'''

    return [z for z in lines if z.strip() != '']
#@+node:ekr.20090513073632.5735: *8* compareRstUnderlines
def compareRstUnderlines(self,s1,s2):

    s1,s2 = s1.rstrip(),s2.rstrip()
    if s1 == s2:
        return True # Don't worry about trailing whitespace.

    n1, n2 = len(s1),len(s2)
    ch1 = n1 and s1[0] or ''
    ch2 = n2 and s2[0] or ''

    val = (
        n1 >= 2 and n2 >= 2 and # Underlinings must be at least 2 long.
        ch1 == ch2 and # The underlining characters must match.
        s1 == ch1 * n1 and # The line must consist only of underlining characters.
        s2 == ch2 * n2)

    return val
#@+node:ekr.20071110144948: *7* checkLeadingWhitespace
def checkLeadingWhitespace (self,line):

    tab_width = self.tab_width
    lws = line[0:g.skip_ws(line,0)]
    w = g.computeWidth(lws,tab_width)
    ok = (w % abs(tab_width)) == 0

    if not ok:
        self.report('leading whitespace not consistent with @tabwidth %d' % tab_width)
        g.es_print('line:',repr(line),color='red')

    return ok
#@+node:ekr.20070911110507: *7* reportMismatch
def reportMismatch (self,lines1,lines2,bad_i):

    kind = g.choose(self.atAuto,'@auto','import command')
    n1,n2 = len(lines1),len(lines2)
    self.error(
        '%s did not import %s perfectly\nfirst mismatched line: %d' % (
            kind,self.root.h,bad_i))

    aList = []
    for i in range(max(0,bad_i-2),min(bad_i+3,max(n1,n2))):
        for lines,n in ((lines1,n1),(lines2,n2)):
            if i < n: line = repr(lines[i])
            else: line = '<eof>'
            aList.append('%4d %s' % (i,line))

    if not g.unitTesting:
        g.es_print('\n'.join(aList),color='blue')

    return False
#@+node:ekr.20070706084535: *6* Code generation
@ None of these methods should ever need to be overridden in subclasses.

#@+node:ekr.20090512080015.5800: *7* adjustParent
def adjustParent (self,parent,headline):

    '''Return the effective parent.

    This is overridden by the rstScanner class.'''

    return parent
#@+node:ekr.20070707073044.1: *7* addRef
def addRef (self,parent):

    '''Create an unindented @others or section reference in the parent node.'''

    c = self.c

    if self.isRst and not self.atAuto:
        return

    if self.treeType == '@file':
        self.appendStringToBody(parent,'@others\n')

    if self.treeType == '@root' and self.methodsSeen:
        self.appendStringToBody(parent,
            g.angleBrackets(' ' + self.methodName + ' methods ') + '\n\n')
#@+node:ekr.20090122201952.6: *7* appendStringToBody & setBodyString (baseScannerClass)
def appendStringToBody (self,p,s):

    '''Similar to c.appendStringToBody,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.appendStringToBody(p,s)

def setBodyString (self,p,s):

    '''Similar to c.setBodyString,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.setBodyString(p,s)
#@+node:ekr.20090512153903.5806: *7* computeBody (baseScannerClass)
def computeBody (self,s,start,sigStart,codeEnd):

    trace = False and not g.unitTesting

    body1 = s[start:sigStart]
    # Adjust start backwards to get a better undent.
    if body1.strip():
        while start > 0 and s[start-1] in (' ','\t'):
            start -= 1

    body1 = self.undentBody(s[start:sigStart],ignoreComments=False)
    body2 = self.undentBody(s[sigStart:codeEnd])
    body = body1 + body2

    if trace: g.trace('body: %s' % repr(body))

    tail = body[len(body.rstrip()):]
    if not '\n' in tail:
        self.warning(
            '%s %s does not end with a newline; one will be added\n%s' % (
            self.functionSpelling,self.sigId,g.get_line(s,codeEnd)))

    return body
#@+node:ekr.20090513073632.5737: *7* createDeclsNode
def createDeclsNode (self,parent,s):

    '''Create a child node of parent containing s.'''

    # Create the node for the decls.
    headline = '%s declarations' % self.methodName
    body = self.undentBody(s)
    self.createHeadline(parent,body,headline)
#@+node:ekr.20070707085612: *7* createFunctionNode
def createFunctionNode (self,headline,body,parent):

    # Create the prefix line for @root trees.
    if self.treeType == '@file':
        prefix = ''
    else:
        prefix = g.angleBrackets(' ' + headline + ' methods ') + '=\n\n'
        self.methodsSeen = True

    # Create the node.
    return self.createHeadline(parent,prefix + body,headline)

#@+node:ekr.20070703122141.77: *7* createHeadline (baseScannerClass)
def createHeadline (self,parent,body,headline):

    return self.importCommands.createHeadline(parent,body,headline)
#@+node:ekr.20090502071837.1: *7* endGen
def endGen (self,s):

    '''Do any language-specific post-processing.'''
    pass
#@+node:ekr.20070703122141.79: *7* getLeadingIndent
def getLeadingIndent (self,s,i,ignoreComments=True):

    '''Return the leading whitespace of a line.
    Ignore blank and comment lines if ignoreComments is True'''

    width = 0
    i = g.find_line_start(s,i)
    if ignoreComments:
        while i < len(s):
            # g.trace(g.get_line(s,i))
            j = g.skip_ws(s,i)
            if g.is_nl(s,j) or g.match(s,j,self.comment_delim):
                i = g.skip_line(s,i) # ignore blank lines and comment lines.
            else:
                i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                break      
    else:
        i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)

    # g.trace('returns:',width)
    return width
#@+node:ekr.20070709094002: *7* indentBody
def indentBody (self,s,lws=None):

    '''Add whitespace equivalent to one tab for all non-blank lines of s.'''

    result = []
    if not lws: lws = self.tab_ws

    for line in g.splitLines(s):
        if line.strip():
            result.append(lws + line)
        elif line.endswith('\n'):
            result.append('\n')

    result = ''.join(result)
    return result
#@+node:ekr.20070705085335: *7* insertIgnoreDirective
def insertIgnoreDirective (self,parent):

    self.appendStringToBody(parent,'@ignore')

    if not g.unitTesting:
        g.es_print('inserting @ignore',color='blue')
#@+node:ekr.20070707113832.1: *7* putClass & helpers
def putClass (self,s,i,sigEnd,codeEnd,start,parent):

    '''Creates a child node c of parent for the class,
    and a child of c for each def in the class.'''

    trace = False and not g.unitTesting
    if trace:
        # g.trace('tab_width',self.tab_width)
        g.trace('sig',s[i:sigEnd])

    # Enter a new class 1: save the old class info.
    oldMethodName = self.methodName
    oldStartSigIndent = self.startSigIndent

    # Enter a new class 2: init the new class info.
    self.indentRefFlag = None

    class_kind = self.classId
    class_name = self.sigId
    headline = '%s %s' % (class_kind,class_name)
    headline = headline.strip()
    self.methodName = headline

    # Compute the starting lines of the class.
    prefix = self.createClassNodePrefix()
    if not self.sigId:
        g.trace('Can not happen: no sigId')
        self.sigId = 'Unknown class name'
    classHead = s[start:sigEnd]
    i = self.extendSignature(s,sigEnd)
    extend = s[sigEnd:i]
    if extend:
        classHead = classHead + extend

    # Create the class node.
    class_node = self.createHeadline(parent,'',headline)

    # Remember the indentation of the class line.
    undentVal = self.getLeadingIndent(classHead,0)

    # Call the helper to parse the inner part of the class.
    putRef,bodyIndent,classDelim,decls,trailing = self.putClassHelper(
        s,i,codeEnd,class_node)
    # g.trace('bodyIndent',bodyIndent,'undentVal',undentVal)

    # Set the body of the class node.
    ref = putRef and self.getClassNodeRef(class_name) or ''

    if trace: g.trace('undentVal',undentVal,'bodyIndent',bodyIndent)

    # Give ref the same indentation as the body of the class.
    if ref:
        bodyWs = g.computeLeadingWhitespace (bodyIndent,self.tab_width)
        ref = '%s%s' % (bodyWs,ref)

    # Remove the leading whitespace.
    result = (
        prefix +
        self.undentBy(classHead,undentVal) +
        self.undentBy(classDelim,undentVal) +
        self.undentBy(decls,undentVal) +
        self.undentBy(ref,undentVal) +
        self.undentBy(trailing,undentVal))

    # Append the result to the class node.
    self.appendTextToClassNode(class_node,result)

    # Exit the new class: restore the previous class info.
    self.methodName = oldMethodName
    self.startSigIndent = oldStartSigIndent
#@+node:ekr.20070707190351: *8* appendTextToClassNode
def appendTextToClassNode (self,class_node,s):

    c = self.c

    self.appendStringToBody(class_node,s) 
#@+node:ekr.20070703122141.105: *8* createClassNodePrefix
def createClassNodePrefix (self):

    '''Create the class node prefix.'''

    if  self.treeType == '@file':
        prefix = ''
    else:
        prefix = g.angleBrackets(' ' + self.methodName + ' methods ') + '=\n\n'
        self.methodsSeen = True

    return prefix
#@+node:ekr.20070703122141.106: *8* getClassNodeRef
def getClassNodeRef (self,class_name):

    '''Insert the proper body text in the class_vnode.'''

    if self.treeType == '@file':
        s = '@others'
    else:
        s = g.angleBrackets(' class %s methods ' % (class_name))

    return '%s\n' % (s)
#@+node:ekr.20070707171329: *8* putClassHelper
def putClassHelper(self,s,i,end,class_node):

    '''s contains the body of a class, not including the signature.

    Parse s for inner methods and classes, and create nodes.'''

    trace = False and not g.unitTesting

    # Increase the output indentation (used only in startsHelper).
    # This allows us to detect over-indented classes and functions.
    old_output_indent = self.output_indent
    self.output_indent += abs(self.tab_width)

    # Parse the decls.
    j = i ; i = self.skipDecls(s,i,end,inClass=True)
    decls = s[j:i]

    # Set the body indent if there are real decls.
    bodyIndent = decls.strip() and self.getIndent(s,i) or None
    if trace: g.trace('bodyIndent',bodyIndent)

    # Parse the rest of the class.
    delim1, delim2 = self.outerBlockDelim1, self.outerBlockDelim2
    if g.match(s,i,delim1):
        # Do *not* use g.skip_ws_and_nl here!
        j = g.skip_ws(s,i + len(delim1))
        if g.is_nl(s,j): j = g.skip_nl(s,j)
        classDelim = s[i:j]
        end2 = self.skipBlock(s,i,delim1=delim1,delim2=delim2)
        start,putRef,bodyIndent2 = self.scanHelper(s,j,end=end2,parent=class_node,kind='class')
    else:
        classDelim = ''
        start,putRef,bodyIndent2 = self.scanHelper(s,i,end=end,parent=class_node,kind='class')

    if bodyIndent is None: bodyIndent = bodyIndent2

    # Restore the output indentation.
    self.output_indent = old_output_indent

    # Return the results.
    trailing = s[start:end]
    return putRef,bodyIndent,classDelim,decls,trailing
#@+node:ekr.20070707082432: *7* putFunction (baseScannerClass)
def putFunction (self,s,sigStart,codeEnd,start,parent):

    '''Create a node of parent for a function defintion.'''

    trace = False and not g.unitTesting
    verbose = False

    # if trace: g.trace(start,sigStart,self.sigEnd,codeEnd)

    # Enter a new function: save the old function info.
    oldStartSigIndent = self.startSigIndent

    if self.sigId:
        headline = self.sigId
    else:
        g.trace('Can not happen: no sigId')
        headline = 'unknown function'

    body = self.computeBody(s,start,sigStart,codeEnd)

    if trace:
        g.trace('parent',parent.h)
        if verbose: g.trace('**body...\n',body)

    parent = self.adjustParent(parent,headline)
    self.lastParent = self.createFunctionNode(headline,body,parent)

    # Exit the function: restore the function info.
    self.startSigIndent = oldStartSigIndent
#@+node:ekr.20070705094630: *7* putRootText
def putRootText (self,p):

    c = self.c

    self.appendStringToBody(p,'%s@language %s\n@tabwidth %d\n' % (
        self.rootLine,self.language,self.tab_width))
#@+node:ekr.20090122201952.5: *7* setBodyString
#@+node:ekr.20070703122141.88: *7* undentBody
def undentBody (self,s,ignoreComments=True):

    '''Remove the first line's leading indentation from all lines of s.'''

    trace = False
    if trace: g.trace('before...\n',g.listToString(g.splitLines(s)))

    if self.isRst:
        return s # Never unindent rst code.

    # Calculate the amount to be removed from each line.
    undentVal = self.getLeadingIndent(s,0,ignoreComments=ignoreComments)
    if undentVal == 0:
        return s
    else:
        result = self.undentBy(s,undentVal)
        if trace: g.trace('after...\n',g.listToString(g.splitLines(result)))
        return result
#@+node:ekr.20081216090156.1: *7* undentBy
def undentBy (self,s,undentVal):

    '''Remove leading whitespace equivalent to undentVal from each line.
    add an underindentEscapeString for underindented line.'''

    trace = False and not g.app.unitTesting

    if self.isRst:
        return s # Never unindent rst code.

    tag = self.c.atFileCommands.underindentEscapeString
    result = [] ; tab_width = self.tab_width
    for line in g.splitlines(s):
        lws_s = g.get_leading_ws(line)
        lws = g.computeWidth(lws_s,tab_width)
        s = g.removeLeadingWhitespace(line,undentVal,tab_width)
        n = lws - undentVal
        if s.strip() and lws < undentVal:
            if trace: g.trace('undentVal: %s, lws: %s, %s' % (
                undentVal,lws,repr(line)))
            result.append("%s%s%s" % (tag,undentVal-lws,s.lstrip()))
        else:
            result.append(s)

    return ''.join(result)

#@+node:ekr.20070801074524: *7* underindentedComment & underindentedLine
def underindentedComment (self,line):

    if self.atAutoWarnsAboutLeadingWhitespace:
        self.warning(
            'underindented python comments.\nExtra leading whitespace will be added\n' + line)

def underindentedLine (self,line):

    self.error(
        'underindented line.\nExtra leading whitespace will be added\n' + line)
#@+node:ekr.20070703122141.78: *6* error, oops, report and warning
def error (self,s):
    self.errors += 1
    self.importCommands.errors += 1
    if g.unitTesting:
        if self.errors == 1:
            g.app.unitTestDict ['actualErrorMessage'] = s
        g.app.unitTestDict ['actualErrors'] = self.errors
        if 0: # For debugging unit tests.
            g.trace(g.callers())
            g.es_print('',s,color='red')
    else:
        g.es_print('error:',s,color='red')

def oops (self):
    g.pr('baseScannerClass oops: %s must be overridden in subclass' % g.callers())

def report (self,message):
    if self.strict: self.error(message)
    else:           self.warning(message)

def warning (self,s):
    if not g.unitTesting:
        g.es_print('warning:',s,color='red')
#@+node:ekr.20070706084535.1: *6* Parsing
@ Scan and skipDecls would typically not be overridden.
#@+node:ekr.20071201072917: *7* adjustDefStart
def adjustDefStart (self,unused_s,i):

    '''A hook to allow the Python importer to adjust the 
    start of a class or function to include decorators.'''

    return i
#@+node:ekr.20070707150022: *7* extendSignature
def extendSignature(self,unused_s,i):

    '''Extend the signature line if appropriate.
    The text *must* end with a newline.

    For example, the Python scanner appends docstrings if they exist.'''

    return i
#@+node:ekr.20071017132056: *7* getIndent
def getIndent (self,s,i):

    j,junk = g.getLine(s,i)
    junk,indent = g.skip_leading_ws_with_indent(s,j,self.tab_width)
    return indent
#@+node:ekr.20070706101600: *7* scan & scanHelper
def scan (self,s,parent):

    '''A language independent scanner: it uses language-specific helpers.

    Create a child of self.root for:
    - Leading outer-level declarations.
    - Outer-level classes.
    - Outer-level functions.
    '''

    # Init the parser status ivars.
    self.methodsSeen = False

    # Create the initial body text in the root.
    self.putRootText(parent)

    # Parse the decls.
    i = self.skipDecls(s,0,len(s),inClass=False)
    decls = s[:i]

    # Create the decls node.
    if decls: self.createDeclsNode(parent,decls)

    # Scan the rest of the file.
    start,junk,junk = self.scanHelper(s,i,end=len(s),parent=parent,kind='outer')

    # Finish adding to the parent's body text.
    self.addRef(parent)
    if start < len(s):
        self.appendStringToBody(parent,s[start:])

    # Do any language-specific post-processing.
    self.endGen(s)
#@+node:ekr.20071018084830: *8* scanHelper
def scanHelper(self,s,i,end,parent,kind):

    '''Common scanning code used by both scan and putClassHelper.'''

    # g.trace(g.callers())
    # g.trace('i',i,g.get_line(s,i))
    assert kind in ('class','outer')
    start = i ; putRef = False ; bodyIndent = None
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif self.startsClass(s,i):  # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            end2 = self.codeEnd # putClass may change codeEnd ivar.
            self.putClass(s,i,self.sigEnd,self.codeEnd,start,parent)
            i = start = end2
        elif self.startsFunction(s,i): # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            self.putFunction(s,self.sigStart,self.codeEnd,start,parent)
            i = start = self.codeEnd
        elif self.startsId(s,i):
            i = self.skipId(s,i)
        elif kind == 'outer' and g.match(s,i,self.outerBlockDelim1): # Do this after testing for classes.
            i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
            # Bug fix: 2007/11/8: do *not* set start: we are just skipping the block.
        else: i += 1
        assert progress < i,'i: %d, ch: %s' % (i,repr(s[i]))

    return start,putRef,bodyIndent
#@+node:ekr.20070712075148: *7* skipArgs
def skipArgs (self,s,i,kind):

    '''Skip the argument or class list.  Return i, ok

    kind is in ('class','function')'''

    start = i
    i = g.skip_ws_and_nl(s,i)
    if not g.match(s,i,'('):
        return start,kind == 'class'

    i = self.skipParens(s,i)
    # skipParens skips the ')'
    if i >= len(s):
        return start,False
    else:
        return i,True 
#@+node:ekr.20070707073859: *7* skipBlock
def skipBlock(self,s,i,delim1=None,delim2=None):

    '''Skip from the opening delim to *past* the matching closing delim.

    If no matching is found i is set to len(s)'''

    trace = False and not g.unitTesting
    start = i
    if delim1 is None: delim1 = self.blockDelim1
    if delim2 is None: delim2 = self.blockDelim2
    match1 = g.choose(len(delim1)==1,g.match,g.match_word)
    match2 = g.choose(len(delim2)==1,g.match,g.match_word)
    assert match1(s,i,delim1)
    level = 0 ; start = i
    startIndent = self.startSigIndent
    if trace: g.trace('***','startIndent',startIndent,g.callers())
    while i < len(s):
        progress = i
        if g.is_nl(s,i):
            backslashNewline = i > 0 and g.match(s,i-1,'\\\n')
            i = g.skip_nl(s,i)
            if not backslashNewline and not g.is_nl(s,i):
                j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                line = g.get_line(s,j)
                if trace: g.trace('indent',indent,line)
                if indent < startIndent and line.strip():
                    # An non-empty underindented line.
                    # Issue an error unless it contains just the closing bracket.
                    if level == 1 and match2(s,j,delim2):
                        pass
                    else:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedLine(line)
        elif s[i] in (' ','\t',):
            i += 1 # speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif match1(s,i,delim1):
            level += 1 ; i += len(delim1)
        elif match2(s,i,delim2):
            level -= 1 ; i += len(delim2)
            # Skip junk following Pascal 'end'
            for z in self.blockDelim2Cruft:
                i2 = g.skip_ws(s,i)
                if g.match(s,i2,z):
                    i = i2 + len(z)
                    break
            if level <= 0:
                if trace: g.trace('returns:',repr(s[start:i]))
                return i

        else: i += 1
        assert progress < i

    self.error('no block')
    if 1:
        g.pr('** no block **')
        i,j = g.getLine(s,start)
        g.trace(i,s[i:j])
    else:
        if trace: g.trace('** no block')
    return start
#@+node:ekr.20070712091019: *7* skipCodeBlock
def skipCodeBlock (self,s,i,kind):

    '''Skip the code block in a function or class definition.'''

    trace = False
    start = i
    i = self.skipBlock(s,i,delim1=None,delim2=None)

    if self.sigFailTokens:
        i = g.skip_ws(s,i)
        for z in self.sigFailTokens:
            if g.match(s,i,z):
                if trace: g.trace('failtoken',z)
                return start,False

    if i > start:
        i = self.skipNewline(s,i,kind)

    if trace:
        g.trace(g.callers())
        g.trace('returns...\n',g.listToString(g.splitLines(s[start:i])))

    return i,True
#@+node:ekr.20070711104014: *7* skipComment & helper
def skipComment (self,s,i):

    '''Skip a comment and return the index of the following character.'''

    if g.match(s,i,self.lineCommentDelim) or g.match(s,i,self.lineCommentDelim2):
        return g.skip_to_end_of_line(s,i)
    else:
        return self.skipBlockComment(s,i)
#@+node:ekr.20070707074541: *8* skipBlockComment
def skipBlockComment (self,s,i):

    '''Skip past a block comment.'''

    start = i

    # Skip the opening delim.
    if g.match(s,i,self.blockCommentDelim1):
        delim2 = self.blockCommentDelim2
        i += len(self.blockCommentDelim1)
    elif g.match(s,i,self.blockCommentDelim1_2):
        i += len(self.blockCommentDelim1_2)
        delim2 = self.blockCommentDelim2_2
    else:
        assert False

    # Find the closing delim.
    k = s.find(delim2,i)
    if k == -1:
        self.error('Run on block comment: ' + s[start:i])
        return len(s)
    else:
        return k + len(delim2)
#@+node:ekr.20070707080042: *7* skipDecls
def skipDecls (self,s,i,end,inClass):

    '''Skip everything until the start of the next class or function.

    The decls *must* end in a newline.'''

    trace = False or self.trace
    start = i ; prefix = None
    classOrFunc = False
    if trace: g.trace(g.callers())
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            # Add the comment to the decl if it *doesn't* start the line.
            i2,junk = g.getLine(s,i)
            i2 = g.skip_ws(s,i2)
            if i2 == i and prefix is None:
                prefix = i2 # Bug fix: must include leading whitespace in the comment.
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
            prefix = None
        elif self.startsClass(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsFunction(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsId(s,i):
            i = self.skipId(s,i)
            prefix = None
        # Don't skip outer blocks: they may contain classes.
        elif g.match(s,i,self.outerBlockDelim1):
            if self.outerBlockEndsDecls:
                break
            else:
                i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
        else:
            i += 1 ;  prefix = None
        assert(progress < i)

    if prefix is not None:
        i = g.find_line_start(s,prefix) # i = prefix
    decls = s[start:i]
    if inClass and not classOrFunc:
        # Don't return decls if a class contains nothing but decls.
        if trace and decls.strip(): g.trace('**class is all decls...\n',decls)
        return start
    elif decls.strip(): 
        if trace or self.trace: g.trace('\n'+decls)
        return i
    else: # Ignore empty decls.
        return start
#@+node:ekr.20070707094858.1: *7* skipId
def skipId (self,s,i):

    return g.skip_id(s,i,chars=self.extraIdChars)
#@+node:ekr.20070730134936: *7* skipNewline
def skipNewline(self,s,i,kind):

    '''Skip whitespace and comments up to a newline, then skip the newline.
    Issue an error if no newline is found.'''

    while i < len(s):
        i = g.skip_ws(s,i)
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        else: break

    if i >= len(s):
        return len(s)

    if g.match(s,i,'\n'):
        i += 1
    else:
        self.error(
            '%s %s does not end in a newline; one will be added\n%s' % (
                kind,self.sigId,g.get_line(s,i)))
        # g.trace(g.callers())

    return i
#@+node:ekr.20070712081451: *7* skipParens
def skipParens (self,s,i):

    '''Skip a parenthisized list, that might contain strings or comments.'''

    return self.skipBlock(s,i,delim1='(',delim2=')')
#@+node:ekr.20070707073627.2: *7* skipString
def skipString (self,s,i):

    # Returns len(s) on unterminated string.
    return g.skip_string(s,i,verbose=False)
#@+node:ekr.20070711132314: *7* startsClass/Function (baseClass) & helpers
# We don't expect to override this code, but subclasses may override the helpers.

def startsClass (self,s,i):
    '''Return True if s[i:] starts a class definition.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasClasses and self.startsHelper(s,i,kind='class',tags=self.classTags)
    return val

def startsFunction (self,s,i):
    '''Return True if s[i:] starts a function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasFunctions and self.startsHelper(s,i,kind='function',tags=self.functionTags)
    return val
#@+node:ekr.20070711134534: *8* getSigId
def getSigId (self,ids):

    '''Return the signature's id.

    By default, this is the last id in the ids list.'''

    return ids and ids[-1]
#@+node:ekr.20070711140703: *8* skipSigStart
def skipSigStart (self,s,i,kind,tags):

    '''Skip over the start of a function/class signature.

    tags is in (self.classTags,self.functionTags).

    Return (i,ids) where ids is list of all ids found, in order.'''

    trace = False and self.trace # or kind =='function'
    ids = [] ; classId = None
    if trace: g.trace('*entry',kind,i,s[i:i+20])
    start = i
    while i < len(s):
        j = g.skip_ws_and_nl(s,i)
        for z in self.sigFailTokens:
            if g.match(s,j,z):
                if trace: g.trace('failtoken',z,'ids',ids)
                return start, [], None
        for z in self.sigHeadExtraTokens:
            if g.match(s,j,z):
                i += len(z) ; break
        else:
            i = self.skipId(s,j)
            theId = s[j:i]
            if theId and theId in tags: classId = theId
            if theId: ids.append(theId)
            else: break

    if trace: g.trace('*exit ',kind,i,i < len(s) and s[i],ids,classId)
    return i, ids, classId
#@+node:ekr.20070712082913: *8* skipSigTail
def skipSigTail(self,s,i,kind):

    '''Skip from the end of the arg list to the start of the block.'''

    trace = False and self.trace
    start = i
    i = g.skip_ws(s,i)
    for z in self.sigFailTokens:
        if g.match(s,i,z):
            if trace: g.trace('failToken',z,'line',g.skip_line(s,i))
            return i,False
    while i < len(s):
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif g.match(s,i,self.blockDelim1):
            if trace: g.trace(repr(s[start:i]))
            return i,True
        else:
            i += 1
    if trace: g.trace('no block delim')
    return i,False
#@+node:ekr.20070712112008: *8* startsHelper
def startsHelper(self,s,i,kind,tags):
    '''return True if s[i:] starts a class or function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''

    # if not tags: return False

    trace = False or self.trace
    verbose = False # kind=='function'
    self.codeEnd = self.sigEnd = self.sigId = None
    self.sigStart = i

    # Underindented lines can happen in any language, not just Python.
    # The skipBlock method of the base class checks for such lines.
    self.startSigIndent = self.getLeadingIndent(s,i)

    # Get the tag that starts the class or function.
    j = g.skip_ws_and_nl(s,i)
    i = self.skipId(s,j)
    self.sigId = theId = s[j:i] # Set sigId ivar 'early' for error messages.
    if not theId: return False

    if tags:
        if theId not in tags:
            if trace and verbose: g.trace('**** %s theId: %s not in tags: %s' % (kind,theId,tags))
            return False

    if trace and verbose: g.trace('kind',kind,'id',theId)

    # Get the class/function id.
    if kind == 'class' and self.sigId in self.anonymousClasses:
        # A hack for Delphi Pascal: interfaces have no id's.
        # g.trace('anonymous',self.sigId)
        classId = theId
        sigId = ''
    else:
        i, ids, classId = self.skipSigStart(s,j,kind,tags) # Rescan the first id.
        sigId = self.getSigId(ids)
        if not sigId:
            if trace and verbose: g.trace('**no sigId',g.get_line(s,i))
            return False

    if self.output_indent < self.startSigIndent:
        if trace: g.trace('**over-indent',sigId)
            #,'output_indent',self.output_indent,'startSigIndent',self.startSigIndent)
        return False

    # Skip the argument list.
    i, ok = self.skipArgs(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no args',g.get_line(s,i))
        return False
    i = g.skip_ws_and_nl(s,i)

    # Skip the tail of the signature
    i, ok = self.skipSigTail(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no tail',g.get_line(s,i))
        return False
    sigEnd = i

    # A trick: make sure the signature ends in a newline,
    # even if it overlaps the start of the block.
    if not g.match(s,sigEnd,'\n') and not g.match(s,sigEnd-1,'\n'):
        if trace and verbose: g.trace('extending sigEnd')
        sigEnd = g.skip_line(s,sigEnd)

    if self.blockDelim1:
        i = g.skip_ws_and_nl(s,i)
        if kind == 'class' and self.sigId in self.anonymousClasses:
            pass # Allow weird Pascal unit's.
        elif not g.match(s,i,self.blockDelim1):
            if trace and verbose: g.trace('no block',g.get_line(s,i))
            return False

    i,ok = self.skipCodeBlock(s,i,kind)
    if not ok: return False
        # skipCodeBlock skips the trailing delim.

    # Success: set the ivars.
    self.sigStart = self.adjustDefStart(s,self.sigStart)
    self.codeEnd = i
    self.sigEnd = sigEnd
    self.sigId = sigId
    self.classId = classId

    # Note: backing up here is safe because
    # we won't back up past scan's 'start' point.
    # Thus, characters will never be output twice.
    k = self.sigStart
    if not g.match(s,k,'\n'):
        self.sigStart = g.find_line_start(s,k)

    # Issue this warning only if we have a real class or function.
    if 0: # wrong.
        if s[self.sigStart:k].strip():
            self.error('%s definition does not start a line\n%s' % (
                kind,g.get_line(s,k)))

    if trace: g.trace(kind,'returns\n'+s[self.sigStart:i])
    return True
#@+node:ekr.20070711104014.1: *7* startsComment
def startsComment (self,s,i):

    return (
        g.match(s,i,self.lineCommentDelim) or
        g.match(s,i,self.lineCommentDelim2) or
        g.match(s,i,self.blockCommentDelim1) or
        g.match(s,i,self.blockCommentDelim1_2)
    )
#@+node:ekr.20070707094858.2: *7* startsId
def startsId(self,s,i):

    return g.is_c_id(s[i:i+1])
#@+node:ekr.20070707172732.1: *7* startsString
def startsString(self,s,i):

    return g.match(s,i,'"') or g.match(s,i,"'")
#@+node:ekr.20070707072749: *6* run (baseScannerClass)
def run (self,s,parent):

    c = self.c
    self.root = root = parent.copy()
    self.file_s = s
    self.tab_width = self.importCommands.getTabWidth(p=root)
    # g.trace('tab_width',self.tab_width)
    # Create the ws equivalent to one tab.
    if self.tab_width < 0:
        self.tab_ws = ' '*abs(self.tab_width)
    else:
        self.tab_ws = '\t'

    # Init the error/status info.
    self.errors = 0
    self.errorLines = []
    self.mismatchWarningGiven = False
    changed = c.isChanged()

    # Use @verbatim to escape section references
    if self.escapeSectionRefs: # 2009/12/27
        s = self.escapeFalseSectionReferences(s)

    # Check for intermixed blanks and tabs.
    if self.strict or self.atAutoWarnsAboutLeadingWhitespace:
        if not self.isRst:
            self.checkBlanksAndTabs(s)

    # Regularize leading whitespace for strict languages only.
    if self.strict: s = self.regularizeWhitespace(s) 

    # Generate the nodes, including directive and section references.
    self.scan(s,parent)

    # Check the generated nodes.
    # Return True if the result is equivalent to the original file.
    ok = self.errors == 0 and self.check(s,parent)
    g.app.unitTestDict ['result'] = ok

    # Insert an @ignore directive if there were any serious problems.
    if not ok: self.insertIgnoreDirective(parent)

    if self.atAuto and ok:
        for p in root.self_and_subtree():
            p.clearDirty()
        c.setChanged(changed)
    else:
        root.setDirty(setDescendentsDirty=False)
        c.setChanged(True)
#@+node:ekr.20071110105107: *7* checkBlanksAndTabs
def checkBlanksAndTabs(self,s):

    '''Check for intermixed blank & tabs.'''

    # Do a quick check for mixed leading tabs/blanks.
    blanks = tabs = 0

    for line in g.splitLines(s):
        lws = line[0:g.skip_ws(line,0)]
        blanks += lws.count(' ')
        tabs += lws.count('\t')

    ok = blanks == 0 or tabs == 0

    if not ok:
        self.report('intermixed blanks and tabs')

    return ok
#@+node:ekr.20070808115837.1: *7* regularizeWhitespace
def regularizeWhitespace (self,s):

    '''Regularize leading whitespace in s:
    Convert tabs to blanks or vice versa depending on the @tabwidth in effect.
    This is only called for strict languages.'''

    changed = False ; lines = g.splitLines(s) ; result = [] ; tab_width = self.tab_width

    if tab_width < 0: # Convert tabs to blanks.
        for line in lines:
            i, w = g.skip_leading_ws_with_indent(line,0,tab_width)
            s = g.computeLeadingWhitespace(w,-abs(tab_width)) + line [i:] # Use negative width.
            if s != line: changed = True
            result.append(s)
    elif tab_width > 0: # Convert blanks to tabs.
        for line in lines:
            s = g.optimizeLeadingWhitespace(line,abs(tab_width)) # Use positive width.
            if s != line: changed = True
            result.append(s)

    if changed:
        action = g.choose(self.tab_width < 0,'tabs converted to blanks','blanks converted to tabs')
        message = 'inconsistent leading whitespace. %s' % action
        self.report(message)

    return ''.join(result)
#@+node:ekr.20070703122141.100: *5* class pythonScanner
class pythonScanner (baseScannerClass):

    @others
#@+node:ekr.20070703122141.101: *6*  __init__
def __init__ (self,importCommands,atAuto):

    # Init the base class.
    baseScannerClass.__init__(self,importCommands,atAuto=atAuto,language='python')

    # Set the parser delims.
    self.lineCommentDelim = '#'
    self.classTags = ['class',]
    self.functionTags = ['def',]
    self.blockDelim1 = self.blockDelim2 = None
        # Suppress the check for the block delim.
        # The check is done in skipSigTail.
    self.strict = True

#@+node:ekr.20071201073102.1: *6* adjustDefStart (python)
def adjustDefStart (self,s,i):

    '''A hook to allow the Python importer to adjust the 
    start of a class or function to include decorators.'''

    if i == 0 or s[i-1] != '\n':
        return i

    while i > 0:
        progress = i

        start = j = g.find_line_start(s,i-2)
        j = g.skip_ws(s,j)
        if not g.match(s,j,'@'):
            return i

        j += 1
        k = g.skip_id(s,j)
        word = s[j:k]

        if word and word not in g.globalDirectiveList:
            # g.trace(repr(word),repr(s[start:i]))
            i = start
            assert i < progress
        else:
            return i
#@+node:ekr.20070707113839: *6* extendSignature
def extendSignature(self,s,i):

    '''Extend the text to be added to the class node following the signature.

    The text *must* end with a newline.'''

    # Add a docstring to the class node,
    # And everything on the line following it
    j = g.skip_ws_and_nl(s,i)
    if g.match(s,j,'"""') or g.match(s,j,"'''"):
        j = g.skip_python_string(s,j)
        if j < len(s): # No scanning error.
            # Return the docstring only if nothing but whitespace follows.
            j = g.skip_ws(s,j)
            if g.is_nl(s,j):
                return j + 1

    return i
#@+node:ekr.20070707073627.4: *6* skipString
def skipString (self,s,i):

    # Returns len(s) on unterminated string.
    return g.skip_python_string(s,i,verbose=False)
#@+node:ekr.20070712090019.1: *6* skipCodeBlock (python) & helpers
def skipCodeBlock (self,s,i,kind):

    trace = False ; verbose = True
    # if trace: g.trace('***',g.callers())
    startIndent = self.startSigIndent
    if trace: g.trace('startIndent',startIndent)
    assert startIndent is not None
    i = start = g.skip_ws_and_nl(s,i)
    parenCount = 0
    underIndentedStart = None # The start of trailing underindented blank or comment lines.
    while i < len(s):
        progress = i
        ch = s[i]
        if g.is_nl(s,i):
            i = g.skip_nl(s,i)
            j = g.skip_ws(s,i)
            if g.is_nl(s,j):
                pass # We have already made progress.
            else:
                if trace and verbose: g.trace(g.get_line(s,i))
                backslashNewline = (i > 0 and g.match(s,i-1,'\\\n'))
                if not backslashNewline:
                    i,underIndentedStart,breakFlag = self.pythonNewlineHelper(
                        s,i,parenCount,startIndent,underIndentedStart)
                    if breakFlag: break
        elif ch == '#':
            i = g.skip_to_end_of_line(s,i)
        elif ch == '"' or ch == '\'':
            i = g.skip_python_string(s,i)
        elif ch in '[{(':
            i += 1 ; parenCount += 1
            # g.trace('ch',ch,parenCount)
        elif ch in ']})':
            i += 1 ; parenCount -= 1
            # g.trace('ch',ch,parenCount)
        else: i += 1
        assert(progress < i)

    # The actual end of the block.
    if underIndentedStart is not None:
        i = underIndentedStart
        if trace: g.trace('***backtracking to underindent range')
        if trace: g.trace(g.get_line(s,i))

    if 0 < i < len(s) and not g.match(s,i-1,'\n'):
        g.trace('Can not happen: Python block does not end in a newline.')
        g.trace(g.get_line(s,i))
        return i,False

    # 2010/02/19: Include all following material
    # until the next 'def' or 'class'
    i = self.skipToTheNextClassOrFunction(s,i,startIndent)

    if (trace or self.trace) and s[start:i].strip():
        g.trace('%s returns\n' % (kind) + s[start:i])
    return i,True
#@+node:ekr.20070801080447: *7* pythonNewlineHelper
def pythonNewlineHelper (self,s,i,parenCount,startIndent,underIndentedStart):

    trace = False
    breakFlag = False
    j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
    if trace: g.trace(
        'startIndent',startIndent,'indent',indent,'parenCount',parenCount,
        'line',repr(g.get_line(s,j)))
    if indent <= startIndent and parenCount == 0:
        # An underindented line: it ends the block *unless*
        # it is a blank or comment line or (2008/9/1) the end of a triple-quoted string.
        if g.match(s,j,'#'):
            if trace: g.trace('underindent: comment')
            if underIndentedStart is None: underIndentedStart = i
            i = j
        elif g.match(s,j,'\n'):
            if trace: g.trace('underindent: blank line')
            # Blank lines never start the range of underindented lines.
            i = j
        else:
            if trace: g.trace('underindent: end of block')
            breakFlag = True # The actual end of the block.
    else:
        if underIndentedStart and g.match(s,j,'\n'):
            # Add the blank line to the underindented range.
            if trace: g.trace('properly indented blank line extends underindent range')
        elif underIndentedStart and g.match(s,j,'#'):
            # Add the (properly indented!) comment line to the underindented range.
            if trace: g.trace('properly indented comment line extends underindent range')
        elif underIndentedStart is None:
            pass
        else:
            # A properly indented non-comment line.
            # Give a message for all underindented comments in underindented range.
            if trace: g.trace('properly indented line generates underindent errors')
            s2 = s[underIndentedStart:i]
            lines = g.splitlines(s2)
            for line in lines:
                if line.strip():
                    junk, indent = g.skip_leading_ws_with_indent(line,0,self.tab_width)
                    if indent <= startIndent:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedComment(line)
            underIndentedStart = None
    if trace: g.trace('breakFlag',breakFlag,'returns',i,'underIndentedStart',underIndentedStart)
    return i,underIndentedStart,breakFlag
#@+node:ekr.20100223094350.5834: *7* skipToTheNextClassOrFunction (New in 4.8)
def skipToTheNextClassOrFunction(self,s,i,lastIndent):

    '''Skip to the next python def or class.
    Return the original i if nothing more is found.
    This allows the "if __name__ == '__main__' hack
    to appear at the top level.'''

    return i ### A rewrite may be needed.

    trace = False # and not g.unitTesting
    c,found,i1 = self.c,False,i
    at_line_start,last_comment,last_nl = True,None,-1
    while i < len(s):
        progress = i
        if self.startsComment(s,i):
            # Break at underindented comments.
            if at_line_start:
                if i == last_nl:
                    n = 0
                else:
                    ws = s[last_nl+1:i]
                    n = g.computeWidth (ws,c.tab_width)
                if n < lastIndent:
                    if trace: g.trace('underindented comment',
                        'ws',repr(ws),'n',n,'lastIndent',lastIndent)
                    found = True ; break
                else:
                    # Remember the start of a range of comments and whitespace.
                    if last_comment is None:
                        last_comment = i
                    last_nl = i = self.skipComment(s,i)
                    at_line_start = True
            else:
                # An interior comment.
                assert last_comment is None
                last_nl = i = self.skipComment(s,i)
                at_line_start = True
        elif self.startsString(s,i):
            at_line_start = False
            last_comment = None
            i = self.skipString(s,i)
        elif at_line_start and (
            g.match_word(s,i,'def') or
            g.match_word(s,i,'class')
        ):
            # Do not break for over-indent matches.
            # This allows something reasonable to happen for::
            # if 0:
            #     def spam():
            #         pass
            ws = s[last_nl+1:i]
            # g.trace('ws',repr(ws))
            n = g.computeWidth (ws,c.tab_width)
            if (not ws or ws.isspace()) and n <= lastIndent:
                found = True ; break
            else: # Ignore the over-indented def.
                if trace: g.trace('overindented','ws',repr(ws),
                    'n',n,'lastIndent',lastIndent)
                last_comment = None
                last_nl = i = g.skip_to_end_of_line(s,i)
                at_line_start = True
        elif s[i] == '@':
            # Leo directives will look like comments,
            # so we can safely assume we have a decorator
            if at_line_start and last_comment is None:
                last_comment = i
            last_nl = i = g.skip_to_end_of_line(s,i)
            at_line_start = True
        elif s[i] ==  '\n':
            at_line_start = True
            last_nl = i
            i += 1
        elif s[i].isspace():
            i += 1
        else:
            at_line_start = False
            last_comment = None
            i += 1
        assert progress < i

    if found:
        if last_comment is None:
            return i
        else:
            return last_comment
    else:
        return i1
#@+node:ekr.20070803101619: *6* skipSigTail
# This must be overridden in order to handle newlines properly.

def skipSigTail(self,s,i,kind):

    '''Skip from the end of the arg list to the start of the block.'''

    while i < len(s):
        ch = s[i]
        if ch == '\n':
            break
        elif ch in (' ','\t',):
            i += 1
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        else:
            break

    return i,g.match(s,i,':')
#@+node:ekr.20090131200406.11: *4* Remove remaining tk-isms from Leo's core
@nocolor-node

Eliminate all tk-indices from leoEditCommands.py

These are marked with ###

(found) wordend, wordstart
(found) lineend, linestart
(found) sel.first, sel.last
(found) w.insert, w.delete
#@+node:ekr.20100108101415.6196: *4* Create insert-tab commands
insert-tab-or-indent-region, insert-hard-tab, insert-soft-tab.
#@+node:ekr.20100122104234.6168: *4* Keystroke for add-nocolor-node ?
Generalize?
#@+node:ekr.20070624135822: *5* Templates for common code fragments
@
Use completion to show fragments.
Allow settings to create fragments:
    - @fragments
        - @fragment name
            body contains actual fragment.

@c

# Invent a way for simple keystrokes to insert fragments, such as:

Fragment 1:

c.beginUpdate()
try:
    pass
finally:
    endUpdate()

Fragment 2:

for p in c.all_positions():
    pass
#@+node:ekr.20090201122309.5: *4* Improve macro commands: and really use them!
@nocolor-node

- The recording logic now returns the entire event.
- The leoKeyEvent ctor now gets the stroke from self.actualEvent.
- Recording ends with ctrl-g: a small changed to k.masterKeyHandler.
- Playing back the macro just calls k.masterKeyHandler.
- Pickle the minimal representation of a key event, namely the stroke.

#@+node:ekr.20100205152016.5837: *4* do @view nodes
#@+node:ekr.20100211072044.5754: *4* Dubious usages of .unitTesting
#@+node:ekr.20031218072017.1723: *5* createMenuEntries
def createMenuEntries (self,menu,table,dynamicMenu=False):

    '''Create a menu entry from the table.
    New in 4.4: this method shows the shortcut in the menu,
    but this method **never** binds any shortcuts.'''

    c = self.c ; f = c.frame ; k = c.k
    if g.app.unitTesting: return

    trace = False
    for data in table:
        << get label & command or continue >>
        << compute commandName & accel from label & command >>
        # Bug fix: 2009/09/30: use canonical stroke.
        accelerator = k.shortcutFromSetting(accel,addKey=False) or ''
        stroke = k.shortcutFromSetting(accel,addKey=True) or ''
        if accelerator:
            accelerator = g.stripBrackets(k.prettyPrintKey(accelerator))
        if trace: # and commandName == 'add-comments':
            g.trace(bunch.val,repr(stroke),repr(accelerator),commandName)
        def masterMenuCallback (c=c,k=k,stroke=stroke,command=command,commandName=commandName,event=None):
            # if trace: g.trace('stroke',stroke)
            return k.masterMenuHandler(stroke,command,commandName)

        realLabel = self.getRealMenuName(label)
        amp_index = realLabel.find("&")
        realLabel = realLabel.replace("&","")
        if sys.platform == 'darwin':
            << clear accelerator if it is a plain key >>

        # c.add_command ensures that c.outerUpdate is called.
        if menu:
            c.add_command(menu,label=realLabel,
                accelerator=accelerator,
                command=masterMenuCallback,
                underline=amp_index)
#@+node:ekr.20051021091958: *6* << get label & command or continue >>
if g.isString(data):
    # New in Leo 4.4.2: Can use the same string for both the label and the command string.
    ok = True
    s = data
    removeHyphens = s and s[0]=='*'
    if removeHyphens: s = s[1:]
    label = self.capitalizeMinibufferMenuName(s,removeHyphens)
    command = s.replace('&','').lower()
    if label == '-':
        self.add_separator(menu)
        continue # That's all.
else:
    ok = type(data) in (type(()), type([])) and len(data) in (2,3)
    if ok:
        if len(data) == 2:
            # New in 4.4b2: command can be a minibuffer-command name (a string)
            label,command = data
        else:
            # New in 4.4: we ignore shortcuts bound in menu tables.
            label,junk,command = data

        if label in (None,'-'):
            self.add_separator(menu)
            continue # That's all.
    else:
        g.trace('bad data in menu table: %s' % repr(data))
        continue # Ignore bad data
#@+node:ekr.20031218072017.1725: *6* << compute commandName & accel from label & command >>
# New in 4.4b2: command can be a minibuffer-command name (a string)
minibufferCommand = type(command) == type('')
accel = None
if minibufferCommand:
    commandName = command 
    command = c.commandsDict.get(commandName)
    if command:
        rawKey,bunchList = c.config.getShortcut(commandName)
        # Pick the first entry that is not a mode.
        for bunch in bunchList:
            if not bunch.pane.endswith('-mode'):
                accel = bunch and bunch.val
                if bunch.pane  == 'text': break # New in Leo 4.4.2: prefer text bindings.
    else:
        if not g.app.unitTesting and not dynamicMenu:
            # Don't warn during unit testing.
            # This may come from a plugin that normally isn't enabled.
            if trace: g.trace('No inverse for %s' % commandName)
        continue # There is no way to make this menu entry.
else:
    # First, get the old-style name.
    commandName = self.computeOldStyleShortcutKey(label)
    rawKey,bunchList = c.config.getShortcut(commandName)
    for bunch in bunchList:
        if not bunch.pane.endswith('-mode'):
            if trace: g.trace('2','%20s' % (bunch.val),commandName)
            accel = bunch and bunch.val ; break
    # Second, get new-style name.
    if not accel:
        << compute emacs_name >>
            # Contains the not-so-horrible kludge.
        if emacs_name:
            commandName = emacs_name
            rawKey,bunchList = c.config.getShortcut(emacs_name)
            # Pick the first entry that is not a mode.
            for bunch in bunchList:
                if not bunch.pane.endswith('-mode'):
                    accel = bunch.val
                    if trace: g.trace('3','%20s' % (bunch.val),commandName)
                    break
        elif not dynamicMenu:
            g.trace('No inverse for %s' % commandName)
#@+node:ekr.20051021100806.1: *7* << compute emacs_name >>
@ One not-so-horrible kludge remains.

The cut/copy/paste commands in the menu tables are not the same as the methods
actually bound to cut/copy/paste-text minibuffer commands, so we must do a bit
of extra translation to discover whether the user has overridden their
bindings.
@c

if command in (f.OnCutFromMenu,f.OnCopyFromMenu,f.OnPasteFromMenu):
    emacs_name = '%s-text' % commandName
else:
    try: # User errors in the table can cause this.
        emacs_name = k.inverseCommandsDict.get(command.__name__)
    except Exception:
        emacs_name = None
#@+node:ekr.20060216110502: *6* << clear accelerator if it is a plain key >>
for z in ('Alt','Ctrl','Command'):
    if accelerator.find(z) != -1:
        break # Found.
else:
    accelerator = ''
#@+node:ekr.20051022043608.1: *5* createOpenWithMenuItemsFromTable
def createOpenWithMenuItemsFromTable (self,menu,table):

    '''Create an entry in the Open with Menu from the table.

    Each entry should be a sequence with 2 or 3 elements.'''

    c = self.c ; k = c.k

    if g.app.unitTesting: return

    for data in table:
        << get label, accelerator & command or continue >>
        # g.trace(label,accelerator)
        realLabel = self.getRealMenuName(label)
        underline=realLabel.find("&")
        realLabel = realLabel.replace("&","")
        callback = self.defineOpenWithMenuCallback(openWithData)

        c.add_command(menu,label=realLabel,
            accelerator=accelerator or '',
            command=callback,underline=underline)
#@+node:ekr.20051022043713.1: *6* << get label, accelerator & command or continue >>
ok = (
    type(data) in (type(()), type([])) and
    len(data) in (2,3)
)

if ok:
    if len(data) == 2:
        label,openWithData = data ; accelerator = None
    else:
        label,accelerator,openWithData = data
        accelerator = k.shortcutFromSetting(accelerator)
        accelerator = accelerator and g.stripBrackets(k.prettyPrintKey(accelerator))
else:
    g.trace('bad data in Open With table: %s' % repr(data))
    continue # Ignore bad data
#@+node:ekr.20031218072017.1725: *5* << compute commandName & accel from label & command >>
# New in 4.4b2: command can be a minibuffer-command name (a string)
minibufferCommand = type(command) == type('')
accel = None
if minibufferCommand:
    commandName = command 
    command = c.commandsDict.get(commandName)
    if command:
        rawKey,bunchList = c.config.getShortcut(commandName)
        # Pick the first entry that is not a mode.
        for bunch in bunchList:
            if not bunch.pane.endswith('-mode'):
                accel = bunch and bunch.val
                if bunch.pane  == 'text': break # New in Leo 4.4.2: prefer text bindings.
    else:
        if not g.app.unitTesting and not dynamicMenu:
            # Don't warn during unit testing.
            # This may come from a plugin that normally isn't enabled.
            if trace: g.trace('No inverse for %s' % commandName)
        continue # There is no way to make this menu entry.
else:
    # First, get the old-style name.
    commandName = self.computeOldStyleShortcutKey(label)
    rawKey,bunchList = c.config.getShortcut(commandName)
    for bunch in bunchList:
        if not bunch.pane.endswith('-mode'):
            if trace: g.trace('2','%20s' % (bunch.val),commandName)
            accel = bunch and bunch.val ; break
    # Second, get new-style name.
    if not accel:
        << compute emacs_name >>
            # Contains the not-so-horrible kludge.
        if emacs_name:
            commandName = emacs_name
            rawKey,bunchList = c.config.getShortcut(emacs_name)
            # Pick the first entry that is not a mode.
            for bunch in bunchList:
                if not bunch.pane.endswith('-mode'):
                    accel = bunch.val
                    if trace: g.trace('3','%20s' % (bunch.val),commandName)
                    break
        elif not dynamicMenu:
            g.trace('No inverse for %s' % commandName)
#@+node:ekr.20051021100806.1: *6* << compute emacs_name >>
@ One not-so-horrible kludge remains.

The cut/copy/paste commands in the menu tables are not the same as the methods
actually bound to cut/copy/paste-text minibuffer commands, so we must do a bit
of extra translation to discover whether the user has overridden their
bindings.
@c

if command in (f.OnCutFromMenu,f.OnCopyFromMenu,f.OnPasteFromMenu):
    emacs_name = '%s-text' % commandName
else:
    try: # User errors in the table can cause this.
        emacs_name = k.inverseCommandsDict.get(command.__name__)
    except Exception:
        emacs_name = None
#@+node:ekr.20061031131434.49: *5* scan
def scan (self,event=None,verbose=True,thread=True):

    c = self.c
    if not c or not c.exists or c.frame.isNullFrame: return
    if g.app.unitTesting: return

    # g.trace('autocompleter')

    if 0: # thread:
        # Use a thread to do the initial scan so as not to interfere with the user.            
        def scan ():
            #g.es("This is for testing if g.es blocks in a thread", color = 'pink' )
            # During unit testing c gets destroyed before the scan finishes.
            if not g.app.unitTesting:
                self.scanOutline(verbose=True)

        t = threading.Thread(target=scan)
        t.setDaemon(True)
        t.start()
    else:
        self.scanOutline(verbose=verbose)
#@+node:ekr.20060127052111.1: *5* cutStack
def cutStack (self):

    u = self ; n = u.max_undo_stack_size

    if n > 0 and u.bead >= n and not g.app.unitTesting:

        # Do nothing if we are in the middle of creating a group.
        i = len(u.beads)-1
        while i >= 0:
            bunch = u.beads[i]
            if hasattr(bunch,'kind') and bunch.kind == 'beforeGroup':
                return
            i -= 1

        # This work regardless of how many items appear after bead n.
        # g.trace('Cutting undo stack to %d entries' % (n))
        u.beads = u.beads[-n:]
        u.bead = n-1
        # g.trace('bead:',u.bead,'len(u.beads)',len(u.beads),g.callers())
#@+node:ekr.20061024075542.1: *5* open
def open (fileName=None):

    global g

    init()

    if g.app.unitTesting:
        return

    if not fileName:
        g.es_print('','leoPymacs.open:','no file name')
        return None

    # openWithFileName checks to see if the file is already open.
    ok, frame = g.openWithFileName(
        fileName,
        old_c=None,
        enableLog=False,
        readAtFileNodesFlag=True)

    c = ok and frame.c or None
    if c:
        g.es_print('','leoPymacs.open:',c)
    else:
        g.es_print('','leoPymacs.open:','can not open',fileName)

    return c
#@+node:ekr.20040715155607: *5* g.scanForAtIgnore
def scanForAtIgnore(c,p):

    """Scan position p and its ancestors looking for @ignore directives."""

    if g.app.unitTesting:
        return False # For unit tests.

    for p in p.self_and_parents():
        d = g.get_directives_dict(p)
        if 'ignore' in d:
            return True

    return False
#@+node:tbrown.20090219095555.61: *5* g.handleUrlInUrlNode
def handleUrlInUrlNode(url):

    # Note: the UNL plugin has its own notion of what a good url is.

    if g.unitTesting: return
    << check the url; return if bad >>
    << pass the url to the web browser >>
#@+node:tbrown.20090219095555.62: *6* << check the url; return if bad >>
@ A valid url is (according to D.T.Hein):

3 or more lowercase alphas, followed by,
one ':', followed by,
one or more of: (excludes !"#;<>[\]^`|)
  $%&'()*+,-./0-9:=?@A-Z_a-z{}~
followed by one of: (same as above, except no minus sign or comma).
  $%&'()*+/0-9:=?@A-Z_a-z}~
@c

urlPattern = "[a-z]{3,}:[\$-:=?-Z_a-z{}~]+[\$-+\/-:=?-Z_a-z}~]"

if not url or len(url) == 0:
    g.es("no url following @url")
    return

# Add http:// if required.
if not re.match('^([a-z]{3,}:)',url):
    url = 'http://' + url
if not re.match(urlPattern,url):
    g.es("invalid url:",url)
    return
#@+node:tbrown.20090219095555.63: *6* << pass the url to the web browser >>
@ Most browsers should handle the following urls:
  ftp://ftp.uu.net/public/whatever.
  http://localhost/MySiteUnderDevelopment/index.html
  file://home/me/todolist.html
@c

try:
    import os
    os.chdir(g.app.loadDir)
    if g.match(url,0,"file:") and url[-4:]==".leo":
        ok,frame = g.openWithFileName(url[5:],None)
    else:
        import webbrowser
        # Mozilla throws a weird exception, then opens the file!
        try: webbrowser.open(url)
        except: pass
except:
    g.es("exception opening",url)
    g.es_exception()
#@+node:ekr.20050920084036.229: *5* yankRectangle
def yankRectangle (self,event,killRect=None):

    '''Yank into the rectangle defined by the start and end of selected text.'''

    c = self.c ; k = self.k
    w = self.editWidget(event)
    if not w: return

    killRect = killRect or self.theKillRectangle
    if g.app.unitTesting:
        # This value is used by the unit test.
        killRect = ['Y1Y','Y2Y','Y3Y','Y4Y']
    elif not killRect:
        k.setLabelGrey('No kill rect') ; return

    w,r1,r2,r3,r4 = self.beginCommand('yank-rectangle')

    n = 0
    for r in range(r1,r3+1):
        # g.trace(n,r,killRect[n])
        if n >= len(killRect): break
        w.delete('%s.%s' % (r,r2), '%s.%s' % (r,r4))
        w.insert('%s.%s' % (r,r2), killRect[n])
        n += 1

    i = '%s.%s' % (r1,r2)
    j = '%s.%s' % (r3,r2+len(killRect[n-1]))
    w.setSelectionRange(i,j,insert=j)

    self.endCommand()
#@+node:ekr.20050920084036.232: *5* stringRectangle
def stringRectangle (self,event):

    '''Prompt for a string, then replace the contents of a rectangle
    with a string on each line.'''

    c = self.c ; k = self.k ; state = k.getState('string-rect')
    if g.app.unitTesting:
        state = 1 ; k.arg = 's...s' # This string is known to the unit test.
        w = self.editWidget(event)
        self.stringRect = self.getRectanglePoints(w)
    if state == 0:
        w = self.editWidget(event) # sets self.w
        if not w or not self.check(event): return
        self.stringRect = self.getRectanglePoints(w)
        k.setLabelBlue('String rectangle: ',protect=True)
        k.getArg(event,'string-rect',1,self.stringRectangle)
    else:
        k.clearState()
        k.resetLabel()
        c.bodyWantsFocus()
        w = self.w
        self.beginCommand('string-rectangle')
        r1, r2, r3, r4 = self.stringRect
        s = w.getAllText()
        for r in range(r1,r3+1):
            i = g.convertRowColToPythonIndex(s,r-1,r2)
            j = g.convertRowColToPythonIndex(s,r-1,r4)
            s = s[:i] + k.arg + s[j:]
        w.setAllText(s)
        i = g.convertRowColToPythonIndex(s,r1-1,r2)
        j = g.convertRowColToPythonIndex(s,r3-1,r2+len(k.arg))
        w.setSelectionRange(i,j)
        self.endCommand()
        # 2010/1/1: Fix bug 480422:
        # string-rectangle kills syntax highlighting.
        c.frame.body.recolor(c.p,incremental=False)

#@+node:ekr.20051218133207: *5* backwardParagraphHelper
def backwardParagraphHelper (self,event,extend):

    w = self.editWidget(event)
    if not w: return

    s = w.getAllText()
    i,j = w.getSelectionRange()
    # A hack for wx gui: set the insertion point to the end of the selection range.
    if g.app.unitTesting:
        w.setInsertPoint(j)
    i,j = g.getLine(s,j)
    line = s[i:j]

    if line.strip():
        # Find the start of the present paragraph.
        while i > 0:
            i,j = g.getLine(s,i-1)
            line = s[i:j]
            if not line.strip(): break

    # Find the end of the previous paragraph.
    while i > 0:
        i,j = g.getLine(s,i-1)
        line = s[i:j]
        if line.strip():
            i = j-1 ; break

    self.moveToHelper(event,i,extend)
#@+node:ekr.20090103070824.11: *5* c.checkFileTimeStamp
def checkFileTimeStamp (self,fn):

    '''
    Return True if the file given by fn has not been changed
    since Leo read it or if the user agrees to overwrite it.
    '''

    trace = False and not g.unitTesting
    c = self

    # Don't assume the file still exists.
    if not g.os_path_exists(fn):
        if trace: g.trace('file no longer exists',fn)
        return True

    timeStamp = c.timeStampDict.get(fn)
    if not timeStamp:
        if trace: g.trace('no time stamp',fn)
        return True

    timeStamp2 = os.path.getmtime(fn)
    if timeStamp == timeStamp2:
        if trace: g.trace('time stamps match',fn,timeStamp)
        return True

    if g.app.unitTesting:
        return False

    if trace:
        g.trace('mismatch',timeStamp,timeStamp2)

    message = '%s\n%s\n%s' % (
        fn,
        g.tr('has been modified outside of Leo.'),
        g.tr('Overwrite this file?'))
    ok = g.app.gui.runAskYesNoCancelDialog(c,
        title = 'Overwrite modified file?',
        message = message)

    return ok == 'yes'
#@+node:ekr.20031218072017.2817: *5*  doCommand
command_count = 0

def doCommand (self,command,label,event=None):

    """Execute the given command, invoking hooks and catching exceptions.

    The code assumes that the "command1" hook has completely handled the command if
    g.doHook("command1") returns False.
    This provides a simple mechanism for overriding commands."""

    c = self ; p = c.p
    commandName = command and command.__name__
    c.setLog()

    self.command_count += 1
    if not g.app.unitTesting and c.config.getBool('trace_doCommand'):
        g.trace(commandName)

    # The presence of this message disables all commands.
    if c.disableCommandsMessage:
        g.es(c.disableCommandsMessage,color='blue')
        return 'break' # Inhibit all other handlers.

    if c.exists and c.inCommand and not g.unitTesting:
        # g.trace('inCommand',c)
        g.es('ignoring command: already executing a command.',color='red')
        return 'break'

    if label and event is None: # Do this only for legacy commands.
        if label == "cantredo": label = "redo"
        if label == "cantundo": label = "undo"
        g.app.commandName = label

    if not g.doHook("command1",c=c,p=p,v=p,label=label):
        try:
            c.inCommand = True
            val = command(event)
            if c and c.exists: # Be careful: the command could destroy c.
                c.inCommand = False
                c.k.funcReturn = val
            # else: g.pr('c no longer exists',c)
        except Exception:
            c.inCommand = False
            if g.app.unitTesting:
                raise
            else:
                g.es_print("exception executing command")
                g.es_exception(c=c)

        if c and c.exists:
            if c.requestCloseWindow:
                g.trace('Closing window after command')
                c.requestCloseWindow = False
                g.app.closeLeoWindow(c.frame)
            else:
                c.outerUpdate()

    # Be careful: the command could destroy c.
    if c and c.exists:
        p = c.p
        g.doHook("command2",c=c,p=p,v=p,label=label)

    return "break" # Inhibit all other handlers.
#@+node:ekr.20090712050729.6017: *5* promptForDangerousWrite
def promptForDangerousWrite (self,fileName,kind):

    c = self.c

    if g.app.unitTesting:
        val = g.app.unitTestDict.get('promptForDangerousWrite')
        return val in (None,True)

    # g.trace(timeStamp, timeStamp2)
    message = '%s %s\n%s\n%s' % (
        kind, fileName,
        g.tr('already exists.'),
        g.tr('Overwrite this file?'))

    ok = g.app.gui.runAskYesNoCancelDialog(c,
        title = 'Overwrite existing file?',
        message = message)

    return ok == 'yes'
#@+node:ekr.20070529083836: *5* cleanLines
def cleanLines (self,p,s):

    '''Return a copy of s, with all trailing whitespace removed.
    If a change was made, update p's body text and set c dirty.'''

    c = self.c ; cleanLines = [] ; changed = False
    lines = g.splitLines(s)
    for line in lines:
        if line.strip():
            cleanLines.append(line)
        elif line.endswith('\n'):
            cleanLines.append('\n')
            if line != '\n': changed = True
        else:
            cleanLines.append('')
            if line != '': changed = True
    s = g.joinLines(cleanLines)

    if changed and not g.app.unitTesting:
        p.setBodyString(s)
        c.setChanged(True)

    return s
#@+node:ekr.20080711093251.5: *5* at.writeOneAtShadowNode & helpers
def writeOneAtShadowNode(self,p,toString,force):

    '''Write p, an @shadow node.

    File indices *must* have already been assigned.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; root = p.copy() ; x = c.shadowController

    fn = p.atShadowFileNodeName()
    if trace: g.trace(p.h,fn)
    if not fn:
        g.es_print('can not happen: not an @shadow node',p.h,color='red')
        return False

    # A hack to support unknown extensions.
    self.adjustTargetLanguage(fn) # May set c.target_language.

    fn = at.fullPath(p)
    at.default_directory = g.os_path_dirname(fn)
    exists = g.os_path_exists(fn)
    if trace: g.trace('exists %s fn %s' % (exists,fn))

    # Bug fix 2010/01/18: Make sure we can compute the shadow directory.
    private_fn = x.shadowPathName(fn)
    if not private_fn:
        return False

    if not toString and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @shadow node would overwrite the existing public file.
        ok = self.promptForDangerousWrite(fn,kind='@shadow')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return

    c.endEditing() # Capture the current headline.
    at.initWriteIvars(root,targetFileName=None, # Not used.
        atShadow=True,
        nosentinels=None, # set below.  Affects only error messages (sometimes).
        thinFile=True, # New in Leo 4.5 b2: private files are thin files.
        scriptWrite=False,
        toString=False, # True: create a fileLikeObject.  This is done below.
        forcePythonSentinels=True) # A hack to suppress an error message.
            # The actual sentinels will be set below.

    # Bug fix: Leo 4.5.1: use x.markerFromFileName to force the delim to match
    #                     what is used in x.propegate changes.
    marker = x.markerFromFileName(fn)
    at.startSentinelComment,at.endSentinelComment=marker.getDelims()

    if g.app.unitTesting: ivars_dict = g.getIvarsDict(at)

    # Write the public and private files to public_s and private_s strings.
    data = []
    for sentinels in (False,True):
        theFile = at.openStringFile(fn)
        at.sentinels = sentinels
        at.writeOpenFile(root,
            nosentinels=not sentinels,toString=False)
            # nosentinels only affects error messages, and then only if atAuto is True.
        s = at.closeStringFile(theFile)
        data.append(s)

    # Set these new ivars for unit tests.
    at.public_s, at.private_s = data

    if g.app.unitTesting:
        exceptions = ('public_s','private_s','sentinels','stringOutput')
        assert g.checkUnchangedIvars(at,ivars_dict,exceptions)

    if at.errors == 0 and not toString:
        # Write the public and private files.
        if trace: g.trace('writing',fn)
        x.makeShadowDirectory(fn) # makeShadowDirectory takes a *public* file name.
        at.replaceFileWithString(private_fn,at.private_s)
        at.replaceFileWithString(fn,at.public_s)

    self.checkPythonCode(root,s=at.private_s,targetFn=fn)

    if at.errors == 0:
        root.clearOrphan()
        root.clearDirty()
    else:
        g.es("not written:",at.outputFileName,color='red')
        root.setDirty() # New in Leo 4.4.8.

    return at.errors == 0
#@+node:ekr.20080819075811.13: *6* adjustTargetLanguage
def adjustTargetLanguage (self,fn):

    """Use the language implied by fn's extension if
    there is a conflict between it and c.target_language."""

    at = self ; c = at.c

    if c.target_language:
        junk,target_ext = g.os_path_splitext(fn)  
    else:
        target_ext = ''

    junk,ext = g.os_path_splitext(fn)

    if ext:
        if ext.startswith('.'): ext = ext[1:]

        language = g.app.extension_dict.get(ext)
        if language:
            c.target_language = language
        else:
            # An unknown language.
            pass # Use the default language, **not** 'unknown_language'
#@+node:bwmulder.20050101094804: *5* at.openForWrite
def openForWrite (self, filename, wb='wb'):

    '''Open a file for writes, handling shadow files.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; x = c.shadowController

    try:
        shadow_filename = x.shadowPathName(filename)
        self.writing_to_shadow_directory = os.path.exists(shadow_filename)
        open_file_name       = g.choose(self.writing_to_shadow_directory,shadow_filename,filename)
        self.shadow_filename = g.choose(self.writing_to_shadow_directory,shadow_filename,None)

        if self.writing_to_shadow_directory:
            if trace: g.trace(filename,shadow_filename)
            x.message('writing %s' % shadow_filename)
            return 'shadow',open(open_file_name,wb)
        else:
            ok = c.checkFileTimeStamp(at.targetFileName)
            return 'check',ok and open(open_file_name,wb)

    except IOError:
        if not g.app.unitTesting:
            g.es_print('openForWrite: exception opening file: %s' % (open_file_name),color='red')
            g.es_exception()
        return 'error',None
#@+node:ekr.20031218072017.2609: *5* app.closeLeoWindow
def closeLeoWindow (self,frame):

    """Attempt to close a Leo window.

    Return False if the user veto's the close."""

    c = frame.c

    # g.trace('frame',frame,g.callers(4))

    c.endEditing() # Commit any open edits.

    if c.promptingForClose:
        # There is already a dialog open asking what to do.
        return False

    g.app.config.writeRecentFilesFile(c)
        # Make sure .leoRecentFiles.txt is written.

    if c.changed:
        c.promptingForClose = True
        veto = frame.promptForSave()
        c.promptingForClose = False
        if veto: return False

    g.app.setLog(None) # no log until we reactive a window.

    g.doHook("close-frame",c=c)
        # This may remove frame from the window list.

    if frame in g.app.windowList:
        g.app.destroyWindow(frame)

    if g.app.windowList:
        # Pick a window to activate so we can set the log.
        frame = g.app.windowList[0]
        frame.deiconify()
        frame.lift()
        frame.c.setLog()
        frame.c.bodyWantsFocus()
        frame.c.outerUpdate()
    elif not g.app.unitTesting:
        g.app.finishQuit()

    return True # The window has been closed.
#@+node:ekr.20041113113140: *5* loadOnePlugin
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.endswith('.py'):
        moduleName = 'leo.plugins.' + moduleOrFileName [:-3]
    else:
        moduleName = moduleOrFileName
    #moduleName = g.shortFileName(moduleName)

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    #plugins_path = g.os_path_finalize_join(g.app.loadDir,"..","plugins")
    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)
    #result = g.importFromPath(moduleName,plugins_path,pluginName=moduleName,verbose=True)
    #print "imp", moduleName
    try:
        toplevel = __import__(moduleName)
        # need to look up through sys.modules, __import__ returns toplevel package
        result = sys.modules[moduleName]

    except Exception as e:
        g.es_print('exception importing plugin ' + moduleName,color='red')
        g.es_exception()
        result = None

    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@+node:ekr.20031218072017.2829: *5* c.openTempFileInExternalEditor
def openTempFileInExternalEditor(self,arg,fn,openType,testing=False):

    '''Open the closed mkstemp file fn in an external editor.
    The arg and openType args come from the data arg to c.openWith.
    '''

    trace = False and not g.unitTesting
    testing = testing or g.unitTesting
    if arg is None: arg = ''

    try:
        if trace: g.trace(repr(openType),repr(arg),repr(fn))
        command = '<no command>'
        if openType == 'os.system':
            if 1:
                # This works, *provided* that arg does not contain blanks.  Sheesh.
                command = 'os.system(%s)' % (arg+fn)
                if trace: g.trace(command)
                if not testing: os.system(arg+fn)
            else:
                # XP does not like this format!
                command = 'os.system("%s %s")' % (arg,fn)
                if not testing: os.system('"%s" "%s"' % (arg,fn))
        elif openType == 'os.startfile':
            command = 'os.startfile(%s)' % (arg+fn)
            if trace: g.trace(command)
            if not testing: os.startfile(arg+fn)
        elif openType == 'exec':
            command = 'exec(%s)' % (arg+fn)
            if trace: g.trace(command)
            if not testing: exec(arg+fn,{},{})
        elif openType == 'os.spawnl':
            filename = g.os_path_basename(arg)
            command = 'os.spawnl(%s,%s,%s)' % (arg,filename,fn)
            if trace: g.trace(command)
            if not testing: os.spawnl(os.P_NOWAIT,arg,filename,fn)
        elif openType == 'os.spawnv':
            filename = os.path.basename(arg[0]) 
            vtuple = arg[1:]
            vtuple.insert(0, filename)
                # add the name of the program as the first argument.
                # Change suggested by Jim Sizelove.
            vtuple.append(fn)
            command = 'os.spawnv(%s,%s)' % (arg[0],repr(vtuple))
            if trace: g.trace(command)
            if not testing: os.spawnv(os.P_NOWAIT,arg[0],vtuple)
        elif openType == 'subprocess.Popen':
            use_shell = True
            if g.isString(arg):
                if arg:
                    vtuple = arg + ' ' + fn
                else:
                    vtuple = fn
            elif isinstance(arg,(list, tuple)):
                vtuple = arg[:]
                vtuple.append(fn)
                use_shell = False
            command = 'subprocess.Popen(%s)' % repr(vtuple)
            if trace: g.trace(command)
            if not testing:
                try:
                    subprocess.Popen(vtuple,shell=use_shell)
                except OSError:
                    g.es_print('vtuple',repr(vtuple))
                    g.es_exception()
        elif g.isCallable(openType):
            # Invoke openWith like this:
            # c.openWith(data=[f,None,None])
            # f will be called with one arg, the filename
            if trace: g.trace('%s(%s)' % (openType,fn))
            command = '%s(%s)' % (openType,fn)
            if not testing: openType(fn)
        else:
            command='bad command:'+str(openType)
            if not testing: g.trace(command)
        return command # for unit testing.
    except Exception:
        g.es('exception executing open-with command:',command)
        g.es_exception()
        return 'oops: %s' % command
#@+node:ekr.20031218072017.1151: *5* tangle.put_all_roots
@
This is the top level method of the second pass. It creates a separate derived file
for each @root directive in the outline. The file is actually written only if
the new version of the file is different from the old version,or if the file did
not exist previously. If changed_only_flag FLAG is True only changed roots are
actually written.
@c

def put_all_roots(self):

    c = self.c ; outline_name = c.mFileName

    for section in self.root_list:

        # g.trace(section.name)
        file_name = c.os_path_finalize_join(self.tangle_directory,section.name)
        mode = c.config.output_newline
        textMode = mode == 'platform'
        if g.unitTesting:
            self.output_file = g.fileLikeObject()
            temp_name = 'temp-file'
        else:
            self.output_file,temp_name = g.create_temp_file(textMode=textMode)
        if not temp_name:
            g.es("can not create temp file")
            break
        <<Get root specific attributes>>
        <<Put @first lines>>
        if self.use_header_flag and self.print_mode == "verbose":
            << Write a banner at the start of the output file >>
        for part in section.parts:
            if part.is_root:
                self.tangle_indent = 0 # Initialize global.
                self.put_part_node(part,False) # output first lws
        self.onl() # Make sure the file ends with a cr/lf
        << unit testing fake files>>
        self.output_file.close()
        self.output_file = None
        << unit testing set result and continue >>
        if self.errors + g.app.scanErrors == 0:
            g.update_file_if_changed(c,file_name,temp_name)
        else:
            g.es("unchanged:",file_name)
            << Erase the temporary file >>
#@+node:ekr.20031218072017.1152: *6* <<Get root specific attributes>>
# Stephen Schaefer, 9/2/02
# Retrieve the full complement of state for the root node
self.language = section.root_attributes.language
self.use_header_flag = section.root_attributes.use_header_flag
self.print_mode = section.root_attributes.print_mode
self.path = section.root_attributes.path
self.page_width = section.root_attributes.page_width
self.tab_width = section.root_attributes.tab_width
# Stephen P. Schaefer, 9/13/2002
self.first_lines = section.root_attributes.first_lines
#@+node:ekr.20031218072017.1153: *6* <<Put @first lines>>
# Stephen P. Schaefer 9/13/2002
if self.first_lines:
    self.os(self.first_lines)
#@+node:ekr.20031218072017.1154: *6* <<Write a banner at the start of the output file>>
# a root section must have at least one part
assert len(section.parts)>0
delims=section.parts[0].delims
if delims[0]:
    self.os(delims[0])
    self.os(" Created by Leo from: ")
    self.os(outline_name)
    self.onl() ; self.onl()
elif delims[1] and delims[2]:
    self.os(delims[1])
    self.os(" Created by Leo from: ")
    self.os(outline_name)
    self.oblank() ; self.os(delims[2])
    self.onl() ; self.onl()
#@+node:ekr.20031218072017.1155: *6* << Erase the temporary file >>
try: # Just delete the temp file.
    os.remove(temp_name)
except: pass
#@+node:sps.20100608083657.20937: *6* << unit testing fake files>>
if g.unitTesting:
    # complications to handle testing of multiple @root directives together with
    # @path directives
    file_name_path = file_name
    if (file_name_path.find(c.openDirectory) == 0):
        relative_path = file_name_path[len(c.openDirectory):]
        # don't confuse /u and /usr as having common prefixes
        if (relative_path[:len(os.sep)] == os.sep):
             file_name_path = relative_path[len(os.sep):]
    self.tangle_output[file_name_path] = self.output_file.get()
#@+node:sps.20100608083657.20938: *6* << unit testing set result and continue >>
if g.unitTesting:
    assert self.errors == 0
    g.app.unitTestDict ['tangle'] = True
    g.app.unitTestDict ['tangle_directory'] = self.tangle_directory
    if g.app.unitTestDict.get('tangle_output_fn'):
        g.app.unitTestDict['tangle_output_fn'] += "\n" + file_name
    else:
        g.app.unitTestDict ['tangle_output_fn'] = file_name
    continue
#@+node:ekr.20041005105605.15: *5* initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels,
            issuePathWarning=True)

    # g.trace(forcePythonSentinels,
    #    self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16: *6* << init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the
temporary file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False
    # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.writeVersion5 = self.new_write and not atShadow

self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@+node:ekr.20100206173123.5801: *4* Fix or eliminate check python syntax commands
@nocolor-node

Directives and section references are not the problem. Rather, the problems are
thinks like 'return' in a node that doesn't look it is in a function.

The solution would likely be to check the entire file at once in checkPython
code. But this won't work for the check-all-python-code command.

Do we really need these checks? I think not, because the automatic checks work
so well.
#@+node:ekr.20100206142026.5967: *5* To do: use g.checkPythonNode as the base of all syntax checking
#@+node:ekr.20040723094220.5: *6* c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@+node:EKR.20040614071102.1: *6* g.getScript
def getScript (c,p,useSelectedText=True,forcePythonSentinels=True,useSentinels=True):

    '''Return the expansion of the selected text of node p.
    Return the expansion of all of node p's body text if there
    is p is not the current node or if there is no text selection.'''

    # New in Leo 4.6 b2: use a pristine atFile handler
    # so there can be no conflict with c.atFileCommands.
    # at = c.atFileCommands
    import leo.core.leoAtFile as leoAtFile
    at = leoAtFile.atFile(c)

    w = c.frame.body.bodyCtrl
    p1 = p and p.copy()
    if not p:
        p = c.p
    try:
        if g.app.inBridge:
            s = p.b
        elif p1:
            s = p.b # Bug fix: Leo 8.8.4.
        elif p == c.p:
            if useSelectedText and w.hasSelection():
                s = w.getSelectedText()
            else:
                s = w.getAllText()
        else:
            s = p.b
        # Remove extra leading whitespace so the user may execute indented code.
        s = g.removeExtraLws(s,c.tab_width)
        if s.strip():
            g.app.scriptDict["script1"]=s
            # Important: converts unicode to utf-8 encoded strings.
            script = at.writeFromString(p.copy(),s,
                forcePythonSentinels=forcePythonSentinels,
                useSentinels=useSentinels)
            script = script.replace("\r\n","\n") # Use brute force.
            # Important, the script is an **encoded string**, not a unicode string.
            g.app.scriptDict["script2"]=script
        else: script = ''
    except Exception:
        g.es_print("unexpected exception in g.getScript")
        g.es_exception()
        script = ''

    # g.trace(type(script),repr(script))
    return script
#@+node:ekr.20050506084734: *6* at.writeFromString
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@+node:ekr.20100206142026.5839: *6* g.checkPythonNode & helper (NEW)
def checkPythonNode (c,s,fn=None,p=None,
    munge=False,suppressErrors=False,
    tabNanny=False,unittest=False,
    suppressErrors=False,
):

    '''The future base of all syntax checking'''

    if not s.strip():
        return
    if munge:
        at = c.atFileCommands
        s = g.toUnicode(s)
        at.writeFromString(p=None,s=s,
            forcePythonSentinels=True,useSentinels=True)
    if not s.strip():
        return
    if fn:
        pass
    elif p:
        fn = '<node: %s>' % p.h
    else:
        fn = '<string'>
    try:
        if not g.isPython3:
            s = g.toEncodedString(s)
        s = s.replace('\r','')
        compile(s+'\n',fn,'exec')
        if tabNanny:
            c.tabNannyNode(p,h,s,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=True,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise
#@+node:ekr.20100206142026.5840: *7* checkPythonNodeHelper
def checkPythonNodeHelper (c,s):




    return g.toUnicode(
        .writeFromString(p = None,s=s,
        forcePythonSentinels=True,useSentinels=True)
#@+node:ekr.20060624085200: *6* g.handleScriptException
def handleScriptException (c,p,script,script1):

    g.es("exception executing script",color='blue')

    full = c.config.getBool('show_full_tracebacks_in_scripts')

    fileName, n = g.es_exception(full=full)

    if p and not script1 and fileName == "<string>":
        c.goToScriptLineNumber(p,script,n)

    << dump the lines near the error >>
#@+node:EKR.20040612215018: *7* << dump the lines near the error >>
if g.os_path_exists(fileName):
    f = open(fileName)
    lines = f.readlines()
    f.close()
else:
    lines = g.splitLines(script)

s = '-' * 20
g.es_print('',s)

# Print surrounding lines.
i = max(0,n-2)
j = min(n+2,len(lines))
while i < j:
    ch = g.choose(i==n-1,'*',' ')
    s = "%s line %d: %s" % (ch,i+1,lines[i])
    g.es('',s,newline=False)
    i += 1
#@+node:ekr.20040723094220: *5* Check Outline commands & allies
#@+node:ekr.20040723094220.1: *6* c.checkAllPythonCode
def checkAllPythonCode(self,event=None,unittest=False,ignoreAtIgnore=True):

    '''Check all nodes in the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    for p in c.all_unique_positions():
        count += 1
        if not unittest:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not g.scanForAtSettings(p) and (
                not ignoreAtIgnore or not g.scanForAtIgnore(c,p)
            ):
                try:
                    c.checkPythonNode(p,unittest)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort
                if unittest and result != "ok":
                    g.pr("Syntax error in %s" % p.cleanHeadString())
                    return result # End the unit test: it has failed.

    if not unittest:
        g.es("check complete",color="blue")

    return result
#@+node:ekr.20040723094220.2: *7* << print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@+node:ekr.20040723094220.3: *6* c.checkPythonCode
def checkPythonCode (self,event=None,
    unittest=False,ignoreAtIgnore=True,
    suppressErrors=False,checkOnSave=False):

    '''Check the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    if not unittest:
        g.es("checking Python code   ")

    for p in c.p.self_and_subtree():

        count += 1
        if not unittest and not checkOnSave:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not ignoreAtIgnore or not g.scanForAtIgnore(c,p):
                try:
                    c.checkPythonNode(p,unittest,suppressErrors)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort

    if not unittest:
        g.es("check complete",color="blue")

    # We _can_ return a result for unit tests because we aren't using doCommand.
    return result
#@+node:ekr.20040723094220.4: *7* << print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@+node:ekr.20040723094220.5: *6* c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@+node:ekr.20040723094220.6: *6* c.tabNannyNode
# This code is based on tabnanny.check.

def tabNannyNode (self,p,headline,body,unittest=False,suppressErrors=False):

    """Check indentation using tabnanny."""

    c = self

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))

    except IndentationError:
        junk,msg,junk = sys.exc_info()
        if not suppressErrors:
            g.es("IndentationError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        if not suppressErrors:
            g.es("TokenError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        if not suppressErrors:
            badline = nag.get_lineno()
            line    = nag.get_line()
            message = nag.get_msg()
            g.es("indentation error in",headline,"line",badline,color="blue")
            g.es(message)
            line2 = repr(str(line))[1:-1]
            g.es("offending line:\n",line2)
        if unittest: raise

    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
        if unittest: raise
#@+node:ekr.20090811141250.5955: *3* Most important features
@ Important: There is another features list for 4.9.
#@+node:ekr.20100520070413.5878: *4* Drag and drop for qt gui
#@+node:ekr.20100128094926.6222: *4*  port pmw to py3k
- Check web site first!
- Create new branch for pmw work.
#@+node:ekr.20090801103907.6018: *4* Add entries to global dicts for more languages
http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780

Especially languages in leo/modes.
#@+node:ekr.20090816125009.5993: *5* @url http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780
#@+node:ekr.20090814190307.5983: *5* print all modes/*.py files
import glob

theDir = g.os_path_finalize_join(g.app.loadDir,'..','modes','*.py')

aList = glob.glob(theDir)

for z in aList:
    print g.os_path_basename(z)

@
Exist:

    "ada"   : "ada",
    "adb"   : "ada",
    "ahk"   : "autohotkey",  # EKR: 2009-01-30.
    "as"    : "actionscript",
    "bas"   : "rapidq",
    "bat"   : "batch",
    "c"     : "c",
    "cfg"   : "config",
    "cpp"   : "cpp",
    "css"   : "css",
    "el"    : "elisp",
    "forth" : "forth",
    "f"     : "fortran",
    "f90"   : "fortran90",
    "h"     : "c",
    "html"  : "html",
    "ini"   : "ini",
    "java"  : "java",
    "ksh"   : "kshell", # Leo 4.5.1.
    "lua"   : "lua",  # ddm 13/02/06
    "nw"    : "noweb",
    "otl"   : "vimoutline",  #TL 8/25/08 Vim's outline plugin
    "p"     : "pascal",
    "pl"    : "perl",   # 11/7/05
    "pod"   : "perlpod", # 11/7/05
    "php"   : "php",
    "py"    : "python",
    "sql"   : "plsql", # qt02537 2005-05-27
    "r"     : "rebol",
    "rb"    : "ruby", # thyrsus 2008-11-05
    "rest"  : "rst",
    "rst"   : "rst",
    "sh"    : "shell",
    "tex"   : "tex",
    "txt"   : "plain",
    "tcl"   : "tcltk",
    "vim"   : "vim",
"w"     : "cweb",
"xml"   : "xml",
"xsl"   : "xslt",

Add first:


ada95.py
antlr.py
apacheconf.py
apdl.py
applescript.py
asp.py
aspect_j.py
assembly_macro32.py
assembly_mcs51.py
assembly_parrot.py
assembly_r2000.py
assembly_x86.py
awk.py
b.py
batch.py
bbj.py
bcel.py
bibtex.py
c.py
chill.py
cobol.py
coldfusion.py
cplusplus.py
csharp.py
css.py
cvs_commit.py
d.py
doxygen.py
dsssl.py
eiffel.py
embperl.py
erlang.py
factor.py
forth.py
fortran.py
fortran90.py
foxpro.py
freemarker.py
gettext.py
groovy.py
haskell.py
hex.py
html.py
i4gl.py
icon.py
idl.py
inform.py
ini.py
inno_setup.py
interlis.py
io.py
java.py
javascript.py
jcl.py
jhtml.py
jmk.py
jsp.py
latex.py
lilypond.py
lisp.py
lotos.py
lua.py
mail.py
makefile.py
maple.py
matlab.py
ml.py
modula3.py
moin.py
mqsc.py
netrexx.py
nqc.py
nsis2.py
objective_c.py
objectrexx.py
occam.py
omnimark.py
pascal.py
patch.py
perl.py
php.py
phpsection.py
pike.py
pl1.py
plain.py
plsql.py
pop11.py
postscript.py
povray.py
powerdynamo.py
progress.py
prolog.py
props.py
psp.py
ptl.py
pvwave.py
pyrex.py
python.py
r.py
rebol.py
redcode.py
relax_ng_compact.py
rest.py
rhtml.py
rib.py
rpmspec.py
rtf.py
ruby.py
rview.py
sas.py
scheme.py
sdl_pr.py
sgml.py
shell.py
shellscript.py
shtml.py
smalltalk.py
smi_mib.py
splus.py
sqr.py
squidconf.py
ssharp.py
svn_commit.py
swig.py
tcl.py
tex.py
texinfo.py
text.py
tpl.py
tsql.py
uscript.py
vbscript.py
velocity.py
verilog.py
vhdl.py
xml.py
xsl.py
zpt.py
__init__.py
#@+node:ekr.20090601083544.6051: *4* Add expand_noweb_references for rst3 plugin
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/3cd5cb06d32264d

> What would work for me is if named sections in a @rst subtree
> would work exactly as they work for other derived files: they
> get inserted at the place where they are referenced.

- Add support for the following options:
    - expand_noweb_references: default False for compatibility.
    - ignore_noweb definitions: default False for compatibility.

- When expand_noweb_references is True, definitions (typically clones)
  must be descendants of the referencing node (in the @rst tree)
#@+node:ekr.20090601083544.6052: *5* post
@nocolor-node

I want to write the documentation for the source program in a @rst3 subtree. In
this @rst3 subtree I want to refer to fragments of the program, like:

In the following code fragment::

  <<code fragment>>

Unfortunately, <<code fragment>> will not be expanded. Furthermore, in order to
get to this work, I should have <<code fragment>> under the @rst3 subtree as
well, but this is then also treated as @rst3 input (which in this case, is not
what I want).
#@+node:ekr.20080918164844.12: *4* Improve headline navigation
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/bce1065d9a332fcd

Now that the leo is more "modeless" (I'm speaking of switching between
outline navigation and body editing modes), which btw is a clear improvement
to how leo used to behave, here are some things that still feel a bit
un-intuitive:

- ctrl+H (edit-headline) "locks" the user into the mode way too much.

   * The headline editing mode should be cancelled when the user does:
      - cursor up/down
      - ESC

   * Even better alternative: I find myself constantly thinking that "ok,
now I need to edit a headline (typically not the current headline), so now
I'll press ctrl+H". I think perhaps pressing up/down should cancel the
current headline editing, and select the next/previous headline for editing.
That is, I wouldn't need to navigate to the headline I want to edit before I
start editing it.

  - cut-node (ctrl+shift+x) selects the wrong node after the cut. The
intuitive assumption is that cut will select the node that "took the place
of the
    current node", instead of starting to travel upwards the set of nodes.

   * Typical use case is the way you usually start deleting a set of items.
You move to the first item and start cutting repeatedly. This wont work with
the current behaviour. 
#@+node:ekr.20080730212711.7: *4* Improve plugins handling
@nocolor-node

- Don't repeat "can not load <plugin>" messages.

- Unify print-plugins and print-plugins-info commands, and make them more informative.

- Fix the plugin mess.

    - Create a way to unload a plugin.  This should be relatively easy.
#@+node:ekr.20090804105939.5993: *5* Possibly redo how plugins are loaded
#@+node:ekr.20080313032655.2: *5* Once a plugin is enabled, it is always enabled
#@+node:ekr.20080923200153.1: *5* Support scan-directives hook again?
# This affects the add_directives plugin.
# Also, the color_markup plugin doesn't work with the threading colorizer.
#@+node:ekr.20080421140032.1: *5* Fix multiple controllers problem in all plugins
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/663e1f9d8e2d1c24

@color
#@+node:ekr.20090724081340.5987: *4* Improve recursive import script and @auto
@nocolor-node

Instead of adding an @ignore directive, it might be better
to change @auto to @@auto.

Should @auto be more lenient with C files?

Improve the recursive import script.
    - Minimize the path names
    - Option to include/exclude the @auto itself

#@+node:ekr.20090907080624.6081: *4* Spell checker should check headlines
#@+node:ekr.20071001052501: *4* Versioning for nodes
@nocolor

One feature I have not seen in SCS system is something which might be called
"history compression": I might be interested in having both version 5 and 6
in my source tree, when the current version is 7, but I am not really interested
in the 2000 steps which transformed 5 into 6 (just suggested this feature to
the bazaar people). This happens actually quite often to me, since I use the
SCS as a back-up system, saving many (uninteresting) intermediate steps while
implementing a new feature.
#@+node:ekr.20100209114432.5750: *3* Better screen shots
- Better screen shots.
#@+node:ekr.20100206074650.5843: ** 4.9 Autocompletion
#@+node:ekr.20090131200406.14: *3* autocompletion
#@+node:ekr.20100506062734.5756: *4* Ville post re autocompleter
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/ee84e52fba476950

> Some of the UI's I've worked with involved going into a state where
> you picked from a numbered, or lettered list of possibilities
> generated based on the currently typed "trigger".  e.g. and expansion
> of trigger "ct" puts a ine like the following in, say, the status
> line:

Note that all design work is unnecessary - this is basically a simple
matter of bugfixing.

qtGui has this method:

http://pastebin.com/GmhZJqDd

Once you can call

w.showCompleter(['hello', 'helloworld'], mycallback )

and select the correct alternative naturally with keyboard (now you
need mouse), almost all of the work is done.

The rest can be provided by codewisecompleter, or any other kind of
completer we may wish to add (e.g. hippie-expand, abbrev expand...).

All discussion regarding the ui design only helps to sidetrack us from
getting a completer that behaves the way completers are "supposed to
behave" on 2010, i.e. the way provided by QCompleter.

-- 
Ville M. Vainio 
#@+node:ekr.20081005065934.12: *4* Links from Ville re Scintilla
@nocolor-node

It seems Scintilla relies on externally generated api description
files to provide autocompletion. Links that may be of interest:

http://www.riverbankcomputing.co.uk/static/Docs/QScintilla2/classQsciAPIs.html#b0f824492bb0f3ca54edb4d46945a3de

http://www.burgaud.com/scite-java-api/

http://scintilla.sourceforge.net/tags2api.py

http://www.koders.com/python/fid7000B9C96CF2C6FB5BCE9DF700365C5B2A1F36A7.aspx?s=gtk#L53
#@+node:ekr.20080113165010: *4* About auto completion
@nocolor

Summary: inspect when possible, ask for types otherwise.

    os.? gives a list of all instances of os module.
    x.? gives a list of all known classes.
    x.# gives list of all known functions.
    self.? gives all known methods and ivars of the enclosing class.
    The user will be able to specify type conventsions, like Leo's c,g,p,t,v vars.

Completed (mostly): user interface stuff.

Performance isn't too hard:
    - Do all scanning in separate threads.
    - Associate node info with tnodes.
    - Update node info when deselecting a node (in tree base class)

Parsing:
    - Forgiving parser is essentially complete.
    - It's easy to parse python def lines.
#@+node:ekr.20080110082845: *4* pyxides: code completion
@nocolor

Python code completion module


From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 20:57:18 +0300

I've been developing IDLE over the past 2 years or so. Even before
that, I helped a friend of mine, Noam Raphael, write IDLE's
auto-completion, which is included in recent versions of IDLE.

Noam wrote the original completion code from scratch, and AFAIK every
Python IDE which features code completion has done the same. Surely
there is -some- functionality which could be useful cross-IDE?
Retrieving possible completions from the namespace, for example. And
we should be learning from each-others' ideas and experiences.

So how about we design a generic Python completion module, that
each IDE could extend, and use for the completion logic?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:06:01 +0100

I am very keen for this. I will help where it is required. PIDA
currently has no code completion (outside what vim/emacs provide),



From: "phil jones" <inters...@gmail.com>
Date: Wed, 6 Jun 2007 11:07:33 -0700

What functions would we ask for a code completion module?

Presumably recognition of the beginnings of
- a) python keywords
- b) classes and functions defined earlier in this file?
- c) in scope variables?

As python is dynamically typed, I guess we can't expect to know the
names of methods of objects?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:13:10 +0100

> Presumably recognition of the beginnings of
> - a) python keywords
> - b) classes and functions defined earlier in this file?
> - c) in scope variables?

does c) include: d) imported modules



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 20:17:30 +0200

> >Presumably recognition of the beginnings of
> >- a) python keywords
> >- b) classes and functions defined earlier in this file?
> >- c) in scope variables?

> does c) include: d) imported modules

For code-completion, I suppose astng[1] could be useful.

1: http://www.logilab.org/project/eid/856



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:48:41 +0200

A good point. I think we all have been thinking about this. Important
issues for the design is the extraction method and the sources.

*the method*
Importing is a lazy, but accurate way of importing, but is security wise
not such a good idea. Parsing throught an AST compiler is better,
however more difficult. Here are two options.

From version 2.5 the standard Python compiler converts internally the
source code to an abstract syntax tree (AST) before producing the
bytecode. So probably that is a good way to go as every python
distribution has this battery included.

As Nicolas suggested earlier on this mailing list, there is another
option: the AST compiler in python or PyPy:

On Mar 14 2006, 12:16 am, Nicolas Chauvat <nicolas.chau...@logilab.fr>
wrote:

> > WingIDE use anASTgenerator written in C (but cross-platform),
> > lightningly quick, and open sourced. This could be a potential
> > starting point.

> > Additionally isn't Python2.5 planned to have a C-written compiler?

> PyPy also produced an improved parser/compiler.

> http://codespeak.net/pypy/dist/pypy/doc/index.html
> http://codespeak.net/pypy/dist/pypy/module/recparser/

But if it could be done with the standard one it is one dependency less.

*the sources*
In the design we could define first the sources:
1 external imported modules from the pythonpath
2 local modules relative to the current file or context dependent
(Blender, Gimp, ...)
3 inner code

For 1:
It might be a good idea to have a function which scans all the modules
from the pythonpath or one specific module to cache all autocompletion
and calltip information of all classes, methods and doc strings. Why?
Modules in the pythonpath don't change so often. With some criteria
(file name, time stamp, size, ...) you could check if updates are
necessary at startup. Having a readymade 'database' (could be python
dictionary or sqlite database) for autocompletion/call tips would speed
up things (and is also more secure if you are importing rather than
parsing. For example trying to provide gtk autocompletion in a wxPython
by importing is problematic).

For 2:
Here you load the parser on demand. Autocompletion/calltip information
can be added to the database.

For 3:
A different kind of parser needs to be used here as per definition code
you edit contains errors while typing. External modules are retrieved
from 1 and 2, for internal code you can scan all the words and add them
to the autocomplete database. As a refinement you can give special
attention to 'self'. Also for calltips you can inherit when there are
assignments, eg
frame = Frame()
than frame inherits autocomplete & calltip information from Frame.

So autocompletion & calltips deals with two steps: extraction and
'database'. If someone has a good parser already, we could use it.
Otherwise we can define an API for the extraction and maybe lazily
implement it first with importing and concentrate first on the
'database'. When the database is ready we can implement the parsing. You
could also implement the parsing first, but than it takes longer before
you have results. Of course the library is GUI independent, it only
works with strings or lists.

What concerns SPE, it uses importing for autocompletion (1+2) and does
internal code analysis for local code (however without the inheriting).

Tal, how does IDLE's autocompletion works?

Stani



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:53:10 +0200

Nicolas Chauvat wrote:
> On Wed, Jun 06, 2007 at 07:13:10PM +0100, Ali Afshar wrote:
>>> Presumably recognition of the beginnings of
>>> - a) python keywords
>>> - b) classes and functions defined earlier in this file?
>>> - c) in scope variables?
>> does c) include: d) imported modules

> For code-completion, I suppose astng[1] could be useful.

> 1: http://www.logilab.org/project/eid/856

How dependent/independent is this from the standard AST compiler or
PyPy? Is it more IDE friendly? Is it based on it or a total independent
implementation?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:59:13 +0100

> A good point. I think we all have been thinking about this. Important
> issues for the design is the extraction method and the sources.

> *the method*
> Importing is a lazy, but accurate way of importing, but is security wise
> not such a good idea. Parsing throught an AST compiler is better,
> however more difficult. Here are two options.

> From version 2.5 the standard Python compiler converts internally the
> source code to an abstract syntax tree (AST) before producing the
> bytecode. So probably that is a good way to go as every python
> distribution has this battery included.

> As Nicolas suggested earlier on this mailing list, there is another
> option: the AST compiler in python or PyPy:

What concerns me about these is whether they would work in a module
which has a syntax error.

I believe Wing's compiler bit of their code completion is open source.
I remember having seen the code.



From: Stani <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 12:08:00 -0700

> What concerns me about these is whether they would work in a module
> which has a syntax error.

> I believe Wing's compiler bit of their code completion is open source.
> I remember having seen the code.

It is indeed, but is implemented in C, which means an extra dependency
and not a 100% python solution. Normally modules (especially in the
pythonpath) which you import don't have syntax errors. Maybe logilabs
implementation handles syntax errors well as it is developed for
PyLint. Nicolas?



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:34:41 +0300

> As python is dynamically typed, I guess we can't expect to know the
> names of methods of objects?

Well, the dir() builtin does just that, though there can be attributes
which won't be included therein. However, the builtin dir() can be
overridden... and ignoring it can break libraries like RPyC which
define a custom dir() function just for this purpose.

This issue has already been run in to by RPyC (an Python RPC lib). The
main developr went ahead and suggested adding a __dir__ method which
will return a list of attributes, and IIRC he has already implemented
a patch for this, and it will likely enter Python2.6.

Until then, I guess we're going to have to rely on dir for this.



From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 6 Jun 2007 12:42:01 -0700

For reference, PyPE auto-parses source code in the background, generating
(among other things) a function/class/method hierarchy.  Its autocomplete
generally sticks to global functions and keywords, but when doing
self.method lookups, it checks the current source code line, looks up in its
index of classes/methods, and trims the results based on known methods in
the current class in the current source file.

It certainly isn't complete (it should try to check base classes of the
class in the same file, it could certainly pay attention to names assigned
in the current scope, the global scope, imports, types of objects as per
WingIDE's assert isinstance(obj, type), etc.), but it also makes the
computation fairly straightforward, fast, and only in reference to the
current document.



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:52:08 +0300

> Tal, how does IDLE's autocompletion works?

Much like Stani said, since Python is interpreted, collection of
possible completions splits into two methods:
1) source code analysis
2) dynamic introspection

Of course, we could do either or a combination of both.

IDLE just uses introspection: since IDLE always has a python shell
running, it just completes according to the shell's state (plus
built-in keywords and modules). This is a very simple method,
obviously lacking. It does allow the user some control of the
completion, though - just import whatever you want to be completable
in the shell. However, introspection is all that is needed in a Python
shell, which is the major reason this is the method used in IDLE.



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 23:59:32 +0200


> How dependent/independent is this from the standard AST compiler or
> PyPy? Is it more IDE friendly? Is it based on it or a total independent
> implementation?

It is independent from PyPy.

The above web page says:

"""
Python Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.Python
Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.
"""

From: "Sylvain ThÃ©nault" <thena...@gmail.com>
Date: Wed, 13 Jun 2007 10:51:04 +0200

> Please let me involve Sylvain in the discussion. As the main author of
> pylint and astng, he will provide better answers.

well logilab-astng is basically a big monkey patching of the compiler
package from the stdlib, so you can't get an astng representation from a
module with syntax errors in. However inference and most others
navigation methods (which are basically the value added by astng) are
"syntax error resilient" : if a dependency module (direct or indirect)
contains a syntax error, you don't get any exception, though since some
information is missing you can miss some results you'ld get if the
faulting module were parseable.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:33:33 +0300

Since astng already does some inference (which we definitely want!)
and is based on the standard Python AST compiler, it sounds like our
#1 candidate. I think we should give the code a serious once-over and
see how well it fits our requirements, and if it can be adapted to
better handle errors. Any volunteers?

Also, has anyone used astng for completion, calltips, or something
similar? Or the standard AST compiler, for that matter?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:40:11 +0300

How does PyPE parse code? Home-rolled, standard AST compiler, something else?

It seems to me we should try to come up with an algorithm for parsing,
before getting to the code. All of the details you mentioned -
noticing assignments, using base-class methods, etc. - could be better
defined and organized this way. Perhaps we could brainstorm on this in
a wiki?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 11:38:40 +0300

Sorry for being away for such a long time. I hope we can get this
conversation rolling again, and get started with the actual work.

I'll try to sum up what has been said so far, and how I see things.

== Top Priorities ==
* Can we implement a parser based on the standard Python AST compiler
(or astng)? For example, can syntax errors be handled well?
* Is importing reasonable security-wise? If not, can it be made secure?

== General issues ==
* Do we aim for just completion, or also calltips? Perhaps also other
meta-data, e.g. place defined, source code, ... (see IPython's '??')
* Dependencies - do we want to allow C-extensions, or are we going for
a Python-only solution? (IDLE would only use such a Python-only tool.)
It seems that we want to pre-process most of the data in the
background, so I don't see why we would want to do this in C for
efficiency reasons.

== Completion sources ==
1) Importing "external" modules
2) Importing/Parsing "local" modules
3) Parsing the current file
4) Using objects/modules from the shell (e.g. IDLE has both editor
windows and a Python shell)

== Importing ==
* Stani mentioned that importing is problematic from a security point
of view. What are the security issues? Are they really an issue for an
IDE? If so, perhaps we could overcome this by importing in some kind
of "sandbox"?
* What are the pros and cons of Importing vs. Parsing?
* If importing is always preferable to parsing unless there's a syntax
error, perhaps try to import and parse on failure?

== Parsing ==
* This is going to be the most complex method - I think we should have
a general idea of how this should work before starting an
implementation. I suggest hashing ideas out on a wiki, since there a
lot of details to consider.
* Can a parser based on the standard AST compiler (or astng) work? Is
there a way to deal with errors? (HIGH PRIORITY!)
* There are other existing, open-source implementations out there -
WingIDE, PyPE have been mentioned. Any others? We should collect these
so we can use the code for learning, and perhaps direct use (if
possible license-wise).

== Shell ==
This is relatively straight-forward - just use dir(). This should be
optional, for use by IDEs which have a shell (support multiple
shells?).

Some known issues from IDLE and PyCrust:
* Handle object proxies such as RPC proxies (e.g. RPyC)
* Handle ZODB "ghost" objects
* Watch out for circular references
* Watch out for objects with special __getattr__/__hasattr__
implementations (for example xmlrpc, soap)

== Persistence ==
* Stani mentioned a 'database'. I feel Sqlite should be at most
optional, to reduce dependencies.
* Do we really want to have the data persistent (between IDE
sessiosns)? If so, we need to support simultaneous instances of the
IDE so they don't corrupt the data. Any other issues? (I have a
feeling this would better be left for later stages of development.)



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 12:22:59 +0300

One more note: We should distinguish between completion in an editor
and completion in a shell. The conversation up until now has focused
on editors, which is reasonable since that is the problematic scene. I
think a generic Python completion library should support completion in
both contexts, especially if it uses can use a shell's namespace for
completion in the editor.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 11:20:19 +0100

I have just implemented a completion mockup using Rope (which is a
refactoring library). It works quite nicely, and definitely worth a
look.

http://rope.sourceforge.net/

It even achieves this kind of completion:

class Banana(object):
    def do_something(self):
         return

def foo():
    return [Banana(), Banana()]

foo()[0].<complete> includes do_something

Which seems pretty impressive to me.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 20:12:50 +0300

Wow, Rope does look very impressive! A quick look at the code tells me
that a lot of work has been invested in it.

So we have one existing Python-only solution. We should evaluate it -
see what it can and can't do, and perhaps take a look at the overall
design.

I'm CC-ing Rope's developer, Ali. Hopefully Ali can help us quickly
understand Rope's code analysis capabilities.

Ali, could you elaborate a bit on what kinds of completion Rope can
do, and the methods it uses? We would especially like to know how your
static and dynamic inference work, what they can accomplish, and what
their limitations are.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 19:45:15 +0100

> Ali, could you elaborate a bit on what kinds of completion Rope can
> do, and the methods it uses? We would especially like to know how your
> static and dynamic inference work, what they can accomplish, and what
> their limitations are.

Well, I haven't really looked at the code. But I can tell you this:

from rope.ide.codeassist import PythonCodeAssist
from rope.base.project import Project
for compl in PythonCodeAssist(Project(package_root)).assist(buffer,
offset).completions:
    print compl

And that is as far as I really got. I expect to get a better look at
it later in the week though...


From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 1 Aug 2007 00:26:14 -0700

> How does PyPE parse code? Home-rolled, standard AST compiler, something else?

The compiler for syntactically correct Python, a line-based compiler
for broken Python.  TO generate a method list for self.methods, using
the current line number, I discover the enclosing class, check the
listing of methods for that class (generated by the compiler or
line-based parsers), and return a valid list for the specified prefix.
 It doesn't walk the inheritance tree, it doesn't do imports, etc.

> It seems to me we should try to come up with an algorithm for parsing,
> before getting to the code. All of the details you mentioned -
> noticing assignments, using base-class methods, etc. - could be better
> defined and organized this way. Perhaps we could brainstorm on this in
> a wiki?

A wiki would be fine, the one for this mailing list would likely be
best (if it is still up and working).  Then again, Rope looks quite
nifty.  I may have to borrow some of that source ;)


Discussion subject changed to "Fwd: Python code completion module" by Tal Einat

From: Ali Gholami Rudi <aligr...@gmail.com>
Date: Aug 1, 2007 5:50 PM

First of all I should note that rope's main goal was being a
refactoring tool and a refactoring tool needs to know a lot about
python modules.  `rope.base` package provides information about python
modules.

Actually what ropeide provides as auto-completion is defined in
`rope.ide.codeassist` module.  This module almost does nothing but use
`rope.base`.  Since `rope.ide` package is not included in the rope
library (which has been separated from ropeide since 0.6m4) it lacks
good documentation and the API might not be easy to use (most of it is
written in the first months of rope's birth).

> ..., could you elaborate a bit on what kinds of completion Rope can
> do, ...

I don't know what to say here.  Well, actually it tries to use the
source code as much as possible and infer things from it.  So I can
say that it can complete any obvious thing that can be inferred by a
human.  Like this is the first parameter of a method and after dots
its attributes can appear or these modules are imported so their names
and contents are available or this is an instance of some known type
and we know its attributes and ... .  Try ropeide (it uses emacs-like
keybinding, C-/ for completion; see ~/.rope if you want to change
that); it completes common cases (and sometimes completes things you
don't expect it to!).

> ..., and the methods it uses?

Rope analyzes python source code and AST.  Rope used to use the
`compiler` module till 0.5 and now it uses `_ast` module.

> We would especially like to know how your
> static and dynamic inference work, what they can accomplish

There are a few examples in docs/overview.txt.  Unit-test modules like
`ropetest.base.objectinfertest` and `advanced_oi_test` might help,
too.  Also have a look at `rope.base.oi.__init__` pydoc for an
overview of how they work; (I'm afraid it is a bit out of date and
carelessly written.)  The idea behind rope's object inference is to
guess what references (names in source-code) hold.  They collect
information about code when they can and use them later.

>..., and what their limitations are.

Many things in rope are approximations that might be exact if some
conditions hold.  For instance rope might assume that every normal
reference in module scope holds only one kind of object.  Apart from
these assumptions both SOI and DOI have their own disadvantages; For
instance SOI fails when dynamic code is evaluated while DOI does not.
Or DOI is slower than SOI.  (Well, after recent enhancements to rope's
SOI I rarely use DOI).

I tried to answer as short as possible.  If there are questions on
specific parts of rope, I'll be happy to answer.

By the way, I tried to reply this mail to the group, but it seems that
your group requires subscription for posting, so I've sent it to you,
instead.
#@+node:ekr.20060927173836.1: *4* Make calltips and autocompleter 'stateless'
@nocolor

Disabled these binding:

auto-complete-force = None # This command needs work before it is useful. Ctrl-period
show-calltips-force = None # This command needs work before it is useful. Alt-parenleft

The problem is that autocompletion depends on state: self.leadinWord,
prevObjects, etc. Thus, it's not presently possible to start the proces
anywhere. Similar remarks apply to calltips, which relies on autocompleter
state.

This is a complex problem, and not very serious now that there is an easy way of
toggling autocompleter and calltips on and off.

@color
#@+node:ekr.20071106083149: *4* Recent post
@killcolor

In general, autocompletion is a tricky problem. Consider:

- There may be no 'clean' version of the source code that you want to
auto-complete: you may be creating a new node, or a new file, and the source
code, being incomplete, will not parse correctly.

- Except in special circumstances, there is no 'real' object corresponding to s,
so there is no way to use Python's inspect module on s. Modules are an
exception: the autocompleter can handle existing modules fairly well. Try "os."
or "os.path." for example.


It might be possible to generalize c.k.defineObjectDict so that the user
could specify autocompleter conventions, say in an @autocompleter node in an
@settings tree.
#@+node:ekr.20091005145253.6058: *3* Features
#@+node:ekr.20090131200406.15: *4* Optional file features
#@+node:ekr.20090622020908.6058: *5* Add lite sentinels
http://groups.google.com/group/leo-editor/browse_thread/thread/c4f2cf250600e4a9
#@+node:ekr.20080311135649.2: *5* Allow different .leo formats
@nocolor

On Tue, Mar 11, 2008 at 7:03 AM, Kent Tenney <kten...@gmail.com> wrote:

> On 3/11/08, derwisch <johannes.hues...@med.uni-heidelberg.de> wrote:

> >  On 11 Mrz., 08:03, "Ville M. Vainio" <vivai...@gmail.com> wrote:
> >  > It could also be argued that

> >  > - Referring to previous cloned vnodes explicitly in XML does not
> >  > necessarily obscure DAG - it follows the "do not repeat yourself"
> rule
> >  > - It will speed up reading
> >  > - Wouldn't it be better for preserving the integrity of the XML file?

> > I would lean towards this line of argumentation. A couple of days I
> >  had my Leo extension destroy the Leo ODM file (which was still valid
> >  according to Leo, but unreadable wrt the extension and broken uAs). I
> >  resorted to editing the Leo file with Emacs, and was quite surprised
> >  to see that the headStrings were attributes of vnodes.

> I'll chime in with my pet peeve re: .leo file structure::

> I think that putting the headstrings on vnodes and body strings on tnodes
> obscures the informational content of the .leo file, and makes the .leo
> file
> format less attractive as a generalized solution to the problem of how to
> manage head/body pairs which live in a hierarchal structure.

> Thanks,
> Kent

> >  I think that
> >  editing the file might have been a bit easier if there had been no
> >  such redundancy. But this is more a feeling rather than a qualified
> >  opinion.

Thanks for all these comments.  I'll respond to them all here.

Clearly, we should be using a standard xml parser to read .leo files.

My present thoughts:

- I personally like human-readable headlines in <v> elements.

- I am open to putting headlines in <t> elements, as an indication that
tnodes do indeed contain headlines and body text.

- I am willing to consider only writing shared subtrees once.

Oh! (An Aha)  All these are preferences.  We can allow any combination of
these provided that headlines appear somewhere.

So that's clean.  This will happen in Leo 4.5. 
#@+node:ekr.20061002093442: *5* Add opml support to new,open, save commands
#@+node:ekr.20071003104917: *5* Make http://edreamleo.org/namespaces/leo-python-editor/1.1 Leo's official namespace
xmlns:leo="http://edreamleo.org/namespaces/leo-python-editor/1.1"
#@+node:ekr.20090218115025.3: *5* Why are attributes pickled by default?
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/326a221f4c698f7a

> On Wed, Feb 18, 2009 at 12:12 PM, Kent Tenney <ktenney@gmail.com> wrote:
>>
>> Currently, Leo pickles the value of unknown attributes unless
>> the name starts with 'str_'
>>
>> Running the following code in node 'UA'
>>
>> p = c.currentPosition()
>> p.v.u = {'hello':'world', 'str_hello':'world'}
>>
>> results in the following in the .leo file:
>>
>> <v t="ktenney.20090218114928.367" str_hello="world"
>> hello="5505776f726c6471002e"><vh>UA</vh></v>
>>
>> I think this is surprising, Python-centric and contrary to the
>> spirit of Leo as a flexible data management platform.
>
> I suppose your point is that you can't create an arbitrarily named attribute
> with a string value. Does that create a real problem?

It requires a translation layer, either to (un)munge the name or
(un)pickle. Real problem?

Let's say each time I think 'I can use UAs to store that' I change
my mind when I realize my values will be in a pickle. (I really don't
want to name all my attributes str_xxx)

> As far as being Python-centric, can you suggest any other way of converting
> arbitrary data to a text string?

How is it done in any other XML file?
I've not used XML for arbitrary data, but it probably can be done.

> Why would that way be better than pickle?

My suspicion is that UAs would be used more for
storing text and numbers (as seems common for XML files)
than Python data objects.

Does Leo use UAs to store pickles?

I'm sure pickling capability is great, but I'm not convinced
it should be the _default._

No big deal.
#@+node:ekr.20080626081829.2: *5* Allow headline comments for @nosent files
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/eb718b4c6d478ac0

I'm just getting started learning how to use Leo. Now, I'd like to use
it for some of my projects, but there's no chance that I can convert
everyone at work to using it, so putting sentinel-filled files in our
repository is out of the question. At the same time, my code looks
awfully bare without sentinels because the documentation ends up in
the section names, not the comments!

So, I was wondering if there's a convenient way to pull the section
names into a comment at the start of each section?

===============

Interesting question.  Am I correct in assuming you are using @nosent trees
to generate your files?  If so, it would be easy to add support for the
following options:

@bool write_section_comments_in_at_nosent_trees
@bool write_node_name_comments_in_at_nosent_trees

The first would write a sentinel consisting of only the section name;
the second would write a sentinel consisting only of the node's headline
(for nodes whose headline is not a section name).

These seem like they would be useful additions.  One can even imagine
corresponding Leo directives so that the comments could be turned on or off
within an @nosent tree.

What do you think?

=====================

> Interesting question.  Am I correct in assuming you are using @nosent trees
> to generate your files?  If so, it would be easy to add support for the
> following options:

> @bool write_section_comments_in_at_nosent_trees
> @bool write_node_name_comments_in_at_nosent_trees

> The first would write a sentinel consisting of only the section name;
> the second would write a sentinel consisting only of the node's headline
> (for nodes whose headline is not a section name).

> These seem like they would be useful additions.  One can even imagine
> corresponding Leo directives so that the comments could be turned on or off
> within an @nosent tree.

That sounds like an excellent solution. Particularly the last bit --
if you could turn section-comments on and off as required, it would
become very convenient to use Leo to produce source that is intended
to also be read by non Leo users. 
#@+node:ekr.20080919085541.3: *5* Use sqlite data base as an alternative representation for .leo files
http://groups.google.com/group/leo-editor/browse_thread/thread/dff0c165e2211691
#@+node:ekr.20090210093316.1: *4* Optional features
#@+node:ekr.20080922115725.1: *5* Finish @shadow
# Allow block comments in private shadow files.
# Compute delims using the private shadow file, not the file extension!
# Can @shadow mark externally changed nodes?
#@+node:ekr.20081004102201.2: *6* Log file for @shadow
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5e7bd3af2d1fbf51

How about a shadow.log file which Leo told what it thought of the relationship
between the node, file and shadow? It might provide useful clues.
#@+node:ekr.20081001062423.1: *6* Can @shadow mark externally changed nodes?
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/c46eabe8a9fe6e8

@color
#@+node:ekr.20080708094444.38: *7* x.propagate_changed_lines
def propagate_changed_lines(self,new_public_lines,old_private_lines,marker,p=None):

    '''Propagate changes from 'new_public_lines' to 'old_private_lines.

    We compare the old and new public lines, create diffs and
    propagate the diffs to the new private lines, copying sentinels as well.

    We have two invariants:
    1. We *never* delete any sentinels.
       New at 2010/01/07: Replacements preserve sentinel locations.
    2. Insertions that happen at the boundary between nodes will be put at
       the end of a node.  However, insertions must always be done within sentinels.
    '''

    trace = False and not g.unitTesting
    verbose = True
    x = self
    # mapping tells which line of old_private_lines each line of old_public_lines comes from.
    old_public_lines, mapping = self.strip_sentinels_with_map(old_private_lines,marker)

    << init vars >>
    << define print_tags >>

    delim1,delim2 = marker.getDelims()
    sm = difflib.SequenceMatcher(None,old_public_lines,new_public_lines)
    prev_old_j = 0 ; prev_new_j = 0

    for tag,old_i,old_j,new_i,new_j in sm.get_opcodes():

        << About this loop >>

        # Verify that SequenceMatcher never leaves gaps.
        if old_i != prev_old_j: # assert old_i == prev_old_j
            x.error('can not happen: gap in old: %s %s' % (old_i,prev_old_j))
        if new_i != prev_new_j: # assert new_i == prev_new_j
            x.error('can not happen: gap in new: %s %s' % (new_i,prev_new_j))

        << Handle the opcode >>

        # Remember the ends of the previous tag ranges.
        prev_old_j = old_j
        prev_new_j = new_j

    # Copy all unwritten sentinels.
    self.copy_sentinels(
        old_private_lines_rdr,
        new_private_lines_wtr,
        marker,
        limit = old_private_lines_rdr.size())

    # Get the result.
    result = new_private_lines_wtr.getlines()
    if 1:
        << do final correctness check>>
    return result
#@+node:ekr.20080708094444.40: *8* << init vars >>
new_private_lines_wtr = self.sourcewriter(self)
# collects the contents of the new file.

new_public_lines_rdr = self.sourcereader(self,new_public_lines)
    # Contains the changed source code.

old_public_lines_rdr = self.sourcereader(self,old_public_lines)
    # this is compared to new_public_lines_rdr to find out the changes.

old_private_lines_rdr = self.sourcereader(self,old_private_lines) # lines_with_sentinels)
    # This is the file which is currently produced by Leo, with sentinels.

# Check that all ranges returned by get_opcodes() are contiguous
old_old_j, old_i2_modified_lines = -1,-1

tag = old_i = old_j = new_i = new_j = None
#@+node:ekr.20080708094444.39: *8* << define print_tags >>
def print_tags(tag, old_i, old_j, new_i, new_j, message):

    sep1 = '=' * 10 ; sep2 = '-' * 20

    g.pr('\n',sep1,message,sep1,p and p.h)

    g.pr('\n%s: old[%s:%s] new[%s:%s]' % (tag,old_i,old_j,new_i,new_j))

    g.pr('\n',sep2)

    table = (
        (old_private_lines_rdr,'old private lines'),
        (old_public_lines_rdr,'old public lines'),
        (new_public_lines_rdr,'new public lines'),
        (new_private_lines_wtr,'new private lines'),
    )

    for f,tag in table:
        f.dump(tag)
        g.pr(sep2)


#@+node:ekr.20080708192807.2: *8* << about this loop >>
@ This loop writes all output lines using a single writer:
new_private_lines_wtr.

The output lines come from two, and *only* two readers:

1. old_private_lines_rdr delivers the complete original sources. All
   sentinels and unchanged regular lines come from this reader.

2. new_public_lines_rdr delivers the new, changed sources. All inserted or
   replacement text comes from this reader.

Each time through the loop, the following are true:

- old_i is the index into old_public_lines of the start of the present
  SequenceMatcher opcode.

- mapping[old_i] is the index into old_private_lines of the start of
  the same opcode.

At the start of the loop, the call to copy_sentinels effectively skips
(deletes) all previously unwritten non-sentinel lines in
old_private_lines_rdr whose index is less than mapping[old_i].

As a result, the opcode handlers do not need to delete elements from
the old_private_lines_rdr explicitly. This explains why opcode
handlers for the 'insert' and 'delete' opcodes are identical.
#@+node:ekr.20080708192807.5: *8* << Handle the opcode >>
# Do not copy sentinels if a) we are inserting and b) limit is at the end of the old_private_lines.
# In this special case, we must do the insert before the sentinels.
limit=mapping[old_i]

if trace: g.trace('tag',tag,'old_i',old_i,'limit',limit)

if tag == 'equal':
    # Copy sentinels up to the limit = mapping[old_i]
    self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)

    # Copy all lines (including sentinels) from the old private file to the new private file.
    start = old_private_lines_rdr.index() # Only used for tag.
    while old_private_lines_rdr.index() <= mapping[old_j-1]:
        line = old_private_lines_rdr.get()
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (
            tag,start,mapping[old_j-1]))

    # Ignore all new lines up to new_j: the same lines (with sentinels) have just been written.
    new_public_lines_rdr.sync(new_j)

elif tag == 'insert':
    if limit < old_private_lines_rdr.size():
        self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)
    # All unwritten lines from old_private_lines_rdr up to mapping[old_i] have already been ignored.
    # Copy lines from new_public_lines_rdr up to new_j.
    start = new_public_lines_rdr.index() # Only used for tag.
    while new_public_lines_rdr.index() < new_j:
        line = new_public_lines_rdr.get()
        if marker.isSentinel(line):
            new_private_lines_wtr.put(
                '%s@verbatim%s\n' % (delim1,delim2),
                tag='%s %s:%s' % ('new sent',start,new_j))
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (tag,start,new_j))

elif tag == 'replace':
    # 2010/01/07: This case is new: it was the same as the 'insert' case.
    start = old_private_lines_rdr.index() # Only used for tag.
    while old_private_lines_rdr.index() <= mapping[old_j-1]:
        old_line = old_private_lines_rdr.get()
        if marker.isSentinel(old_line):
            # Important: this should work for @verbatim sentinels
            # because the next line will also be replaced.
            new_private_lines_wtr.put(old_line,tag='%s %s:%s' % (
                'replace: copy sentinel',start,new_j))
        else:
            new_line = new_public_lines_rdr.get()
            new_private_lines_wtr.put(new_line,tag='%s %s:%s' % (
                'replace: new line',start,new_j))

elif tag=='delete':
    # Copy sentinels up to the limit = mapping[old_i]
    self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)
    # Leave new_public_lines_rdr unchanged.

else: g.trace('can not happen: unknown difflib.SequenceMather tag: %s' % repr(tag))

if trace and verbose:
    print_tags(tag, old_i, old_j, new_i, new_j, "After tag")
#@+node:ekr.20080708094444.45: *8* << do final correctness check >>
t_sourcelines, t_sentinel_lines = self.separate_sentinels(
    new_private_lines_wtr.lines, marker)

self.check_the_final_output(
    new_private_lines   = result,
    new_public_lines    = new_public_lines,
    sentinel_lines      = t_sentinel_lines,
    marker              = marker)
#@+node:ekr.20090402072059.13: *6* Create a general mechanism for aux (shadow, _db) files
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/4ec30df3f1db8db3

On Sat, Mar 28, 2009 at 3:24 AM, VR <viktor.ransmayr@gmail.com> wrote:


    When I tried to de-install Leo-4.6b1 I succeeded, but the program
    reported that 5 directories
    were not removed.

    Three of the directories where

    1) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\config
    2) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\doc
    3) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\plugins

    [containing]


    a) .leoSettings.leo_db
    b) .leoDocs.leo_db
    c) .leo_shadow
    d) .leoPluginsRef.leo_db


Thanks for this report. I think it is important, and needs a good solution.

I dislike all these files being sprayed around the file system. I'd like to see
these files placed somewhere the ~/.leo directory. Is there a reason why this
would be a bad idea?

Similarly, we might also prefer to have shadow files place in, say,
~/.leo/shadow_files.

In both cases, I think we want to create files that indicate their location.
Either that, or mirror their location in (subdirectories) ~/.leo. In other
words, this is a general problem, and it would be good to have a robust, general
solution.
#@+node:ekr.20090601083544.6067: *5* Make all commands available to all commanders
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/a83082cec5ad3df8

QQQ (Ville)
So to create command you would do

import leoPlugins

def mycmd(c,p, event):
  print c,p

leoPlugins.expose_command('my-command', mycmd)
leoPlugins.expose_button('press-this',mycmd)

[EKR: I would rather use g.app.exposeCommand, g.app.exposeButton].

These would be available on *all* new commanders, and the current
commander as well (for easy testing). Plugins would not have to
contain more code than what is presented above.

The idea is to have a global command dict, [EKR: g.app.commandsDict]
and global button dict.
There is one after-create-frame handler that introduces all the
entries in this dict to the commander command dict.
QQQ

============


QQQ
g.app.global_commands_dict, which gets copied to c on commander
creation. it's rev 1889, you'll note that it's a simple
implementation. I didn't add g.button yet. An example:

@g.command('bookmark')
def bookmark(event):
    c = event.get('c')
    p = c.currentPosition()
    bookmarks.append(p.gnx)
    g.es('bookmarked') 
QQQ
#@+node:ekr.20081119132758.2: *5* Support @ifgui in settings trees
#@+node:ekr.20080803063553.4: *5* Allow translation/abbreviation for any Leo directive, including headline directives
#@+node:ekr.20080727122007.1: *5* Allow user to set background colors of nodes
What uA should be used to specify node colors?

if the foreground / background color API uses uAs,
would/should the uAs use the reserved "leo_&lt;something&gt;" namespace?
#@+node:ekr.20080813064908.8: *5* Find a way to limit length of lines in indented nodes
#@+node:ekr.20080802070659.11: *5* Make node attributes visible, and supported by Leo's core
#@+node:ekr.20080806054207.3: *5* Auto scroll outline pane if headline would become invisible
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/76789df8aac08c70

When using leo as outliner, I often use only node headlines to write
down some data. If the headline string is too long, the cursor goes
beyond the visible area. When modifying a node headline, is it
possible to make leo to auto-scroll, so the cursor is always visible? 
#@+node:ekr.20070521105645: *5* Improve api docs with epydoc?
@nocolor
http://sourceforge.net/forum/message.php?msg_id=4319363
By: ktenney

I think there is room for improvement in documenting Leo's
API, making it easier to write these kind of scripts.
I'm not sure of the best way to do that.

Epydoc seems to be the most active project in this realm.
http://epydoc.sourceforge.net/epydoc.html
#@+node:ekr.20061116054917.6: *5* Remove blanks in calltips
#@+node:ekr.20080628095358.1: *5* Make each Leo command a class
http://groups.google.com/group/leo-editor/browse_thread/thread/5688ed9aaa39be2e#

@nocolor

The main difficulty I see in the migration is creating the tables in the getPublicCommands methods in the various classes in leoEditCommands.py.  At present, these tables associate command names (strings) with corresponding methods.  The form of getPublicCommands is always:

def getPublicCommands (self):
  return {
    'command-name1': self.methodName1,
    'command-name2': self.methodName2,
    ...
  }

Thinking out loud, let's see whether the migration can be done easily.  We would change the entry:

    'command-name1': self.methodNameN,

to:

    'command-name1': self.classNameN(self),

That is, the table creates an instance of the class by calling the class's ctor, with self (the container object) as the ctor's only argument.  To make this work, all we need to do is give the class a __call__ method whose signature matches the signature of methodNameN, that is, the signature used to call methods previously.

Well, isn't this nice.  We can transition gradually, as needed.  No need *ever* to do a mass migration.  It should be easy to verify this scheme with one or two examples.  Please report your experiences if you decide to play around with this.

Edward

P.S.  I think it would be good style to append "Class" to the name of each command class. This makes it clear that self.myCommandClass(self) is a ctor.
#@+node:ekr.20090714085914.5994: *4* Optional new commands
#@+node:ekr.20071004120359.2: *5* Do expand-region-abbrevs from
See: regionalExpandAbbrev.
#@+node:ekr.20090402072059.2: *5* clone-find-all-once
@

First do a normal clone-find-all for the word "clone". Then click the script
button and do it again. Notice that children of previously found nodes don't get
added again in the modified version.
#@+node:ekr.20090402072059.4: *6* @@@button my clone find all
import leo.core.leoFind as leoFind 

def new_find_all(self):
    << do some initial stuff >>


    while 1:
        pos, newpos = self.findNextMatch()
        if pos is None: break

        if count % 10 == 0 and count > 0:
            g.es("still searching, matches found: ", count)

        << Skip node if it's a child of a previously found node >>

        count += 1

        s = w.getAllText()
        i,j = g.getLine(s,pos)
        line = s[i:j]
        if not self.clone_find_all:
            self.printLine(line,allFlag=True)
        if self.clone_find_all and self.p.v.t not in clones:
            # g.trace(self.p.v.t,self.p.h)
            if not clones:
                undoData = u.beforeInsertNode(c.p)
                << create the found node >>
            clones.append(self.p.v.t)
            positions.append(self.p)
            << create a clone of p under the find node >>

    if self.clone_find_all and clones:
        u.afterInsertNode(found,undoType,undoData,dirtyVnodeList=[])
        c.selectPosition(found)
        c.setChanged(True)

    self.restore(data)
    c.redraw()
    g.es("found",count,"matches")


leoFind.leoFind.findAll = new_find_all

c.executeMinibufferCommand("clone-find-all") 
#@+node:ekr.20090402072059.5: *7* << do some initial stuff >>
g.es("findAll..., self: ", self)

c = self.c ; w = self.s_ctrl ; u = c.undoer
undoType = 'Clone Find All'
if not self.checkArgs():
    return
self.initInHeadline()
if self.clone_find_all:
    self.p = None # Restore will select the root position.
data = self.save()
self.initBatchCommands()
count = 0 ; clones = []; positions = []
#@+node:ekr.20090402072059.6: *7* << create the found node >>
oldRoot = c.rootPosition()
found = oldRoot.insertAfter()
found.moveToRoot(oldRoot)
c.setHeadString(found,'Found: ' + self.find_text)
c.setRootPosition(found) # New in Leo 4.5.
#@+node:ekr.20090402072059.7: *7* << create a clone of p under the find node >>
q = self.p.clone()
q.moveToLastChildOf(found)
#@+node:ekr.20090402072059.8: *7* << Skip node if it's a child of a previously found node >>
<< def: is a child of b >>

is_child_of_previous = False
for previously_found in positions:
    if is_a_child_of_b(self.p, previously_found):
        is_child_of_previous = True
        break

if is_child_of_previous:
    continue
#@+node:ekr.20090402072059.9: *8* << def: is a child of b >>

def is_a_child_of_b(a, b):
    for child in b.children_iter():
        if a.t == child.t:
            return True
        if is_a_child_of_b(a, child):
            return True
    return False
#@+node:ekr.20060306194040: ** Leo Video & slide show
@nocolor
http://sourceforge.net/forum/message.php?msg_id=3615177
By: ktenney

High on my ToLearn list is vnc2swf
http://www.unixuser.org/~euske/vnc2swf/


http://sourceforge.net/forum/message.php?msg_id=3615278
By: James

A lot of people are now using Wink for demonstrations
(http://www.debugmode.com/wink/), it's is free and seems to work well.

Check out http://murl.se/11332
At the bottom they talk about tools and techniques.
http://showmedo.com seems like it would be a good
place to host vids also.

I've listened/watched a fair number of things like this;
my recomendation is to get a good microphone and
pre-amp to record your voice, and prepare the audio
track carefully. It is so aggravating when
it's hard to discern the words being spoken.

Thanks,
Kent
#@+node:ekr.20060531134434: *3* Tutorials
http://sourceforge.net/forum/message.php?msg_id=3758271

From: Rich

Tutorials would be great. I use Liberty BASIC, (http://libertybasic.conforums.com)
and it has a very good tutorial -- leads the beginner by the hand through much
of the language. Also the help file has working code snippets
to cut-n-paste-n-play-with. I'd like to see something like:

[Buttons]
...[What are Buttons good for?]
...[How do I make my own buttons?]
......[Some commands you can use with buttons]
......[Where to find button commands]
#@+node:ekr.20091006063434.16252: *3* A slide show for newbies
#@+node:ekr.20060531134434.1: *3* Screencasts
@nocolor
http://sourceforge.net/forum/message.php?msg_id=3758303
By: ktenney

My sense is that documentation/screencasts has the
greatest potential for expanding Leo's mindshare.

I really like those produced by the good folks
at Dabo;
http://leafe.com/screencasts/
http://leafe.com/screencasts/populategrid.html

The TurboGears people have taken this to the extreme;
http://www.turbogears.org/ultimate.html

Leo is different enough that it warrants a 
demonstration of it's advantages.

-------------------

https://sourceforge.net/forum/message.php?msg_id=4396251
By: ktenney

2 good screencasts on making screencasts;

http://murl.se/26296
#@+node:ekr.20060829103523: *3* Render Leo slideshows
#@-all
#@-leo
