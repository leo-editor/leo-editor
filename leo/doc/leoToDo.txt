#@+leo-ver=5-thin
#@+node:ekr.20100119205347.6015: * @thin ../doc/leoToDo.txt
#@+all
#@+node:ekr.20100109214940.6225: ** 4.8 to do

#@+node:ekr.20100903162809.5866: *3* First
#@+node:ekr.20101021160326.5949: *4* Fix bug 577047: Invalid @path directory does not warn user
@nocolor-node

Specifying a @path directory causes Leo to save an "@thin file.ext" node below
it in Leo's home directory without any warning. The next time Leo is opened it
issues an error that it can not find the file.

It should instead issue a warning that the @path directory does not exist.

If this occurs when the saving of @thin nodes to files is performed as part of
the user closing Leo, the closing of Leo should be aborted to prevent the loss
of data.
#@+node:ekr.20101022055534.5978: *5*  at.Read summary...
# Drivers: no real inits...
def readAll(self,root,partialFlag=False):
def readAtShadowNodes (self,p):

# Drivers: call at.scanDefaultDirectory...
def readOneAtAutoNode (self,fileName,p): 
    # Calls at.scanDefaultDirectory
    # Calls ic.createOutline.
def readOneAtEditNode (self,fn,p):
    # Calls at.scanDefaultDirectory
    # Calls g.readFileIntoString
def readOneAtShadowNode (self,fn,p):
    # Calls at.scanDefaultDirectory
    # Calls at.read

# Do real inits. All of these call initReadIvars....
def checkDerivedFile (self, event=None):
def read(self,root,importFileName=None,fromString=None,atShadow=False,force=False):
#@+node:ekr.20070919133659: *6* at.checkDerivedFile
def checkDerivedFile (self, event=None):

    at = self ; c = at.c ; p = c.p

    if not p.isAtFileNode() and not p.isAtThinFileNode():
        return g.es('Please select an @thin or @file node',color='red')

    fn = p.anyAtFileNodeName()
    path = g.os_path_dirname(c.mFileName)
    fn = g.os_path_finalize_join(g.app.loadDir,path,fn)
    if not g.os_path_exists(fn):
        return g.es_print('file not found: %s' % (fn),color='red')

    s,e = g.readFileIntoString(fn)
    if s is None: return

    # Create a dummy, unconnected, vnode as the root.
    root_v = leoNodes.vnode(context=c)
    root = leoNodes.position(root_v)
    theFile = g.fileLikeObject(fromString=s)
    # 2010/01/22: readOpenFiles now determines whether a file is thin or not.
    at.initReadIvars(root,fn)
    if at.errors: return
    at.openFileForReading(fromString=s)
    if not at.inputFile: return
    at.readOpenFile(root,at.inputFile,fn)
    at.inputFile.close()
    if at.errors == 0:
        g.es_print('check-derived-file passed',color='blue')
#@+node:ekr.20041005105605.21: *6* at.read & helpers
def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    trace = False and not g.unitTesting
    if trace: g.trace(root.h)
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    at.fromString = fromString
    if at.errors:
        if trace: g.trace('Init error')
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if fileName and at.inputFile:
        c.setFileTimeStamp(fileName)
    elif fromString: # 2010/09/02.
        pass
    else:
        g.trace('No inputFile')
        return False
    root.v.at_read = True # Remember that we have read this file.

    # Get the file from the cache if possible.
    if fromString:
        s,loaded,fileKey = fromString,False,None
    else:
        s,loaded,fileKey = c.cacher.readFile(fileName,root)
    # 2010/02/24: Never read an external file
    # with file-like sentinels from the cache.
    isFileLike = loaded and at.isFileLike(s)
    if not loaded or isFileLike:
        # if trace: g.trace('file-like file',fileName)
        force = True # Disable caching.
    if loaded and not force:
        if trace: g.trace('in cache',fileName)
        at.inputFile.close()
        root.clearDirty()
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    if isFileLike:
        if g.unitTesting:
            if 0: print("converting @file format in",root.h)
            g.app.unitTestDict['read-convert']=True
        else:
            g.es("converting @file format in",root.h,color='red')
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
        # Sets the following ivars:
            # at.explicitLineEnding
            # at.output_newline
            # at.encoding
            # at.language
            # at.page_width
            # at.default_directory *** path**
            # at.tab_width

    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.deleteUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToVnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if isFileLike:
        # 2010/02/24: Make the root @file node dirty so it will
        # be written automatically when saving the file.
        root.setDirty()
        c.setChanged(True) # Essential, to keep dirty bit set.
    if at.errors == 0 and not isFileLike and not fromString:
        c.cacher.writeFile(root,fileKey)

    if trace: g.trace('at.errors',at.errors)
    return at.errors == 0
#@+node:ekr.20041005105605.25: *7* at.deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
        if hasattr(v,"tempBodyList"):
            delattr(v,"tempBodyList")
#@+node:ekr.20100122130101.6174: *7* at.deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@+node:ekr.20071105164407: *7* at.deleteUnvisitedNodes & helpers
def deleteUnvisitedNodes (self,root):

    '''Delete unvisited nodes in root's subtree, not including root.

    Actually, instead of deleting the nodes, we move them to be children of the
    'Resurrected Nodes' r.
    '''

    at = self

    if not root.hasChildren():
        return

    # Carefully set up the arguments.
    aList = [z.copy() for z in root.subtree() if not z.isVisited()]
    if not aList: return

    r = at.createResurrectedNodesNode()
    assert r not in aList
    callback=at.defineResurrectedNodeCallback(r,root)

    # Now move the nodes.
    root.firstChild().deletePositionsInList(aList,callback)
#@+node:ekr.20100803073751.5817: *8* createResurrectedNodesNode
def createResurrectedNodesNode(self):

    '''Create a 'Resurrected Nodes' node as the last top-level node.'''

    at = self ; c = at.c ; tag = 'Resurrected Nodes'

    # Find the last top-level node.
    last = c.rootPosition()
    while last.hasNext():
        last.moveToNext()

    if last.h == tag:
        # The 'Resurrected Nodes' node already exists.
        p = last
    else:
        # Create the 'Resurrected Nodes' node after 'last'.
        p = last.insertAfter()
        p.setHeadString(tag)

    p.expand()
    return p
#@+node:ekr.20100803073751.5818: *8* defineResurrectedNodeCallback
def defineResurrectedNodeCallback (self,r,root):

    '''Define a callback that moves node p as r's last child.'''

    def callback(p,r=r.copy(),root=root):

        '''The resurrected nodes callback.'''

        child = r.insertAsLastChild()
        child.h = 'From %s' % root.h
        p.moveToLastChildOf(child)

        if g.unitTesting:
            # g.trace(p.h,r.h)
            pass 
        else:
            g.es('resurrected node:',p.h,color='red')
            g.es('in file:',root.h,color='blue')

    return callback


#@+node:ekr.20041005105605.22: *7* at.initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName
#@+node:ekr.20100224050618.11547: *7* at.isFileLike
def isFileLike (self,s):

    '''Return True if s has file-like sentinels.'''

    trace = False and not g.unitTesting
    at = self ; tag = "@+leo"
    s = g.toUnicode(s)
    i = s.find(tag)
    if i == -1:
        if trace: g.trace('found: False',repr(s))
        return True # Don't use the cashe.
    else:
        j,k = g.getLine(s,i)
        line = s[j:k]
        valid,new_df,start,end,isThin = \
            at.parseLeoSentinel(line)
        if trace: g.trace('found: True isThin:',
            isThin,repr(line))
        return not isThin
#@+node:ekr.20070909100252: *6* at.readOneAtAutoNode
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors: return # 2010/10/21

    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # 2010/7/28: Remember that we have seen the @auto node.
    p.v.at_read = True # Create the attribute

    s,ok,fileKey = c.cacher.readFile(fileName,p)
    if ok: return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        c.cacher.writeFile(p,fileKey)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@+node:ekr.20090225080846.3: *6* at.readOneAtEditNode
def readOneAtEditNode (self,fn,p):

    at = self ; c = at.c ; ic = c.importCommands
    oldChanged = c.isChanged()

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors: return # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    junk,ext = g.os_path_splitext(fn)

    # 2010/7/28: Remember that we have seen the @edit node.
    p.v.at_read = True # Create the attribute

    if not g.unitTesting:
        g.es("reading @edit:", g.shortFileName(fn))

    s,e = g.readFileIntoString(fn,kind='@edit')
    if s is None: return
    encoding = g.choose(e is None,'utf-8',e)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    changed = c.isChanged()
    head = ''
    ext = ext.lower()
    if ext in ('.html','.htm'):   head = '@language html\n'
    elif ext in ('.txt','.text'): head = '@nocolor\n'
    else:
        language = ic.languageForExtension(ext)
        if language and language != 'unknown_language':
            head = '@language %s\n' % language
        else:
            head = '@nocolor\n'

    p.b = g.u(head) + g.toUnicode(s,encoding=encoding,reportErrors='True')

    if not changed: c.setChanged(False)
    g.doHook('after-edit',p=p)
#@+node:ekr.20080711093251.7: *6* at.readOneAtShadowNode
def readOneAtShadowNode (self,fn,p):

    at = self ; c = at.c ; x = c.shadowController

    if not fn == p.atShadowFileNodeName():
        return at.error('can not happen: fn: %s != atShadowNodeName: %s' % (
            fn, p.atShadowFileNodeName()))

    # 2010/7/28: Remember that we have seen the @shadow node.
    p.v.at_read = True # Create the attribute

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Sets at.default_directory
    if at.errors: return # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    shadow_fn     = x.shadowPathName(fn)
    shadow_exists = g.os_path_exists(shadow_fn) and g.os_path_isfile(shadow_fn)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    if shadow_exists:
        at.read(p,atShadow=True)
    else:
        if not g.unitTesting: g.es("reading:",p.h)
        ok = at.importAtShadowNode(fn,p)
        if ok:
            # Create the private file automatically.
            at.writeOneAtShadowNode(p,toString=False,force=True)
#@+node:ekr.20080712080505.1: *7* at.importAtShadowNode
def importAtShadowNode (self,fn,p):

    at = self ; c = at.c  ; ic = c.importCommands
    oldChanged = c.isChanged()

    # Delete all the child nodes.
    while p.hasChildren():
        p.firstChild().doDelete()

    # Import the outline, exactly as @auto does.
    ic.createOutline(fn,parent=p.copy(),atAuto=True,atShadow=True)

    if ic.errors:
        g.es_print('errors inhibited read @shadow',fn,color='red')

    if ic.errors or not g.os_path_exists(fn):
        p.clearDirty()
        c.setChanged(oldChanged)

    # else: g.doHook('after-shadow', p = p)

    return ic.errors == 0
#@+node:ekr.20101022055534.5977: *5*  at.Write summary...
# Drivers: no real inits...
def writeAll(self,
    writeAtFileNodesFlag=False,writeDirtyAtFileNodesFlag=False,toString=False):
def writeAllHelper (self,p,force,toString,writeAtFileNodesFlag,writtenFiles):
    # Checks for changed path.
def writeAtAutoNodes (self,event=None): # Thin wrapper
def writeDirtyAtAutoNodes (self,event=None): # Thin wrapper
def writeAtShadowNodes (self,event=None): # Thin wrapper
def writeDirtyAtShadowNodes (self,event=None): # Thin wrapper
def writeMissing(self,p,toString=False):

# Do real inits. All of these call initWriteIvars...
def asisWrite(self,root,toString=False):
def write (self,root,kind = '@unknown', # Should not happen.
    nosentinels = False,thinFile = False,scriptWrite = False,toString = False):
def writeOneAtAutoNode(self,p,toString,force):
def writeOneAtShadowNode(self,p,toString,force):
def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):
def writeOneAtEditNode(self,p,toString,force=False):
#@+node:ekr.20041005105605.154: *6* at.asisWrite
def asisWrite(self,root,toString=False):

    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    try:
        # Note: @asis always writes all nodes,
        # so there can be no orphan or ignored nodes.
        targetFileName = root.atAsisFileNodeName()
        at.initWriteIvars(root,targetFileName,toString=toString)
        # "look ahead" computation of eventual fileName.
        eventualFileName = c.os_path_finalize_join(
            at.default_directory,at.targetFileName)
        exists = g.os_path_exists(eventualFileName)
        if not hasattr(root.v,'at_read') and exists:
            # Prompt if writing a new @asis node would overwrite the existing file.
            ok = self.promptForDangerousWrite(eventualFileName,kind='@asis')
            if ok:
                root.v.at_read = True # Create the attribute for all clones.
            else:
                g.es("not written:",eventualFileName)
                return
        if at.errors: return
        if not at.openFileForWriting(root,targetFileName,toString):
            # openFileForWriting calls root.setDirty() if there are errors.
            return
        for p in root.self_and_subtree():
            << Write p's headline if it starts with @@ >>
            << Write p's body >>
        at.closeWriteFile()
        at.replaceTargetFileIfDifferent(root) # Sets/clears dirty and orphan bits.
    except Exception:
        at.writeException(root) # Sets dirty and orphan bits.

silentWrite = asisWrite # Compatibility with old scripts.
#@+node:ekr.20041005105605.155: *7* << Write p's headline if it starts with @@ >>
s = p.h

if g.match(s,0,"@@"):
    s = s[2:]
    if s and len(s) > 0:
        # at.outputFile is a fileLikeObject.
        s = g.toEncodedString(s,at.encoding,reportErrors=True)
        at.outputFile.write(s)
#@+node:ekr.20041005105605.156: *7* << Write p's body >>
s = p.b

if s:
    s = g.toEncodedString(s,at.encoding,reportErrors=True) # 3/7/03
    at.outputStringWithLineEndings(s)
#@+node:ekr.20041005105605.144: *6* at.write & helper
def write (self,root,
    kind = '@unknown', # Should not happen.
    nosentinels = False,
    thinFile = False,
    scriptWrite = False,
    toString = False,
):
    """Write a 4.x derived file.
    root is the position of an @<file> node"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    << set at.targetFileName >>
    at.initWriteIvars(root,at.targetFileName,
        nosentinels = nosentinels, thinFile = thinFile,
        scriptWrite = scriptWrite, toString = toString)

    # "look ahead" computation of eventual fileName.
    eventualFileName = c.os_path_finalize_join(
        at.default_directory,at.targetFileName)
    exists = g.os_path_exists(eventualFileName)

    if trace:
        g.trace('default_dir',
            g.os_path_exists(at.default_directory),
            at.default_directory)
        g.trace('eventual_fn',exists,eventualFileName)

    if not scriptWrite and not toString:
        # 2010/7/28: The read logic now sets the at_read bit for @nosent nodes,
        # so we can just use promptForDangerousWrite.
        if not hasattr(root.v,'at_read') and exists:
            # Prompt if writing a new @file or @thin node would
            # overwrite an existing file.
            ok = self.promptForDangerousWrite(eventualFileName,kind)
            if ok:
                root.v.at_read = True # Create the attribute for all clones.
            else:
                g.es("not written:",eventualFileName)
                << set dirty and orphan bits >> # 2010/10/21.
                return

    if not at.openFileForWriting(root,at.targetFileName,toString):
        # openFileForWriting calls root.setDirty() if there are errors.
        return

    try:
        at.writeOpenFile(root,nosentinels=nosentinels,toString=toString)
        assert root==at.root,'write'
        if toString:
            at.closeWriteFile() # sets self.stringOutput
            # Major bug: failure to clear this wipes out headlines!
            # Minor bug: sometimes this causes slight problems...
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
        else:
            at.closeWriteFile()
            if at.errors > 0 or root.isOrphan():
                << set dirty and orphan bits >>
                g.es("not written:",at.outputFileName)
            else:
                at.replaceTargetFileIfDifferent(root)
                    # Sets/clears dirty and orphan bits.

    except Exception:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        if toString:
            at.exception("exception preprocessing script")
            root.v._p_changed = True
        else:
            at.writeException() # Sets dirty and orphan bits.
#@+node:ekr.20041005105605.145: *7* << set at.targetFileName >>
if toString:
    at.targetFileName = "<string-file>"
elif nosentinels:
    at.targetFileName = root.atNoSentFileNodeName()
elif thinFile:
    at.targetFileName = root.atThinFileNodeName()
    if not at.targetFileName:
        # We have an @file node.
        at.targetFileName = root.atFileNodeName()
else:
    at.targetFileName = root.atFileNodeName()
#@+node:ekr.20041005105605.146: *7* << set dirty and orphan bits >>
# Setting the orphan and dirty flags tells Leo to write the tree..
root.setOrphan()
root.setDirty()
# Delete the temp file.
self.remove(at.outputFileName) 

#@+node:ekr.20050506084734: *6* at.writeFromString
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok,'writeFromString' # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@+node:ekr.20070806141607: *6* at.writeOneAtAutoNode & helpers
def writeOneAtAutoNode(self,p,toString,force):

    '''Write p, an @auto node.

    File indices *must* have already been assigned.'''

    at = self ; c = at.c ; root = p.copy()

    fileName = p.atAutoNodeName()
    if not fileName and not toString: return False

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors:
        root.setDirty() # 2010/10/21
        return # 2010/10/21

    fileName = c.os_path_finalize_join(at.default_directory,fileName)
    exists = g.os_path_exists(fileName)
    if not toString and exists and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @auto node would overwrite the existing file.
        ok = self.promptForDangerousWrite(fileName,kind='@auto')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fileName)
            return

    # Prompt if writing a new @auto node would overwrite an existing file.
    if (not toString and not hasattr(p.v,'at_read') and
        g.os_path_exists(fileName)
    ):
        ok = self.promptForDangerousWrite(fileName,kind='@auto')
        if ok:
            p.v.at_read = True # Create the attribute
        else:
            g.es("not written:",fileName)
            return False

    # This code is similar to code in at.write.
    c.endEditing() # Capture the current headline.
    at.targetFileName = g.choose(toString,"<string-file>",fileName)

    at.initWriteIvars(root,at.targetFileName,
        atAuto=True,
        nosentinels=True,thinFile=False,scriptWrite=False,
        toString=toString)

    ok = at.openFileForWriting (root,fileName=fileName,toString=toString)
    isAtAutoRst = root.isAtAutoRstNode()
    if ok:
        if isAtAutoRst:
            ok2 = c.rstCommands.writeAtAutoFile(root,fileName,self.outputFile)
            if not ok2: at.errors += 1
        else:
            at.writeOpenFile(root,nosentinels=True,toString=toString)
        at.closeWriteFile() # Sets stringOutput if toString is True.
        # g.trace('at.errors',at.errors)
        if at.errors == 0:
            # g.trace('toString',toString,'force',force,'isAtAutoRst',isAtAutoRst)
            at.replaceTargetFileIfDifferent(root,ignoreBlankLines=isAtAutoRst)
                # Sets/clears dirty and orphan bits.
        else:
            g.es("not written:",at.outputFileName)
            root.setDirty() # New in Leo 4.4.8.

    elif not toString:
        root.setDirty() # Make _sure_ we try to rewrite this file.
        g.es("not written:",at.outputFileName)

    return ok
#@+node:ekr.20090225080846.5: *6* at.writeOneAtEditNode
def writeOneAtEditNode(self,p,toString,force=False):

    '''Write one @edit node.'''

    at = self ; c = at.c ; root = p.copy()
    c.endEditing()

    fn = p.atEditNodeName()
    if not fn and not toString: return False

    if p.hasChildren():
        g.es('@edit nodes must not have children',color='red')
        g.es('To save your work, convert @edit to @auto or @thin')
        return False

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors:
        g.es("not written:",p.h) # 2010/10/21
        root.setDirty() # 2010/10/21
        return False # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    exists = g.os_path_exists(fn)
    if not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @edit node would overwrite the existing file.
        ok = self.promptForDangerousWrite(fn,kind='@edit')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return False

    at.targetFileName = fn
    at.initWriteIvars(root,at.targetFileName,
        atAuto=True, atEdit=True,
        nosentinels=True,thinFile=False,
        scriptWrite=False,toString=toString)

    # Compute the file's contents.
    # Unlike the @nosent file logic it does not add a final newline.
    contents = ''.join([s for s in g.splitLines(p.b)
        if at.directiveKind4(s,0) == at.noDirective])

    if toString:
        at.stringOutput = contents
        return True

    ok = at.openFileForWriting(root,fileName=fn,toString=False)
    if ok:
        self.os(contents)
        at.closeWriteFile()
    if ok and at.errors == 0:
        at.replaceTargetFileIfDifferent(root) # Sets/clears dirty and orphan bits.
    else:
        g.es("not written:",at.outputFileName)
        root.setDirty()

    return ok
#@+node:ekr.20080711093251.5: *6* at.writeOneAtShadowNode & helpers
def writeOneAtShadowNode(self,p,toString,force):

    '''Write p, an @shadow node.

    File indices *must* have already been assigned.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; root = p.copy() ; x = c.shadowController

    fn = p.atShadowFileNodeName()
    if trace: g.trace(p.h,fn)
    if not fn:
        g.es_print('can not happen: not an @shadow node',p.h,color='red')
        return False

    # A hack to support unknown extensions.
    self.adjustTargetLanguage(fn) # May set c.target_language.

    fn = at.fullPath(p)
    at.default_directory = g.os_path_dirname(fn)
    exists = g.os_path_exists(fn)
    if trace: g.trace('exists %s fn %s' % (exists,fn))

    # Bug fix 2010/01/18: Make sure we can compute the shadow directory.
    private_fn = x.shadowPathName(fn)
    if not private_fn:
        return False

    if not toString and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @shadow node would overwrite the existing public file.
        ok = self.promptForDangerousWrite(fn,kind='@shadow')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return

    c.endEditing() # Capture the current headline.

    at.initWriteIvars(root,targetFileName=None, # Not used.
        atShadow=True,
        nosentinels=None, # set below.  Affects only error messages (sometimes).
        thinFile=True, # New in Leo 4.5 b2: private files are thin files.
        scriptWrite=False,
        toString=False, # True: create a fileLikeObject.  This is done below.
        forcePythonSentinels=True) # A hack to suppress an error message.
            # The actual sentinels will be set below.

    # Bug fix: Leo 4.5.1: use x.markerFromFileName to force the delim to match
    #                     what is used in x.propegate changes.
    marker = x.markerFromFileName(fn)
    at.startSentinelComment,at.endSentinelComment=marker.getDelims()

    if g.app.unitTesting: ivars_dict = g.getIvarsDict(at)

    # Write the public and private files to public_s and private_s strings.
    data = []
    for sentinels in (False,True):
        theFile = at.openStringFile(fn)
        at.sentinels = sentinels
        at.writeOpenFile(root,
            nosentinels=not sentinels,toString=False)
            # nosentinels only affects error messages, and then only if atAuto is True.
        s = at.closeStringFile(theFile)
        data.append(s)

    # Set these new ivars for unit tests.
    at.public_s, at.private_s = data

    if g.app.unitTesting:
        exceptions = ('public_s','private_s','sentinels','stringOutput')
        assert g.checkUnchangedIvars(at,ivars_dict,exceptions),'writeOneAtShadowNode'

    if at.errors == 0 and not toString:
        # Write the public and private files.
        if trace: g.trace('writing',fn)
        x.makeShadowDirectory(fn) # makeShadowDirectory takes a *public* file name.
        at.replaceFileWithString(private_fn,at.private_s)
        at.replaceFileWithString(fn,at.public_s)

    self.checkPythonCode(root,s=at.private_s,targetFn=fn)

    if at.errors == 0:
        root.clearOrphan()
        root.clearDirty()
    else:
        g.es("not written:",at.outputFileName,color='red')
        root.setDirty() # New in Leo 4.4.8.

    return at.errors == 0
#@+node:ekr.20080819075811.13: *7* adjustTargetLanguage
def adjustTargetLanguage (self,fn):

    """Use the language implied by fn's extension if
    there is a conflict between it and c.target_language."""

    at = self ; c = at.c

    if c.target_language:
        junk,target_ext = g.os_path_splitext(fn)  
    else:
        target_ext = ''

    junk,ext = g.os_path_splitext(fn)

    if ext:
        if ext.startswith('.'): ext = ext[1:]

        language = g.app.extension_dict.get(ext)
        if language:
            c.target_language = language
        else:
            # An unknown language.
            pass # Use the default language, **not** 'unknown_language'
#@+node:ekr.20101022055534.5983: *5*  Found: scanAllDirectives
#@+node:ekr.20101022055534.5984: *6* defs
#@+node:ekr.20031218072017.1380: *7* g.Directive utils...
# New in Leo 4.6:
# g.findAtTabWidthDirectives, g.findLanguageDirectives and
# g.get_directives_dict use re module for faster searching.
#@+node:EKR.20040504150046.4: *8* g.comment_delims_from_extension
def comment_delims_from_extension(filename):

    """
    Return the comment delims corresponding to the filename's extension.

    >>> import leo.core.leoGlobals as g
    >>> g.comment_delims_from_extension(".py")
    ('#', '', '')

    >>> g.comment_delims_from_extension(".c")
    ('//', '/*', '*/')

    >>> g.comment_delims_from_extension(".html")
    ('', '<!--', '-->')

    """

    if filename.startswith('.'):
        # Python 2.6 changes how splitext works.
        root,ext = None,filename
    else:
        root, ext = os.path.splitext(filename)
    if ext == '.tmp':
        root, ext = os.path.splitext(root)

    language = g.app.extension_dict.get(ext[1:])
    if ext:
        return g.set_delims_from_language(language)
    else:
        g.trace("unknown extension: %s, filename: %s, root: %s" % (
            repr(ext),repr(filename),repr(root)))
        return '','',''
#@+node:ekr.20071109165315: *8* g.stripPathCruft
def stripPathCruft (path):

    '''Strip cruft from a path name.'''

    if not path:
        return path # Retain empty paths for warnings.

    if len(path) > 2 and (
        (path[0]=='<' and path[-1] == '>') or
        (path[0]=='"' and path[-1] == '"') or
        (path[0]=="'" and path[-1] == "'")
    ):
        path = path[1:-1].strip()

    # We want a *relative* path, not an absolute path.
    return path
#@+node:ekr.20090214075058.8: *8* g.findAtTabWidthDirectives (must be fast)
g_tabwidth_pat = re.compile(r'(^@tabwidth)',re.MULTILINE)

def findTabWidthDirectives(c,p):

    '''Return the language in effect at position p.'''

    if c is None:
        return # c may be None for testing.

    w = None
    # 2009/10/02: no need for copy arg to iter
    for p in p.self_and_parents():
        if w: break
        for s in p.h,p.b:
            if w: break
            anIter = g_tabwidth_pat.finditer(s)
            for m in anIter:
                word = m.group(0)
                i = m.start(0)
                j = g.skip_ws(s,i + len(word))
                junk,w = g.skip_long(s,j)
                if w == 0: w = None
    return w
#@+node:ekr.20090214075058.6: *8* g.findLanguageDirectives (must be fast)
g_language_pat = re.compile(r'(^@language)',re.MULTILINE)

def findLanguageDirectives(c,p):

    '''Return the language in effect at position p.'''

    trace = False and not g.unitTesting

    if c is None:
        return # c may be None for testing. 
    if c.target_language:
        language = c.target_language.lower()
    else:
        language = 'python'
    found = False
    # 2009/10/02: no need for copy arg to iter.
    for p in p.self_and_parents():
        if found: break
        for s in p.h,p.b:
            if found: break
            anIter = g_language_pat.finditer(s)
            for m in anIter:
                word = m.group(0)
                i = m.start(0)
                j = i + len(word)
                k = g.skip_line(s,j)
                language = s[j:k].strip()
                found = True

    if trace: g.trace(language)
    return language
#@+node:ekr.20031218072017.1385: *8* g.findReference
# Called from the syntax coloring method that colorizes section references.

def findReference(c,name,root):

    '''Find the section definition for name.

    If a search of the descendants fails,
    and an ancestor is an @root node,
    search all the descendants of the @root node.
    '''

    for p in root.subtree():
        assert(p!=root)
        if p.matchHeadline(name) and not p.isAtIgnoreNode():
            return p

    # New in Leo 4.7: expand the search for @root trees.
    for p in root.self_and_parents():
        d = g.get_directives_dict(p)
        if 'root' in d:
            for p2 in p.subtree():
                if p2.matchHeadline(name) and not p2.isAtIgnoreNode():
                    return p2

    # g.trace("not found:",name,root)
    return c.nullPosition()
#@+node:ekr.20090214075058.9: *8* g.get_directives_dict (must be fast)
# The caller passes [root_node] or None as the second arg.
# This allows us to distinguish between None and [None].

g_noweb_root = re.compile('<'+'<'+'*'+'>'+'>'+'=',re.MULTILINE)

def get_directives_dict(p,root=None):

    """Scan p for @directives found in globalDirectiveList.

    Returns a dict containing the stripped remainder of the line
    following the first occurrence of each recognized directive"""

    trace = False and not g.unitTesting
    verbose = False
    if trace: g.trace('*'*20,p.h)

    if root: root_node = root[0]
    d = {}

    # Do this every time so plugins can add directives.
    pat = g.compute_directives_re()
    directives_pat = re.compile(pat,re.MULTILINE)

    # The headline has higher precedence because it is more visible.
    for kind,s in (('head',p.h),('body',p.b)):
        anIter = directives_pat.finditer(s)
        for m in anIter:
            word = m.group(0)[1:] # Omit the @
            i = m.start(0)
            if word.strip() not in d:
                j = i + 1 + len(word)
                k = g.skip_line(s,j)
                val = s[j:k].strip()
                if j < len(s) and s[j] not in (' ','\t','\n'):
                    # g.es_print('invalid character after directive',s[max(0,i-1):k-1],color='red')
                    # if trace:g.trace(word,repr(val),s[i:i+20])
                    pass # Not a valid directive: just ignore it.
                else:
                    directive_word = word.strip()
                    if directive_word in ('root-doc', 'root-code'):
                        d['root'] = val # in addition to optioned version
                    d[directive_word] = val
                    if trace: g.trace(word.strip(),kind,repr(val))
                    # A special case for @path in the body text of @<file> nodes.
                    # Don't give an actual warning: just set some flags.
                    if kind == 'body' and word.strip() == 'path' and p.isAnyAtFileNode():
                        g.app.atPathInBodyWarning = p.h
                        d['@path_in_body'] = p.h
                        if trace: g.trace('@path in body',p.h)

    if root:
        anIter = g_noweb_root.finditer(p.b)
        for m in anIter:
            if root_node:
                d["root"]=0 # value not immportant
            else:
                g.es('%s= may only occur in a topmost node (i.e., without a parent)' % (
                    g.angleBrackets('*')))
            break

    if trace and verbose: g.trace('%4d' % (len(p.h) + len(p.b)),g.callers(5))
    return d
#@+node:ekr.20090214075058.10: *9* compute_directives_re
def compute_directives_re ():

    '''Return an re pattern which will match all Leo directives.'''

    global globalDirectiveList

    aList = ['^@%s' % z for z in globalDirectiveList
                if z != 'others']

    if 0: # 2010/02/01
        # The code never this, and this regex is broken
        # because it can confuse g.get_directives_dict.
        # @others can have leading whitespace.
        aList.append(r'^\s@others\s')

    return '|'.join(aList)
#@+node:ekr.20080827175609.1: *8* g.get_directives_dict_list (must be fast)
def get_directives_dict_list(p1):

    """Scans p and all its ancestors for directives.

    Returns a list of dicts containing pointers to
    the start of each directive"""

    trace = False and not g.unitTesting

    if trace: time1 = g.getTime()

    result = []

    if p1:
        p1 = p1.copy()
        for p in p1.self_and_parents():
            if p.hasParent(): root = None
            else:             root = [p.copy()]
            result.append(g.get_directives_dict(p,root=root))

        if trace:
            n = len(p1.h) + len(p1.b)
            g.trace('%4d %s' % (n,g.timeSince(time1)))

    return result
#@+node:ekr.20031218072017.1386: *8* g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@+node:ekr.20080827175609.52: *8* g.scanAtCommentAndLanguageDirectives
def scanAtCommentAndAtLanguageDirectives(aList):

    '''Scan aList for @comment and @language directives.

    @comment should follow @language if both appear in the same node.'''

    lang = None

    for d in aList:

        comment = d.get('comment')
        language = d.get('language')

        # Important: assume @comment follows @language.
        if language:
            # if g.unitTesting: g.trace('language',language)
            lang,delim1,delim2,delim3 = g.set_language(language,0)

        if comment:
            # if g.unitTesting: g.trace('comment',comment)
            delim1,delim2,delim3 = g.set_delims_from_string(comment)

        if comment or language:
            delims = delim1,delim2,delim3
            return {'language':lang,'comment':comment,'delims':delims}

    return None
#@+node:ekr.20080827175609.32: *8* g.scanAtEncodingDirectives
def scanAtEncodingDirectives(aList):

    '''Scan aList for @encoding directives.'''

    for d in aList:
        encoding = d.get('encoding')
        if encoding and g.isValidEncoding(encoding):
            # g.trace(encoding)
            return encoding
        elif encoding and not g.app.unitTesting:
            g.es("invalid @encoding:",encoding,color="red")

    return None
#@+node:ekr.20080827175609.53: *8* g.scanAtHeaderDirectives
def scanAtHeaderDirectives(aList):

    '''scan aList for @header and @noheader directives.'''

    for d in aList:
        if d.get('header') and d.get('noheader'):
            g.es_print("conflicting @header and @noheader directives",color='red')
#@+node:ekr.20080827175609.33: *8* g.scanAtLineendingDirectives
def scanAtLineendingDirectives(aList):

    '''Scan aList for @lineending directives.'''

    for d in aList:

        e = d.get('lineending')
        if e in ("cr","crlf","lf","nl","platform"):
            lineending = g.getOutputNewline(name=e)
            return lineending
        # else:
            # g.es("invalid @lineending directive:",e,color="red")

    return None
#@+node:ekr.20080827175609.34: *8* g.scanAtPagewidthDirectives
def scanAtPagewidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @pagewidth directives.'''

    for d in aList:
        s = d.get('pagewidth')
        if s is not None:
            i, val = g.skip_long(s,0)
            if val != None and val > 0:
                # g.trace(val)
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @pagewidth",s,color="red")

    return None
#@+node:ekr.20100507084415.5760: *8* g.scanAtRootDirectives
def scanAtRootDirectives(aList):

    '''Scan aList for @root directives.'''

    for d in aList:
        s = d.get('root')
        if s is not None:
            i, mode = g.scanAtRootOptions(s,0)
            g.trace(mode)
            return mode

    return None
#@+node:ekr.20031218072017.3154: *8* g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    # g.trace(mode,g.callers(3))

    return i,mode
#@+node:ekr.20031218072017.3155: *9* << scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','\n','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@+node:ekr.20080827175609.37: *8* g.scanAtTabwidthDirectives & scanAllTabWidthDirectives
def scanAtTabwidthDirectives(aList,issue_error_flag=False):

    '''Scan aList for @tabwidth directives.'''

    for d in aList:
        s = d.get('tabwidth')
        if s is not None:
            junk,val = g.skip_long(s,0)
            if val not in (None,0):
                return val
            else:
                if issue_error_flag and not g.app.unitTesting:
                    g.es("ignoring @tabwidth",s,color="red")
    return None

def scanAllAtTabWidthDirectives(c,p):

    '''Scan p and all ancestors looking for @tabwidth directives.'''

    if c and p:
        aList = g.get_directives_dict_list(p)
        val = g.scanAtTabwidthDirectives(aList)
        ret = g.choose(val is None,c.tab_width,val)
    else:
        ret = None
    # g.trace(ret,p and p.h,ret)
    return ret
#@+node:ekr.20080831084419.4: *8* g.scanAtWrapDirectives & scanAllAtWrapDirectives
def scanAtWrapDirectives(aList,issue_error_flag=False):

    '''Scan aList for @wrap and @nowrap directives.'''

    for d in aList:
        if d.get('wrap') is not None:
            return True
        elif d.get('nowrap') is not None:
            return False

    return None

def scanAllAtWrapDirectives(c,p):

    '''Scan p and all ancestors looking for @wrap/@nowrap directives.'''

    if c and p:
        default = c and c.config.getBool("body_pane_wraps")
        aList = g.get_directives_dict_list(p)

        val = g.scanAtWrapDirectives(aList)
        ret = g.choose(val is None,default,val)
    else:
        ret = None
    # g.trace(ret,p.h)
    return ret
#@+node:ekr.20080901195858.4: *8* g.scanDirectives  (for compatibility only)
def scanDirectives(c,p=None):

    return c.scanAllDirectives(p)
#@+node:ekr.20040715155607: *8* g.scanForAtIgnore
def scanForAtIgnore(c,p):

    """Scan position p and its ancestors looking for @ignore directives."""

    if g.app.unitTesting:
        return False # For unit tests.

    for p in p.self_and_parents():
        d = g.get_directives_dict(p)
        if 'ignore' in d:
            return True

    return False
#@+node:ekr.20040712084911.1: *8* g.scanForAtLanguage
def scanForAtLanguage(c,p):

    """Scan position p and p's ancestors looking only for @language and @ignore directives.

    Returns the language found, or c.target_language."""

    # Unlike the code in x.scanAllDirectives, this code ignores @comment directives.

    if c and p:
        for p in p.self_and_parents():
            d = g.get_directives_dict(p)
            if 'language' in d:
                z = d["language"]
                language,delim1,delim2,delim3 = g.set_language(z,0)
                return language

    return c.target_language
#@+node:ekr.20041123094807: *8* g.scanForAtSettings
def scanForAtSettings(p):

    """Scan position p and its ancestors looking for @settings nodes."""

    for p in p.self_and_parents():
        h = p.h
        h = g.app.config.canonicalizeSettingName(h)
        if h.startswith("@settings"):
            return True

    return False
#@+node:ekr.20031218072017.1382: *8* g.set_delims_from_language
# Returns a tuple (single,start,end) of comment delims

def set_delims_from_language(language):

    trace = False and not g.unitTesting

    val = g.app.language_delims_dict.get(language)
    # if language.startswith('huh'): g.pdb()

    if val:
        delim1,delim2,delim3 = g.set_delims_from_string(val)
        if trace: g.trace(repr(language),
            repr(delim1),repr(delim2),repr(delim3),g.callers(5))
        if delim2 and not delim3:
            return '',delim1,delim2
        else: # 0,1 or 3 params.
            return delim1,delim2,delim3
    else:
        return '','','' # Indicate that no change should be made
#@+node:ekr.20031218072017.1383: *8* g.set_delims_from_string
def set_delims_from_string(s):

    """Returns (delim1, delim2, delim2), the delims following the @comment directive.

    This code can be called from @language logic, in which case s can point at @comment"""

    # Skip an optional @comment
    tag = "@comment"
    i = 0
    if g.match_word(s,i,tag):
        i += len(tag)

    count = 0 ; delims = ['','','']
    while count < 3 and i < len(s):
        i = j = g.skip_ws(s,i)
        while i < len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        if j == i: break
        delims[count] = s[j:i] or ''
        count += 1

    # 'rr 09/25/02
    if count == 2: # delims[0] is always the single-line delim.
        delims[2] = delims[1]
        delims[1] = delims[0]
        delims[0] = ''

    # 7/8/02: The "REM hack": replace underscores by blanks.
    # 9/25/02: The "perlpod hack": replace double underscores by newlines.
    for i in range(0,3):
        if delims[i]:
            delims[i] = delims[i].replace("__",'\n').replace('_',' ')

    return delims[0], delims[1], delims[2]
#@+node:ekr.20031218072017.1384: *8* g.set_language
def set_language(s,i,issue_errors_flag=False):

    """Scan the @language directive that appears at s[i:].

    The @language may have been stripped away.

    Returns (language, delim1, delim2, delim3)
    """

    tag = "@language"
    # g.trace(g.get_line(s,i))
    assert(i != None)
    # assert(g.match_word(s,i,tag))
    if g.match_word(s,i,tag):
        i += len(tag)
    # Get the argument.
    i = g.skip_ws(s, i)
    j = i ; i = g.skip_c_id(s,i)
    # Allow tcl/tk.
    arg = s[j:i].lower()
    if app.language_delims_dict.get(arg):
        language = arg
        delim1, delim2, delim3 = g.set_delims_from_language(language)
        return language, delim1, delim2, delim3

    if issue_errors_flag:
        g.es("ignoring:",g.get_line(s,i))

    return None, None, None, None,
#@+node:ekr.20081001062423.9: *8* g.setDefaultDirectory & helpers
# This is a refactoring, used by leoImport.scanDefaultDirectory and
# atFile.scanDefaultDirectory

def setDefaultDirectory(c,p,importing=False):

    ''' Compute a default directory by scanning @path directives.
    Return (default_dir,error_message).'''

    if not p: return '',''
    default_dir,error = g.getAbsPathFromNode(c,p),''

    if not default_dir:
        default_dir,error = g.getPathFromDirectives(c,p)

    if c and c.frame and not default_dir and not error:
        default_dir = g.findDefaultDirectory(c)

    if not default_dir and not importing and not error:
        # This should never happen: c.openDirectory should be a good last resort.
        error = "No absolute directory specified anywhere."

    return default_dir, error
#@+node:ekr.20081001062423.10: *9* g.getAbsPathFromNode
# An absolute path in an @file node over-rides everything else.
# A relative path gets appended to the relative path by the open logic.

def getAbsPathFromNode(c,p,name=''): # Name is for unit testing.

    default_dir = ''
    if p:
        name = p.anyAtFileNodeName()

    if name:
        theDir = g.os_path_dirname(name)
        if theDir and g.os_path_isabs(theDir):
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)

    return default_dir
#@+node:ekr.20081001062423.11: *9* g.getPathFromDirectives
def getPathFromDirectives(c,p,createFlag=True):

    '''Scan for @path directives.'''

    trace = False and not g.unitTesting
    default_dir = '' ; error = ''
    if not p: return default_dir,error
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if path:
        base = g.getBaseDirectory(c) # returns "" on error.
        path = c.os_path_finalize_join(base,path)
        exists = g.os_path_exists(path)
        if createFlag:
            if exists:
                default_dir = path
            else:
                default_dir = g.makeAllNonExistentDirectories(path,c=c)
                if not default_dir:
                    error = "invalid @path: %s" % path
        else:
            default_dir = path
            if not exists:
                error = "does not exist: @path %s" % path

    return default_dir,error
#@+node:ekr.20081001062423.12: *9* g.findDefaultDirectory (major change)
# This code is executed if no valid absolute path was specified in
# the @file node or in an @path directive.

def findDefaultDirectory(c):

    '''Attempt to find a suitable default directory.'''

    default_dir = ''

    # Check that c.openDirectory and c.frame.openDirectory are in synch.
    if c.openDirectory != c.frame.openDirectory:
        g.trace('***can not happen: c.openDirectory != c.frame.openDirectory')
        g.trace('c.openDirectory',c.openDirectory)
        g.trace('c.frame.openDirectory',c.frame.openDirectory)

    if not g.os_path_isabs(c.openDirectory):
        g.trace('*** can not happen: relative c.openDirectory',c.openDirectory)

    for theDir in (c.openDirectory,g.getBaseDirectory(c)):
        if theDir and g.os_path_isabs(theDir): # Errors may result in relative or invalid path.
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)
            if default_dir: break

    return default_dir
#@+node:ekr.20101022055534.5985: *7* Not shown tangle.scanAllDirectives
# No change will be made to the tangle code.
#@+node:ekr.20080827175609.39: *7* c.scanAllDirectives
def scanAllDirectives(self,p=None):

    '''Scan p and ancestors for directives.

    Returns a dict containing the results, including defaults.'''

    c = self ; p = p or c.p

    # Set defaults
    language = c.target_language and c.target_language.lower()
    lang_dict = {
        'language':language,
        'delims':g.set_delims_from_language(language),
    }
    wrap = c.config.getBool("body_pane_wraps")

    table = (
        ('encoding',    None,           g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
        ('wrap',        wrap,           g.scanAtWrapDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process: do *not* set commander ivars.
    lang_dict = d.get('lang-dict')

    return {
        "delims"        : lang_dict.get('delims'),
        "encoding"      : d.get('encoding'),
        "language"      : lang_dict.get('language'),
        "lineending"    : d.get('lineending'),
        "pagewidth"     : d.get('pagewidth'),
        "path"          : d.get('path') or g.getBaseDirectory(c),
        "tabwidth"      : d.get('tabwidth'),
        "pluginsList"   : [], # No longer used.
        "wrap"          : d.get('wrap'),
    }
#@+node:ekr.20080923070954.4: *7* at.scanAllDirectives
def scanAllDirectives(self,p,
    scripting=False,importing=False,
    reading=False,forcePythonSentinels=False,
    createPath=True,
    issuePathWarning=False,
):

    '''Scan p and p's ancestors looking for directives,
    setting corresponding atFile ivars.'''

    trace = False and not g.unitTesting
    at = self ; c = self.c
    g.app.atPathInBodyWarning = None
    << set ivars >>
    lang_dict = {'language':at.language,'delims':delims,}
    table = (
        ('encoding',    at.encoding,    g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    if issuePathWarning and g.app.atPathInBodyWarning:
        g.es('warning: ignoring @path directive in',
            g.app.atPathInBodyWarning,color='red')

    # Post process.
    lang_dict       = d.get('lang-dict')
    delims          = lang_dict.get('delims')
    lineending      = d.get('lineending')
    if lineending:
        at.explicitLineEnding = True
        at.output_newline = lineending
    else:
        at.output_newline = g.getOutputNewline(c=c) # Init from config settings.

    at.encoding             = d.get('encoding')
    at.language             = lang_dict.get('language')
    at.page_width           = d.get('pagewidth')
    at.default_directory    = d.get('path')
    at.tab_width            = d.get('tabwidth')

    if not importing and not reading:
        # Don't override comment delims when reading!
        << set comment strings from delims >>

    # For unit testing.
    d = {
        "all"       : all,
        "encoding"  : at.encoding,
        "language"  : at.language,
        "lineending": at.output_newline,
        "pagewidth" : at.page_width,
        "path"      : at.default_directory,
        "tabwidth"  : at.tab_width,
    }
    if trace: g.trace(d)
    return d
#@+node:ekr.20080923070954.14: *8* << Set ivars >>
self.page_width = self.c.page_width
self.tab_width  = self.c.tab_width

self.default_directory = None # 8/2: will be set later.

# g.trace(c.target_language)

if c.target_language:
    c.target_language = c.target_language.lower()

delims = g.set_delims_from_language(c.target_language)
at.language = c.target_language

at.encoding = c.config.default_derived_file_encoding
at.output_newline = g.getOutputNewline(c=self.c) # Init from config settings.
#@+node:ekr.20080923070954.13: *8* << Set comment strings from delims >>
if forcePythonSentinels:
    # Force Python language.
    delim1,delim2,delim3 = g.set_delims_from_language("python")
    self.language = "python"
else:
    delim1,delim2,delim3 = delims

# Use single-line comments if we have a choice.
# delim1,delim2,delim3 now correspond to line,start,end
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else: # Emergency!
    # assert(0)
    if not g.app.unitTesting:
        g.es_print("unknown language: using Python comment delimiters")
        g.es_print("c.target_language:",c.target_language)
        g.es_print('','delim1,delim2,delim3:','',delim1,'',delim2,'',delim3)
    at.startSentinelComment = "#" # This should never happen!
    at.endSentinelComment = ""

# g.trace(repr(self.startSentinelComment),repr(self.endSentinelComment))
#@+node:ekr.20080901195858.4: *7* g.scanDirectives  (for compatibility only)
def scanDirectives(c,p=None):

    return c.scanAllDirectives(p)
#@+node:ekr.20101022055534.5986: *6* Calls that **do** use path
#@+node:ekr.20041005105605.15: *7* at.initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels,
            issuePathWarning=True)
        # Sets the following ivars:
            # at.explicitLineEnding
            # at.output_newline
            # at.encoding
            # at.language
            # at.page_width
            # at.default_directory  *** path ***
            # at.tab_width

    # g.trace(forcePythonSentinels,
    #    self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16: *8* << init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the
temporary file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False
    # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.writeVersion5 = self.new_write and not atShadow

self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@+node:ekr.20041005105605.21: *7* at.read & helpers
def read(self,root,importFileName=None,
    fromString=None,atShadow=False,force=False
):

    """Read an @thin or @file tree."""

    trace = False and not g.unitTesting
    if trace: g.trace(root.h)
    at = self ; c = at.c
    fileName = at.initFileName(fromString,importFileName,root)
    if not fileName:
        at.error("Missing file name.  Restoring @file tree from .leo file.")
        return False
    at.initReadIvars(root,fileName,
        importFileName=importFileName,atShadow=atShadow)
    at.fromString = fromString
    if at.errors:
        if trace: g.trace('Init error')
        return False
    fileName = at.openFileForReading(fromString=fromString)
    if fileName and at.inputFile:
        c.setFileTimeStamp(fileName)
    elif fromString: # 2010/09/02.
        pass
    else:
        g.trace('No inputFile')
        return False
    root.v.at_read = True # Remember that we have read this file.

    # Get the file from the cache if possible.
    if fromString:
        s,loaded,fileKey = fromString,False,None
    else:
        s,loaded,fileKey = c.cacher.readFile(fileName,root)
    # 2010/02/24: Never read an external file
    # with file-like sentinels from the cache.
    isFileLike = loaded and at.isFileLike(s)
    if not loaded or isFileLike:
        # if trace: g.trace('file-like file',fileName)
        force = True # Disable caching.
    if loaded and not force:
        if trace: g.trace('in cache',fileName)
        at.inputFile.close()
        root.clearDirty()
        return True
    if not g.unitTesting:
        g.es("reading:",root.h)
    if isFileLike:
        if g.unitTesting:
            if 0: print("converting @file format in",root.h)
            g.app.unitTestDict['read-convert']=True
        else:
            g.es("converting @file format in",root.h,color='red')
    root.clearVisitedInTree()
    d = at.scanAllDirectives(root,importing=at.importing,reading=True)
        # Sets the following ivars:
            # at.explicitLineEnding
            # at.output_newline
            # at.encoding
            # at.language
            # at.page_width
            # at.default_directory *** path**
            # at.tab_width

    thinFile = at.readOpenFile(root,at.inputFile,fileName,deleteNodes=True)
    at.inputFile.close()
    root.clearDirty() # May be set dirty below.
    if at.errors == 0:
        at.deleteUnvisitedNodes(root)
        at.deleteTnodeList(root)
    if at.errors == 0 and not at.importing:
        # Used by mod_labels plugin.
        self.copyAllTempBodyStringsToVnodes(root,thinFile)
    at.deleteAllTempBodyStrings()
    if isFileLike:
        # 2010/02/24: Make the root @file node dirty so it will
        # be written automatically when saving the file.
        root.setDirty()
        c.setChanged(True) # Essential, to keep dirty bit set.
    if at.errors == 0 and not isFileLike and not fromString:
        c.cacher.writeFile(root,fileKey)

    if trace: g.trace('at.errors',at.errors)
    return at.errors == 0
#@+node:ekr.20041005105605.25: *8* at.deleteAllTempBodyStrings
def deleteAllTempBodyStrings(self):

    for v in self.c.all_unique_nodes():
        if hasattr(v,"tempBodyString"):
            delattr(v,"tempBodyString")
        if hasattr(v,"tempBodyList"):
            delattr(v,"tempBodyList")
#@+node:ekr.20100122130101.6174: *8* at.deleteTnodeList
def deleteTnodeList (self,p): # atFile method.

    '''Remove p's tnodeList.'''

    v = p.v

    if hasattr(v,"tnodeList"):

        if False: # Not an error, but a useful trace.
            s = "deleting tnodeList for " + repr(v)
            g.es_print(s,color="blue")

        delattr(v,"tnodeList")
        v._p_changed = True
#@+node:ekr.20071105164407: *8* at.deleteUnvisitedNodes & helpers
def deleteUnvisitedNodes (self,root):

    '''Delete unvisited nodes in root's subtree, not including root.

    Actually, instead of deleting the nodes, we move them to be children of the
    'Resurrected Nodes' r.
    '''

    at = self

    if not root.hasChildren():
        return

    # Carefully set up the arguments.
    aList = [z.copy() for z in root.subtree() if not z.isVisited()]
    if not aList: return

    r = at.createResurrectedNodesNode()
    assert r not in aList
    callback=at.defineResurrectedNodeCallback(r,root)

    # Now move the nodes.
    root.firstChild().deletePositionsInList(aList,callback)
#@+node:ekr.20100803073751.5817: *9* createResurrectedNodesNode
def createResurrectedNodesNode(self):

    '''Create a 'Resurrected Nodes' node as the last top-level node.'''

    at = self ; c = at.c ; tag = 'Resurrected Nodes'

    # Find the last top-level node.
    last = c.rootPosition()
    while last.hasNext():
        last.moveToNext()

    if last.h == tag:
        # The 'Resurrected Nodes' node already exists.
        p = last
    else:
        # Create the 'Resurrected Nodes' node after 'last'.
        p = last.insertAfter()
        p.setHeadString(tag)

    p.expand()
    return p
#@+node:ekr.20100803073751.5818: *9* defineResurrectedNodeCallback
def defineResurrectedNodeCallback (self,r,root):

    '''Define a callback that moves node p as r's last child.'''

    def callback(p,r=r.copy(),root=root):

        '''The resurrected nodes callback.'''

        child = r.insertAsLastChild()
        child.h = 'From %s' % root.h
        p.moveToLastChildOf(child)

        if g.unitTesting:
            # g.trace(p.h,r.h)
            pass 
        else:
            g.es('resurrected node:',p.h,color='red')
            g.es('in file:',root.h,color='blue')

    return callback


#@+node:ekr.20041005105605.22: *8* at.initFileName
def initFileName (self,fromString,importFileName,root):

    if fromString:
        fileName = "<string-file>"
    elif importFileName:
        fileName = importFileName
    elif root.isAnyAtFileNode():
        fileName = root.anyAtFileNodeName()
    else:
        fileName = None

    return fileName
#@+node:ekr.20100224050618.11547: *8* at.isFileLike
def isFileLike (self,s):

    '''Return True if s has file-like sentinels.'''

    trace = False and not g.unitTesting
    at = self ; tag = "@+leo"
    s = g.toUnicode(s)
    i = s.find(tag)
    if i == -1:
        if trace: g.trace('found: False',repr(s))
        return True # Don't use the cashe.
    else:
        j,k = g.getLine(s,i)
        line = s[j:k]
        valid,new_df,start,end,isThin = \
            at.parseLeoSentinel(line)
        if trace: g.trace('found: True isThin:',
            isThin,repr(line))
        return not isThin
#@+node:ekr.20081006100835.1: *7* c.getNodePath & c.getNodeFileName
def getNodePath (self,p):

    '''Return the path in effect at node p.'''

    c = self
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    return path

def getNodeFileName (self,p):

    '''Return the full file name at node p,
    including effects of all @path directives.

    Return None if p is no kind of @file node.'''

    c = self
    d = c.scanAllDirectives(p)
    path = d.get('path')

    name = ''
    for p in p.self_and_parents():
        name = p.anyAtFileNodeName()
        if name: break

    if name:
        name = g.os_path_finalize_join(path,name)
    return name
#@+node:ekr.20100216141722.5634: *7* getFileLines (leoEditCommands)
def getFileLines (self,root,fileName):

    '''Read the file into lines.'''

    c = self.c
    isAtEdit = root.isAtEditNode()
    isAtNoSent = root.isAtNoSentFileNode()

    if isAtNoSent or isAtEdit:
        # Write a virtual file containing sentinels.
        at = c.atFileCommands
        kind = g.choose(isAtNoSent,'@nosent','@edit')
        at.write(root,kind=kind,nosentinels=False,toString=True)
        lines = g.splitLines(at.stringOutput)
    else:
        # Calculate the full path.
        d = g.scanDirectives(c,p=root)
        path = d.get("path")
        # g.trace('path',path,'fileName',fileName)
        fileName = c.os_path_finalize_join(path,fileName)
        lines    = self.openFile(fileName)

    return lines
#@+node:ekr.20090502071837.60: *7* init_write (rstCommands)
def init_write (self,p):

    self.initOptionsFromSettings() # Still needed.

    # Set the encoding from any parent @encoding directive.
    # This can be overridden by @rst-option encoding=whatever.
    c = self.c
    d = c.scanAllDirectives(p)
    self.encoding = d.get('encoding') or 'utf-8'
    self.path = d.get('path') or ''

    # g.trace('path:',self.path)
#@+node:ekr.20031218072017.3045: *7* setDefaultDirectoryForNewFiles (fileCommands)
def setDefaultDirectoryForNewFiles (self,fileName):

    """Set c.openDirectory for new files for the benefit of leoAtFile.scanAllDirectives."""

    c = self.c

    if not c.openDirectory:
        theDir = g.os_path_dirname(fileName)
        if theDir and g.os_path_isabs(theDir) and g.os_path_exists(theDir):
            c.openDirectory = c.frame.openDirectory = theDir
#@+node:ekr.20101022055534.5987: *6* Calls that do not use path
#@+node:ekr.20031218072017.2824: *7* c.getOpenWithExt
def getOpenWithExt (self,p,ext):

    trace = False and not g.app.unitTesting
    c = self

    if not ext:
        # if node is part of @<file> tree, get ext from file name
        for p2 in p.self_and_parents():
            if p2.isAnyAtFileNode():
                fn = p2.h.split(None,1)[1]
                ext = g.os_path_splitext(fn)[1]
                if trace: g.trace('found node:',ext,p2.h)
                break

    if not ext:
        theDict = c.scanAllDirectives()
        language = theDict.get('language')
        ext = g.app.language_extension_dict.get(language)
        if trace: g.trace('found directive',language,ext)

    if not ext:
        ext = '.txt'
        if trace: g.trace('use default (.txt)')

    if ext[0] != '.':
        ext = '.'+ext

    return ext
#@+node:ekr.20100203050306.5937: *7* c.createOpenWithTempFile
def createOpenWithTempFile (self,p,ext):

    trace = False and not g.unitTesting
    c = self ; f = None

    # May be over-ridden by mod_tempfname plugin.
    fn = c.openWithTempFilePath(p,ext)

    try:
        if g.os_path_exists(fn):
            g.es('recreating:  ',g.shortFileName(fn),color='red')
        else:
            g.es('creating:  ',g.shortFileName(fn),color='blue')
        f = open(fn,'w')
        # Convert s to whatever encoding is in effect.
        d = c.scanAllDirectives(p)
        encoding = d.get('encoding',None)
        if encoding == None:
            encoding = c.config.default_derived_file_encoding
        if g.isPython3: # 2010/02/09
            s = p.b
        else:
            s = g.toEncodedString(p.b,encoding,reportErrors=True) 
        f.write(s)
        f.flush()
        f.close()
        try:
            time = g.os_path_getmtime(fn)
            if time: g.es('time: ',time)
        except:
            time = None

        # Remove previous entry from app.openWithFiles if it exists.
        for d in g.app.openWithFiles[:]:
            if p.v == d.get('v'):
                if trace: g.trace('removing',d.get('path'))
                g.app.openWithFiles.remove(d)

        d = {
            # Used by app.destroyOpenWithFilesForFrame.
            'c':c,
            # Used here and by app.destroyOpenWithFileWithDict.
            'path':fn,
            # Used by c.testForConflicts.
            'body':s,
            'encoding':encoding,
            'time':time,
            # Used by the open_with plugin.
            'p':p.copy(),
            # Used by c.openWithHelper, and below.
            'v':p.v,
        }
        g.app.openWithFiles.append(d)
        return fn
    except:
        if f: f.close()
        g.es('exception creating temp file',color='red')
        g.es_exception()
        return None
#@+node:ekr.20031218072017.1704: *7* convertAllBlanks
def convertAllBlanks (self,event=None):

    '''Convert all blanks to tabs in the selected outline.'''

    c = self ; u = c.undoer ; undoType = 'Convert All Blanks'
    current = c.p

    if g.app.batchMode:
        c.notValidInBatchMode(undoType)
        return

    d = c.scanAllDirectives()
    tabWidth  = d.get("tabwidth")
    count = 0 ; dirtyVnodeList = []
    u.beforeChangeGroup(current,undoType)
    for p in current.self_and_subtree():
        # g.trace(p.h,tabWidth)
        innerUndoData = u.beforeChangeNodeContents(p)
        if p == current:
            changed,dirtyVnodeList2 = c.convertBlanks(event)
            if changed:
                count += 1
                dirtyVnodeList.extend(dirtyVnodeList2)
        else:
            changed = False ; result = []
            text = p.v.b
            # assert(g.isUnicode(text))
            lines = text.split('\n')
            for line in lines:
                i,w = g.skip_leading_ws_with_indent(line,0,tabWidth)
                s = g.computeLeadingWhitespace(w,abs(tabWidth)) + line[i:] # use positive width.
                if s != line: changed = True
                result.append(s)
            if changed:
                count += 1
                dirtyVnodeList2 = p.setDirty()
                dirtyVnodeList.extend(dirtyVnodeList2)
                result = '\n'.join(result)
                p.setBodyString(result)
                u.afterChangeNodeContents(p,undoType,innerUndoData)
    u.afterChangeGroup(current,undoType,dirtyVnodeList=dirtyVnodeList)
    if not g.unitTesting:
        g.es("blanks converted to tabs in",count,"nodes")
            # Must come before c.redraw().
    if count > 0:
        c.redraw_after_icons_changed()
#@+node:ekr.20031218072017.1705: *7* convertAllTabs
def convertAllTabs (self,event=None):

    '''Convert all tabs to blanks in the selected outline.'''

    c = self ; u = c.undoer ; undoType = 'Convert All Tabs'
    current = c.p

    if g.app.batchMode:
        c.notValidInBatchMode(undoType)
        return
    theDict = c.scanAllDirectives()
    tabWidth  = theDict.get("tabwidth")
    count = 0 ; dirtyVnodeList = []
    u.beforeChangeGroup(current,undoType)
    for p in current.self_and_subtree():
        undoData = u.beforeChangeNodeContents(p)
        if p == current:
            changed,dirtyVnodeList2 = self.convertTabs(event)
            if changed:
                count += 1
                dirtyVnodeList.extend(dirtyVnodeList2)
        else:
            result = [] ; changed = False
            text = p.v.b
            # assert(g.isUnicode(text))
            lines = text.split('\n')
            for line in lines:
                i,w = g.skip_leading_ws_with_indent(line,0,tabWidth)
                s = g.computeLeadingWhitespace(w,-abs(tabWidth)) + line[i:] # use negative width.
                if s != line: changed = True
                result.append(s)
            if changed:
                count += 1
                dirtyVnodeList2 = p.setDirty()
                dirtyVnodeList.extend(dirtyVnodeList2)
                result = '\n'.join(result)
                p.setBodyString(result)
                u.afterChangeNodeContents(p,undoType,undoData)
    u.afterChangeGroup(current,undoType,dirtyVnodeList=dirtyVnodeList)
    if not g.unitTesting:
        g.es("tabs converted to blanks in",count,"nodes")
    if count > 0:
        c.redraw_after_icons_changed()
#@+node:ekr.20031218072017.1821: *7* convertBlanks
def convertBlanks (self,event=None):

    '''Convert all blanks to tabs in the selected node.'''

    c = self ; changed = False ; dirtyVnodeList = []
    head,lines,tail,oldSel,oldYview = c.getBodyLines(expandSelection=True)

    # Use the relative @tabwidth, not the global one.
    theDict = c.scanAllDirectives()
    tabWidth  = theDict.get("tabwidth")
    if tabWidth:
        result = []
        for line in lines:
            s = g.optimizeLeadingWhitespace(line,abs(tabWidth)) # Use positive width.
            if s != line: changed = True
            result.append(s)
        if changed:
            undoType = 'Convert Blanks'
            result = ''.join(result)
            oldSel = None
            dirtyVnodeList = c.updateBodyPane(head,result,tail,undoType,oldSel,oldYview) # Handles undo

    return changed,dirtyVnodeList
#@+node:ekr.20031218072017.1822: *7* convertTabs
def convertTabs (self,event=None):

    '''Convert all tabs to blanks in the selected node.'''

    c = self ; changed = False ; dirtyVnodeList = []
    head,lines,tail,oldSel,oldYview = self.getBodyLines(expandSelection=True)

    # Use the relative @tabwidth, not the global one.
    theDict = c.scanAllDirectives()
    tabWidth  = theDict.get("tabwidth")
    if tabWidth:
        result = []
        for line in lines:
            i,w = g.skip_leading_ws_with_indent(line,0,tabWidth)
            s = g.computeLeadingWhitespace(w,-abs(tabWidth)) + line[i:] # use negative width.
            if s != line: changed = True
            result.append(s)
        if changed:
            undoType = 'Convert Tabs'
            result = ''.join(result)
            oldSel = None
            dirtyVnodeList = c.updateBodyPane(head,result,tail,undoType,oldSel,oldYview) # Handles undo

    return changed,dirtyVnodeList
#@+node:ekr.20031218072017.1824: *7* dedentBody
def dedentBody (self,event=None):

    '''Remove one tab's worth of indentation from all presently selected lines.'''

    c = self ; current = c.p ; undoType='Unindent'

    d = c.scanAllDirectives(current) # Support @tab_width directive properly.
    tab_width = d.get("tabwidth",c.tab_width)
    head,lines,tail,oldSel,oldYview = self.getBodyLines()

    result = [] ; changed = False
    for line in lines:
        i, width = g.skip_leading_ws_with_indent(line,0,tab_width)
        s = g.computeLeadingWhitespace(width-abs(tab_width),tab_width) + line[i:]
        if s != line: changed = True
        result.append(s)

    if changed:
        result = ''.join(result)
        c.updateBodyPane(head,result,tail,undoType,oldSel,oldYview)
#@+node:ekr.20031218072017.1830: *7* indentBody (indent-region)
def indentBody (self,event=None):

    '''The indent-region command indents each line of the selected body text,
    or each line of a node if there is no selected text. The @tabwidth directive
    in effect determines amount of indentation. (not yet) A numeric argument
    specifies the column to indent to.'''

    c = self ; current = c.p ; undoType='Indent Region'
    d = c.scanAllDirectives(current) # Support @tab_width directive properly.
    tab_width = d.get("tabwidth",c.tab_width)
    head,lines,tail,oldSel,oldYview = self.getBodyLines()

    result = [] ; changed = False
    for line in lines:
        i, width = g.skip_leading_ws_with_indent(line,0,tab_width)
        s = g.computeLeadingWhitespace(width+abs(tab_width),tab_width) + line[i:]
        if s != line: changed = True
        result.append(s)

    if changed:
        result = ''.join(result)
        c.updateBodyPane(head,result,tail,undoType,oldSel,oldYview)
#@+node:ekr.20050312114529.1: *7* addComments
def addComments (self,event=None):

    '''Convert all selected lines in the body text to comment lines.'''

    c = self ; p = c.p
    d = c.scanAllDirectives(p)
    d1,d2,d3 = d.get('delims') # d1 is the line delim.
    head,lines,tail,oldSel,oldYview = self.getBodyLines()
    if not lines:
        g.es('no text selected',color='blue')
        return

    d2 = d2 or '' ; d3 = d3 or ''
    if d1: openDelim,closeDelim = d1+' ',''
    else:  openDelim,closeDelim = d2+' ',d3+' '

    # Comment out non-blank lines.
    result = []
    for line in lines:
        if line.strip():
            i = g.skip_ws(line,0)
            result.append(line[0:i]+openDelim+line[i:]+closeDelim)
        else:
            result.append(line)

    result = ''.join(result)
    c.updateBodyPane(head,result,tail,undoType='Add Comments',oldSel=None,oldYview=oldYview)
#@+node:ekr.20050312114529.2: *7* deleteComments
def deleteComments (self,event=None):

    '''Remove one level of comment delimiters from all selected lines in the body text.'''

    c = self ; p = c.p
    d = c.scanAllDirectives(p)
    # d1 is the line delim.
    d1,d2,d3 = d.get('delims')

    head,lines,tail,oldSel,oldYview = self.getBodyLines()
    result = []
    if not lines:
        g.es('no text selected',color='blue')
        return

    if d1:
        # Remove the single-line comment delim in front of each line
        for line in lines:
            i = g.skip_ws(line,0)
            if g.match(line,i,d1):
                j = g.skip_ws(line,i + len(d1))
                result.append(line[0:i] + line[j:])
            else:
                result.append(line)
    else:
        n = len(lines)
        for i in range(n):
            line = lines[i]
            if i not in (0,n-1):
                result.append(line)
            if i == 0:
                j = g.skip_ws(line,0)
                if g.match(line,j,d2):
                    k = g.skip_ws(line,j + len(d2))
                    result.append(line[0:j] + line[k:])
                else:
                    g.es('',"'%s'" % (d2),"not found",color='blue')
                    return
            if i == n-1:
                if i == 0:
                    line = result[0] ; result = []
                s = line.rstrip()
                if s.endswith(d3):
                    result.append(s[:-len(d3)].rstrip())
                else:
                    g.es('',"'%s'" % (d3),"not found",color='blue')
                    return

    result = ''.join(result)
    c.updateBodyPane(head,result,tail,undoType='Delete Comments',oldSel=None,oldYview=oldYview)
#@+node:ekr.20031218072017.1834: *7* << compute vars for reformatParagraph >>
theDict = c.scanAllDirectives()
pageWidth = theDict.get("pagewidth")
tabWidth  = theDict.get("tabwidth")

original = w.getAllText()
oldSel =  w.getSelectionRange()
oldYview = body.getYScrollPosition()

head,lines,tail = c.findBoundParagraph()
#@+node:ekr.20060417172056: *7* addRemoveHelper
def addRemoveHelper(self,event,ch,add,undoType):

    c = self.c ; k = self.k ; w = self.editWidget(event)
    if not w: return

    if w.hasSelection():s = w.getSelectedText()
    else:               s = w.getAllText()
    if not s: return

    # Insert or delete spaces instead of tabs when negative tab width is in effect.
    d = c.scanAllDirectives() ; width = d.get('tabwidth')
    if ch == '\t' and width < 0: ch = ' ' * abs(width)

    self.beginCommand(undoType=undoType)

    lines = g.splitLines(s)

    if add:
        result = [ch + line for line in lines]
    else:
        result = [g.choose(line.startswith(ch),line[len(ch):],line) for line in lines]

    result = ''.join(result)

    # g.trace('add',add,'hasSelection',w.hasSelection(),'result',repr(result))

    if w.hasSelection():
        i,j = w.getSelectionRange()
        w.delete(i,j)
        w.insert(i,result)
        w.setSelectionRange(i,i+len(result))
    else:
        w.setAllText(result)
        w.setSelectionRange(0,len(s))

    self.endCommand(changed=True,setLabel=True)

#@+node:ekr.20051026092433.1: *7* backwardDeleteCharacter
def backwardDeleteCharacter (self,event=None):

    '''Delete the character to the left of the cursor.'''

    c = self.c ; p = c.p
    w = self.editWidget(event)
    if not w: return

    wname = c.widget_name(w)
    ins = w.getInsertPoint()
    i,j = w.getSelectionRange()
    # g.trace(wname,i,j,ins)

    if wname.startswith('body'):
        self.beginCommand()
        try:
            d = c.scanAllDirectives(p)
            tab_width = d.get("tabwidth",c.tab_width)
            changed = True
            if i != j:
                w.delete(i,j)
                w.setSelectionRange(i,i,insert=i)
            elif i == 0:
                changed = False
            elif tab_width > 0:
                w.delete(ins-1)
                w.setSelectionRange(ins-1,ins-1,insert=ins-1)
            else:
                << backspace with negative tab_width >>
        finally:
            self.endCommand(changed=True,setLabel=False) # Necessary to make text changes stick.
    else:
        # No undo in this widget.
        # Make sure we actually delete something if we can.
        s = w.getAllText()
        if i != j:
            j = max(i,min(j,len(s)))
            w.delete(i,j)
            w.setSelectionRange(i,i,insert=i)
        elif ins != 0:
            # Do nothing at the start of the headline.
            w.delete(ins-1)
            ins = ins-1
            w.setSelectionRange(ins,ins,insert=ins)
#@+node:ekr.20051026092746: *8* << backspace with negative tab_width >>
s = prev = w.getAllText()
ins = w.getInsertPoint()
i,j = g.getLine(s,ins)
s = prev = s[i:ins]
n = len(prev)
abs_width = abs(tab_width)

# Delete up to this many spaces.
n2 = (n % abs_width) or abs_width
n2 = min(n,n2) ; count = 0

while n2 > 0:
    n2 -= 1
    ch = prev[n-count-1]
    if ch != ' ': break
    else: count += 1

# Make sure we actually delete something.
i = ins-(max(1,count))
w.delete(i,ins)
w.setSelectionRange(i,i,insert=i)
#@+node:ekr.20051026171121.1: *7* updateAutoIndent (leoEditCommands)
def updateAutoIndent (self,p,w):

    c = self.c ; d = c.scanAllDirectives(p)
    tab_width = d.get("tabwidth",c.tab_width)
    # Get the previous line.
    s = w.getAllText()
    ins = w.getInsertPoint()
    i = g.skip_to_start_of_line(s,ins)
    i,j = g.getLine(s,i-1)
    s = s[i:j-1]
    # g.trace(i,j,repr(s))

    # Add the leading whitespace to the present line.
    junk, width = g.skip_leading_ws_with_indent(s,0,tab_width)
    # g.trace('width',width,'tab_width',tab_width)

    if s and s [-1] == ':':
        # For Python: increase auto-indent after colons.
        if g.findLanguageDirectives(c,p) == 'python':
            width += abs(tab_width)
    if self.smartAutoIndent:
        # Determine if prev line has unclosed parens/brackets/braces
        bracketWidths = [width] ; tabex = 0
        for i in range(0,len(s)):
            if s [i] == '\t':
                tabex += tab_width-1
            if s [i] in '([{':
                bracketWidths.append(i+tabex+1)
            elif s [i] in '}])' and len(bracketWidths) > 1:
                bracketWidths.pop()
        width = bracketWidths.pop()
    ws = g.computeLeadingWhitespace(width,tab_width)
    if ws:
        i = w.getInsertPoint()
        w.insert(i,ws)
        w.setInsertPoint(i+len(ws))
#@+node:ekr.20051027172949: *7* updateAutomatchBracket
def updateAutomatchBracket (self,p,w,ch,oldSel):

    # assert ch in ('(',')','[',']','{','}')

    c = self.c ; d = c.scanAllDirectives(p)
    i,j = oldSel
    language = d.get('language')
    s = w.getAllText()

    if ch in ('(','[','{',):
        automatch = language not in ('plain',)
        if automatch:
            ch = ch + {'(':')','[':']','{':'}'}.get(ch)
        if i != j: w.delete(i,j)
        w.insert(i,ch)
        if automatch:
            ins = w.getInsertPoint()
            w.setInsertPoint(ins-1)
    else:
        ins = w.getInsertPoint()
        ch2 = ins<len(s) and s[ins] or ''
        if ch2 in (')',']','}'):
            ins = w.getInsertPoint()
            w.setInsertPoint(ins+1)
        else:
            if i != j: w.delete(i,j)
            w.insert(i,ch)
            w.setInsertPoint(i+1)
#@+node:ekr.20051026092433: *7* updateTab
def updateTab (self,p,w,smartTab=True):

    c = self.c

    # g.trace('tab_width',tab_width)
    i,j = w.getSelectionRange()
        # Returns insert point if no selection, with i <= j.

    if i != j:
        # w.delete(i,j)
        c.indentBody()
    else:
        d = c.scanAllDirectives(p)
        tab_width = d.get("tabwidth",c.tab_width)
        # Get the preceeding characters.
        s = w.getAllText()
        # start = g.skip_to_start_of_line(s,i)
        start,end = g.getLine(s,i)
        before = s[start:i]
        after = s[i:end]
        if after.endswith('\n'): after = after[:-1]
        ws = g.get_leading_ws(before)
        s2 = s[start:i] # The characters before the insert point.

        # Only do smart tab at the start of a blank line.
        doSmartTab = (smartTab and c.smart_tab and i == start)
            # Truly at the start of the line.
            # and not after # Nothing *at all* after the cursor.
        # g.trace(doSmartTab,'i %s start %s after %s' % (i,start,repr(after)))

        if doSmartTab:
            self.updateAutoIndent(p,w)
            # Add a tab if otherwise nothing would happen.
            if s == w.getAllText():
                self.doPlainTab(s,i,tab_width,w)
        else:
            self.doPlainTab(s,i,tab_width,w)
#@+node:ekr.20100822092546.5835: *7* write_slides & helper
def write_slides (self,p,toString=False):

    '''Convert p's children to slides.'''

    c = self.c ; p = p.copy() ; h = p.h
    i = g.skip_id(h,1) # Skip the '@'
    kind,fn = h[:i].strip(),h[i:].strip()
    if not fn: return g.es('%s requires file name' % (kind),color='red')
    title = p and p.firstChild().h or '<no slide>'
    title = title.strip().capitalize()
    n_tot = p.numberOfChildren()

    n = 1
    for child in p.children():
        self.init_write(p) # ScanAllDirectives sets self.path and self.encoding.
        self.scanAllOptions(child) # Settings for child are valid after this call.
        # Compute the slide's file name.
        fn2,ext = g.os_path_splitext(fn)
        fn2 = '%s-%03d%s' % (fn2,n,ext) # Use leading zeros for :glob:.
        n += 1
        # Write the rst sources to self.source.
        self.outputFile = StringIO()
        self.writeSlideTitle(title,n-1,n_tot)
        self.writeBody(child)
        self.source = self.outputFile.getvalue() # the rST sources.
        self.outputFile,self.stringOutput = None,None
        self.write_files(ext,fn2,
            callDocutils=self.getOption('call_docutils'),
            toString=toString,
            writeIntermediateFile=self.getOption('write_intermediate_file'))
#@+node:ekr.20100822174725.5836: *8* writeSlideTitle
def writeSlideTitle (self,title,n,n_tot):

    '''Write the title, underlined with the '#' character.'''

    if n != 1:
        title = '%s (%s of %s)' % (title,n,n_tot)

    width = max(4,len(g.toEncodedString(title,
        encoding=self.encoding,reportErrors=False)))

    self.write('%s\n%s \n\n' % (title,('#'*width)))
#@+node:ekr.20090502071837.45: *7* initCodeBlockString
def initCodeBlockString(self,p):

    trace = False and not g.unitTesting
    c = self.c
    # if trace: os.system('cls')
    d = c.scanAllDirectives(p)
    language = d.get('language')
    if language is None: language = 'python'
    else: language = language.lower()
    syntax = SilverCity is not None

    if trace: g.trace('language',language,'language.title()',language.title(),p.h)

    # Note: lines that end with '\n\n' are a signal to handleCodeMode.
    s = self.getOption('code_block_string')
    if s:
        self.code_block_string = s.replace('\\n','\n')
    elif syntax and language in ('python','ruby','perl','c'):
        self.code_block_string = '**code**:\n\n.. code-block:: %s\n\n' % (
            language.title())
    else:
        self.code_block_string = '**code**:\n\n.. class:: code\n..\n\n::\n\n'
#@+node:ekr.20041126042730: *7* getTabWidth
def getTabWidth (self,p=None):

    c = self.c
    if 1:
        # Faster, more self-contained.
        val = g.scanAllAtTabWidthDirectives(c,p)
        return val
    else:
        d = c.scanAllDirectives(p)
        w = d.get("tabwidth")
        if w not in (0,None):
            return w
        else:
            return self.c.tab_width
#@+node:ekr.20101022055534.5979: *5*  Found: scanDefaultDirectory
#@+node:ekr.20101022055534.5981: *6* Defs & g.setDefaultDirectory
#@+node:ekr.20041005105605.236: *7* at.scanDefaultDirectory
def scanDefaultDirectory(self,p,importing=False):

    """Set the default_directory ivar by looking for @path directives.

    The caller must check at.errors."""

    at = self ; c = at.c

    at.default_directory,error = g.setDefaultDirectory(c,p,importing)

    if error:
        at.error(error)
#@+node:ekr.20080211085914: *7* scanDefaultDirectory (leoImport)
def scanDefaultDirectory(self,p):

    """Set the default_directory ivar by looking for @path directives."""

    c = self.c

    self.default_directory, error = g.setDefaultDirectory(c,p,importing=False)

    if error:
        self.error(error)
#@+node:ekr.20081001062423.9: *7* g.setDefaultDirectory & helpers
# This is a refactoring, used by leoImport.scanDefaultDirectory and
# atFile.scanDefaultDirectory

def setDefaultDirectory(c,p,importing=False):

    ''' Compute a default directory by scanning @path directives.
    Return (default_dir,error_message).'''

    if not p: return '',''
    default_dir,error = g.getAbsPathFromNode(c,p),''

    if not default_dir:
        default_dir,error = g.getPathFromDirectives(c,p)

    if c and c.frame and not default_dir and not error:
        default_dir = g.findDefaultDirectory(c)

    if not default_dir and not importing and not error:
        # This should never happen: c.openDirectory should be a good last resort.
        error = "No absolute directory specified anywhere."

    return default_dir, error
#@+node:ekr.20081001062423.10: *8* g.getAbsPathFromNode
# An absolute path in an @file node over-rides everything else.
# A relative path gets appended to the relative path by the open logic.

def getAbsPathFromNode(c,p,name=''): # Name is for unit testing.

    default_dir = ''
    if p:
        name = p.anyAtFileNodeName()

    if name:
        theDir = g.os_path_dirname(name)
        if theDir and g.os_path_isabs(theDir):
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)

    return default_dir
#@+node:ekr.20081001062423.11: *8* g.getPathFromDirectives
def getPathFromDirectives(c,p,createFlag=True):

    '''Scan for @path directives.'''

    trace = False and not g.unitTesting
    default_dir = '' ; error = ''
    if not p: return default_dir,error
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if path:
        base = g.getBaseDirectory(c) # returns "" on error.
        path = c.os_path_finalize_join(base,path)
        exists = g.os_path_exists(path)
        if createFlag:
            if exists:
                default_dir = path
            else:
                default_dir = g.makeAllNonExistentDirectories(path,c=c)
                if not default_dir:
                    error = "invalid @path: %s" % path
        else:
            default_dir = path
            if not exists:
                error = "does not exist: @path %s" % path

    return default_dir,error
#@+node:ekr.20081001062423.12: *8* g.findDefaultDirectory (major change)
# This code is executed if no valid absolute path was specified in
# the @file node or in an @path directive.

def findDefaultDirectory(c):

    '''Attempt to find a suitable default directory.'''

    default_dir = ''

    # Check that c.openDirectory and c.frame.openDirectory are in synch.
    if c.openDirectory != c.frame.openDirectory:
        g.trace('***can not happen: c.openDirectory != c.frame.openDirectory')
        g.trace('c.openDirectory',c.openDirectory)
        g.trace('c.frame.openDirectory',c.frame.openDirectory)

    if not g.os_path_isabs(c.openDirectory):
        g.trace('*** can not happen: relative c.openDirectory',c.openDirectory)

    for theDir in (c.openDirectory,g.getBaseDirectory(c)):
        if theDir and g.os_path_isabs(theDir): # Errors may result in relative or invalid path.
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)
            if default_dir: break

    return default_dir
#@+node:ekr.20101022055534.5980: *6* Calls to at.scanDefaultDirectory
#@+node:ekr.20041005105605.13: *7* at.initReadIvars
def initReadIvars(self,root,fileName,
    importFileName=None,
    perfectImportRoot=None,
    atShadow=False,
):

    importing = importFileName is not None

    self.initCommonIvars()

    << init ivars for reading >>
        # sets self.errors = 0
    self.scanDefaultDirectory(root,importing=importing)
    if self.errors: return

    # Init state from arguments.
    self.fromString = False
    self.perfectImportRoot = perfectImportRoot
    self.importing = importing
    self.root = root
    self.targetFileName = fileName
    self.thinFile = False # 2010/01/22: was thinFile
    self.atShadow = atShadow
#@+node:ekr.20041005105605.14: *8* << init ivars for reading >>
self.cloneSibCount = 0
    # n > 1: Make sure n cloned sibs exists at next @+node sentinel
self.correctedLines = 0
self.docOut = [] # The doc part being accumulated.
self.done = False # True when @-leo seen.
self.endSentinelIndentStack = []
    # Restored indentation for @-others and @-<< sentinels.
    # Used only when readVersion5.
self.endSentinelStack = []
    # Contains entries for +node sentinels only when not readVersion5
self.endSentinelLevelStack = []
    # The saved level, len(at.thinNodeStack), for @-others and @-<< sentinels.
    # Used only when readVersion5.
self.endSentinelNodeStack = []
    # Used only when readVersion5.
self.importing = False
self.importRootSeen = False
self.indentStack = []
self.inputFile = None
self.lastLines = [] # The lines after @-leo
self.lastRefNode = None
    # The previous reference node, for at.readAfterRef.
    # No stack is needed because -<< sentinels restore at.v
    # to the node needed by at.readAfterRef.
self.lastThinNode = None
    # The last thin node at this level.
    # Used by createThinChild4.
self.leadingWs = ""
self.lineNumber = 0 # New in Leo 4.4.8.
self.out = None
self.outStack = []
self.readVersion = '' # New in Leo 4.8: "4" or "5" for new-style thin files.
self.readVersion5 = False # synonym for at.readVersion >= '5' and not atShadow.
self.rootSeen = False
self.tnodeList = []
    # Needed until old-style @file nodes are no longer supported.
self.tnodeListIndex = 0
self.v = None
self.vStack = [] # Stack of at.v values.
self.thinNodeStack = [] # Entries are vnodes.
self.updateWarningGiven = False
#@+node:ekr.20070909100252: *7* at.readOneAtAutoNode
def readOneAtAutoNode (self,fileName,p):

    at = self ; c = at.c ; ic = c.importCommands

    oldChanged = c.isChanged()

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors: return # 2010/10/21

    fileName = c.os_path_finalize_join(at.default_directory,fileName)

    # 2010/7/28: Remember that we have seen the @auto node.
    p.v.at_read = True # Create the attribute

    s,ok,fileKey = c.cacher.readFile(fileName,p)
    if ok: return

    if not g.unitTesting:
        g.es("reading:",p.h)

    ic.createOutline(fileName,parent=p.copy(),atAuto=True)

    if ic.errors:
        # Note: the file contains an @ignore,
        # so no unintended write can happen.
        g.es_print('errors inhibited read @auto',fileName,color='red')

    if ic.errors or not g.os_path_exists(fileName):
        p.clearDirty()
        c.setChanged(oldChanged)
    else:
        c.cacher.writeFile(p,fileKey)
        g.doHook('after-auto', p = p)  # call after-auto callbacks
#@+node:ekr.20090225080846.3: *7* at.readOneAtEditNode
def readOneAtEditNode (self,fn,p):

    at = self ; c = at.c ; ic = c.importCommands
    oldChanged = c.isChanged()

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors: return # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    junk,ext = g.os_path_splitext(fn)

    # 2010/7/28: Remember that we have seen the @edit node.
    p.v.at_read = True # Create the attribute

    if not g.unitTesting:
        g.es("reading @edit:", g.shortFileName(fn))

    s,e = g.readFileIntoString(fn,kind='@edit')
    if s is None: return
    encoding = g.choose(e is None,'utf-8',e)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    changed = c.isChanged()
    head = ''
    ext = ext.lower()
    if ext in ('.html','.htm'):   head = '@language html\n'
    elif ext in ('.txt','.text'): head = '@nocolor\n'
    else:
        language = ic.languageForExtension(ext)
        if language and language != 'unknown_language':
            head = '@language %s\n' % language
        else:
            head = '@nocolor\n'

    p.b = g.u(head) + g.toUnicode(s,encoding=encoding,reportErrors='True')

    if not changed: c.setChanged(False)
    g.doHook('after-edit',p=p)
#@+node:ekr.20080711093251.7: *7* at.readOneAtShadowNode
def readOneAtShadowNode (self,fn,p):

    at = self ; c = at.c ; x = c.shadowController

    if not fn == p.atShadowFileNodeName():
        return at.error('can not happen: fn: %s != atShadowNodeName: %s' % (
            fn, p.atShadowFileNodeName()))

    # 2010/7/28: Remember that we have seen the @shadow node.
    p.v.at_read = True # Create the attribute

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Sets at.default_directory
    if at.errors: return # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    shadow_fn     = x.shadowPathName(fn)
    shadow_exists = g.os_path_exists(shadow_fn) and g.os_path_isfile(shadow_fn)

    # Delete all children.
    while p.hasChildren():
        p.firstChild().doDelete()

    if shadow_exists:
        at.read(p,atShadow=True)
    else:
        if not g.unitTesting: g.es("reading:",p.h)
        ok = at.importAtShadowNode(fn,p)
        if ok:
            # Create the private file automatically.
            at.writeOneAtShadowNode(p,toString=False,force=True)
#@+node:ekr.20080712080505.1: *8* at.importAtShadowNode
def importAtShadowNode (self,fn,p):

    at = self ; c = at.c  ; ic = c.importCommands
    oldChanged = c.isChanged()

    # Delete all the child nodes.
    while p.hasChildren():
        p.firstChild().doDelete()

    # Import the outline, exactly as @auto does.
    ic.createOutline(fn,parent=p.copy(),atAuto=True,atShadow=True)

    if ic.errors:
        g.es_print('errors inhibited read @shadow',fn,color='red')

    if ic.errors or not g.os_path_exists(fn):
        p.clearDirty()
        c.setChanged(oldChanged)

    # else: g.doHook('after-shadow', p = p)

    return ic.errors == 0
#@+node:ekr.20070806141607: *7* at.writeOneAtAutoNode & helpers
def writeOneAtAutoNode(self,p,toString,force):

    '''Write p, an @auto node.

    File indices *must* have already been assigned.'''

    at = self ; c = at.c ; root = p.copy()

    fileName = p.atAutoNodeName()
    if not fileName and not toString: return False

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors:
        root.setDirty() # 2010/10/21
        return # 2010/10/21

    fileName = c.os_path_finalize_join(at.default_directory,fileName)
    exists = g.os_path_exists(fileName)
    if not toString and exists and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @auto node would overwrite the existing file.
        ok = self.promptForDangerousWrite(fileName,kind='@auto')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fileName)
            return

    # Prompt if writing a new @auto node would overwrite an existing file.
    if (not toString and not hasattr(p.v,'at_read') and
        g.os_path_exists(fileName)
    ):
        ok = self.promptForDangerousWrite(fileName,kind='@auto')
        if ok:
            p.v.at_read = True # Create the attribute
        else:
            g.es("not written:",fileName)
            return False

    # This code is similar to code in at.write.
    c.endEditing() # Capture the current headline.
    at.targetFileName = g.choose(toString,"<string-file>",fileName)

    at.initWriteIvars(root,at.targetFileName,
        atAuto=True,
        nosentinels=True,thinFile=False,scriptWrite=False,
        toString=toString)

    ok = at.openFileForWriting (root,fileName=fileName,toString=toString)
    isAtAutoRst = root.isAtAutoRstNode()
    if ok:
        if isAtAutoRst:
            ok2 = c.rstCommands.writeAtAutoFile(root,fileName,self.outputFile)
            if not ok2: at.errors += 1
        else:
            at.writeOpenFile(root,nosentinels=True,toString=toString)
        at.closeWriteFile() # Sets stringOutput if toString is True.
        # g.trace('at.errors',at.errors)
        if at.errors == 0:
            # g.trace('toString',toString,'force',force,'isAtAutoRst',isAtAutoRst)
            at.replaceTargetFileIfDifferent(root,ignoreBlankLines=isAtAutoRst)
                # Sets/clears dirty and orphan bits.
        else:
            g.es("not written:",at.outputFileName)
            root.setDirty() # New in Leo 4.4.8.

    elif not toString:
        root.setDirty() # Make _sure_ we try to rewrite this file.
        g.es("not written:",at.outputFileName)

    return ok
#@+node:ekr.20090225080846.5: *7* at.writeOneAtEditNode
def writeOneAtEditNode(self,p,toString,force=False):

    '''Write one @edit node.'''

    at = self ; c = at.c ; root = p.copy()
    c.endEditing()

    fn = p.atEditNodeName()
    if not fn and not toString: return False

    if p.hasChildren():
        g.es('@edit nodes must not have children',color='red')
        g.es('To save your work, convert @edit to @auto or @thin')
        return False

    at.errors = 0 # 2010/10/21
    at.scanDefaultDirectory(p,importing=True) # Set default_directory
    if at.errors:
        g.es("not written:",p.h) # 2010/10/21
        root.setDirty() # 2010/10/21
        return False # 2010/10/21

    fn = c.os_path_finalize_join(at.default_directory,fn)
    exists = g.os_path_exists(fn)
    if not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @edit node would overwrite the existing file.
        ok = self.promptForDangerousWrite(fn,kind='@edit')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return False

    at.targetFileName = fn
    at.initWriteIvars(root,at.targetFileName,
        atAuto=True, atEdit=True,
        nosentinels=True,thinFile=False,
        scriptWrite=False,toString=toString)

    # Compute the file's contents.
    # Unlike the @nosent file logic it does not add a final newline.
    contents = ''.join([s for s in g.splitLines(p.b)
        if at.directiveKind4(s,0) == at.noDirective])

    if toString:
        at.stringOutput = contents
        return True

    ok = at.openFileForWriting(root,fileName=fn,toString=False)
    if ok:
        self.os(contents)
        at.closeWriteFile()
    if ok and at.errors == 0:
        at.replaceTargetFileIfDifferent(root) # Sets/clears dirty and orphan bits.
    else:
        g.es("not written:",at.outputFileName)
        root.setDirty()

    return ok
#@+node:ekr.20031218072017.3210: *6* createOutline (leoImport)
def createOutline (self,fileName,parent,
    atAuto=False,atShadow=False,s=None,ext=None):

    c = self.c ; u = c.undoer ; s1 = s
    w = c.frame.body

    # New in Leo 4.4.7: honor @path directives.
    self.errors = 0 # 2010/10/21
    self.scanDefaultDirectory(parent) # sets .defaultDirectory.
    if self.errors: return None # 2010/10/21

    fileName = c.os_path_finalize_join(self.default_directory,fileName)
    junk,self.fileName = g.os_path_split(fileName)
    self.methodName,self.fileType = g.os_path_splitext(self.fileName)
    self.setEncoding(p=parent,atAuto=atAuto)
    if not ext: ext = self.fileType
    ext = ext.lower()
    if not s:
        if atShadow: kind = '@shadow '
        elif atAuto: kind = '@auto '
        else: kind = ''
        s,e = g.readFileIntoString(fileName,encoding=self.encoding,kind=kind)
        if s is None: return None
        if e: self.encoding = e

    # Create the top-level headline.
    if atAuto:
        p = parent.copy()
        p.setBodyString('')
    else:
        undoData = u.beforeInsertNode(parent)
        p = parent.insertAsLastChild()

        if self.treeType == "@file":
            p.initHeadString("@file " + fileName)
        elif self.treeType is None:
            # 2010/09/29: by convention, we use the short file name.
            p.initHeadString(g.shortFileName(fileName))
        else:
            p.initHeadString(fileName)
        u.afterInsertNode(p,'Import',undoData)

    if self.treeType == '@root': # 2010/09/29.
        self.rootLine = "@root-code "+self.fileName+'\n'
    else:
        self.rootLine = ''

    if p.isAtAutoRstNode(): # @auto-rst is independent of file extension.
        func = self.scanRstText
    else:
        func = self.importDispatchDict.get(ext)

    if func and not c.config.getBool('suppress_import_parsing',default=False):
        s = s.replace('\r','')
        func(s,p,atAuto=atAuto)
    else:
        # Just copy the file to the parent node.
        s = s.replace('\r','')
        self.scanUnknownFileType(s,p,ext,atAuto=atAuto)

    if atAuto:
        # Remember that we have read this file.
        # Fixes bug 488894: unsettling dialog when saving Leo file
        # after creating and populating an @auto node.
        # Important: this often sets the bit in the wrong node:
        # The caller may have to set the bit in the "real" root node.
        p.v.at_read = True # Create the attribute

    p.contract()
    w.setInsertPoint(0)
    w.seeInsertPoint()
    return p
#@+node:ekr.20101022055534.5988: *5*  Found: scanAtPathDirectives
#@+node:ekr.20080828103146.15: *6* c.scanAtPathDirectives
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and (force or createPath) and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@+node:ekr.20101022055534.5990: *6* Calls
#@+node:ekr.20090530055015.6050: *7* at.fullPath
def fullPath (self,p,simulate=False):

    '''Return the full path (including fileName) in effect at p.

    Neither the path nor the fileName will be created if it does not exist.
    '''

    at = self ; c = at.c
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList,createPath=False)
    if simulate: # for unit tests.
        fn = p.h
    else:
        fn = p.anyAtFileNodeName()
    if fn:
        path = g.os_path_finalize_join(path,fn)
    else:
        g.trace('can not happen: not an @<file> node:',g.callers(4))
        for p2 in p.self_and_parents():
            g.trace(p2.h)
        path = ''

    # g.trace(p.h,repr(path))
    return path
#@+node:ekr.20080923070954.4: *7* at.scanAllDirectives
def scanAllDirectives(self,p,
    scripting=False,importing=False,
    reading=False,forcePythonSentinels=False,
    createPath=True,
    issuePathWarning=False,
):

    '''Scan p and p's ancestors looking for directives,
    setting corresponding atFile ivars.'''

    trace = False and not g.unitTesting
    at = self ; c = self.c
    g.app.atPathInBodyWarning = None
    << set ivars >>
    lang_dict = {'language':at.language,'delims':delims,}
    table = (
        ('encoding',    at.encoding,    g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    if issuePathWarning and g.app.atPathInBodyWarning:
        g.es('warning: ignoring @path directive in',
            g.app.atPathInBodyWarning,color='red')

    # Post process.
    lang_dict       = d.get('lang-dict')
    delims          = lang_dict.get('delims')
    lineending      = d.get('lineending')
    if lineending:
        at.explicitLineEnding = True
        at.output_newline = lineending
    else:
        at.output_newline = g.getOutputNewline(c=c) # Init from config settings.

    at.encoding             = d.get('encoding')
    at.language             = lang_dict.get('language')
    at.page_width           = d.get('pagewidth')
    at.default_directory    = d.get('path')
    at.tab_width            = d.get('tabwidth')

    if not importing and not reading:
        # Don't override comment delims when reading!
        << set comment strings from delims >>

    # For unit testing.
    d = {
        "all"       : all,
        "encoding"  : at.encoding,
        "language"  : at.language,
        "lineending": at.output_newline,
        "pagewidth" : at.page_width,
        "path"      : at.default_directory,
        "tabwidth"  : at.tab_width,
    }
    if trace: g.trace(d)
    return d
#@+node:ekr.20080923070954.14: *8* << Set ivars >>
self.page_width = self.c.page_width
self.tab_width  = self.c.tab_width

self.default_directory = None # 8/2: will be set later.

# g.trace(c.target_language)

if c.target_language:
    c.target_language = c.target_language.lower()

delims = g.set_delims_from_language(c.target_language)
at.language = c.target_language

at.encoding = c.config.default_derived_file_encoding
at.output_newline = g.getOutputNewline(c=self.c) # Init from config settings.
#@+node:ekr.20080923070954.13: *8* << Set comment strings from delims >>
if forcePythonSentinels:
    # Force Python language.
    delim1,delim2,delim3 = g.set_delims_from_language("python")
    self.language = "python"
else:
    delim1,delim2,delim3 = delims

# Use single-line comments if we have a choice.
# delim1,delim2,delim3 now correspond to line,start,end
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else: # Emergency!
    # assert(0)
    if not g.app.unitTesting:
        g.es_print("unknown language: using Python comment delimiters")
        g.es_print("c.target_language:",c.target_language)
        g.es_print('','delim1,delim2,delim3:','',delim1,'',delim2,'',delim3)
    at.startSentinelComment = "#" # This should never happen!
    at.endSentinelComment = ""

# g.trace(repr(self.startSentinelComment),repr(self.endSentinelComment))
#@+node:ekr.20081006100835.1: *7* c.getNodePath & c.getNodeFileName
def getNodePath (self,p):

    '''Return the path in effect at node p.'''

    c = self
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    return path

def getNodeFileName (self,p):

    '''Return the full file name at node p,
    including effects of all @path directives.

    Return None if p is no kind of @file node.'''

    c = self
    d = c.scanAllDirectives(p)
    path = d.get('path')

    name = ''
    for p in p.self_and_parents():
        name = p.anyAtFileNodeName()
        if name: break

    if name:
        name = g.os_path_finalize_join(path,name)
    return name
#@+node:ekr.20080827175609.39: *7* c.scanAllDirectives
def scanAllDirectives(self,p=None):

    '''Scan p and ancestors for directives.

    Returns a dict containing the results, including defaults.'''

    c = self ; p = p or c.p

    # Set defaults
    language = c.target_language and c.target_language.lower()
    lang_dict = {
        'language':language,
        'delims':g.set_delims_from_language(language),
    }
    wrap = c.config.getBool("body_pane_wraps")

    table = (
        ('encoding',    None,           g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
        ('wrap',        wrap,           g.scanAtWrapDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process: do *not* set commander ivars.
    lang_dict = d.get('lang-dict')

    return {
        "delims"        : lang_dict.get('delims'),
        "encoding"      : d.get('encoding'),
        "language"      : lang_dict.get('language'),
        "lineending"    : d.get('lineending'),
        "pagewidth"     : d.get('pagewidth'),
        "path"          : d.get('path') or g.getBaseDirectory(c),
        "tabwidth"      : d.get('tabwidth'),
        "pluginsList"   : [], # No longer used.
        "wrap"          : d.get('wrap'),
    }
#@+node:ekr.20081001062423.11: *7* g.getPathFromDirectives
def getPathFromDirectives(c,p,createFlag=True):

    '''Scan for @path directives.'''

    trace = False and not g.unitTesting
    default_dir = '' ; error = ''
    if not p: return default_dir,error
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if path:
        base = g.getBaseDirectory(c) # returns "" on error.
        path = c.os_path_finalize_join(base,path)
        exists = g.os_path_exists(path)
        if createFlag:
            if exists:
                default_dir = path
            else:
                default_dir = g.makeAllNonExistentDirectories(path,c=c)
                if not default_dir:
                    error = "invalid @path: %s" % path
        else:
            default_dir = path
            if not exists:
                error = "does not exist: @path %s" % path

    return default_dir,error
#@+node:ekr.20080923124254.16: *7* tangle.scanAllDirectives
def scanAllDirectives(self,p):

    """Scan vnode p and p's ancestors looking for directives,
    setting corresponding tangle ivars and globals.
    """

    c = self.c
    self.init_directive_ivars()
    if p:
        s = p.b
        << Collect @first attributes >>

    table = (
        ('encoding',    self.encoding,  g.scanAtEncodingDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives), 
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    lang_dict = {'language':None,'delims':None}
    self.parent_language_comment_settings(p,lang_dict)

    # Post process.
    lineending      = d.get('lineending')
    if lineending:
        self.output_newline = lineending
    self.encoding             = d.get('encoding')
    self.language             = lang_dict.get('language')
    self.init_delims          = lang_dict.get('delims')
    self.page_width           = d.get('pagewidth')
    self.tangle_directory     = d.get('path')
    self.tab_width            = d.get('tabwidth')

    # Handle the print-mode directives.
    self.print_mode = None
    for d in aList:
        for key in ('verbose','terse','quiet','silent'):
            if d.get(key) is not None:
                self.print_mode = key ; break
        if self.print_mode: break
    if not self.print_mode: self.print_mode = 'verbose'

    # g.trace(self.tangle_directory)

    # For unit testing.
    return {
        "encoding"  : self.encoding,
        "language"  : self.language,
        "lineending": self.output_newline,
        "pagewidth" : self.page_width,
        "path"      : self.tangle_directory,
        "tabwidth"  : self.tab_width,
    }
#@+node:ekr.20080923124254.17: *8* << Collect @first attributes >>
@
Stephen P. Schaefer 9/13/2002: Add support for @first. Unlike other
root attributes, does *NOT* inherit from parent nodes.
@c

tag = "@first"
sizeString = len(s) # DTHEIN 13-OCT-2002: use to detect end-of-string
i = 0
while 1:
    # DTHEIN 13-OCT-2002: directives must start at beginning of a line
    if not g.match_word(s,i,tag):
        i = g.skip_line(s,i)
    else:
        i = i + len(tag)
        j = i = g.skip_ws(s,i)
        i = g.skip_to_end_of_line(s,i)
        if i>j:
            self.first_lines += s[j:i] + '\n'
        i = g.skip_nl(s,i)
    if i >= sizeString:  # DTHEIN 13-OCT-2002: get out when end of string reached
        break
#@+node:ekr.20101021160326.5950: *5*  Notes
@nocolor-node

A **strict helper** is called only by one method.

***** Part 1: c.scanAtPathDirectives

# This is the proximate cause of the bug.
# ***** c.scanAtPathDirectives return *no* error indication.
# ***** at.scanAllDirectives **also** returns *no* error indication.

There are only *2* calls to at.scanAllDirectives.

at.initWriteIvars
    at.scanAllDirectives
        c.scanAtPathDirectives *****
            g.makeAllNonExistentDirectories

at.read
    at.scanAllDirectives

===============

# Exactly *6* callers of c.scanAtPathDirectives

c.scanAllDirectives <----- This is also a problem
    * There appears to be a bogus default for the path.
    * There is no error indication.
    ** However, the path is very seldom used.
        - init_write (rstCommands)

c.getNodePath (a thin wrapper: not called from Leo's core!)

tangle.scanAllDirectives
    Not a big problem: tangle is on its way out.

at.scanAllDirectives <----- This is the big problem.

at.fullPath
    c.scanAtPathDirectives(createPath=False)

g.getPathFromDirectives (a strict helper of g.setDefaultDirectory)

***** Part 2: g.setDefaultDirectory (calls c.scanAtPathDirectives)

# g.setDefaultDirectory is horribly complex

g.setDefaultDirectory
    g.getAbsPathFromNode (strict helper)
        g.makeAllNonExistentDirectories
    g.getPathFromDirectives (strict helper)
        c.scanAtPathDirectives *****
            g.makeAllNonExistentDirectories

================

# Exactly *2* callers of g.setDefaultDirectory

# Both call self.error if g.setDefaultDirectory returns an error.

*** Change: all calls to these now use the following pattern:

    self.errors = 0 
    self.scanDefaultDirectory(...)
    if self.errors: return # Possibly with other error handling.

at.scanDefaultDirectory (called by several atFile methods)
    g.setDefaultDirectory 

leoImport.scanDefaultDirectory (called by createOutline)
    g.setDefaultDirectory

===================

Part 3: initReadIvars

**** Why don't all top-level methods call initReadIvars???
    Maybe because they call scanDefaultDirectory instead.

#@+node:ekr.20101022055534.8517: *5*  Posting
@nocolor-node

The following are notes to myself. Feel free to ignore them. Otoh, they will
give some indication of what lies beneath Leo. The outward simplicity of Leo is
an illusion created by a lot of complex code. Nowhere is this more true than
with file names and paths.

577047 is a nasty bug that must be fixed:

Specifying a @path directory causes Leo to save an "@thin file.ext" node
below it in Leo's home directory without any warning. The next time Leo is
opened it issues an error that it can not find the file.

===== Notes

The relevant code is mind boggling. I have spent about 8 hours *preparing* to
fix this bug. (And another hour writing this post :-)

There are *extensive* notes in the node:

    To do-->@thin ../doc/leoToDo.txt-->4.8 to do-->First-->
    Fix bug 577047: Invalid @path directory does not warn user

These notes make extensive use of lists of nodes initially created by
clone-find-all.

===== The problems

1. In essence, the bug happens because g.makeAllNonExistentDirectories can fail.
It can fail either because an @path path is invalid, or because the user has
forbidden the automatic creation of directories.

Alas, calls to g.makeAllNonExistentDirectories exist deep inside various calling
trees. We must ensure that callers of methods that *eventually* call
g.makeAllNonExistentDirectories check for the possibility that the path does not
exist.

2. Another problem is that the path computation methods (buried deep inside the
code) are extremely complex and in some cases use dubious or just-plain-wrong
defaults.

3. At the code level, the problem is that the relevant code was "helpfully"
buried in c.scanAllDirectives, at.scanAllDirectives, at.scanDefaultDirectory,
leoImport.scanDefaultDirectory and g.setDefaultDirectory. As a result, there is
at present no way to check for errors.

===== The solution

1. Take the path-related stuff out of c/at.scanAllDirectives.

2. Make all path computations explicit, so that they can be checked for errors.

===== Strategy

Here are the principles that I'll follow:

1. Fix in the trunk. This is an urgent bug, and we might as well all test it
immediately. This should be safe enough provided all unit tests pass.

2. Don't leave any time bombs behind. This mean truly fixing the problem, not
applying a feeble patch.

We could leave the path-related stuff in c/at.scanAllDirectives for
compatibility, but that would be sweeping a lot of dirt under that rug. Much
better to do the job properly, regardless of short-term pain. Thus, I must rip
the path-related code out of c.at/scanAllDirectives.

Happily, most calls to c.scanAllDirectives never used the computed path. The 3
that do will have to be revised. Ditto for the 2 calls to at.scanAllDirectives.

3. Do the minimum possible, consistent with point 2. There will be no massive
refactorings or other changes.

I'll avoid changing the path computation methods if at all possible. To do this,
I want to make the dubious or wrong defaults irrelevant.

I'll resist the urge to replace c.scanAllDirectives by one or more of the
helpers in:

    @thin leoGlobals.py-->Commands & Directives-->g.Directive utils...

This would be a reasonable thing to do, and in many cases the clearest thing to
do. However, it's not necessary and would needlessly delay Leo 4.8.
#@+node:ekr.20101022055534.5982: *5*  Strategy
@nocolor-node

1. Make errors explicit.
    - (Done) All callers now check at.scanDefaultDirectory for errors
      and take appropriate measures on error.

2. Remove path stuff from c.scanAllDirectives
    ** Most callers of c.scanAllDirectives do not, in fact, use the path.
    - Those callers that *do* use the path should use one of the following:
        at.scanDefaultDirectory
        ic.scanDefaultDirectory
        g.getDefaultDirectory
        **or**
            # Used in c.getNodePath
            # Could be used in c.getNodeFileName
            aList = g.get_directives_dict_list(p)
            path = c.scanAtPathDirectives(aList)

    * fc.setDefaultDirectoryForNewFiles sets c.openDirectory **for** at.scanAllDirectives.

    - The following use d[path] returned by c.scanAllDirectives:
        c.getNodeFileName
        getFileLines (leoEditCommands)
            ** calls g.scanDirectives.
            ** probably should just call replacement for c.scanAllDirectives
        init_write (rstCommands)

    * g.scanDirectives just calls c.scanAllDirectives.

3. Remove path stuff from at.scanAllDirectives.

    ** at.scanAllDirectives sets at.default_directory

    - The following call at.scanAllDirectives:
        at.read
        at.initWriteIvars
#@+node:ekr.20041005105605.15: *5* at.initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels,
            issuePathWarning=True)
        # Sets the following ivars:
            # at.explicitLineEnding
            # at.output_newline
            # at.encoding
            # at.language
            # at.page_width
            # at.default_directory  *** path ***
            # at.tab_width

    # g.trace(forcePythonSentinels,
    #    self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16: *6* << init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the
temporary file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False
    # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.writeVersion5 = self.new_write and not atShadow

self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@+node:ekr.20041005105605.142: *5* at.openFileForWriting & helper
def openFileForWriting (self,root,fileName,toString):

    at = self
    at.outputFile = None

    if toString:
        at.shortFileName = g.shortFileName(fileName)
        at.outputFileName = "<string: %s>" % at.shortFileName
        at.outputFile = g.fileLikeObject()
    else:
        ok = at.openFileForWritingHelper(fileName)

        # New in Leo 4.4.8: set dirty bit if there are errors.
        if not ok: at.outputFile = None

    # New in 4.3 b2: root may be none when writing from a string.
    if root:
        if at.outputFile:
            root.clearOrphan()
        else:
            root.setOrphan()
            root.setDirty()

    return at.outputFile is not None
#@+node:ekr.20041005105605.143: *6* at.openFileForWritingHelper & helper
def openFileForWritingHelper (self,fileName):

    '''Open the file and return True if all went well.'''

    at = self ; c = at.c

    try:
        at.shortFileName = g.shortFileName(fileName)
        at.targetFileName = c.os_path_finalize_join(at.default_directory,fileName)
        path = g.os_path_dirname(at.targetFileName)
        if not path or not g.os_path_exists(path):
            if path:
                path = g.makeAllNonExistentDirectories(path,c=c)
            if not path or not g.os_path_exists(path):
                path = g.os_path_dirname(at.targetFileName)
                at.writeError("path does not exist: " + path)
                return False
    except Exception:
        at.exception("exception creating path: %s" % repr(path))
        g.es_exception()
        return False

    if g.os_path_exists(at.targetFileName):
        try:
            if not os.access(at.targetFileName,os.W_OK):
                at.writeError("can not open: read only: " + at.targetFileName)
                return False
        except AttributeError:
            pass # os.access() may not exist on all platforms.

    try:
        at.outputFileName = at.targetFileName + ".tmp"
        kind,at.outputFile = self.openForWrite(at.outputFileName,'wb')
        if not at.outputFile:
            kind = g.choose(kind=='check',
                'did not overwrite','can not create')
            at.writeError("%s %s" % (kind,at.outputFileName))
            return False
    except Exception:
        at.exception("exception creating:" + at.outputFileName)
        return False

    return True
#@+node:bwmulder.20050101094804: *7* at.openForWrite
def openForWrite (self, filename, wb='wb'):

    '''Open a file for writes, handling shadow files.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; x = c.shadowController

    try:
        shadow_filename = x.shadowPathName(filename)
        self.writing_to_shadow_directory = os.path.exists(shadow_filename)
        open_file_name       = g.choose(self.writing_to_shadow_directory,shadow_filename,filename)
        self.shadow_filename = g.choose(self.writing_to_shadow_directory,shadow_filename,None)

        if self.writing_to_shadow_directory:
            if trace: g.trace(filename,shadow_filename)
            x.message('writing %s' % shadow_filename)
            return 'shadow',open(open_file_name,wb)
        else:
            ok = c.checkFileTimeStamp(at.targetFileName)
            return 'check',ok and open(open_file_name,wb)

    except IOError:
        if not g.app.unitTesting:
            g.es_print('openForWrite: exception opening file: %s' % (open_file_name),color='red')
            g.es_exception()
        return 'error',None
#@+node:ekr.20080923070954.4: *5* at.scanAllDirectives
def scanAllDirectives(self,p,
    scripting=False,importing=False,
    reading=False,forcePythonSentinels=False,
    createPath=True,
    issuePathWarning=False,
):

    '''Scan p and p's ancestors looking for directives,
    setting corresponding atFile ivars.'''

    trace = False and not g.unitTesting
    at = self ; c = self.c
    g.app.atPathInBodyWarning = None
    << set ivars >>
    lang_dict = {'language':at.language,'delims':delims,}
    table = (
        ('encoding',    at.encoding,    g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    if issuePathWarning and g.app.atPathInBodyWarning:
        g.es('warning: ignoring @path directive in',
            g.app.atPathInBodyWarning,color='red')

    # Post process.
    lang_dict       = d.get('lang-dict')
    delims          = lang_dict.get('delims')
    lineending      = d.get('lineending')
    if lineending:
        at.explicitLineEnding = True
        at.output_newline = lineending
    else:
        at.output_newline = g.getOutputNewline(c=c) # Init from config settings.

    at.encoding             = d.get('encoding')
    at.language             = lang_dict.get('language')
    at.page_width           = d.get('pagewidth')
    at.default_directory    = d.get('path')
    at.tab_width            = d.get('tabwidth')

    if not importing and not reading:
        # Don't override comment delims when reading!
        << set comment strings from delims >>

    # For unit testing.
    d = {
        "all"       : all,
        "encoding"  : at.encoding,
        "language"  : at.language,
        "lineending": at.output_newline,
        "pagewidth" : at.page_width,
        "path"      : at.default_directory,
        "tabwidth"  : at.tab_width,
    }
    if trace: g.trace(d)
    return d
#@+node:ekr.20080923070954.14: *6* << Set ivars >>
self.page_width = self.c.page_width
self.tab_width  = self.c.tab_width

self.default_directory = None # 8/2: will be set later.

# g.trace(c.target_language)

if c.target_language:
    c.target_language = c.target_language.lower()

delims = g.set_delims_from_language(c.target_language)
at.language = c.target_language

at.encoding = c.config.default_derived_file_encoding
at.output_newline = g.getOutputNewline(c=self.c) # Init from config settings.
#@+node:ekr.20080923070954.13: *6* << Set comment strings from delims >>
if forcePythonSentinels:
    # Force Python language.
    delim1,delim2,delim3 = g.set_delims_from_language("python")
    self.language = "python"
else:
    delim1,delim2,delim3 = delims

# Use single-line comments if we have a choice.
# delim1,delim2,delim3 now correspond to line,start,end
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else: # Emergency!
    # assert(0)
    if not g.app.unitTesting:
        g.es_print("unknown language: using Python comment delimiters")
        g.es_print("c.target_language:",c.target_language)
        g.es_print('','delim1,delim2,delim3:','',delim1,'',delim2,'',delim3)
    at.startSentinelComment = "#" # This should never happen!
    at.endSentinelComment = ""

# g.trace(repr(self.startSentinelComment),repr(self.endSentinelComment))
#@+node:ekr.20041005105605.236: *5* at.scanDefaultDirectory
def scanDefaultDirectory(self,p,importing=False):

    """Set the default_directory ivar by looking for @path directives.

    The caller must check at.errors."""

    at = self ; c = at.c

    at.default_directory,error = g.setDefaultDirectory(c,p,importing)

    if error:
        at.error(error)
#@+node:ekr.20041005105605.144: *5* at.write & helper
def write (self,root,
    kind = '@unknown', # Should not happen.
    nosentinels = False,
    thinFile = False,
    scriptWrite = False,
    toString = False,
):
    """Write a 4.x derived file.
    root is the position of an @<file> node"""

    trace = False and not g.unitTesting
    at = self ; c = at.c
    c.endEditing() # Capture the current headline.

    << set at.targetFileName >>
    at.initWriteIvars(root,at.targetFileName,
        nosentinels = nosentinels, thinFile = thinFile,
        scriptWrite = scriptWrite, toString = toString)

    # "look ahead" computation of eventual fileName.
    eventualFileName = c.os_path_finalize_join(
        at.default_directory,at.targetFileName)
    exists = g.os_path_exists(eventualFileName)

    if trace:
        g.trace('default_dir',
            g.os_path_exists(at.default_directory),
            at.default_directory)
        g.trace('eventual_fn',exists,eventualFileName)

    if not scriptWrite and not toString:
        # 2010/7/28: The read logic now sets the at_read bit for @nosent nodes,
        # so we can just use promptForDangerousWrite.
        if not hasattr(root.v,'at_read') and exists:
            # Prompt if writing a new @file or @thin node would
            # overwrite an existing file.
            ok = self.promptForDangerousWrite(eventualFileName,kind)
            if ok:
                root.v.at_read = True # Create the attribute for all clones.
            else:
                g.es("not written:",eventualFileName)
                << set dirty and orphan bits >> # 2010/10/21.
                return

    if not at.openFileForWriting(root,at.targetFileName,toString):
        # openFileForWriting calls root.setDirty() if there are errors.
        return

    try:
        at.writeOpenFile(root,nosentinels=nosentinels,toString=toString)
        assert root==at.root,'write'
        if toString:
            at.closeWriteFile() # sets self.stringOutput
            # Major bug: failure to clear this wipes out headlines!
            # Minor bug: sometimes this causes slight problems...
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
        else:
            at.closeWriteFile()
            if at.errors > 0 or root.isOrphan():
                << set dirty and orphan bits >>
                g.es("not written:",at.outputFileName)
            else:
                at.replaceTargetFileIfDifferent(root)
                    # Sets/clears dirty and orphan bits.

    except Exception:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        if toString:
            at.exception("exception preprocessing script")
            root.v._p_changed = True
        else:
            at.writeException() # Sets dirty and orphan bits.
#@+node:ekr.20041005105605.145: *6* << set at.targetFileName >>
if toString:
    at.targetFileName = "<string-file>"
elif nosentinels:
    at.targetFileName = root.atNoSentFileNodeName()
elif thinFile:
    at.targetFileName = root.atThinFileNodeName()
    if not at.targetFileName:
        # We have an @file node.
        at.targetFileName = root.atFileNodeName()
else:
    at.targetFileName = root.atFileNodeName()
#@+node:ekr.20041005105605.146: *6* << set dirty and orphan bits >>
# Setting the orphan and dirty flags tells Leo to write the tree..
root.setOrphan()
root.setDirty()
# Delete the temp file.
self.remove(at.outputFileName) 

#@+node:ekr.20080827175609.39: *5* c.scanAllDirectives
def scanAllDirectives(self,p=None):

    '''Scan p and ancestors for directives.

    Returns a dict containing the results, including defaults.'''

    c = self ; p = p or c.p

    # Set defaults
    language = c.target_language and c.target_language.lower()
    lang_dict = {
        'language':language,
        'delims':g.set_delims_from_language(language),
    }
    wrap = c.config.getBool("body_pane_wraps")

    table = (
        ('encoding',    None,           g.scanAtEncodingDirectives),
        ('lang-dict',   lang_dict,      g.scanAtCommentAndAtLanguageDirectives),
        ('lineending',  None,           g.scanAtLineendingDirectives),
        ('pagewidth',   c.page_width,   g.scanAtPagewidthDirectives),
        ('path',        None,           c.scanAtPathDirectives),
        ('tabwidth',    c.tab_width,    g.scanAtTabwidthDirectives),
        ('wrap',        wrap,           g.scanAtWrapDirectives),
    )

    # Set d by scanning all directives.
    aList = g.get_directives_dict_list(p)
    d = {}
    for key,default,func in table:
        val = func(aList)
        d[key] = g.choose(val is None,default,val)

    # Post process: do *not* set commander ivars.
    lang_dict = d.get('lang-dict')

    return {
        "delims"        : lang_dict.get('delims'),
        "encoding"      : d.get('encoding'),
        "language"      : lang_dict.get('language'),
        "lineending"    : d.get('lineending'),
        "pagewidth"     : d.get('pagewidth'),
        "path"          : d.get('path') or g.getBaseDirectory(c),
        "tabwidth"      : d.get('tabwidth'),
        "pluginsList"   : [], # No longer used.
        "wrap"          : d.get('wrap'),
    }
#@+node:ekr.20080828103146.15: *5* c.scanAtPathDirectives
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and (force or createPath) and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@+node:ekr.20031218072017.3119: *5* g.makeAllNonExistentDirectories
# This is a generalization of os.makedir.

def makeAllNonExistentDirectories (theDir,c=None,force=False,verbose=True):

    """Attempt to make all non-existent directories"""

    trace = False and not g.unitTesting
    testing = trace # True: don't actually make the directories.

    if force:
        create = True # Bug fix: g.app.config will not exist during startup.
    elif c:
        create = c.config and c.config.create_nonexistent_directories
    else:
        create = (g.app and g.app.config and
            g.app.config.create_nonexistent_directories)

    if c: theDir = g.os_path_expandExpression(theDir,c=c)

    dir1 = theDir = g.os_path_normpath(theDir)

    ok = g.os_path_isdir(dir1) and g.os_path_exists(dir1)

    if trace: g.trace('ok',ok,'create',create,'force',force,dir1,g.callers())

    if ok:
        return ok
    elif not force and not create:
        if trace:
            g.trace('did not create: force and create are both false')
        return ok

    if trace:
        g.trace('\n',theDir,'\n',g.callers(4))
        # g.trace('c exists: %s force: %s create: %s dir: %s' % (
            # c is not None,force,create,theDir))

    # Split theDir into all its component parts.
    paths = []
    while len(theDir) > 0:
        head,tail=g.os_path_split(theDir)
        if len(tail) == 0:
            paths.append(head)
            break
        else:
            paths.append(tail)
            theDir = head
    path = ""
    paths.reverse()
    if trace: g.trace('paths:',paths)
    for s in paths:
        path = g.os_path_finalize_join(path,s)
        if not g.os_path_exists(path):
            try:
                if testing:
                    g.trace('***making',path)
                else:
                    os.mkdir(path)
                if verbose and not testing and not g.app.unitTesting:
                    # g.trace('***callers***',g.callers(5))
                    g.es_print("created directory:",path,color='red')
            except Exception:
                # g.trace(g.callers())
                if verbose: g.es_print("exception creating directory:",path,color='red')
                g.es_exception()
                return None
    return dir1 # All have been created.
#@+node:ekr.20081001062423.9: *5* g.setDefaultDirectory & helpers
# This is a refactoring, used by leoImport.scanDefaultDirectory and
# atFile.scanDefaultDirectory

def setDefaultDirectory(c,p,importing=False):

    ''' Compute a default directory by scanning @path directives.
    Return (default_dir,error_message).'''

    if not p: return '',''
    default_dir,error = g.getAbsPathFromNode(c,p),''

    if not default_dir:
        default_dir,error = g.getPathFromDirectives(c,p)

    if c and c.frame and not default_dir and not error:
        default_dir = g.findDefaultDirectory(c)

    if not default_dir and not importing and not error:
        # This should never happen: c.openDirectory should be a good last resort.
        error = "No absolute directory specified anywhere."

    return default_dir, error
#@+node:ekr.20081001062423.10: *6* g.getAbsPathFromNode
# An absolute path in an @file node over-rides everything else.
# A relative path gets appended to the relative path by the open logic.

def getAbsPathFromNode(c,p,name=''): # Name is for unit testing.

    default_dir = ''
    if p:
        name = p.anyAtFileNodeName()

    if name:
        theDir = g.os_path_dirname(name)
        if theDir and g.os_path_isabs(theDir):
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)

    return default_dir
#@+node:ekr.20081001062423.11: *6* g.getPathFromDirectives
def getPathFromDirectives(c,p,createFlag=True):

    '''Scan for @path directives.'''

    trace = False and not g.unitTesting
    default_dir = '' ; error = ''
    if not p: return default_dir,error
    aList = g.get_directives_dict_list(p)
    path = c.scanAtPathDirectives(aList)
    if path:
        base = g.getBaseDirectory(c) # returns "" on error.
        path = c.os_path_finalize_join(base,path)
        exists = g.os_path_exists(path)
        if createFlag:
            if exists:
                default_dir = path
            else:
                default_dir = g.makeAllNonExistentDirectories(path,c=c)
                if not default_dir:
                    error = "invalid @path: %s" % path
        else:
            default_dir = path
            if not exists:
                error = "does not exist: @path %s" % path

    return default_dir,error
#@+node:ekr.20081001062423.12: *6* g.findDefaultDirectory (major change)
# This code is executed if no valid absolute path was specified in
# the @file node or in an @path directive.

def findDefaultDirectory(c):

    '''Attempt to find a suitable default directory.'''

    default_dir = ''

    # Check that c.openDirectory and c.frame.openDirectory are in synch.
    if c.openDirectory != c.frame.openDirectory:
        g.trace('***can not happen: c.openDirectory != c.frame.openDirectory')
        g.trace('c.openDirectory',c.openDirectory)
        g.trace('c.frame.openDirectory',c.frame.openDirectory)

    if not g.os_path_isabs(c.openDirectory):
        g.trace('*** can not happen: relative c.openDirectory',c.openDirectory)

    for theDir in (c.openDirectory,g.getBaseDirectory(c)):
        if theDir and g.os_path_isabs(theDir): # Errors may result in relative or invalid path.
            if g.os_path_exists(theDir):
                default_dir = theDir
            else:
                default_dir = g.makeAllNonExistentDirectories(theDir,c=c)
            if default_dir: break

    return default_dir
#@+node:ekr.20090502071837.60: *5* init_write (rstCommands)
def init_write (self,p):

    self.initOptionsFromSettings() # Still needed.

    # Set the encoding from any parent @encoding directive.
    # This can be overridden by @rst-option encoding=whatever.
    c = self.c
    d = c.scanAllDirectives(p)
    self.encoding = d.get('encoding') or 'utf-8'
    self.path = d.get('path') or ''

    # g.trace('path:',self.path)
#@+node:ekr.20080211085914: *5* scanDefaultDirectory (leoImport)
def scanDefaultDirectory(self,p):

    """Set the default_directory ivar by looking for @path directives."""

    c = self.c

    self.default_directory, error = g.setDefaultDirectory(c,p,importing=False)

    if error:
        self.error(error)
#@+node:ekr.20101021160326.5948: *4* Fix rst3 unbounded recursion
@nocolor-node

on doing an Alt-X rst3 command

Traceback (most recent call last):
  File "leoCommands.py", line 359, in doCommand
    val = command(event)
  File "leoCommands.py", line 764, in minibufferCallback
    retval = function(keywords)
  File "mod_scripting.py", line 642, in __call__
    self.controller.executeScriptFromButton(self.p,self.b,self.buttonText)
  File "mod_scripting.py", line 667, in executeScriptFromButton
    c.executeScript(args=args,p=p,silent=True)
  File "leoCommands.py", line 1991, in executeScript
    script = g.getScript(c,p,useSelectedText=useSelectedText)
  File "leoGlobals.py", line 4358, in getScript
    at = leoAtFile.atFile(c)
  File "leoAtFile.py", line 145, in __init__
    'check-python-code-on-write',default=True)
  File "leoCommands.py", line 7436, in getBool
    return g.app.config.getBool(self.c,setting,default=default)
  File "leoConfig.py", line 1445, in getBool
    val = self.get(c,setting,"bool")
  File "leoConfig.py", line 1337, in get
    isLeoSettings = c and c.shortFileName().endswith('leoSettings.leo')
  File "leoCommands.py", line 6673, in shortFileName
    return g.shortFileName(self.mFileName)
  File "leoGlobals.py", line 2548, in shortFileName
    return g.os_path_basename(fileName)
  File "leoGlobals.py", line 3401, in os_path_basename
    path = g.toUnicodeFileEncoding(path)
  File "leoGlobals.py", line 3643, in toUnicodeFileEncoding
    return g.toUnicode(path)
  File "leoGlobals.py", line 4636, in toUnicode
    elif mustConvert(s):
  File "leoGlobals.py", line 4632, in mustConvert
    return type(s) != types.UnicodeType
RuntimeError: maximum recursion depth exceeded while calling a Python object
#@+node:ekr.20100827095120.5862: *4* First: Fix script problem
@nocolor-node

seeking help with broken script node after upgrade to 4.7
http://groups.google.com/group/leo-editor/browse_thread/thread/1d9b947a1945dd57

The following is a better listing:

=============================
from mod_scripting import scriptingController
sc = scriptingController(c)

c.frame.addIconRow()
first = True
for node in p.following_siblings_iter():
   if first:
       first = False
       continue
   h = node.headString()
   buttonText = sc.getButtonText(h)
   statusLine = "Hoist %s" % h
   b = sc.createIconButton(text=buttonText,
                           command=None,
                           shortcut=None,
                           statusLine=statusLine,
                           bg='yellow')
   def deleteButtonCallback(event=None,sc=sc,b=b):
       sc.deleteButton(b)

   def hoistButtonCallback (event=None,c=c,p=node.copy()):
       while (c.canDehoist()):
           c.dehoist()
       c.selectPosition(p)
       c.hoist()

   b.configure(command=hoistButtonCallback)
   b.bind('<3>',deleteButtonCallback)
=============================

On Windows, I have determined that the problem occurs at
c.frame.addIconRow(). The traceback I get is:

exception executing script
AttributeError: 'ToolbarTkIconBarClass' object has no attribute
'iconFrameContainerFrame'
--------------------
 line 4324:
* line 4325:             w =
Tk.Frame(self.iconFrameContainerFrame,height=height,bd=2,relief="groove")
 line 4326:             w.pack(fill="x",pady=2)
 line 4327:             self.iconFrame = w

Is there some other object I should be using instead of c.frame? I
simply don't understand the connection between the error and my
script.
#@+node:ekr.20100221142603.5620: *4* Fix bug 524890: Incomplete derived file
@nocolor-node

This is the @others bug

1. Create the following tree

Instead of the expected test1.c file of:

Content (clone)
Content (clone)

I got just:

Content (clone)
#@+node:ekr.20100221142603.5625: *5* @@shadow clone-bug-test.py@
# This buglet has been around for a long long time.
# It's not clear what Leo can do to fix it.
# In the meantime, don't put clones under two different
# @others directives :-)

<< A >>
<< B >>
@others
# end
#@+node:ekr.20100221142603.5626: *6* << a >>
# Node a
@others
#@+node:ekr.20100221142603.5629: *7* clone
# Content (clone)
#@+node:ekr.20100221142603.5628: *6* << b >>
# Node b
@others
#@+node:ekr.20100221142603.5629: *7* clone
# Content (clone)
#@+node:ekr.20100826110728.5841: *4* Cool: Allow proportional fonts in plain text
@nocolor-node


I have an outline with the default target language set to plain, but
with imported @shadow source code nodes.
The default body font is set to a mono-spaced font for the benefit of
the source code, but I'd really like all my plain-text descriptive
nodes to be in a proportional font.
Can I set a proportional font to use in all "@language plain" nodes
while retaining the mono-spaced font for all @language csharp" nodes?

=====================
Actually, almost all the machinery is in place to do this.  For
example, see in leoSettings.leo, the node

@settings-->Colors-->Syntax colors & options-->Options for jEdit
colorer-->Language-specific colors

As I have just verified, these will work for the Qt colorizer.  For example:

@font python keyword1 fonts

with body text:

python_keyword1_font_family = DejaVu Sans Mono
python_keyword1_font_size = 20
python_keyword1_font_slant = roman
   # roman, italic
python_keyword1_font_weight = bold
   # normal, bold

Produces quite big keyword :-)

There are some issues that may have to be addressed re defaults, but
I'd like to see this happen in the next day or so.  It would be a
really good feature.

Edward
#@+node:ekr.20100827095120.5863: *4* Urgent: fix @shadow problem
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/dbe098206376ec8d

I'm working with Leo 4.7.1 final (build 3005, dated 26 Feb 2010) and
just noticed a bug in propagate_changed_lines within leoShadow.py.
I haven't worked out the complete fix for this, but thought I'd
mention it now so that others don't stumble over it unawares.
It's the handling of the 'replace' tag (new code dated 7 Jan 2010)
which does not handle the case when the number of new lines is
different from the number of old lines. In fact the number of new
lines can be either greater or less than the number of old lines, so
the code needs a little more complexity to deal with this. Currently
it only replaces the same number of lines as were in the old file.
There's an added twist in that if sentinels occur in the middle of the
old lines, it won't be clear how to distribute the new lines on either
side of the sentinels.
I'll comment further when I've thought about this some more, but for
now, this is just a road cone to mark the spot.

==========================

After a little more thought, I suspect that the simple approach is
likely to be the best, at least initially.
I'd suggest placing a condition (if new_public_lines_rdr.index() <
new_j) on the copying of new public lines to new private lines, then
finishing off with a loop copied from the 'insert' tag above -- (while
new_public_lines_rdr.index() < new_j ...).

I'm not in a position to get involved with direct editing of the code
within SourceForge, but I contribute these thoughts in the hope that
an active contributor may be able to make something of them.

Nick
#@+node:ekr.20100904134301.11007: *4* Document leoremote plugin
@nocolor-node

Ville's server code to interact with a running Leo
http://mail.google.com/mail/#inbox/12adebe2ffe80572

Reusing Emacs instances with gnuserv
http://www.debian-administration.org/articles/257

#@+node:ekr.20100904134301.8336: *4* Generate pdf on Linux
El 01/05/09 15:12, Ville M. Vainio escribi:

- make latex
- cd _build/latex
- make all-pdf
#@+node:ekr.20100906091349.5848: *4* Allow @url nodes to specify urls in body text
@nocolor-node

Having to type the url after @url in headline is annoying.

The @url handler should look into the first line of body for url, if the text in
the headline is not an url. This way, the headline could actually be
descriptive.

I know some plugin does this, but there is no reason why this couldn't be the
default behavior.
#@+node:ekr.20100906091349.5849: *4* Reorganize Leo docs
@nocolor-node

Structure of Leo's User Documentation
http://groups.google.com/group/leo-editor/browse_thread/thread/d02df89c0b831a7c

Re-arranging the documentation along those lines would lead to the
following:

* Front Matter
* Preface
* What People Are Saying About Leo
* FAQ
* Slides
* Chapter 1: Installing Leo
* Chapter 2: The Leo Tutorial
* Chapter 3: Using Outlines
* Chapter 5: Using Leos Commands
* Chapter 6: Designing with Leo
* Chapter 14: Creating Documents with Leo
* Chapter 7: Scripting Leo with Python
* Chapter 8: Customizing Leo
* Chapter 12: Plugins
* Chapter 13: Writing Plugins
* Chapter 20: Unit testing with Leo
* Chapter 16: Debugging with Leo
* Chapter 17: Using ZODB with Leo
* Chapter 18: Leo and Emacs
* Chapter 19: Embedding Leo with the leoBridge module
* Chapter 21: IPython and Leo
* Chapter 22: Using Vim Bindings with Leo
* Chapter 23: Eliminating sentinel lines with @shadow
* Chapter 15: Controlling Syntax Coloring
* Chapter 4: Leos Reference
* Chapter 9: History of Leo
* Chapter 10: Theory of Operation
* Chapter 11: White Papers
* Appendices
* Glossary
* Whats New in Leo 

At the risk of being repetitious, I've never found any documentation as
accessible as Django's, from this starting point:
http://docs.djangoproject.com/en/dev/ 
#@+node:ekr.20100827095120.5870: *3* Before a1
#@+node:ekr.20060306194040: *4* Leo Video & slide show
@nocolor

The curse of knowledge
http://groups.google.com/group/leo-editor/browse_thread/thread/3e75787223ee9303

(Rich) I'd like to see something like:

[Buttons]
...[What are Buttons good for?]
...[How do I make my own buttons?]
......[Some commands you can use with buttons]
......[Where to find button commands]
#@+node:ekr.20100828074347.5828: *5* Resources
http://sourceforge.net/forum/message.php?msg_id=3615177
By: ktenney

High on my ToLearn list is vnc2swf
http://www.unixuser.org/~euske/vnc2swf/

http://sourceforge.net/forum/message.php?msg_id=3615278
By: James

A lot of people are now using Wink for demonstrations
(http://www.debugmode.com/wink/), it's is free and seems to work well.

Check out http://murl.se/11332
At the bottom they talk about tools and techniques.
http://showmedo.com seems like it would be a good
place to host vids also.

I've listened/watched a fair number of things like this;
my recomendation is to get a good microphone and
pre-amp to record your voice, and prepare the audio
track carefully. It is so aggravating when
it's hard to discern the words being spoken.

http://sourceforge.net/forum/message.php?msg_id=3758271

From: Rich

Tutorials would be great. I use Liberty BASIC, (http://libertybasic.conforums.com)
and it has a very good tutorial -- leads the beginner by the hand through much
of the language. Also the help file has working code snippets
to cut-n-paste-n-play-with. 
#@+node:ekr.20100827114047.5899: *4* Installer, etc.
#@+node:ekr.20100907092144.6076: *5* Make sure distribution contains correct files
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/dea95cd8ab976cac
Status of 'make-leo-zip' in Outline 'leoDist' ?

On Sep 6, 2:39 pm, VR <viktor.ransm...@gmail.com> wrote:

> * The file 'INSTALL.TXT' contains the outline text with sentinels from
> 'Chapter 1: Installing Leo'

That can't be good.  I'll make sure sentinels don't appear in the distro.

> * The file 'PKG-INFO.TXT' is OK. - However it uses an old version,
> i.e. '4.7.1-final'

> * The file 'README' is OK. - However it also uses this old version.

The script isn't meant to update these automatically.  I use a checklist to remind me to do such things.

> * However neither of these files are not added to the archive ...

I'll check this.  I'm not sure this is a problem, but it could be.

Thanks for your careful checking.  Such checking is essential when preparing for releases.

I've added this discussion to my internal distribution checklist.

Edward
#@+node:ekr.20100828110445.5824: *5* Finish installer
@nocolor-node

Docs and installer should have top priority
http://groups.google.com/group/leo-editor/browse_thread/thread/8ed5b2034bd218d8

2. Migration. If I upgrade from Python 2.6 to 2.7 for reasons
unrelated to Leo, I'll presumably need to reinstall Leo as well. It
would be nice not to have to.

These goals could possibly be achieved by installing Leo in an
independent directory (chosen by the user as part of the installation)
and adding a .pth file into Python's site-packages directory (see
documentation for the site module). Then the leo script can be
installed alongside the package - so you have

    ... Program Files\Leo\
            leo.bat
            package\leo\...

leo.pth:
...\Program Files\Leo\package 
#@+node:ekr.20100826110728.5844: *5* Fix install problem
@nocolor-node

I installed leo 4.7.1, python31, qt4 pyqtgpl 4.7.4 for py31.
I figured out on my own to make a shortcut to launchLeo.py at this
location:

C:\Python31\Lib\site-packages\Leo-4.7.1-final\launchLeo.py

which works. (whooppee)

However the shortcuts that the "leo install" created don't work they
abort.
#@+node:ekr.20100827114047.5900: *5* Convert to leoPy.leo EKRleoPy.leo, etc.
#@+node:ekr.20100827114047.5896: *4* Docs
#@+node:ekr.20100826110728.5846: *5* Add explanation of icon box to tutorial
> 1) Is there a place I can go to find what indicators could appear in
> the icon box, and also what they mean?

Here :-)

Blue box: node contains text.
Red vertical bar: node is marked.
Circular arrow: node is cloned.
Outer box is black: node is dirty.
#@+node:ekr.20100827114047.5894: *5* Fix documentation for expand-all-subheads
@nocolor-node

https://bugs.launchpad.net/leo-editor/+bug/604037

The manual mentions "Expand All Subheads", and it is implemented in
leoCommands.py, but it is not present in leoEditCommands.py, and is thus
unavailable except in python scripts. If this was intended, I'll remove it from
the manual; if not, I'll add it to leoEditCommands.py.
#@+node:ekr.20100827095120.5860: *5* Fix chapter 14 typos
@nocolor-node

I've recreated my feedback notes using the online service Diigo.
Here's a link to see the highlights and sticky notes: http://diigo.com/0c9u2

This is an experiment as I've been researching Diigo-like services for
about a week, and would like to know if this would be an acceptable
method when there are lots of things to be commented on for Leo's web
pages. Otherwise I would do email when there are only a few comments.

When you go to the link, you'll see pink highlighted text, with a
small icon in the top left of each text "piece" with a number. Hover
over it to cause the sticky note to be displayed. The number
represents the number of comments entered on the sticky note.

Usually when I'm highlighting edits to be made (like in Acrobat), I
only highlight the specific word or punctuation that needs attention.
With Diigo, there are two problems:

a) there seems to be a minimal number of characters that need to be
highlighted before you get an option to add a sticky note, and

b) Diigo appears to "remember" the location of highlights/stickies
based on where the text first occurs on the page. If you highlight
text halfway into the document that also appears at the beginning of
the document, reloading the web page causes your highlight to "move"
without warning to the beginning of the document. This took a while
for me to realize, because I'd keep redoing highlights, not knowing I
was spinning my wheels. (I don't know what will happen to these
annotations if Chapter 14 is changed and reuploaded. Probably it will
still "find" the highlighted text that hasn't changed and be able to
show the sticky notes.)

The solution to both issues is to highlight more text than you want,
and make sure it's enough text to identify its location uniquely on
the web page. I noted in the sticky note where extra text highlighting
was done, eventually saying I did it due to a Diigo bug.

You do NOT need to sign up for Diigo to see the edits, but there are
two benefits I can see for collaborating on web pages. If you had an
account (and you can use your Google account, like I did), you could:

1) Add comments to the comments I've made. Without an account, when a
sticky note is displayed, it acts like you could type in a comment and
click on Post. But when you click on Post the comment is not saved
anywhere, and there's no message that it was sent to /dev/null.

2) Navigate easier through the list of annotations, if you also
install the Diigo toolbar. There's a "Comment" button that when
clicked opens up a side bar listing all annotations. The biggest
feature I wish Diigo had was an easy way to go to the previous/next
annotation to be sure I see them all.

3) Create the first sticky note for highlighted text that Diigo has
trouble dealing with: Text highlighted at the very beginning of the
line causes the icon to appear at the very end of the line above it.
The problem is, you need to hover over the highlighted text to cause
the icon to appear that allows adding the sticky note. But you can't
move the mouse fast enough :) from the highlighted text to the icon at
the end of the line above it. The solution is to sign in to your Diigo
account, go to My Library, find your highlighted text and choose the
"Add Sticky Note" link.

Phew, been working on this and the Chapter 14 edits for hours. Time to
take a break.
#@+node:ekr.20100827095120.5864: *5* Clarify read @file node command
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/150a356ad24fe3b1

Fix/clarify menus and documentation

Also, removed incorrect error message:

The "Read @<file> Nodes" works to incorporate external changes in the select
tree, though it does generate an incorrect message:

    "no @<file> nodes in the selected tree".
#@+node:ekr.20100521130114.5904: *5* Plugins documentation thread
@nocolor-node

We want better docs, automatically, and a way to update @enabled-plugins.

http://groups.google.com/group/leo-editor/browse_thread/thread/b409aac6ca8cd33b
#@+node:ekr.20101004092958.5914: *3* To do: write treepad scanner
@ treepad.py is from the treepad website
#@+node:ekr.20101004092958.5939: *4* treepad.py
@first #! /usr/local/bin/python

# treepad.py

@language python
@tabwidth -4
@others
if __name__ == '__main__':
    Main().Run()

#@+node:ekr.20101004092958.5940: *5* treepad declarations
import sys, os, re, string

# constants
VERSION = "<Treepad version 2.7>"

# regexes
END_RE = re.compile(r'^<end node> ([^ ]+)$')
#@+node:ekr.20101004092958.5941: *5* class Node
class Node:
    @others
#@+node:ekr.20101004092958.5942: *6* __init__
def __init__(self):
    self.title    = ""
    self.level    = 0
    self.article  = []
    self.children = []
    self.parent   = None
    self.end      = ""
#@+node:ekr.20101004092958.5943: *6* __str__
def __str__(self):
    return "%s/%d" % (self.title, self.level)
#@+node:ekr.20101004092958.5944: *6* addchild
def addchild(self, node):
    assert self.level == node.level-1 and node.parent is None
    node.parent = self
    self.children.append( node )
#@+node:ekr.20101004092958.5945: *6* findparent
def findparent(self, node):
    if self.level == (node.level-1): return self
    return self.parent.findparent(node)
#@+node:ekr.20101004092958.5946: *6* writenode
def writenode(self, fp):
    fp.write("dt=Text\n")
    fp.write("<node>\n")
    fp.write("%s\n" % self.title)
    fp.write("%s\n" % self.level)
    for line in self.article:
        fp.write("%s\n" % line)
    fp.write("<end node> %s\n" % self.end)
#@+node:ekr.20101004092958.5947: *6* writetree
def writetree(self, fp):
    self.writenode(fp)
    for node in self.children:
        node.writetree(fp)

#@+node:ekr.20101004092958.5948: *5* class NodeReader
class NodeReader:
    @others
#@+node:ekr.20101004092958.5949: *6* __init__
def __init__(self, fname, fp):
    self.fname    = fname
    self.fp       = fp
#@+node:ekr.20101004092958.5950: *6* expect
def expect(self, text, line=None):
    if line is None:
        line = self.fp.readline().strip()
    assert line == text, "expected " + line + " == " + text
#@+node:ekr.20101004092958.5951: *6* readstart
def readstart(self):
    self.expect(VERSION)
#@+node:ekr.20101004092958.5952: *6* readnode
def readnode(self):
    line = self.fp.readline()
    if line is None:
        return None
    line = line.strip()
    if len(line) < 1:
        return None
    self.expect("dt=Text", line)
    self.expect("<node>")
    node = Node()
    node.title = self.fp.readline().strip()
    node.level = int(self.fp.readline().strip())
    while 1:
        line = self.fp.readline()
        m = re.match(END_RE, line)
        if m:
            node.end = m.group(1).strip()
            break
        node.article.append( line.strip() )
    return node

#@+node:ekr.20101004092958.5953: *5* class TreeReader
class TreeReader:
    @others
#@+node:ekr.20101004092958.5954: *6* __init__
def __init__(self, fname, fp=None):
    if fp is None: fp = open(fname, 'r')
    self.nodereader = NodeReader(fname, fp)
    self.root = None
    self.prev = None
#@+node:ekr.20101004092958.5955: *6* add
def add(self, node):
    if self.prev is None:
        assert node.level == 0
        self.root = node
    else:
        assert node.level > 0
        parent = self.prev.findparent(node)
        parent.addchild( node )
    self.prev = node
#@+node:ekr.20101004092958.5956: *6* read
def read(self):
    self.nodereader.readstart()
    prev = None
    while 1:
        node = self.nodereader.readnode()
        if node is None: break
        self.add(node)

#@+node:ekr.20101004092958.5957: *5* class TreeWriter
class TreeWriter:
    @others
#@+node:ekr.20101004092958.5958: *6* __init__
def __init__(self, fname, fp=None):
    if fp is None: fp = open(fname, 'w')
    self.fname = fname
    self.fp    = fp
#@+node:ekr.20101004092958.5959: *6* write
def write(self, root):
    self.fp.write("%s\n" % VERSION)
    root.writetree(self.fp)

#@+node:ekr.20101004092958.5960: *5* class Main
class Main:
    @others
#@+node:ekr.20101004092958.5961: *6* __init__
def __init__(self):
    self.infile  = sys.argv[1]
    self.outfile = sys.argv[2]
    self.reader  = TreeReader(self.infile)
    self.writer  = TreeWriter(self.outfile)
#@+node:ekr.20101004092958.5962: *6* Run

def Run(self):
    self.reader.read()
    self.writer.write(self.reader.root)

#@+node:ekr.20100915101910.5891: *3* Make sure cache works after bzr revert
#@+node:ekr.20100827114047.5895: *3* Bugs
#@+node:ekr.20100903090944.5850: *4* Other bugs
#@+node:ekr.20100522090453.5912: *5* Fix bugs with @verbatim, @raw and @end_raw
@nocolor-node

> In the @file family of derived files (@thin, @nosent, etc.)  (i.e.,
> not @root), you can prevent any interpretation of the immediately
> following line with the "@verbatim" directive

This is not true, although it might appear to be true.

There is an @verbatim *sentinel*, but no @verbatim *directive*.

For example, I have just verified that the following does not work:

@verbatim
<< undefined ref >>

@raw and @end_raw do work as described.

There appear to be several bugs in this area:

1. Leo probably should warn that @verbatim does not exist as a
directive, although technically Leo is supposed to write anything that
looks like a sentinel but isn't "verbatim".

2. Leo does appear to read @raw and @end_raw properly in @thin files,
but Leo improperly issues the (red) log message,
converting @file format in @thin test_verbatim_sentinel.py
#@+node:ekr.20100827114047.5893: *5* Fix rst file problems
@nocolor-node

Reported by TL:

When editing a Docutils file in an external editor (exported from
Leo), I always get a "Replace changed outline with external changes?"
dialog box when I save the file in the external editor. This appears
to occur because a newline is added to the end of the file when it is
imported back into Leo.

Note: The addition of a newline occurs even if the imported file
already has a newline at the end of the file.

There appears to be two problems:

1) Leo always adds a newline even if the already has one.
2) After Leo has added the newline it mistakenly marks the buffer as
modified.
#@+node:ekr.20100220190251.5616: *6* Fix rst bug?
# See handleCodeMode
#@+node:ekr.20100220190251.5617: *7* report
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/c212814815c92aac

The indentation of the second @doc causes the doc part to look like
a continuation of the code:: directive.

It's not clear whether this bug is worth fixing, and it's not clear whether
there would be side effects of any potential fix.

The simplest fix appears to be in handleCodeMode.
#@+node:ekr.20090502071837.72: *7* handleCodeMode & helper
def handleCodeMode (self,lines):

    '''Handle the preprocessed body text in code mode as follows:

    - Blank lines are copied after being cleaned.
    - @ @rst-markup lines get copied as is.
    - Everything else gets put into a code-block directive.'''

    result = [] ; n = 0 ; code = []
    while n < len(lines):
        s = lines [n] ; n += 1
        if (
            self.isSpecialDocPart(s,'@rst-markup') or (
                self.getOption('show_doc_parts_as_paragraphs') and
                self.isSpecialDocPart(s,None)
            )
        ):
            if code:
                self.finishCodePart(result,code)
                code = []
            result.append('')
            n, lines2 = self.getDocPart(lines,n)
            # A fix, perhaps dubious, to a bug discussed at
            # http://groups.google.com/group/leo-editor/browse_thread/thread/c212814815c92aac
            # lines2 = [z.lstrip() for z in lines2]
            # g.trace('lines2',lines2)
            result.extend(lines2)
        elif not s.strip() and not code:
            pass # Ignore blank lines before the first code block.
        elif not code: # Start the code block.
            result.append('')
            result.append(self.code_block_string)
            code.append(s)
        else: # Continue the code block.
            code.append(s)

    if code:
        self.finishCodePart(result,code)
        code = []

    # Munge the result so as to keep docutils happy.
    # Don't use self.rstripList: it's not the same.
    # g.trace(result)
    result2 = []
    for z in result:
        if z == '': result2.append('\n\n')
        # 2010/08/27: Fix bug 618482.
        # elif not z.rstrip(): pass
        elif z.endswith('\n\n'): result2.append(z) # Leave alone.
        else: result2.append('%s\n' % z.rstrip())

    return result2
#@+node:ekr.20090502071837.73: *8* formatCodeModeLine
def formatCodeModeLine (self,s,n,numberOption):

    if not s.strip(): s = ''

    if numberOption:
        return '\t%d: %s' % (n,s)
    else:
        return '\t%s' % s
#@+node:ekr.20090502071837.74: *8* rstripList
def rstripList (self,theList):

    '''Removed trailing blank lines from theList.'''

    # 2010/08/27: fix bug 618482.
    s = ''.join(theList).rstrip()
    return s.split('\n')
#@+node:ekr.20090502071837.75: *8* finishCodePart
def finishCodePart (self,result,code):

    numberOption = self.getOption('number_code_lines')
    code = self.rstripList(code)
    i = 0
    for line in code:
        i += 1
        result.append(self.formatCodeModeLine(line,i,numberOption))
#@+node:ekr.20100220204150.5627: *7* @@rst hello.html
@ @rst-options
verbose=True
code_mode=True
show_doc_parts_as_paragraphs=True
number_code_lines=True
write_intermediate_file=True
@c

#@+node:ekr.20100220204150.5628: *8* Greet the world
@
Greet the world, politely
@c

g.es ("Hello, world")

@
    Was that polite enough?
    Indentation.
@c
#@+node:ekr.20100830120622.5829: *5* Fix python import problems
@nocolor-node

> > Hmm, I guess that would be more clear, although I think I'd like an option to include it in the following def to avoid
> >
> > Decoration
> > index
> > Decoration
> > add_user
>
> Sure.  Decorations must always be part of a definition.

Well, personally I'd like to have them included in the definition, but I think Kent's preference for a separate node is reasonable to.  If your function and hence definition node is called "pluralize", and it's decorated with something like "@authenticate_user", you may never check the innocent looking pluralize definition to find out what on earth's triggering the mysterious network database call.  And this isn't a completely specious example, authentication may have been added to stop pluralize being used in a user existence detection exploit or something.  OTOH in well behaved code like CherryPy apps you don't want a separate node for every @cherrypy.expose.

Bottom line is I think we're asking for a set of @settings to fine tune python import behavior:

@python_import_interdef = previous | next | own_node | ai
@python_import_decoration = next | own_node

I'm not sure I believe the AI option is possible / practical, and am not asking for it, just listing it :-)

I'd also like

@python_import_init_in_class_node = true | false

as often there's more docs on a class in the __init__ than the class docstring.

I think that's really all we're talking about, some @settings to test during import.
#@+node:ekr.20100827114047.5892: *5* Fix toggle-split-direction
Should preserve scrollbar location and appropriate window ratio.

https://bugs.launchpad.net/leo-editor/+bug/581031/+editstatus
#@+node:ekr.20100826110728.5839: *5* Relocating .leo_shadow directories
@nocolor-node

2008

http://groups.google.com/group/leo-editor/browse_thread/thread/b738e3f8d164f9fc

May 10, 2010

Kent

I think there could be quite a bit of interest in moving
the shadow files to their own tree, avoiding what might
be considered 'pollution' of a tree of files in @shadow nodes.

Edward has said that this would add a lot of complexity to Leo.

It seems that a VCS back end for Leo might simplify the
task of arbitrary shadow file location, as well as adding
versioning capability.


Those of us old enough to remember the Groucho Marx show will know what I am ...

bogomil
 to me

In order to relocate .leo_shadow directories in home dir, I have made
the following changes leoShadow.py:
1. Introduce new setting 'shadow_in_home_dir':
   x.ctor:
     ...
     self.shadow_prefix = c.config.getString('shadow_prefix') or ''

=>  self.shadow_in_home_dir = c.config.getBool('shadow_in_home_dir')
or False
    ...

2. Make the following line:
   x.shadowDirName and shadowPathName:
      ...
      fileDir = g.os_path_dirname(filename)

=>   if self.shadow_in_home_dir:
        fileDir = "//".join([baseDir, fileDir.replace(':','%')])

In this way I keep .leo_shadow dirs in a tree and it is ok if the user
reorgs the original tree.

=====================
Edward K. Ream
 to bogomil

Thanks for these suggestions.  I'll try them soon.

A few minor comments about the code.

>  self.shadow_in_home_dir = c.config.getBool('shadow_in_home_dir') or False

This works (because c.config.getBool returns None if the setting does
not exist). Thus, the "or False" part merely replaces None by False.
I prefer the following:

self.shadow_in_home_dir = c.config.getBool('shadow_in_home_dir',default=False)

>   if self.shadow_in_home_dir:
>         fileDir = "//".join([baseDir, fileDir.replace(':','%')])

This looks like a Windows-only solution because of ':'.  It might fail
in strange ways on other platforms.
#@+node:ekr.20100827095120.5858: *5* Improve .ini importer
#@+node:ekr.20100826110728.5840: *5* rst with show-comments-as-paragraph
@nocolor-node

derwish

It seems that this option only works as expected for comments at the
beginning of a node.

A Leo file with the following contents would be rendered with  the
second comment inside the PRE-element of the code paragraph.

I am using Leo 4.7b2, build 2404

<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet ekr_test?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="0"
clone_windows="0"/>
<globals body_outline_ratio="0.5">
       <global_window_position top="30" left="12" height="600" width="800"/>
       <global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="huesingjohannes.20090706083342.1221"
str_leo_pos="2,0"><vh>@chapters</vh></v>
<v t="huesingjohannes.20091022082006.1227"><vh>@url U:/leo/hello.html</
vh></v>
<v t="huesingjohannes.20090706083342.1220" a="E"><vh>@rst U:\leo
\hello.html</vh>
<v t="huesingjohannes.20090706083342.5924"><vh>Greet the world</vh></
v>
</v>
</vnodes>
<tnodes>
<t tx="huesingjohannes.20090706083342.1220">@ @rst-options
verbose=True
code_mode=True
show_doc_parts_as_paragraphs=True
number_code_lines=False

@c

</t>
<t tx="huesingjohannes.20090706083342.1221"></t>
<t tx="huesingjohannes.20090706083342.5924">@
    Greet the world, politely
@c

g.es ("Hello, world")

@
   Was that polite enough?
@c</t>
<t tx="huesingjohannes.20091022082006.1227"></t>
</tnodes>
</leo_file>

========================

Is there anyone here who could help me on this? It would be really nice if I
didn't have to restrain myself to comments only at the top of a node.


==========================
Thanks for this report.  Sorry for the delay in responding.  Please
file an official bug report.  It does seem like a real bug.


If I can fix it cleanly tomorrow before Leo 4.7 final I shall. Otherwise soon.

=======================
Ok. I have simple fixes, but none are safe enough to include in Leo 4.7 final...

In the meantime, removing the leading whitespace from the first line
of the second @doc part should be a good enough workaround.

There are three possible fixes, all similar:

1. In getDocPart (in leoRst.py), change::

   result.append(s)

to:

   result.append(s.lstrip())

There are two such lines in getDocPart.  Probably both should be
changed.

2. The same fix, conditional on a new 'stripLines' keyword arg.  Like
this:

   if stripLines:
       result.append(s.lstrip())
   else:
       result.append(s)

Again, this change affects two lines in getDocPart.

The idea is that handleCodeMode would be the only method to set the
stripLines arg:

   n, lines2 = self.getDocPart(lines,n)

3. A change to handleCodeMode.  After the line:

   n, lines2 = self.getDocPart(lines,n)

add the line:

   lines2 = [z.lstrip() for z in lines2]

As I write this, I am thinking that change #3 is the simplest change,
with the fewest side effects.

We can test any one of these solutions starting early in the Leo 4.8
release cycle, but none  is safe enough to include in Leo 4.7 final.

If you would, please test fix #3 and report your results.  Thanks.
#@+node:ekr.20100826110728.5842: *5* g.redirect breaks ipython
@nocolor-node

I am using the ipython bridge more and more. Its great.   I noticed
that if I run a script from leo that includes the g.redirectStdout()
or g.redirectStderr() functions, the leo gui will freeze if I have an
ipython bridge open.  I have found this behavior on Windows, but
haven't checked it yet on Linux.

I'm checking here first before submitting a bug.

rod

=================
Thanks for this report.  Please do submit a bug.  Thanks.

Edward
#@+node:ekr.20100223133351.5998: *5* show-invisibles doesn't work for blank lines
#@+node:ekr.20081208102356.1: *5* Threading colorizer doesn't handle multiple body editors
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5be7a099b299327e

> Tk only colorizes one body editor, and if you delete that editor it
> colorizes no editor.

Thanks for this report.  This is a problem, never noticed until now,
with the threading colorizer.  A workaround is to disable the
threading colorizer plugin. 
#@+node:ekr.20100131161507.6303: *5* Unit tests that all commands have docstrings
# Just make the test.  It doesn't have to pass.
#@+node:ekr.20100521090440.5885: *5* Fix mac unicode crasher
#@+node:ekr.20100521090440.5886: *6* Report
@nocolor-node

I put the following in qtGui.py after

# Last minute-munges to keysym.

    if sys.platform.startswith('darwin'):
        darwinmap = {
            'Alt-Key-5': '[',
            'Alt-Key-6': ']',
            'Alt-Key-7': '|',
            'Alt-slash': '\\',
            'Alt-Key-8': '{',
            'Alt-Key-9': '}',
            'Alt-e': '',
            'Alt-l': '@',
        }
        if tkKey in darwinmap:
            tkKey = stroke = darwinmap[tkKey]

It works quite reasonabe. Sometimes (not really well reproducable)
following message appears:

/Users/tst/Leo-4.7-final/leo/core/leoKeys.py:3363: UnicodeWarning:
Unicode equal comparison failed to convert both arguments to Unicode -
interpreting them as being unequal
  if k.abortAllModesKey and stroke == k.abortAllModesKey:
/Users/scalet/Leo-4.7-final/leo/core/leoKeys.py:2521: UnicodeWarning:
Unicode equal comparison failed to convert both arguments to Unicode -
interpreting them as being unequal
  if k.abortAllModesKey and stroke == k.abortAllModesKey: # 'Control-
g'

nonetheless the special characters were inserted as expected.

I think all this is quite a hack, but ... thanks for the hack, most
important for me it's working for now. 
#@+node:ekr.20100804095820.5812: *5* Fix thumb drive spec problem
#@+node:ekr.20100204052559.5791: *3* Make TOC sidebar collapsible
@nocolor-node
@wrap

http://groups.google.com/group/leo-editor/browse_thread/thread/abe236a45b0511c7

http://www.google.com/url?sa=t&source=web&ct=res&cd=4&ved=0CBYQFjAD&url=http%3A%2F%2Fbugs.python.org%2Fissue3143&ei=bW5oS-eQIJDalAfqlYyGCA&usg=AFQjCNGyhpE3wZ2jvfwA0dwjCfoAxleDRQ&sig2=2CRD7hNMmx1NzFHMyOq_cQ

includes code for the CSS stylesheet (sidebar.js) to do make the sidebar collapsable.

EKR:

1. Place sidebar.js in leo\doc\html\_build\html\_static

2. Add the following line in the <head> section of all .html files in leo\doc\html\_build\html:

    <script type="text/javascript" src="sidebar.js"></script>

Now the sidebar is collapsable. Mousing over the divider shows a << icon. When
the sidebar is collapsed, mousing over the left edge shows a >> button.

The question is, how to do this automatically?
#@+node:ekr.20101004092958.5913: *3* New auto completer
#@+node:ekr.20101004092958.6008: *4*  codewise stuff
#@+node:ekr.20101004092958.5964: *5* codewise crash

c:\leo.repo\trunk>python -m codewise setup

c:\leo.repo\trunk>c:\Python31\python.exe -m codewise setup
Creating template c:\Users\edreamleo/.ctags
Initializing CodeWise db at c:\Users\edreamleo/.codewise.db
c:\Users\edreamleo/.codewise.db
<sqlite3.Connection object at 0x02B881A0>

c:\leo.repo\trunk>python -m codewise init

c:\leo.repo\trunk>c:\Python31\python.exe -m codewise init
Initializing CodeWise db at c:\Users\edreamleo/.codewise.db
c:\Users\edreamleo/.codewise.db
<sqlite3.Connection object at 0x02BA21A0>

c:\leo.repo\trunk>python -m codewise parse c:\leo.repo\trunk

c:\leo.repo\trunk>c:\Python31\python.exe -m codewise parse
Traceback (most recent call last):
  File "c:\Python31\lib\runpy.py", line 128, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "c:\Python31\lib\runpy.py", line 34, in _run_code
    exec(code, run_globals)
  File "c:\Python31\lib\site-packages\codewise.py", line 454, in <module>
    main()
  File "c:\Python31\lib\site-packages\codewise.py", line 440, in main
    cmd_parse(args)
  File "c:\Python31\lib\site-packages\codewise.py", line 368, in cmd_parse
    assert args
AssertionError

c:\leo.repo\trunk>scripts

c:\leo.repo\trunk>cd c:\Scripts

c:\Scripts>ed python.bat

c:\Scripts>echo off
Could Not Find c:\Scripts\*.~?~

c:\Scripts>tr

c:\Scripts>cd c:\leo.repo\trunk

c:\leo.repo\trunk>python -m codewise parse c:\leo.repo\trunk

c:\leo.repo\trunk>c:\Python31\python.exe -m codewise parse c:\leo.repo\trunk
c:\Users\edreamleo/.codewise.db
ctags -R --sort=no -f - c:\leo.repo\trunk

c:\leo.repo\trunk>python -m codewise parse c:\python31\lib

c:\leo.repo\trunk>c:\Python31\python.exe -m codewise parse c:\python31\lib
c:\Users\edreamleo/.codewise.db
ctags -R --sort=no -f - c:\python31\lib
Traceback (most recent call last):
  File "c:\Python31\lib\runpy.py", line 128, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "c:\Python31\lib\runpy.py", line 34, in _run_code
    exec(code, run_globals)
  File "c:\Python31\lib\site-packages\codewise.py", line 454, in <module>
    main()
  File "c:\Python31\lib\site-packages\codewise.py", line 440, in main
    cmd_parse(args)
  File "c:\Python31\lib\site-packages\codewise.py", line 370, in cmd_parse
    cw.parse(args)
  File "c:\Python31\lib\site-packages\codewise.py", line 307, in parse
    self.feed_ctags(f)
  File "c:\Python31\lib\site-packages\codewise.py", line 250, in feed_ctags
    fil = fields[1]
IndexError: list index out of range

c:\leo.repo\trunk>
#@+node:ekr.20101004092958.6009: *5* codewise.py
@first #!/usr/bin/env python

<< docstring >>
<< usage >>
<< decls >>

@language python
@tabwidth -4

@others

if __name__ == "__main__":
    main()
#@+node:ekr.20101004092958.6010: *6* << docstring >>
""" CodeWise - global code intelligence database

Why codewise:

- Exuberant ctags is an excellent code scanner
- Unfortunately, TAGS file lookup sucks for "find methods of this class"
- TAGS files can be all around the hard drive. CodeWise database is
  just one file (by default ~/.codewise.db)
- I wanted to implement modern code completion for Leo editor

- This is usable as a python module, or a command line tool.

"""
#@+node:ekr.20101004092958.6011: *6* << usage >>
USAGE = """
codewise setup
 (Optional - run this first to create template ~/.ctags)

codewise init
 Create/recreate the global database

codewise parse /my/project /other/project
 Parse specified directories (with recursion) and add results to db

codewise m
 List all classes

codewise m MyClass
 Show all methods in MyClass

codewise f PREFIX
 Show all symbols (also nonmember functiosn) starting with PREFIX.
 PREFIX can be omitted to get a list of all symbols

codewise parseall
 Clear database, reparse all paths previously added by 'codewise parse'

codewise sciapi pyqt.api
 Parse an api file (as supported by scintilla, eric4...)

Commands you don't probably need:

codewise tags TAGS
 Dump already-created tagfile TAGS to database

""" 
#@+node:ekr.20101004092958.6012: *6* << decls >>
import os,sys
import sqlite3

isPython3 = sys.version_info >= (3,0,0) # EKR.

DEFAULT_DB = os.path.expanduser("~/.codewise.db")

DB_SCHEMA = """
BEGIN TRANSACTION;
CREATE TABLE class (id INTEGER PRIMARY KEY, file INTEGER,  name TEXT, searchpattern TEXT);
CREATE TABLE file (id INTEGER PRIMARY KEY, path TEXT);
CREATE TABLE function (id INTEGER PRIMARY KEY, class INTEGER, file INTEGER, name TEXT, searchpattern TEXT);
CREATE TABLE datasource (type TEXT, src TEXT);

CREATE INDEX idx_class_name ON class(name ASC);
CREATE INDEX idx_function_class ON function(class ASC);

COMMIT;
"""

#@+node:ekr.20101004092958.6013: *6* Top level
#@+node:ekr.20101004092958.6014: *7* Commands
#@+node:ekr.20101004092958.6015: *8* cmd_functions
def cmd_functions(args):
    cw = CodeWise()

    if args:
        funcs = cw.get_functions(args[0])
    else:
        funcs = cw.get_functions()
    lines = list(set(el[0] + "\t" + el[1] for el in funcs))
    lines.sort()
    printlines(lines)
    return lines # EKR
#@+node:ekr.20101004092958.6016: *8* cmd_init
def cmd_init(args):

    print("Initializing CodeWise db at", DEFAULT_DB)
    if os.path.isfile(DEFAULT_DB):
        os.remove(DEFAULT_DB)

    cw = CodeWise()
#@+node:ekr.20101004092958.6017: *8* cmd_members
def cmd_members(args):
    cw = CodeWise()
    if not args:
        lines = cw.classcache.keys()
        lines.sort()
        printlines(lines)        
        return [] # EKR

    mems = cw.get_members([args[0]])
    lines = list(set(el + "\t" + pat for el, pat in mems))
    lines.sort()
    printlines(lines)
    return lines # EKR
#@+node:ekr.20101004092958.6018: *8* cmd_parse
def cmd_parse(args):
    assert args
    cw = CodeWise()
    cw.parse(args)
#@+node:ekr.20101004092958.6019: *8* cmd_parseall
def cmd_parseall(args):
    cw = CodeWise()
    cw.parseall()
#@+node:ekr.20101004092958.6020: *8* cmd_scintilla
def cmd_scintilla(args):
    cw = CodeWise()
    for fil in args:
        f = open(fil)
        cw.feed_scintilla(f)
        f.close()
#@+node:ekr.20101004092958.6021: *8* cmd_setup
def cmd_setup(args):

    ctagsfile = os.path.expanduser("~/.ctags")
    print("Creating template",ctagsfile)
    assert not os.path.isfile(ctagsfile)
    open(ctagsfile, "w").write("--exclude=*.html\n--exclude=*.css\n")
    cmd_init(args)
#@+node:ekr.20101004092958.6022: *8* cmd_tags
def cmd_tags(args):
    cw = CodeWise()
    cw.feed_ctags(open(args[0]))
#@+node:ekr.20101004092958.6023: *7* main
def main():
    if len(sys.argv) < 2:
        print(USAGE)
        return
    cmd = sys.argv[1]
    #print "cmd",cmd
    args = sys.argv[2:]
    if cmd == 'tags':
        cmd_tags(args)
    elif cmd == 'm':
        cmd_members(args)
    elif cmd == 'f':
        cmd_functions(args)        
    elif cmd =='parse':
        cmd_parse(args)
    elif cmd =='parseall':
        cmd_parseall(args)
    elif cmd =='sciapi':
        cmd_scintilla(args)
    elif cmd == 'init':
        cmd_init(args)
    elif cmd == 'setup':
        cmd_setup(args)
#@+node:ekr.20101004092958.6024: *7* printlines
def printlines(lines):
    for l in lines:
        try:
            print(l)
        except Exception: # EKR: UnicodeEncodeError:            
            pass
#@+node:ekr.20101004092958.6025: *7* run_ctags
def run_ctags(paths):
    cm = 'ctags -R --sort=no -f - ' + " ".join(paths)
    print(cm)
    f = os.popen(cm)
    return f
#@+node:ekr.20101004092958.6026: *6* class CodeWise
class CodeWise:
    @others
#@+node:ekr.20101004092958.6027: *7* __init__
def __init__(self, dbpath = None):

    if dbpath is None:
        # use "current" db from env var
        dbpath = DEFAULT_DB

    print(dbpath)

    self.reset_caches()

    if not os.path.exists(dbpath):
        self.createdb(dbpath)
    else:
        self.dbconn = c = sqlite3.connect(dbpath)
        self.create_caches()
#@+node:ekr.20101004092958.6028: *7* createdb
def createdb(self, dbpath):

    self.dbconn = c = sqlite3.connect(dbpath)
    print(self.dbconn)
    c.executescript(DB_SCHEMA)
    c.commit()
    c.close()
#@+node:ekr.20101004092958.6029: *7* create_caches
def create_caches(self):
    """ read existing db and create caches """

    c = self.cursor()

    c.execute('select id, name from class')
    for idd, name in c:
        self.classcache[name] = idd

    c.execute('select id, path from file')
    for idd, name in c:
        self.filecache[name] = idd

    c.close()
    #print self.classcache
#@+node:ekr.20101004092958.6030: *7* reset_caches
def reset_caches(self):
    self.classcache = {}
    self.filecache = {}

    self.fileids_scanned = set()
#@+node:ekr.20101004092958.6031: *7* cursor
def cursor(self):
    return self.dbconn.cursor()
#@+node:ekr.20101004092958.6032: *7* class_id
def class_id(self, classname):
    """ return class id. May create new class """

    if classname is None:
        return 0

    idd = self.classcache.get(classname)
    if idd is None:
        c = self.cursor()
        c.execute('insert into class(name) values (?)' , [classname])
        c.close()
        idd = c.lastrowid
        self.classcache[classname] = idd
    return idd
#@+node:ekr.20101004092958.6033: *7* get_members
def get_members(self, classnames):

    clset = set(classnames)

    class_by_id = dict((v,k) for k,v in self.classcache.items())
    file_by_id = dict((v,k) for k,v in self.filecache.items())


    res = []
    for name, idd in self.classcache.items():
        if name in clset:
            c = self.cursor()
            #print idd
            c.execute('select name, class, file, searchpattern from function where class = (?)',(idd,))

            for name, klassid, fileid, pat in c:
                res.append((name, pat))

    return res
#@+node:ekr.20101004092958.6034: *7* get_functions
def get_functions(self, prefix = None):

    c = self.cursor()

    if prefix is not None:
        c.execute('select name, class, file, searchpattern from function where name like (?)',( prefix + '%',))
    else:
        c.execute('select name, class, file, searchpattern from function')

    return [(name, pat, klassid, fileid) for name, klassid, fileid, pat in c]
#@+node:ekr.20101004092958.6035: *7* file_id
def file_id(self, fname):
    if fname == '':
        return 0

    idd = self.filecache.get(fname)
    if idd is None:
        c = self.cursor()
        c.execute('insert into file(path) values (?)', [fname] )
        idd = c.lastrowid

        self.filecache[fname] = idd
        self.fileids_scanned.add(idd)
    else:
        if idd in self.fileids_scanned:
            return idd

        # we are rescanning a file with old entries - nuke old entries
        #print "rescan", fname
        c = self.cursor()
        c.execute("delete from function where file = (?)", (idd, ))
        #self.dbconn.commit()
        self.fileids_scanned.add(idd)

    return idd
#@+node:ekr.20101004092958.6036: *7* feed_function
def feed_function(self, func_name, class_name, file_name, aux):
    """ insert one function

    'aux' can be a search pattern (as with ctags), signature, or description.
    """
    clid = self.class_id(class_name)
    fid = self.file_id(file_name)
    c = self.cursor()
    c.execute('insert into function(class, name, searchpattern, file) values (?, ?, ?, ?)',
              [clid, func_name, aux, fid])
#@+node:ekr.20101004092958.6037: *7* feed_scintilla
def feed_scintilla(self, apifile_obj):
    """ handle scintilla api files

    Syntax is like:

    qt.QApplication.style?4() -> QStyle
    """

    for l in apifile_obj:
        if not isPython3:
            l = unicode(l, 'utf8', 'replace')
        parts = l.split('?')
        fullsym = parts[0].rsplit('.',1)
        klass, func = fullsym

        if len(parts) == 2:
            desc = parts[1]
        else:
            desc = ''

        # now our class is like qt.QApplication. We do the dirty trick and
        # remove all but actual class name

        shortclass = klass.rsplit('.',1)[-1]

        #print func, klass, desc
        self.feed_function(func.strip(), shortclass.strip(), '', desc.strip())
    self.dbconn.commit()
#@+node:ekr.20101004092958.6038: *7* feed_ctags
def feed_ctags(self,tagsfile_obj):
    for l in tagsfile_obj:
        #print l
        if not isPython3:
            l = unicode(l, 'utf8', 'replace')
        if l.startswith('!'):
            continue
        fields = l.split('\t')
        m = fields[0]
        fil = fields[1]
        pat = fields[2]
        typ = fields[3]
        klass = None
        try:
            ext = fields[4]
            if ext and ext.startswith('class:'):
                klass = ext.split(':',1)[1].strip()
                idd = self.class_id(klass)
                #print "klass",klass, idd

        except IndexError:
            ext = None
            # class id 0 = function
            idd = 0

        c = self.cursor()
        #print fields

        fid = self.file_id(fil)

        c.execute('insert into function(class, name, searchpattern, file) values (?, ?, ?, ?)',
                  [idd, m, pat, fid])

    self.dbconn.commit()
    #c.commit()
#@+node:ekr.20101004092958.6039: *7* add_source
def add_source(self, type, src):
    c = self.cursor()
    c.execute('insert into datasource(type, src) values (?,?)', (type,src))
    self.dbconn.commit()
#@+node:ekr.20101004092958.6040: *7* sources
def sources(self):
    c = self.cursor()
    c.execute('select type, src from datasource')
    return list(c)
#@+node:ekr.20101004092958.6041: *7* zap_symbols
def zap_symbols(self):
    c = self.cursor()
    tables = ['class', 'file', 'function']
    for t in tables:
        c.execute('delete from ' + t)
    self.dbconn.commit()
#@+node:ekr.20101004092958.6042: *7* parseall
# high level commands        
def parseall(self):
    sources = self.sources()
    self.reset_caches()
    self.zap_symbols()
    tagdirs = [td for typ, td in sources if typ == 'tagdir']
    self.parse(tagdirs)
    self.dbconn.commit()
#@+node:ekr.20101004092958.6043: *7* parse
def parse(self, paths):
    paths = set(os.path.abspath(p) for p in paths)
    f = run_ctags(paths)
    self.feed_ctags(f)
    sources = self.sources()
    for a in paths:
        if ('tagdir', a) not in sources:            
            self.add_source('tagdir', a)
#@+node:ekr.20101004092958.6044: *6* class ContextSniffer
class ContextSniffer:
    """ Class to analyze surrounding context and guess class

    For simple dynamic code completion engines

    """
    @others
#@+node:ekr.20101004092958.6045: *7* __init__
def __init__(self):
    # var name => list of classes
    self.vars = {}
#@+node:ekr.20101004092958.6046: *7* declare
def declare(self, var, klass):
    print("declare",var,klass)
    vars = self.vars.get(var, [])
    if not vars:
        self.vars[var] = vars
    vars.append(klass)
#@+node:ekr.20101004092958.6047: *7* push_declarations
def push_declarations(self, body):
    for l in body.splitlines():
        l = l.lstrip()
        if not l.startswith('#'):
            continue
        l = l.lstrip('#')
        parts = l.strip(':')
        if len(parts) != 2:
            continue
        self.declare(parts[0].strip(), parts[1].strip())
#@+node:ekr.20101004092958.6048: *7* set_small_context
def set_small_context(self, body):
    """ Set immediate function """
    self.push_declarations(body)
#@+node:ekr.20101004092958.6049: *5* codewise experiments
import codewise as cw
# print(dir(cw))

cw.cmd_init()
#@+node:ekr.20101004092958.6050: *5* How to make codewise work
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/ac3f8789010c882e/a1558a10eb8537c0?lnk=gst&q=codewise#a1558a10eb8537c0

1. Make sure you have exuberant ctags (not just regular ctags)
installed.  It's an Ubuntu package, so easy if you're using Ubuntu.

2. Install Ville's python module "codewise".  This is a small module on
which the Leo plugin relies.

   bzr branch lp:codewise
   cd codewise
   sudo python setup.py install

3. You need a recent trunk version of leo to get the plugin which uses
the above module.

4. Enable the plugin by putting "codewisecompleter.py" on an
uncommented line in your @enabled-plugins @settings node.

5. On the command line:

if you have an existing ~/.ctags for some reason, and it's nothing you
need to keep:

  rm ~/.ctags

then

  codewise setup
  codewise init
  codewise parse .../path/to/leo/  # assuming you want completion on
                                   # leo code
  codewise parse .../some/other/project/

Then, after restarting leo if necessary, type

c.op<Alt-0> in the body editor to find all the c. methods starting
with 'op' etc.

Nice work Ville, thanks.

==================

Thanks for this, I hope others will take a stab at it as well, given
sane instructions (I burned my free cycles frantically coding this
thing and neglected the all-important HOWTO). This is important
because functional completion is the single most important thing still
missing from Leo. Or, well, was ;-).

Especially the presentation part (QCompleter) needs some care, so you
can operate it from your keyboard alone. It should probably be moved
to core (qtgui, perhaps leoQTextEditWIdget), so codewise completer can
just invoke w.complete(list_of_completions) that will bring up the
QCompleter popup.

> Then, after restarting leo if necessary, type

> c.op<Alt-0> in the body editor to find all the c. methods starting
> with 'op' etc.

Also, try the explicit declarations:

# w : SomeClass

w.<alt+0>

And self.<alt+0> 
#@+node:ekr.20101002144536.5831: *4* Test auto scanner
import leo.core.leoKeys as leoKeys

leoKeys.AutoCompleterScanner(c).scan()
#@+node:ekr.20101002192824.5989: *4* Changed
# Search for ###
#@+node:ekr.20101002192824.5916: *5*  ctor (autocompleter)
def __init__ (self,k):

    self.c = k.c
    self.k = k
    self.calltips = {}
        # Keys are language, values are dicts:
        # keys are ids, values are signatures.
    self.language = None
    self.leadinWord = None
    self.membersList = None
    self.prefix = None
    self.prefixes = []
    self.scanned = False
    self.selection = None # The selection range on entry.
    self.selectedText = None # The selected text on entry.
    self.tabList = []
    self.tabListIndex = -1
    self.tabName = None # The name of the main completion tab.
    self.useTabs = True # True: show results in autocompleter tab.
    self.verbose = False # True: print all members.
    self.watchwords = {} # Keys are ids, values are lists of ids that can follow a id dot.
    self.widget = None # The widget that should get focus after autocomplete is done.
#@+node:ekr.20101002192824.5997: *5* calltip
def calltip (self):

    c = self.c
    w = self.widget
    word = w.getSelectedText()
    language = g.scanForAtLanguage(c,c.p)
    d = self.calltips.get(language)
    s = '()'
    if d:
        aList = d.get(word,[])
        g.trace(word,repr(aList))
        if aList:
            s = aList[0]
    s = s.replace(word,'').replace('(self,','(').replace('(self)','()').strip()

    # insert the text and set j1 and j2
    junk,j = w.getSelectionRange() # Returns insert point if no selection.
    w.insert(j,s)
    c.frame.body.onBodyChanged('Typing')
    j1,j2 = j + 1, j + len(s)

    # End autocompletion mode, putting the insertion point after the suggested calltip.
    self.finish()
    c.widgetWantsFocusNow(w)
    w.setSelectionRange(j1,j2,insert=j2)
#@+node:ekr.20101002192824.5988: *5* chain
def chain (self):

    c = self.c ; w = self.widget
    word = w.getSelectedText()
    i,j = w.getSelectionRange()
    w.insert(j,'.')
    w.setInsertPoint(j+1)
    self.finish()
    self.start(chain=True)
#@+node:ekr.20101002192824.5941: *5* doBackSpace (autocompleter)
def doBackSpace (self):

    '''Cut back to previous prefix.'''

    s = self.prefixes and self.prefixes.pop() or ''
    self.setSelection(s)
    self.computeCompletionList()
#@+node:ekr.20101002192824.5948: *5* getLeadinWord & helper
def getLeadinWord (self,w):

    i,word = self.findAnchor(w)

    if word and not word.isdigit():
        self.setMembersList(word)
        self.beginTabName(word)
        self.leadinWord = word
        return True
    else:
        self.membersList = []
        self.leadinWord = None
        return False
#@+node:ekr.20101002192824.5945: *6* findAnchor
def findAnchor (self,w):

    '''
    Scan backward for the word before the last period.
    Returns (j,word) where j is a Python index.'''

    i = j = w.getInsertPoint()
    s = w.getAllText()

    # Scan backward for the next '.'
    while i > 1 and s[i-1] != '.':
        # g.trace(i-1,s[i-1])
        i -= 1

    if i <= 0 or s[i-1] != '.':
        return 0,''

    i,j = g.getWord(s,i-2)
    word = s[i:j]
    if word == '.':
        # g.trace('word is dot')
        return 0,''
    else:
        # g.trace(i,j,repr(word))
        return j,word
#@+node:ekr.20101002192824.5951: *5* insertNormalChar
def insertNormalChar (self,ch,keysym):

    k = self.k ; w = self.widget

    g.trace(ch,self.prefix)

    if g.isWordChar(ch):
        # Look ahead to see if the character completes any item.
        s = w.getSelectedText() + ch
        tabList,common_prefix = g.itemsMatchingPrefixInList(
            s,self.membersList,matchEmptyPrefix=True)
        #g.trace('tabList',repr(tabList))
        #g.trace('common_prefix',repr(common_prefix))
        if tabList:
            # Add the character.
            self.tabList = tabList
            self.extendSelection(ch)
            s = w.getSelectedText()
            if s.startswith(self.prefix):
                self.prefix = self.prefix + ch
            self.computeCompletionList()
    elif ch == '(':
        self.calltip()
    else:
        self.extendSelection(ch)
        self.finish()
#@+node:ekr.20101002192824.5953: *5* setMembersList & helpers
def setMembersList (self,word):

    self.membersList = self.watchwords.get(word)
    self.membersList.sort()

    # g.trace(word,self.membersList)
#@+node:ekr.20101002192824.5954: *6* getObjectFromAttribute
def getObjectFromAttribute (self,word):

    obj = self.theObject

    if obj and self.hasAttr(obj,word):
        self.push(self.theObject)
        self.theObject = self.getAttr(obj,word)
        self.appendToKnownObjects(self.theObject)
        self.membersList = self.getMembersList(self.theObject)
    else:
        # No special support for 'self' here.
        # Don't clear the stack here!
        self.membersList = []
        self.theObject = None
#@+node:ekr.20101002192824.5956: *6* completeFromObject
def completeFromObject (self,obj):

    if obj:
        self.appendToKnownObjects(obj)
        self.push(self.theObject)
        self.theObject = obj
        self.membersList = self.getMembersList(obj=obj)
    else:
        self.theObject = None
        self.clear()
        self.membersList = []
#@+node:ekr.20101002192824.5925: *5* showCalltips (TO DO)
def showCalltips (self,event=None,force=False):

    '''Show the calltips at the cursor.'''

    c = self.c ; k = c.k ; w = g.app.gui.eventWidget(event)
    if not w: return

    # Insert the calltip if possible, but not in headlines.
    if (k.enable_calltips or force) and not c.widget_name(w).startswith('head'):
        self.widget = w
        self.prefix = ''
        self.selection = w.getSelectionRange()
        self.selectedText = w.getSelectedText()
        self.leadinWord = self.findCalltipWord(w)
        self.calltip()
    else:
        # Just insert the invocation character as usual.
        k.masterCommand(event,func=None,stroke=None,commandName=None)

    return 'break'
#@+node:ekr.20101002192824.5958: *5* start
def start (self,event=None,w=None,prefix=None,chain=False):

    c = self.c
    if w: self.widget = w
    else: w = self.widget

    # We wait until now to define these dicts so that more classes and objects will exist.
    if not self.scanned:
        self.scanned = True
        # scanner = leoKeys.AutoCompleterScanner(c)
        scanner = AutoCompleterScanner(c)
        scanner.scan()
        self.calltips = scanner.calltips
        self.watchwords = scanner.watchwords

    self.selection = w.getSelectionRange()
    self.prefix = prefix or w.getSelectedText()
    if chain:
        if self.prefix not in self.prefixes:
            self.prefixes.append(self.prefix)
    else:
        self.prefixes = [self.prefix]
    self.selectedText = w.getSelectedText()
    flag = self.getLeadinWord(w)
    # g.trace(flag,self.membersList)
    if self.membersList:
        if not flag:
            # Remove the (leading) invocation character.
            i = w.getInsertPoint()
            s = w.getAllText()
            if i > 0 and s[i-1] == '.':
                s = g.app.gui.stringDelete(s,i-1)
                w.setAllText(s)
                c.frame.body.onBodyChanged('Typing')
        if self.useTabs:
            self.autoCompleterStateHandler(event)
        else:
            self.computeCompletionList()
            return self.tabList
    else:
        self.abort()
#@+node:ekr.20101002192824.5843: *4* test-new-ac
# To do:
# - Fix findAnchor.
# - Report duck type in completion tab: callable if calltips exist.
# - What to do about library files and imports?

import re
import string
import sys
import time

@others

ac = NewAutoCompleter(c.k)
w = c.frame.body.bodyCtrl
event = g.bunch(char='e',keysym='e')
n = len(p.b)
if 0:
    w.setSelectionRange(n-7,n)
else:
    w.setInsertPoint(n)

ac.start(event=event,w=w)

# The cursor must be at the end
# p.s
#@+node:ekr.20101002192824.6019: *5* class AutoCompleterScanner
class AutoCompleterScanner:

    '''A class that scans for autocompleter completions.'''

    @others
#@+node:ekr.20101002192824.6020: *6*  ctor & helper (AutoCompleterScanner)
def __init__ (self,c):

    self.c = c

    # Set by definePatterns...
    self.okchars = None
    self.pats = {}

    # Set by scanners...
    self.calltips = {}
    self.watchwords = {}

    self.definePatterns()
#@+node:ekr.20101002192824.6021: *7* definePatterns
def definePatterns (self):

    self.space = r'[ \t\r\f\v ]+' # one or more whitespace characters.
    self.end = r'\w+\s*\([^)]*\)' # word (\w) ws ( any ) (can cross lines)

    # Define re patterns for various languages.
    # These patterns match method/function definitions.
    self.pats = {}
    self.pats ['python'] = re.compile(r'def\s+%s' % self.end)
        # def ws word ( any ) # Can cross line boundaries.
    self.pats ['java'] = re.compile(
        r'((public\s+|private\s+|protected\s+)?(static%s|\w+%s){1,2}%s)' % (
            self.space,self.space,self.end))
    self.pats ['perl'] = re.compile(r'sub\s+%s' % self.end)
    self.pats ['c++'] = re.compile(r'((virtual\s+)?\w+%s%s)' % (self.space,self.end))
    self.pats ['c'] = re.compile(r'\w+%s%s' % (self.space,self.end))

    # Define self.okchars.
    okchars = {}
    for z in string.ascii_letters:
        okchars [z] = z
    okchars ['_'] = '_'
    self.okchars = okchars 
#@+node:ekr.20101002192824.6022: *6* scan & dumps
def scan (self):

    '''Build the database from the outline'''

    trace = True and not g.unitTesting
    verbose = False
    if trace: t1 = time.time()
    c = self.c
    for p in c.all_unique_positions():
        self.scanForAutoCompleter(p.b)

    p = c.rootPosition()
    seen = {}
    while p:
        key = p.key()
        if not key in seen:
            seen[key] = True
            if p.isAnyAtFileNode():
                # scanForAtLanguage is expensive!
                language = g.scanForAtLanguage(c,p)
                for p2 in p.self_and_subtree():
                    seen[p2.key()] = True
                    self.scanForCallTip(p2.b,language)
        p.moveToThreadNext()

    if trace:
        t2 = time.time()
        if verbose:
            self.dumpTips()
            self.dumpWords()
        self.printSummary(t2-t1)

#@+node:ekr.20101002192824.6023: *7* dumpTips
def dumpTips (self):

    print('calltips...\n\n')
    for key in sorted(self.calltips):
        d = self.calltips.get(key)
        if d:
            if 1:
                d2 = {}
                for key2 in list(d.keys()):
                    aList = d.get(key2)
                    if len(aList) == 1:
                        s = aList[0]
                        if s.startswith(key2):
                            s = s[len(key2):].strip()
                        d2[key2] = s
                    else:
                        aList2 = []
                        for s in aList:
                            if s.startswith(key2):
                                s = s[len(key2):].strip()
                            aList2.append(s)
                        d2[key2] = aList2
                print('\n%s:\n\n' % (key),g.dictToString(d2))
            else:
                print('\n%s:\n\n' % (key),g.dictToString(d))
#@+node:ekr.20101002192824.6024: *7* dumpWords
def dumpWords (self):

    print('autocompleter words...\n\n')
    show = ['aList','c','d','f','g','gui','k','m','p','s','t','v','w']
    keys = show or sorted(self.watchwords)
    for key in keys:
        aList = self.watchwords.get(key)
        aList.sort()
        print('\n%s:' % (key),g.listToString(aList)) #repr(aList))
    print()
#@+node:ekr.20101002192824.6025: *7* printSummary
def printSummary (self,t):

    n  = len(list(self.watchwords.keys()))

    n2 = 0
    for language in list(self.calltips.keys()):
        d = self.calltips.get(language)
        n2 += len(list(d.keys()))

    g.es_print('scanned %s words, %s tips in %3.2fs sec.' % (
        n,n2,t))
#@+node:ekr.20101002192824.6026: *6* scanForAutoCompleter & helper
def scanForAutoCompleter (self,s):

    '''This function scans text for the autocompleter database.'''

    aList = []
    strings = s.split('.')
    if not strings: return

    for i in range(len(strings)-1):
        self.makeAutocompletionList(strings[i],strings[i+1],aList)

    if aList:
        for key,val in aList:
            aList2 = self.watchwords.get(key,[])
            # val = str(val)
            if val not in aList2:
                aList2.append(val)
                self.watchwords [key] = aList2
#@+node:ekr.20101002192824.6027: *7* makeAutocompletionList
def makeAutocompletionList (self,a,b,glist):

    '''We have seen a.b, where a and b are arbitrary strings.
    Append (a1.b1) to glist.
    To compute a1, scan backwards in a until finding whitespace.
    To compute b1, scan forwards in b until finding a char not in okchars.
    '''

    # Compute reverseFindWhitespace inline.
    i = len(a) -1
    while i >= 0:
        # if a[i].isspace() or a [i] == '.':
        if a[i] not in self.okchars:
            a1 = a [i+1:] ; break
        i -= 1
    else:
        a1 = a

    # Compute getCleanString inline.
    i = 0
    for ch in b:
        if ch not in self.okchars:
            b1 = b[:i] ; break
        i += 1
    else:
        b1 = b

    if b1:
        glist.append((a1,b1),)
#@+node:ekr.20101002192824.6028: *6* scanForCallTip & helper
def scanForCallTip (self,s,language):

    '''this function scans text for calltip info'''

    d = self.calltips.get(language,{})
    pat = self.pats.get(language or 'python')

    # Set results to a list of all the function/method defintions in s.
    results = pat and pat.findall(s) or []

    for z in results:
        if isinstance(z,tuple): z = z [0]
        if language == 'python':
            z = self.cleanPythonTip(z)
        pieces2 = z.split('(')
        # g.trace(pieces2)
        pieces2 [0] = pieces2 [0].split() [-1]
        a, junk = pieces2 [0], pieces2 [1]
        aList = d.get(a,[])
        if z not in aList:
            aList.append(z)
            d [a] = aList

    self.calltips [language] = d
#@+node:ekr.20101002192824.6029: *7* cleanPythonTip
def cleanPythonTip (self,s):

    result = []
    i = g.skip_ws(s,3)
    while i < len(s):
        ch = s[i]
        if ch in ' \t\n':
            i += 1
        elif ch == '#':
            # Remove comment.
            i += 1
            while i < len(s):
                i += 1
                if s[i-1] == '\n': break
        else:
            result.append(ch)
            i += 1
    return ''.join(result)
#@+node:ekr.20101002192824.5915: *5* class NewAutoCompleter (New)
class NewAutoCompleter:

    '''A class that inserts autocompleted and calltip text in text widgets.
    This class shows alternatives in the tabbed log pane.

    The keyHandler class contains hooks to support these characters:
    invoke-autocompleter-character (default binding is '.')
    invoke-calltips-character (default binding is '(')
    '''

    @others
#@+node:ekr.20101002192824.5916: *6*  ctor (autocompleter)
def __init__ (self,k):

    self.c = k.c
    self.k = k
    self.calltips = {}
        # Keys are language, values are dicts:
        # keys are ids, values are signatures.
    self.language = None
    self.leadinWord = None
    self.membersList = None
    self.prefix = None
    self.prefixes = []
    self.scanned = False
    self.selection = None # The selection range on entry.
    self.selectedText = None # The selected text on entry.
    self.tabList = []
    self.tabListIndex = -1
    self.tabName = None # The name of the main completion tab.
    self.useTabs = True # True: show results in autocompleter tab.
    self.verbose = False # True: print all members.
    self.watchwords = {} # Keys are ids, values are lists of ids that can follow a id dot.
    self.widget = None # The widget that should get focus after autocomplete is done.
#@+node:ekr.20101002192824.5919: *6* Top level
#@+node:ekr.20101002192824.5920: *7* autoComplete
def autoComplete (self,event=None,force=False):

    '''An event handler called from k.masterKeyHanderlerHelper.'''

    g.trace()

    c = self.c ; k = self.k ; gui = g.app.gui
    w = gui.eventWidget(event) or c.get_focus()

    # First, handle the invocation character as usual.
    k.masterCommand(event,func=None,stroke=None,commandName=None)

    # Allow autocompletion only in the body pane.
    if not c.widget_name(w).lower().startswith('body'):
        return 'break'

    self.language = g.scanForAtLanguage(c,c.p)
    if w and self.language == 'python' and (k.enable_autocompleter or force):
        self.start(event=event,w=w)

    return 'break'
#@+node:ekr.20101002192824.5921: *7* autoCompleteForce
def autoCompleteForce (self,event=None):

    '''Show autocompletion, even if autocompletion is not presently enabled.'''

    return self.autoComplete(event,force=True)
#@+node:ekr.20101002192824.5922: *7* autoCompleterStateHandler
def autoCompleterStateHandler (self,event):

    trace = False and not g.app.unitTesting
    c = self.c ; k = self.k ; gui = g.app.gui
    tag = 'auto-complete' ; state = k.getState(tag)
    ch = gui.eventChar(event)
    keysym = gui.eventKeysym(event)

    if trace: g.trace(repr(ch),repr(keysym),state)

    if state == 0:
        c.frame.log.clearTab(self.tabName)
        self.computeCompletionList()
        k.setState(tag,1,handler=self.autoCompleterStateHandler) 
    elif keysym in (' ','Return'):
        self.finish()
    elif keysym == 'Escape':
        self.abort()
    elif keysym == 'Tab':
        self.doTabCompletion()
    elif keysym in ('\b','BackSpace'): # Horrible hack for qt plugin.
        self.doBackSpace()
    elif keysym == '.':
        self.chain()
    ###elif keysym == '?':
    ###    self.info()
    elif keysym == '!':
        # Toggle between verbose and brief listing.
        self.verbose = not self.verbose
        self.computeCompletionList(verbose=self.verbose)
    elif ch and ch in string.printable:
        self.insertNormalChar(ch,keysym)
    else:
        # if trace: g.trace('ignore',repr(ch))
        return 'do-standard-keys'
#@+node:ekr.20101002192824.5924: *7* enable/disable/toggleAutocompleter/Calltips
def disableAutocompleter (self,event=None):
    '''Disable the autocompleter.'''
    self.k.enable_autocompleter = False
    self.showAutocompleterStatus()

def disableCalltips (self,event=None):
    '''Disable calltips.'''
    self.k.enable_calltips = False
    self.showCalltipsStatus()

def enableAutocompleter (self,event=None):
    '''Enable the autocompleter.'''
    self.k.enable_autocompleter = True
    self.showAutocompleterStatus()

def enableCalltips (self,event=None):
    '''Enable calltips.'''
    self.k.enable_calltips = True
    self.showCalltipsStatus()

def toggleAutocompleter (self,event=None):
    '''Toggle whether the autocompleter is enabled.'''
    self.k.enable_autocompleter = not self.k.enable_autocompleter
    self.showAutocompleterStatus()

def toggleCalltips (self,event=None):
    '''Toggle whether calltips are enabled.'''
    self.k.enable_calltips = not self.k.enable_calltips
    self.showCalltipsStatus()
#@+node:ekr.20101002192824.5925: *7* showCalltips (TO DO)
def showCalltips (self,event=None,force=False):

    '''Show the calltips at the cursor.'''

    c = self.c ; k = c.k ; w = g.app.gui.eventWidget(event)
    if not w: return

    # Insert the calltip if possible, but not in headlines.
    if (k.enable_calltips or force) and not c.widget_name(w).startswith('head'):
        self.widget = w
        self.prefix = ''
        self.selection = w.getSelectionRange()
        self.selectedText = w.getSelectedText()
        self.leadinWord = self.findCalltipWord(w)
        self.calltip()
    else:
        # Just insert the invocation character as usual.
        k.masterCommand(event,func=None,stroke=None,commandName=None)

    return 'break'
#@+node:ekr.20101002192824.5926: *7* showCalltipsForce
def showCalltipsForce (self,event=None):

    '''Show the calltips at the cursor, even if calltips are not presently enabled.'''

    return self.showCalltips(event,force=True)
#@+node:ekr.20101002192824.5927: *7* showAutocompleter/CalltipsStatus
def showAutocompleterStatus (self):
    '''Show the autocompleter status on the status line.'''

    k = self.k
    if not g.unitTesting:
        s = 'autocompleter %s' % g.choose(k.enable_autocompleter,'On','Off')
        g.es(s,color='red')

def showCalltipsStatus (self):
    '''Show the autocompleter status on the status line.'''
    k = self.k
    if not g.unitTesting:
        s = 'calltips %s' % g.choose(k.enable_calltips,'On','Off')
        g.es(s,color='red')
#@+node:ekr.20101002192824.5928: *6* Helpers
#@+node:ekr.20101002192824.5929: *7* .abort & exit (autocompleter)
def abort (self):

    k = self.k
    k.keyboardQuit(event=None,setDefaultStatus=False)
        # Stay in the present input state.
    self.exit(restore=True)

def exit (self,restore=False): # Called from keyboard-quit.

    k = self ; c = self.c 
    w = self.widget or c.frame.body.bodyCtrl
    for name in (self.tabName,'Modules','Info'):
        c.frame.log.deleteTab(name)
    c.widgetWantsFocusNow(w)
    i,j = w.getSelectionRange()
    if restore:
        if i != j: w.delete(i,j)
        w.insert(i,self.selectedText)
    w.setSelectionRange(j,j,insert=j)

    ### self.clear()
    ### self.theObject = None
#@+node:ekr.20101002192824.5930: *7* append/begin/popTabName
def appendTabName (self,word):

    self.setTabName(self.tabName + word + '.')

def beginTabName (self,word):

    # g.trace(word,g.callers())
    ### if word == 'self' and self.selfClassName:
    ###    word = '%s (%s)' % (word,self.selfClassName)
    self.setTabName('AutoComplete ' + word + '.')

def clearTabName (self):

    self.setTabName('AutoComplete ')

def popTabName (self):

    s = self.tabName
    i = s.rfind('.',0,-1)
    if i > -1:
        self.setTabName(s[0:i])

# Underscores are not valid in Pmw tab names!
def setTabName (self,s):

    c = self.c
    if self.useTabs:
        if self.tabName:
            c.frame.log.deleteTab(self.tabName)
        self.tabName = s.replace('_','') or ''
        c.frame.log.clearTab(self.tabName)
#@+node:ekr.20101002192824.5931: *7* appendToKnownObjects
def appendToKnownObjects (self,obj):

    if 0:
        if type(obj) in (types.InstanceType,types.ModuleType,types):
            if hasattr(obj,'__name__'):
                self.knownObjects[obj.__name__] = obj
                # g.trace('adding',obj.__name__)
#@+node:ekr.20101002192824.5997: *7* calltip
def calltip (self):

    c = self.c
    w = self.widget
    word = w.getSelectedText()
    language = g.scanForAtLanguage(c,c.p)
    d = self.calltips.get(language)
    s = '()'
    if d:
        aList = d.get(word,[])
        g.trace(word,repr(aList))
        if aList:
            s = aList[0]
    s = s.replace(word,'').replace('(self,','(').replace('(self)','()').strip()

    # insert the text and set j1 and j2
    junk,j = w.getSelectionRange() # Returns insert point if no selection.
    w.insert(j,s)
    c.frame.body.onBodyChanged('Typing')
    j1,j2 = j + 1, j + len(s)

    # End autocompletion mode, putting the insertion point after the suggested calltip.
    self.finish()
    c.widgetWantsFocusNow(w)
    w.setSelectionRange(j1,j2,insert=j2)
#@+node:ekr.20101002192824.5988: *7* chain
def chain (self):

    c = self.c ; w = self.widget
    word = w.getSelectedText()
    i,j = w.getSelectionRange()
    w.insert(j,'.')
    w.setInsertPoint(j+1)
    self.finish()
    self.start(chain=True)
#@+node:ekr.20101002192824.5940: *7* computeCompletionList
def computeCompletionList (self,verbose=False):

    c = self.c ; w = self.widget
    c.widgetWantsFocus(w)
    s = w.getSelectedText()
    self.tabList,common_prefix = g.itemsMatchingPrefixInList(
        s,self.membersList,matchEmptyPrefix=True)

    if not common_prefix:
        if verbose or len(self.tabList) < 25 or not self.useTabs:
            self.tabList,common_prefix = g.itemsMatchingPrefixInList(
                s,self.membersList,matchEmptyPrefix=True)
        else: # Show the possible starting letters.
            d = {}
            for z in self.tabList:
                ch = z and z[0] or ''
                if ch:
                    n = d.get(ch,0)
                    d[ch] = n + 1
            aList = [ch+'...%d' % (d.get(ch)) for ch in sorted(d)]
            self.tabList = aList

    if self.useTabs:
        c.frame.log.clearTab(self.tabName) # Creates the tab if necessary.
        if self.tabList:
            self.tabListIndex = -1 # The next item will be item 0.
            self.setSelection(common_prefix)
        g.es('','\n'.join(self.tabList),tabName=self.tabName)
#@+node:ekr.20101002192824.5941: *7* doBackSpace (autocompleter)
def doBackSpace (self):

    '''Cut back to previous prefix.'''

    s = self.prefixes and self.prefixes.pop() or ''
    self.setSelection(s)
    self.computeCompletionList()
#@+node:ekr.20101002192824.5942: *7* doTabCompletion (autocompleter)
def doTabCompletion (self):

    '''Handle tab completion when the user hits a tab.'''

    c = self.c ; w = self.widget
    s = w.getSelectedText()

    if s.startswith(self.prefix) and self.tabList:
        # g.trace('cycle','prefix',repr(self.prefix),len(self.tabList),repr(s))
        # Set the label to the next item on the tab list.
        self.tabListIndex +=1
        if self.tabListIndex >= len(self.tabList):
           self.tabListIndex = 0
        self.setSelection(self.tabList[self.tabListIndex])
    else:
        self.computeCompletionList()

    c.widgetWantsFocusNow(w)
#@+node:ekr.20101002192824.5943: *7* extendSelection
def extendSelection (self,s):

    '''Append s to the presently selected text.'''

    c = self.c ; w = self.widget
    c.widgetWantsFocusNow(w)

    i,j = w.getSelectionRange()
    w.insert(j,s)
    j += 1
    w.setSelectionRange(i,j,insert=j)
    c.frame.body.onBodyChanged('Typing')
#@+node:ekr.20101002192824.5944: *7* findCalltipWord
def findCalltipWord (self,w):

    i = w.getInsertPoint()
    s = w.getAllText()
    if i > 0:
        i,j = g.getWord(s,i-1)
        word = s[i:j]
        return word
    else:
        return ''
#@+node:ekr.20101002192824.5946: *7* finish
def finish (self):

    c = self.c ; k = c.k

    k.keyboardQuit(event=None,setDefaultStatus=False)
        # Stay in the present input state.

    for name in (self.tabName,'Modules','Info'):
        c.frame.log.deleteTab(name)

    c.frame.body.onBodyChanged('Typing')
    c.recolor()
    ### self.clear()
    ### self.theObject = None
#@+node:ekr.20101002192824.5948: *7* getLeadinWord & helper
def getLeadinWord (self,w):

    i,word = self.findAnchor(w)

    if word and not word.isdigit():
        self.setMembersList(word)
        self.beginTabName(word)
        self.leadinWord = word
        return True
    else:
        self.membersList = []
        self.leadinWord = None
        return False
#@+node:ekr.20101002192824.5945: *8* findAnchor
def findAnchor (self,w):

    '''
    Scan backward for the word before the last period.
    Returns (j,word) where j is a Python index.'''

    i = j = w.getInsertPoint()
    s = w.getAllText()

    # Scan backward for the next '.'
    while i > 1 and s[i-1] != '.':
        # g.trace(i-1,s[i-1])
        i -= 1

    if i <= 0 or s[i-1] != '.':
        return 0,''

    i,j = g.getWord(s,i-2)
    word = s[i:j]
    if word == '.':
        # g.trace('word is dot')
        return 0,''
    else:
        # g.trace(i,j,repr(word))
        return j,word
#@+node:ekr.20101002192824.5949: *7* getMembersList
def getMembersList (self,obj):

    '''Return a list of possible autocompletions for self.leadinWord.'''

    if obj:
        aList = inspect.getmembers(obj)
        members = ['%s:%s' % (a,g.prettyPrintType(b))
            for a,b in aList if not a.startswith('__')]
        members.sort()
        return members
    else:
        return []
#@+node:ekr.20101002192824.6005: *7* info (rewrite)
def info (self):

    c = self.c ; doc = None ; obj = self.theObject ; w = self.widget

    word = w.getSelectedText()

    if not word:
        # Never gets called, but __builtin__.f will work.
        word = self.findCalltipWord(w)
        if word:
            # Try to get the docstring for the Python global.
            f = __builtins__.get(self.leadinWord)
            doc = f and f.__doc__

    if not doc:
        if not self.hasAttr(obj,word):
            g.es('no docstring for',word,color='blue')
            return
        obj = self.getAttr(obj,word)
        doc = inspect.getdoc(obj)

    if doc:
        c.frame.log.clearTab('Info',wrap='word')
        g.es('',doc,tabName='Info')
    else:
        g.es('no docstring for',word,color='blue')
#@+node:ekr.20101002192824.5951: *7* insertNormalChar
def insertNormalChar (self,ch,keysym):

    k = self.k ; w = self.widget

    g.trace(ch,self.prefix)

    if g.isWordChar(ch):
        # Look ahead to see if the character completes any item.
        s = w.getSelectedText() + ch
        tabList,common_prefix = g.itemsMatchingPrefixInList(
            s,self.membersList,matchEmptyPrefix=True)
        #g.trace('tabList',repr(tabList))
        #g.trace('common_prefix',repr(common_prefix))
        if tabList:
            # Add the character.
            self.tabList = tabList
            self.extendSelection(ch)
            s = w.getSelectedText()
            if s.startswith(self.prefix):
                self.prefix = self.prefix + ch
            self.computeCompletionList()
    elif ch == '(':
        self.calltip()
    else:
        self.extendSelection(ch)
        self.finish()
#@+node:ekr.20101002192824.5952: *7* push, pop, clear, stackNames (To be deleted)
if 0:
    def push (self,obj):
        if obj is not None:
            self.prevObjects.append(obj)

    def pop (self):
        obj = self.prevObjects.pop()
        return obj

    def clear (self):
        self.prevObjects = []

    def stackNames (self):
        aList = []
        for z in self.prevObjects:
            if hasattr(z,'__name__'):
                aList.append(z.__name__)
            elif hasattr(z,'__class__'):
                aList.append(z.__class__.__name__)
            else:
                aList.append(str(z))
        return aList
#@+node:ekr.20101002192824.5953: *7* setMembersList & helpers
def setMembersList (self,word):

    self.membersList = self.watchwords.get(word)
    self.membersList.sort()

    # g.trace(word,self.membersList)
#@+node:ekr.20101002192824.5954: *8* getObjectFromAttribute
def getObjectFromAttribute (self,word):

    obj = self.theObject

    if obj and self.hasAttr(obj,word):
        self.push(self.theObject)
        self.theObject = self.getAttr(obj,word)
        self.appendToKnownObjects(self.theObject)
        self.membersList = self.getMembersList(self.theObject)
    else:
        # No special support for 'self' here.
        # Don't clear the stack here!
        self.membersList = []
        self.theObject = None
#@+node:ekr.20101002192824.5956: *8* completeFromObject
def completeFromObject (self,obj):

    if obj:
        self.appendToKnownObjects(obj)
        self.push(self.theObject)
        self.theObject = obj
        self.membersList = self.getMembersList(obj=obj)
    else:
        self.theObject = None
        self.clear()
        self.membersList = []
#@+node:ekr.20101002192824.5957: *7* setSelection
def setSelection (self,s):

    g.trace(s,g.callers(2))

    c = self.c ; w = self.widget
    c.widgetWantsFocusNow(w)

    if w.hasSelection():
        i,j = w.getSelectionRange()
        w.delete(i,j)
    else:
        i = w.getInsertPoint()

    # Don't go past the ':' that separates the completion from the type.
    n = s.find(':')
    if n > -1: s = s[:n]

    w.insert(i,s)
    j = i + len(s)
    w.setSelectionRange(i,j,insert=j)

    # New in Leo 4.4.2: recolor immediately to preserve the new selection in the new colorizer.
    c.frame.body.recolor(c.p,incremental=True)
    # Usually this call will have no effect because the body text has not changed.
    c.frame.body.onBodyChanged('Typing')
#@+node:ekr.20101002192824.5958: *7* start
def start (self,event=None,w=None,prefix=None,chain=False):

    c = self.c
    if w: self.widget = w
    else: w = self.widget

    # We wait until now to define these dicts so that more classes and objects will exist.
    if not self.scanned:
        self.scanned = True
        # scanner = leoKeys.AutoCompleterScanner(c)
        scanner = AutoCompleterScanner(c)
        scanner.scan()
        self.calltips = scanner.calltips
        self.watchwords = scanner.watchwords

    self.selection = w.getSelectionRange()
    self.prefix = prefix or w.getSelectedText()
    if chain:
        if self.prefix not in self.prefixes:
            self.prefixes.append(self.prefix)
    else:
        self.prefixes = [self.prefix]
    self.selectedText = w.getSelectedText()
    flag = self.getLeadinWord(w)
    # g.trace(flag,self.membersList)
    if self.membersList:
        if not flag:
            # Remove the (leading) invocation character.
            i = w.getInsertPoint()
            s = w.getAllText()
            if i > 0 and s[i-1] == '.':
                s = g.app.gui.stringDelete(s,i-1)
                w.setAllText(s)
                c.frame.body.onBodyChanged('Typing')
        if self.useTabs:
            self.autoCompleterStateHandler(event)
        else:
            self.computeCompletionList()
            return self.tabList
    else:
        self.abort()
#@+node:ekr.20080603052650.466: ** 4.9 Vim stuff
@nocolor

4.8 vim, cleanups, your mission...

http://groups.google.com/group/leo-editor/browse_thread/thread/141690c553bfde55

Vim mode users: your top 3 complaints, please
#@+node:ekr.20100828074347.5827: *3* Vim bindings
#@+node:ekr.20100521090440.5887: *4* Generalize minibuffer code
Just playing with part of a template system, the (partial) mock up for
"range()" is:

def tabStopNaming (event=None):

  stateName = 'naming'
  k = c.k
  state = k.getState(stateName)

  help = ('start-value -- optional, -> fill-in or tab eliminate.  ',
           'end-value -- required, -> fill-in.  ',
           'step -- optional, ->fill-in or tab to eliminate.  ')
  tabStop = ('start-value', 'end-value', 'step')

  if state == 0:
      k.setLabelBlue(help[0],protect=True)
      k.getArg(event,stateName,1,tabStopNaming)
      # g.es('does this ever executed?') # yes, imediately!
  else:
      k.clearState()
      g.es_print('%s : %s' % (tabStop[0], k.arg))
      k.setLabelBlue('')

tabStopNaming()

=====================================================
This is hardwired for the first parameter.  Things I need to expand
this:

1. put in a variable that cycles through the tabStops

2. In this mock up, you are entering the parameters in the minibuffer,
a more advanced version would collect each keypress and put it in the
body at the current tabStop, a tab would finalize the entry and
advance to the next stop, no text other than the 'help', ends up in
the minibuffer.

Sinc I'm only modifying existing code without real understanding of
what Leo is doing, andy guidance would be appreciated.

Tom

=======================

Thanks for this work.  You obviously understand the present code well
enough to play with it.

Generalizing the minibuffer code would be a good thing to do.  I
suppose we could define some kind of language that would create, or
rather simulate, hand-written code.  In a sense, @mode nodes are
intended to do this also.

As I look at leoKeys.py again I'll keep this example in the back of my
mind as something that it would be good to support more easily.

Edward
#@+node:ekr.20100210102224.5744: *4* Notes for key bindings
@nocolor-node

Requirements:
    - Existing bindings must still be valid.
    - But @mode does not have to remain.

Think data:
    - Drive binding by tables.
    *** Design these tables first.
    - Table design should be flixible.
      It can change without affecting user.

keySequence class?
    - Represents a sequence of keystrokes.

bufferMode class?
    - Might encapsulate directives, etc.

bindHelper class?
    - Would mediate various aspects of binding.
    - c.bindHelper or k.bindHelper?
#@+node:ekr.20060927173836.6: *4* Don't abort mode if there are problems with bindings
# Or give a better message.
#@+node:ekr.20100113075303.6270: *4* Easiest vim problems
#@+node:ekr.20100112051224.6229: *5* (vim) Binding Arrow keys (fixed?)
Binding arrow keys, with or without Shift, Ctrl, Alt, and their combinations, to
commands or @mode nodes have no effect.
#@+node:ekr.20100112051224.6239: *5* Displaying mode help
@nocolor-node

The "--> mode-help" command has the following issues related to the
display of the "Help" tab:

1. Key label always capitalized.

Vim commands are mapped to both lower-case and upper-case keys but always appear
mapped to upper-case keys within the "Help" tab.

2. Layout of tab's contents.

To improve readability and better support narrow tab cards, display the mode's
label without the "enter-" and "-mode" text and place the key label before the
mode label.

For example, the following entries would change from::
    enter-vi-delete-line-mode d
    enter-vi-delete-to-begin-of-word-mode b
to::
    d : vi-delete-line
    b : vi-delete-to-begin-of-word
#@+node:ekr.20100112051224.6225: *5* Repeat last cursor movement command
Support the ';' key: repeat the last "To character" or "Find character" command.
#@+node:ekr.20090629183608.8445: *5* Cursors (easiest)
Vi normally uses two different "current character" designators depending on the
current state.

Insert state:

In the Insert state, a vertical bar is placed between two characters to indicate
where the next key will be inserted. Leo's cursor is of this type.

Command state: 

In the Command state, vi expects that the cursor is highlighting a current
character and provides commands to enter the insert state or paste text either
before or after that current character. Leo's vi emulation currently does not
support a "current character" cursor. As a result, inserting and pasting before
or after is replaced by inserting or pasting "at" the current cursor location.
For example, the 'i' and 'a' command are both mapped to enter the insert state
at the current cursor location.
#@+node:ekr.20100112051224.6231: *5* Undo command (fixed?)
Using the "undo" command (key 'u') to undo a change to a node's headline text
only works correctly after another node has been selected. It appears that
changes made to a node's headline text are not recorded in Leo's change history
until the edited node has lost focus.
#@+node:ekr.20100113075303.6271: *4* Mode-oriented bindings
#@+node:ekr.20100112051224.6228: *5* Binding numeric keys (modes-oriented bindings)
Mapping a number to a command or an @mode node works but can not be used as it
prevents the number from being entered as text while in Vi's insert state.
#@+node:ekr.20100112051224.6230: *5* Binding 'bksp' key (mode-oriented bindings)
Binding 'bksp' key to back-char to move back a character in command mode
prevents 'bksp' from deleting characters in text edit mode.
#@+node:ekr.20080616110054.2: *4* Support vim dot command
The ability to repeat the last editing related command by pressing the period
key is not supported and there is no workaround in place.

Binding keys within nodes:

Some commands can be "easily" repeated by having the command's mode
bind itself to the period key.  This is not currently working.

Support commands requesting input:

Add companion commands that reuse input.  For example, a zap-to-
character-again command could exist which will reuse the key entered
in the last zap-to-character command.  With this support, the mode
that performs the initial command would assign the period key to a
companion mode that is identical to the initial mode but with the zap-
to-character command replaced by the zap-to-character-again command.

Commands requiring companion commands are:
  zap-to-character
  find-character
  backward-find-character
  (Any others?)

Notes:

- The copy of the character should be saved somewhere that does NOT affect the
  contents of the clipboard.

- The same or a separate storage location can be used for all commands to retain
  a copy of the character entered by the user. It doesn't matter since only the
  last command is assigned to the period key to be re-executed.
#@+node:ekr.20100113075303.6272: *4* Argument handling
#@+node:ekr.20100112051224.6222: *5* Commands requesting user input (hard?)
Commands requesting user input must be the last command executed within an @mode
node. This prevents the implementation of commands such as "yank to <character>"
that requires a "copy to clipboard" operation after the "find-character"
command.
#@+node:ekr.20100112051224.6226: *5* Range prefix to commands (k.getArgs)
The ability to specify a numeric range prefix is not supported. For example,
entering "3dd" will not delete the next three lines and "20G" will not move the
cursor to the 20th line in the file.

#@+node:ekr.20100112051224.6227: *5* Range prefix to objects (k.getArgs)
The ability to specify a numeric range prefix to an object is not supported. For
example, the "d2fx" command should Delete up to and including the 2nd Found "x"
character.
#@+node:ekr.20100112051224.6223: *4* Editing node headlines using @mode nodes
Commands modifying or selecting headline text do not work correctly within a
@mode node.

This eliminates accurate implementation of vi's delete/change/substitute/yank
object commands. As a workaround, the commands are currently written to only
select the text. The user must perform the subsequent delete, change,
substitute, and yank.
#@+node:ekr.20100112051224.6246: *4* Missing commands
#@+node:ekr.20100112051224.6232: *5* Toggle case command
Leo provides support for switching to upper or lower case but no method exists
to toggle between cases (used by Vi's "~" command).

#@+node:ekr.20100112051224.6233: *5* Replace current character command
Vi's "r" command allows user to replace the current character with the next
entered character.
#@+node:ekr.20100112051224.6234: *5* Move current line
Vi has a collection of "z<movement>" commands that will move the
current line to the top, middle, and bottom of the screen.  They are
not supported in Leo.
#@+node:ekr.20100112051224.6235: *5* Move buffer up/down
Vi maps keys to scroll the text up/down one line and by half the
number of visible lines.  Leo does not support this.

#@+node:ekr.20100112051224.6236: *5* Word-related commands
Vi supports two types of words in its commands:

1. Words that consist of only a subset of the character set and
2. words that consist of all characters except the space and tab characters.

Leo's always considers a word to consist of a subset of characters
although some word related commands include different characters
than others.
#@+node:ekr.20100112051224.6237: *5* Forward and backward by sentences
Leo's sentence related functions:

- do not stop at empty lines.
- do not skip periods within words.
- do not stop at sentences ending in non-periods.
- do not stop at the end or beginning of the buffer.

Note: see forwardSentenceHelper and backSentenceHelper functions.
#@+node:ekr.20100112051224.6238: *5* Focus to body pane
Leo functions exist which unconditionally set focus to the body pane
regardless of the active pane.

For example, bracket matching commands ("%" key) do not work within
a node's headline text.  Instead, the command is performed on the
node's body text.
#@+node:ekr.20090629183608.8446: *5* Notes about commands
Yank vs. Yank:
Vi's "yank" commands copy the selected text TO the clipboard.
Leo's "yank" commands insert text FROM the clipboard.

copy-text in modes:
Leo's copy-text command does not work within a mode.  As a result,
all "copy to clipboard" capability is being implemented using the
kill-<object> command followed by Leo's "yank" command to put the
text back.

paste-text in modes:
The paste-text command does not work within an @mode node.  Leo's
"yank" command is used instead.

delete-node does not copy node to clipboard:
A copy-node command is issued to copy the node to the clipboard
followed by the delete-node command.
#@+node:ekr.20100521090440.5890: *3* Cleanups: first
#@+node:ekr.20100223123910.5930: *4* recentFilesController
@
The present operation of recent files is surprising.

Recent files should be a global list, managed by a single controller.
#@+node:ekr.20100219083854.5616: *4* Simplify i/o
#@+node:ekr.20100211125418.11612: *5* Revise g.readFileIntoString
@nocolor-node

- Create g.readFileWithUnknownEncodingIntoString.
    - Only this function should return ok,e.

- g.readFileIntoString should assume utf-8, and support explicit encodings.

We also need the following functions:

- g.openFileForReading.
- g.openFileForWriting.
#@+node:ekr.20100202145902.6106: *4* Init all settings in c.initConfigSettings
@nocolor-node

To do:

- remove most of the logic in configSettings.__init__.
- Move config ivars to the commander.
#@+node:ekr.20100130042842.6404: *5* Reading settings (do not delete)
Here are the calls to g.app.getxxx

# runLeo.createFrame
fileName = g.app.config.getString(c=None,setting='default_leo_file')

# c.configSettings.initIvar
# Why not init these settings by hand???
val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

# g.es and g.es_print
keys['color'] = g.app.config.getColor(None,"log_error_color") or 'red'

# leoPlugins.loadHandlers
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')
s = g.app.config.getEnabledPlugins()

# leoPlugins.loadOnePlugin
verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

#@+node:ekr.20041120064303: *6* readSettingsFiles & helpers (g.app.config)
def readSettingsFiles (self,fileName,verbose=True):

    '''Read settings from one file or the standard settings files.'''

    trace = False and not g.unitTesting
    verbose = verbose or trace
    giveMessage = (verbose and not g.app.unitTesting and
        not self.silent and not g.app.batchMode)
    if trace: g.trace(fileName,g.callers())
    self.write_recent_files_as_needed = False # Will be set later.
    localConfigFile = self.getLocalConfigFile(fileName)
    table = self.defineSettingsTable(fileName,localConfigFile)
    for path,localFlag in table:
        assert path and g.os_path_exists(path)
        isZipped = path and zipfile.is_zipfile(path)
        isLeo = isZipped or path.endswith('.leo')
        if isLeo:
            if giveMessage:
                s = 'reading settings in %s' % path
                # This occurs early in startup, so use the following instead of g.es_print.
                if not g.isPython3:
                    s = g.toEncodedString(s,'ascii')
                g.es_print(s,color='blue')
            c = self.openSettingsFile(path)
            if c:
                self.updateSettings(c,localFlag)
                g.app.destroyWindow(c.frame)
                self.write_recent_files_as_needed = c.config.getBool(
                    'write_recent_files_as_needed')

    self.readRecentFiles(localConfigFile)
    self.inited = True
    self.setIvarsFromSettings(None)
#@+node:ekr.20101021041958.6008: *7* getLocalConfigFile
# This can't be done in initSettingsFiles because
# the local directory does not yet exist.

def getLocalConfigFile (self,fileName):

    if not fileName:
        return None

    theDir = g.os_path_dirname(fileName)
    path = g.os_path_join(theDir,'leoSettings.leo')

    if g.os_path_exists(path):
        return path
    else:
        return None
#@+node:ekr.20101021041958.6004: *7* defineSettingsTable
def defineSettingsTable (self,fileName,localConfigFile):

    global_table = (
        (self.globalConfigFile,False),
        (self.homeFile,False),
        # (localConfigFile,False),
        (self.myGlobalConfigFile,False),
        (self.myHomeConfigFile,False),
        (self.machineConfigFile,False),
        # (myLocalConfigFile,False),
        # New in Leo 4.6: the -c file is in *addition* to other config files.
        (g.app.oneConfigFilename,False),
    )

    if fileName:
        path = g.os_path_finalize(fileName)
        theDir = g.os_path_dirname(fileName)
        myLocalConfigFile = g.os_path_join(theDir,'myLeoSettings.leo')
        local_table = (
            (localConfigFile,False),
            (myLocalConfigFile,False),
        )
        table1 = [z for z in global_table if z not in global_table]
        table1.append((path,True),)
    else:
        table1 = global_table

    seen = [] ; table = []
    for path,localFlag in table1:
        if path and g.os_path_exists(path):
            # Make sure we mark files seen no matter how they are specified.
            path = g.os_path_realpath(g.os_path_finalize(path))
            if path.lower() not in seen:
                seen.append(path.lower())
                table.append((path,localFlag),)
    # g.trace(table)
    return table
#@+node:ekr.20041117085625: *7* openSettingsFile
def openSettingsFile (self,path):

    theFile,isZipped = g.openLeoOrZipFile(path)
    if not theFile: return None

    # Similar to g.openWithFileName except it uses a null gui.
    # Changing g.app.gui here is a major hack.
    oldGui = g.app.gui
    g.app.gui = leoGui.nullGui("nullGui")
    c,frame = g.app.newLeoCommanderAndFrame(
        fileName=path,relativeFileName=None,
        initEditCommanders=False,updateRecentFiles=False)
    frame.log.enable(False)
    g.app.lockLog()
    ok = frame.c.fileCommands.open(
        theFile,path,readAtFileNodesFlag=False,silent=True) # closes theFile.
    g.app.unlockLog()
    c.openDirectory = frame.openDirectory = g.os_path_dirname(path)
    g.app.gui = oldGui
    return ok and c
#@+node:ekr.20051013161232: *7* updateSettings
def updateSettings (self,c,localFlag):

    # g.trace(localFlag,c)

    d = self.readSettings(c,localFlag)

    if d:
        d['_hash'] = theHash = c.hash()
        if localFlag:
            self.localOptionsDict[theHash] = d
        else:
            self.localOptionsList.insert(0,d)

    if 0: # Good trace.
        if localFlag:
            g.trace(c.fileName())
            g.trace(d and list(d.keys()))
#@+node:ekr.20041118104831.2: *6* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118084146.1: *6* set (g.app.config)
def set (self,c,setting,kind,val):

    '''Set the setting.  Not called during initialization.'''

    trace = False and not g.unitTesting # and setting == 'create_nonexistent_directories'
    # if trace: g.pdb()

    found = False ;  key = self.munge(setting)
    if trace: g.trace(setting,kind,val)

    if c:
        d = self.localOptionsDict.get(c.hash())
        found = True # Bug fix: 2010/08/30.

    if not found:
        theHash = c.hash()
        for d in self.localOptionsList:
            hash2 = d.get('_hash')
            if theHash == hash2:
                found = True ; break

    if not found:
        d = self.dictList [0]

    d[key] = g.Bunch(setting=setting,kind=kind,val=val,tag='setting')

    if 0:
        dkind = d.get('_hash','<no hash: %s>' % c.hash())
        g.trace(dkind,setting,kind,val)
#@+node:ekr.20041118104240: *6* initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@+node:ekr.20041228042224: *6* setIvarsFromSettings (g.app.config)
def setIvarsFromSettings (self,c):

    '''Init g.app.config ivars or c's ivars from settings.

    - Called from readSettingsFiles with c = None to init g.app.config ivars.
    - Called from c.__init__ to init corresponding commmander ivars.'''

    trace = False and not g.unitTesting
    verbose = False

    if not self.inited: return

    # Ignore temporary commanders created by readSettingsFiles.
    if trace and verbose: g.trace('*' * 10)
    if trace: g.trace(
        'inited',self.inited,
        c and c.shortFileName() or '<no c>',g.callers(2))

    d = self.ivarsDict
    keys = list(d.keys())
    keys.sort()
    for key in keys:
        if key != '_hash':
            bunch = d.get(key)
            if bunch:
                ivar = bunch.ivar # The actual name of the ivar.
                kind = bunch.kind
                val = self.get(c,key,kind) # Don't use bunch.val!
                if c:
                    if trace and verbose: g.trace("%20s %s = %s" % (
                        g.shortFileName(c.mFileName),ivar,val))
                    setattr(c,ivar,val)
                else:
                    if trace and verbose: g.trace("%20s %s = %s" % (
                        'g.app.config',ivar,val))
                    setattr(self,ivar,val)
#@+node:ekr.20100130042842.9008: *5*  Notes
@nocolor-node

colorizeAnyLanguage.
    g.app.config.defaultFontFamily

c.scanAtPathDirectives:
    relative_path_base_directory:

** Methods that write recent files:
    recentFileMessageWritten (Probabaly ok)

c.configSettings.__init__:

** copies these ivars by hand.
    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize
** calls initIvar and initEncoding to copy other ivars.

g.makeAllNonExistentDirectories:
    # Uses one or the other, depending on the c arg.
    c.create_nonexistent_directories
    g.app.config.create_nonexistent_directories

g.getOutputNewline:
    # Uses one or the other, depending on the c arg.
    c.config.output_newline
    g.app.config.output_newline

g.doHook:
    g.app.config.use_plugins

loadOnePlugin:
    g.app.config.enabledPluginsFileName

leoGui.getFontFromParams:
    g.app.config.defaultFont

k.addModeCommands and several other methods use:
    g.app.config.modeCommandsDict
#@+node:ekr.20100130042842.9010: *6* at_root_bodies_start_in_doc_mode
@nocolor-node

at_root_bodies_start_in_doc_mode

c.scanAtRootDirectives
    should use c.config.getBool instead of the weird code.

g.scanAtRootOptions
    Why doesn't this use c.config ivars??
    Actually, this should be tangle.scanAtRootOptions.  We know c!

leoImport.convertVnodeToWeb:
    Uses c.config.at_root_bodies_start_in_doc_mode
#@+node:ekr.20080828103146.12: *7* c.scanAtRootDirectives
# Called only by scanColorDirectives.

def scanAtRootDirectives(self,aList):

    '''Scan aList for @root-code and @root-doc directives.'''

    c = self

    # To keep pylint happy.
    tag = 'at_root_bodies_start_in_doc_mode'
    start_in_doc = hasattr(c.config,tag) and getattr(c.config,tag)

    # New in Leo 4.6: dashes are valid in directive names.
    for d in aList:
        if 'root-code' in d:
            return 'code'
        elif 'root-doc' in d:
            return 'doc'
        elif 'root' in d:
            return g.choose(start_in_doc,'doc','code')

    return None
#@+node:ekr.20031218072017.3154: *7* g.scanAtRootOptions
def scanAtRootOptions (s,i,err_flag=False):

    # The @root has been eaten when called from tangle.scanAllDirectives.
    if g.match(s,i,"@root"):
        i += len("@root")
        i = g.skip_ws(s,i)

    mode = None 
    while g.match(s,i,'-'):
        << scan another @root option >>

    if mode == None:
        doc = app.config.at_root_bodies_start_in_doc_mode
        mode = g.choose(doc,"doc","code")

    # g.trace(mode,g.callers(3))

    return i,mode
#@+node:ekr.20031218072017.3155: *8* << scan another @root option >>
i += 1 ; err = -1

if g.match_word(s,i,"code"): # Just match the prefix.
    if not mode: mode = "code"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
elif g.match(s,i,"doc"): # Just match the prefix.
    if not mode: mode = "doc"
    elif err_flag: g.es("modes conflict in:",g.get_line(s,i))
else:
    err = i-1

# Scan to the next minus sign.
while i < len(s) and s[i] not in (' ','\t','\n','-'):
    i += 1

if err > -1 and err_flag:
    z_opt = s[err:i]
    z_line = g.get_line(s,i)
    g.es("unknown option:",z_opt,"in",z_line)
#@+node:ekr.20100131161507.6302: *6* Replace all of these by config.get methods
c.config.default_at_auto_file_encoding
c.config.default_derived_file_encoding
#@+node:ekr.20100202145902.6108: *6* code
#@+node:ekr.20031218072017.1880: *7* colorizeAnyLanguage & allies
def colorizeAnyLanguage (self,p,leading=None,trailing=None):

    """Color the body pane either incrementally or non-incrementally"""

    c = self.c ; w = c.frame.body.bodyCtrl

    if not c.config.getBool('use_syntax_coloring'):
        # There have been reports of this trace causing crashes.
        # Certainly it is not necessary.
        # g.trace('no coloring')
        return

    if self.killFlag:
        self.removeAllTags()
        return
    try:
        # g.trace('incremental',self.incremental)
        << initialize ivars & tags >>
        g.doHook("init-color-markup",colorer=self,p=self.p,v=self.p)
        if self.incremental and (
            << all state ivars match >> ):
            << incrementally color the text >>
        else:
            << non-incrementally color the text >>
        << update state ivars >>
        return "ok" # for testing.
    except:
        << set state ivars to "unknown" >>
        if self.c:
            g.es_exception()
        else:
            import traceback ; traceback.print_exc()
        return "error" # for unit testing.
#@+node:ekr.20031218072017.1602: *8* << initialize ivars & tags >> colorizeAnyLanguage
# Copy the arguments.
self.p = p

# Get the body text, converted to unicode.
self.allBodyText = w.getAllText()
sel = w.getInsertPoint()
start,end = g.convertPythonIndexToRowCol(self.allBodyText,sel)
start += 1 # Simulate the old 1-based Tk scheme.  self.index undoes this hack.
# g.trace('new',start,end)

if self.language: self.language = self.language.lower()
# g.trace(self.count,self.p)
# g.trace(body.tag_names())

if not self.incremental:
    self.removeAllTags()
    # self.removeAllImages()

<< configure fonts >>
<< configure tags >>
<< configure language-specific settings >>

self.hyperCount = 0 # Number of hypertext tags
self.count += 1
lines = self.allBodyText.split('\n')
#@+node:ekr.20060829084924: *9* << configure fonts >> (revise,maybe)
# Get the default body font.
defaultBodyfont = self.fonts.get('default_body_font')
if not defaultBodyfont:
    defaultBodyfont = c.config.getFontFromParams(
        "body_text_font_family", "body_text_font_size",
        "body_text_font_slant",  "body_text_font_weight",
        c.config.defaultBodyFontSize)
    self.fonts['default_body_font'] = defaultBodyfont

# Configure fonts.
w = c.frame.body.bodyCtrl
keys = sorted(default_font_dict)
for key in keys:
    option_name = default_font_dict[key]
    # First, look for the language-specific setting, then the general setting.
    for name in ('%s_%s' % (self.language,option_name),(option_name)):
        font = self.fonts.get(name)
        if font:
            # g.trace('found',name,id(font))
            w.tag_config(key,font=font)
            break
        else:
            family = c.config.get(name + '_family','family')
            size   = c.config.get(name + '_size',  'size')   
            slant  = c.config.get(name + '_slant', 'slant')
            weight = c.config.get(name + '_weight','weight')
            if family or slant or weight or size:
                family = family or g.app.config.defaultFontFamily
                size   = size or str(c.config.defaultBodyFontSize)
                slant  = slant or 'roman'
                weight = weight or 'normal'
                font = c.config.getFontFromParams(family,size,slant,weight)
                # Save a reference to the font so it 'sticks'.
                self.fonts[name] = font 
                # g.trace(key,name,family,size,slant,weight,id(font))
                w.tag_config(key,font=font)
                break
    else: # Neither the general setting nor the language-specific setting exists.
        if len(list(self.fonts.keys())) > 1: # Restore the default font.
            # g.trace('default',key)
            w.tag_config(key,font=defaultBodyfont)
#@+node:ekr.20031218072017.1603: *9* << configure tags >>
# g.trace('configure tags',self.c.frame.body.bodyCtrl)

for name in default_colors_dict:
    option_name,default_color = default_colors_dict[name]
    option_color = c.config.getColor(option_name)
    color = g.choose(option_color,option_color,default_color)
    # g.trace(name,color)
    # Must use foreground, not fg.
    try:
        c.frame.body.tag_configure(name, foreground=color)
    except: # Recover after a user error.
        c.frame.body.tag_configure(name, foreground=default_color)

underline_undefined = c.config.getBool("underline_undefined_section_names")
use_hyperlinks      = c.config.getBool("use_hyperlinks")
self.use_hyperlinks = use_hyperlinks

# underline=var doesn't seem to work.
if 0: # use_hyperlinks: # Use the same coloring, even when hyperlinks are in effect.
    c.frame.body.tag_configure("link",underline=1) # defined
    c.frame.body.tag_configure("name",underline=0) # undefined
else:
    c.frame.body.tag_configure("link",underline=0)
    if underline_undefined:
        c.frame.body.tag_configure("name",underline=1)
    else:
        c.frame.body.tag_configure("name",underline=0)

# 8/4/02: we only create tags for whitespace when showing invisibles.
if self.showInvisibles:
    for name,option_name,default_color in (
        ("blank","show_invisibles_space_background_color","Gray90"),
        ("tab",  "show_invisibles_tab_background_color",  "Gray80")):
        option_color = c.config.getColor(option_name)
        color = g.choose(option_color,option_color,default_color)
        try:
            c.frame.body.tag_configure(name,background=color)
        except: # Recover after a user error.
            c.frame.body.tag_configure(name,background=default_color)

# 11/15/02: Colors for latex characters.  Should be user options...

if 1: # Alas, the selection doesn't show if a background color is specified.
    c.frame.body.tag_configure("latexModeBackground",foreground="black")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue")
    c.frame.body.tag_configure("latexBackground",foreground="black")
    c.frame.body.tag_configure("latexKeyword",foreground="blue")
else: # Looks cool, and good for debugging.
    c.frame.body.tag_configure("latexModeBackground",foreground="black",background="seashell1")
    c.frame.body.tag_configure("latexModeKeyword",foreground="blue",background="seashell1")
    c.frame.body.tag_configure("latexBackground",foreground="black",background="white")
    c.frame.body.tag_configure("latexKeyword",foreground="blue",background="white")

# Tags for wiki coloring.
if self.showInvisibles:
    c.frame.body.tag_configure("elide",background="yellow")
else:
    c.frame.body.tag_configure("elide",elide="1")
c.frame.body.tag_configure("bold",font=self.bold_font)
c.frame.body.tag_configure("italic",font=self.italic_font)
c.frame.body.tag_configure("bolditalic",font=self.bolditalic_font)
for name in self.color_tags_list:
    c.frame.body.tag_configure(name,foreground=name)
#@+node:ekr.20031218072017.370: *9* << configure language-specific settings >> colorizer
# Define has_string, keywords, single_comment_start, block_comment_start, block_comment_end.

if self.language == "cweb": # Use C comments, not cweb sentinel comments.
    delim1,delim2,delim3 = g.set_delims_from_language("c")
elif self.comment_string:
    delim1,delim2,delim3 = g.set_delims_from_string(self.comment_string)
elif self.language == "plain": # 1/30/03
    delim1,delim2,delim3 = None,None,None
else:
    delim1,delim2,delim3 = g.set_delims_from_language(self.language)

self.single_comment_start = delim1
self.block_comment_start = delim2
self.block_comment_end = delim3

# A strong case can be made for making this code as fast as possible.
# Whether this is compatible with general language descriptions remains to be seen.
self.case_sensitiveLanguage = self.language not in case_insensitiveLanguages
self.has_string = self.language != "plain"
if self.language == "plain":
    self.string_delims = ()
elif self.language in ("elisp","html"):
    self.string_delims = ('"')
else:
    self.string_delims = ("'",'"')
self.has_pp_directives = self.language in ("c","csharp","cweb","latex")

# The list of languages for which keywords exist.
# Eventually we might just use language_delims_dict.keys()
languages = [
    "actionscript","ada","c","csharp","css","cweb","elisp","html","java","latex","lua",
    "pascal","perl","perlpod","php","plsql","python","rapidq","rebol","ruby","shell","tcltk"]

self.keywords = []
if self.language == "cweb":
    for i in self.c_keywords:
        self.keywords.append(i)
    for i in self.cweb_keywords:
        self.keywords.append(i)
else:
    for name in languages:
        if self.language==name: 
            # g.trace("setting keywords for",name)
            self.keywords = getattr(self, name + "_keywords")

# Color plain text unless we are under the control of @nocolor.
# state = g.choose(self.flag,"normal","nocolor")
state = self.setFirstLineState()

if 1: # 10/25/02: we color both kinds of references in cweb mode.
    self.lb = "<<"
    self.rb = ">>"
else:
    self.lb = g.choose(self.language == "cweb","@<","<<")
    self.rb = g.choose(self.language == "cweb","@>",">>")
#@+node:ekr.20031218072017.1881: *8* << all state ivars match >>
self.flag == self.last_flag and
self.last_language == self.language
#@+node:ekr.20031218072017.1882: *8* << incrementally color the text >>
@ Each line has a starting state. The starting state for the first line
is always "normal".

We need remember only self.lines and self.states between colorizing.
It is not necessary to know where the text comes from, only what the
previous text was! We must always colorize everything when changing
nodes, even if all lines match, because the context may be different.

We compute the range of lines to be recolored by comparing leading
lines and trailing lines of old and new text. All other lines (the
middle lines) must be colorized, as well as any trailing lines whose
states may have changed as the result of changes to the middle lines.
@c

if self.trace: g.trace("incremental",self.language)

# 6/30/03: make a copies of everything
old_lines = self.lines[:]
old_states = self.states[:]
new_lines = lines[:]
new_states = []

new_len = len(new_lines)
old_len = len(old_lines)

if new_len == 0:
    self.states = []
    self.lines = []
    return

# Bug fix: 11/21/02: must test against None.
if leading != None and trailing != None:
    # g.pr("leading,trailing:",leading,trailing)
    leading_lines = leading
    trailing_lines = trailing
else:
    << compute leading, middle & trailing lines >>

middle_lines = new_len - leading_lines - trailing_lines
# g.pr("middle lines", middle_lines)

<< clear leading_lines if middle lines involve @color or @recolor  >>
<< initialize new states >>
<< colorize until the states match >>
#@+node:ekr.20031218072017.1883: *9* << compute leading, middle & trailing  lines >>
@ The leading lines are the leading matching lines. The trailing lines
are the trailing matching lines. The middle lines are all other new
lines. We will color at least all the middle lines. There may be no
middle lines if we delete lines.
@c

min_len = min(old_len,new_len)

i = 0
while i < min_len:
    if old_lines[i] != new_lines[i]:
        break
    i += 1
leading_lines = i

if leading_lines == new_len:
    # All lines match, and we must color _everything_.
    # (several routine delete, then insert the text again,
    # deleting all tags in the process).
    # g.pr("recolor all")
    leading_lines = trailing_lines = 0
else:
    i = 0
    while i < min_len - leading_lines:
        if old_lines[old_len-i-1] != new_lines[new_len-i-1]:
            break
        i += 1
    trailing_lines = i
#@+node:ekr.20031218072017.1884: *9* << clear leading_lines if middle lines involve @color or @recolor  >>
@ 11/19/02: Changing @color or @nocolor directives requires we recolor
all leading states as well.
@c

if trailing_lines == 0:
    m1 = new_lines[leading_lines:]
    m2 = old_lines[leading_lines:]
else:
    m1 = new_lines[leading_lines:-trailing_lines]
    m2 = old_lines[leading_lines:-trailing_lines]
m1.extend(m2) # m1 now contains all old and new middle lines.
if m1:
    for s in m1:
        ### s = g.toUnicode(s)
        i = g.skip_ws(s,0)
        if g.match_word(s,i,"@color") or g.match_word(s,i,"@nocolor"):
            leading_lines = 0
            break
#@+node:ekr.20031218072017.1885: *9* << initialize new states >>
# Copy the leading states from the old to the new lines.
i = 0
while i < leading_lines and i < old_len: # 12/8/02
    new_states.append(old_states[i])
    i += 1

# We know the starting state of the first middle line!
if middle_lines > 0 and i < old_len:
    new_states.append(old_states[i])
    i += 1

# Set the state of all other middle lines to "unknown".
first_trailing_line = max(0,new_len - trailing_lines)
while i < first_trailing_line:
    new_states.append("unknown")
    i += 1

# Copy the trailing states from the old to the new lines.
i = max(0,old_len - trailing_lines)
while i < old_len and i < len(old_states):
    new_states.append(old_states[i])
    i += 1

# 1/8/03: complete new_states by brute force.
while len(new_states) < new_len:
    new_states.append("unknown")
#@+node:ekr.20031218072017.1886: *9* << colorize until the states match >>
# Colorize until the states match.
# All middle lines have "unknown" state, so they will all be colored.

# Start in the state _after_ the last leading line, which may be unknown.
i = leading_lines
while i > 0:
    if i < old_len and i < new_len:
        state = new_states[i]
        # assert(state!="unknown") # This can fail.
        break
    else:
        i -= 1

if i == 0:
    # Color plain text unless we are under the control of @nocolor.
    # state = g.choose(self.flag,"normal","nocolor")
    state = self.setFirstLineState()
    new_states[0] = state

# The new_states[] will be "unknown" unless the lines match,
# so we do not need to compare lines here.
while i < new_len:
    self.line_index = i + 1
    state = self.colorizeLine(new_lines[i],state)
    i += 1
    # Set the state of the _next_ line.
    if i < new_len and state != new_states[i]:
        new_states[i] = state
    else: break

# Update the ivars
self.states = new_states
self.lines = new_lines
#@+node:ekr.20031218072017.1887: *8* << non-incrementally color the text >>
if self.trace: g.trace("non-incremental",self.language)

self.line_index = 1 # The Tk line number for indices, as in n.i
for s in lines:
    state = self.colorizeLine(s,state)
    self.line_index += 1
#@+node:ekr.20031218072017.1888: *8* << update state ivars >>
self.last_flag = self.flag
self.last_language = self.language
#@+node:ekr.20031218072017.1889: *8* << set state ivars to "unknown" >>
self.last_flag = "unknown"
self.last_language = "unknown"
#@+node:ekr.20080828103146.15: *7* c.scanAtPathDirectives
def scanAtPathDirectives(self,aList,force=False,createPath=True):

    '''Scan aList for @path directives.
    Return a reasonable default if no @path directive is found.'''

    trace = False and (force or createPath) and not g.unitTesting
    verbose = True

    c = self
    c.scanAtPathDirectivesCount += 1 # An important statistic.
    if trace and verbose: g.trace('**entry',g.callers(4))

    # Step 1: Compute the starting path.
    # The correct fallback directory is the absolute path to the base.
    if c.openDirectory:  # Bug fix: 2008/9/18
        base = c.openDirectory
    else:
        base = g.app.config.relative_path_base_directory
        if base and base == "!":    base = g.app.loadDir
        elif base and base == ".":  base = c.openDirectory

    if trace and verbose:
        g.trace('base   ',base)
        g.trace('loadDir',g.app.loadDir)

    absbase = c.os_path_finalize_join(g.app.loadDir,base)

    if trace and verbose: g.trace('absbase',absbase)

    # Step 2: look for @path directives.
    paths = [] ; fileName = None
    for d in aList:
        # Look for @path directives.
        path = d.get('path')
        warning = d.get('@path_in_body')
        if trace and path:
            g.trace('**** d',d)
            g.trace('**** @path path',path)
        if path is not None: # retain empty paths for warnings.
            # Convert "path" or <path> to path.
            path = g.stripPathCruft(path)
            if path and not warning:
                paths.append(path)
            # We will silently ignore empty @path directives.

    # Add absbase and reverse the list.
    paths.append(absbase)
    paths.reverse()

    # Step 3: Compute the full, effective, absolute path.
    if trace and verbose:
        g.printList(paths,tag='c.scanAtPathDirectives: raw paths')
    path = c.os_path_finalize_join(*paths)
    if trace and verbose: g.trace('joined path:',path)

    # Step 4: Make the path if necessary.
    if path and createPath and not g.os_path_exists(path):
        ok = g.makeAllNonExistentDirectories(path,c=c,force=force)
        if not ok:
            if force:
                g.es_print('c.scanAtPathDirectives: invalid @path: %s' % (path),color='red')
            path = absbase # Bug fix: 2008/9/18

    if trace: g.trace('returns',path)

    return path
#@+node:ekr.20041118104831.2: *7* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20031218072017.3119: *7* g.makeAllNonExistentDirectories
# This is a generalization of os.makedir.

def makeAllNonExistentDirectories (theDir,c=None,force=False,verbose=True):

    """Attempt to make all non-existent directories"""

    trace = False and not g.unitTesting
    testing = trace # True: don't actually make the directories.

    if force:
        create = True # Bug fix: g.app.config will not exist during startup.
    elif c:
        create = c.config and c.config.create_nonexistent_directories
    else:
        create = (g.app and g.app.config and
            g.app.config.create_nonexistent_directories)

    if c: theDir = g.os_path_expandExpression(theDir,c=c)

    dir1 = theDir = g.os_path_normpath(theDir)

    ok = g.os_path_isdir(dir1) and g.os_path_exists(dir1)

    if trace: g.trace('ok',ok,'create',create,'force',force,dir1,g.callers())

    if ok:
        return ok
    elif not force and not create:
        if trace:
            g.trace('did not create: force and create are both false')
        return ok

    if trace:
        g.trace('\n',theDir,'\n',g.callers(4))
        # g.trace('c exists: %s force: %s create: %s dir: %s' % (
            # c is not None,force,create,theDir))

    # Split theDir into all its component parts.
    paths = []
    while len(theDir) > 0:
        head,tail=g.os_path_split(theDir)
        if len(tail) == 0:
            paths.append(head)
            break
        else:
            paths.append(tail)
            theDir = head
    path = ""
    paths.reverse()
    if trace: g.trace('paths:',paths)
    for s in paths:
        path = g.os_path_finalize_join(path,s)
        if not g.os_path_exists(path):
            try:
                if testing:
                    g.trace('***making',path)
                else:
                    os.mkdir(path)
                if verbose and not testing and not g.app.unitTesting:
                    # g.trace('***callers***',g.callers(5))
                    g.es_print("created directory:",path,color='red')
            except Exception:
                # g.trace(g.callers())
                if verbose: g.es_print("exception creating directory:",path,color='red')
                g.es_exception()
                return None
    return dir1 # All have been created.
#@+node:ekr.20031218072017.1386: *7* g.getOutputNewline
def getOutputNewline (c=None,name=None):

    '''Convert the name of a line ending to the line ending itself.

    Priority:
    - Use name if name given
    - Use c.config.output_newline if c given,
    - Otherwise use g.app.config.output_newline.'''

    if name: s = name
    elif c:  s = c.config.output_newline
    else:    s = app.config.output_newline

    if not s: s = ''
    s = s.lower()
    if s in ( "nl","lf"): s = '\n'
    elif s == "cr": s = '\r'
    elif s == "platform": s = os.linesep  # 12/2/03: emakital
    elif s == "crlf": s = "\r\n"
    else: s = '\n' # Default for erroneous values.
    # g.trace(c,name,c.config.output_newline,'returns',repr(s))

    if g.isPython3:
        s = str(s)
    return s
#@+node:ekr.20031218072017.1596: *7* g.doHook
@ This global function calls a hook routine.  Hooks are identified by the tag param.
Returns the value returned by the hook routine, or None if the there is an exception.

We look for a hook routine in three places:
1. c.hookFunction
2. app.hookFunction
3. leoPlugins.doPlugins()
We set app.hookError on all exceptions.  Scripts may reset app.hookError to try again.
@c

def doHook(tag,*args,**keywords):

    trace = False ; verbose = False

    if g.app.killed or g.app.hookError: # or (g.app.gui and g.app.gui.isNullGui):
        return None

    if args:
        # A minor error in Leo's core.
        g.pr("***ignoring args param.  tag = %s" % tag)

    if not g.app.config.use_plugins:
        if tag in ('open0','start1'):
            s = "Plugins disabled: use_plugins is 0 in a leoSettings.leo file."
            g.es_print(s,color="blue")
        return None

    # Get the hook handler function.  Usually this is doPlugins.
    c = keywords.get("c")
    f = (c and c.hookFunction) or g.app.hookFunction

    if trace and (verbose or tag != 'idle'):
        g.trace('tag',tag,'f',f and f.__name__)

    if not f:
        ### import leo.core.leoPlugins as leoPlugins
        g.app.hookFunction = f = g.app.pluginsController.doPlugins

    try:
        # Pass the hook to the hook handler.
        # g.pr('doHook',f.__name__,keywords.get('c'))
        return f(tag,keywords)
    except Exception:
        g.es_exception()
        g.app.hookError = True # Supress this function.
        g.app.idleTimeHook = False # Supress idle-time hook
        return None # No return value
#@+node:ekr.20041113113140: *7* loadOnePlugin
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.startswith('@'):
        if trace: g.trace('ignoring Leo directive')
        return False # Allow Leo directives in @enabled-plugins nodes.

    if moduleOrFileName.endswith('.py'):
        moduleName = 'leo.plugins.' + moduleOrFileName [:-3]
    elif moduleOrFileName.startswith('leo.plugins.'):
        moduleName = moduleOrFileName
    else:
        moduleName = 'leo.plugins.' + moduleOrFileName

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)

    try:
        toplevel = __import__(moduleName)
        # need to look up through sys.modules, __import__ returns toplevel package
        result = sys.modules[moduleName]

    except g.UiTypeException:
        if not g.unitTesting and not g.app.batchMode:
            g.es_print('Plugin %s does not support %s gui' % (
                moduleName,g.app.gui.guiName()))
        result = None

    except ImportError:
        if trace or tag == 'open0': # Just give the warning once.
            g.es_print('plugin does not exist:',moduleName,color='red')
        result = None

    except Exception as e:
        g.es_print('exception importing plugin ' + moduleName,color='red')
        g.es_exception()
        result = None

    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@+node:ekr.20061031131434.100: *7* addModeCommands (enterModeCallback)
def addModeCommands (self):

    '''Add commands created by @mode settings to c.commandsDict and k.inverseCommandsDict.'''

    k = self ; c = k.c
    d = g.app.config.modeCommandsDict # Keys are command names: enter-x-mode.

    # Create the callback functions and update c.commandsDict and k.inverseCommandsDict.
    for key in d:

        def enterModeCallback (event=None,name=key):
            k.enterNamedMode(event,name)

        c.commandsDict[key] = f = enterModeCallback
        k.inverseCommandsDict [f.__name__] = key
        # g.trace('leoCommands %24s = %s' % (f.__name__,key))
#@+node:ekr.20041118104831.1: *5* class configSettings (leoCommands)
class configSettings:

    """A class to hold config settings for commanders."""

    @others
#@+node:ekr.20041118104831.2: *6* configSettings.__init__ (c.configSettings)
def __init__ (self,c):

    trace = False and not g.unitTesting
    self.c = c

    if trace: g.trace('+' * 20,'(c.configSettings)',
        c and c.shortFileName(),g.callers(5))

    # Init these here to keep pylint happy.
    self.default_derived_file_encoding = None
    self.new_leo_file_encoding = None
    self.redirect_execute_script_output_to_log_pane = None

    self.defaultBodyFontSize = g.app.config.defaultBodyFontSize
    self.defaultLogFontSize  = g.app.config.defaultLogFontSize
    self.defaultMenuFontSize = g.app.config.defaultMenuFontSize
    self.defaultTreeFontSize = g.app.config.defaultTreeFontSize

    for key in g.app.config.encodingIvarsDict:
        if key != '_hash':
            self.initEncoding(key)

    for key in g.app.config.ivarsDict:
        if key != '_hash':
            self.initIvar(key)
#@+node:ekr.20041118104240: *6* initIvar (c.configSettings)
def initIvar(self,key):

    trace = False and not g.unitTesting
    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.ivarsDict.get(key)
    ivarName = bunch.ivar
    val = g.app.config.get(c,ivarName,kind=None) # kind is ignored anyway.

    if val or not hasattr(self,ivarName):
        if trace: g.trace('c.configSettings',c.shortFileName(),ivarName,val)
        setattr(self,ivarName,val)
#@+node:ekr.20041118104414: *6* initEncoding
def initEncoding (self,key):

    c = self.c

    # N.B. The key is munged.
    bunch = g.app.config.encodingIvarsDict.get(key)
    encodingName = bunch.ivar
    encoding = g.app.config.get(c,encodingName,kind='string')

    # New in 4.4b3: use the global setting as a last resort.
    if encoding:
        # g.trace('c.configSettings',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)
    else:
        encoding = getattr(g.app.config,encodingName)
        # g.trace('g.app.config',c.shortFileName(),encodingName,encoding)
        setattr(self,encodingName,encoding)

    if encoding and not g.isValidEncoding(encoding):
        g.es("bad", "%s: %s" % (encodingName,encoding))
#@+node:ekr.20041118053731: *6* Getters (c.configSettings)
def get (self,setting,theType):
    '''A helper function: return the commander's setting, checking the type.'''
    return g.app.config.get(self.c,setting,theType)

def getAbbrevDict (self):
    '''return the commander's abbreviation dictionary.'''
    return g.app.config.getAbbrevDict(self.c)

def getBool (self,setting,default=None):
    '''Return the value of @bool setting, or the default if the setting is not found.'''
    return g.app.config.getBool(self.c,setting,default=default)

def getButtons (self):
    '''Return a list of tuples (x,y) for common @button nodes.'''
    return g.app.config.atCommonButtonsList # unusual.

def getColor (self,setting):
    '''Return the value of @color setting.'''
    return g.app.config.getColor(self.c,setting)

def getCommands (self):
    '''Return the list of tuples (headline,script) for common @command nodes.'''
    return g.app.config.atCommonCommandsList # unusual.

def getData (self,setting):
    '''Return a list of non-comment strings in the body text of @data setting.'''
    return g.app.config.getData(self.c,setting)

def getDirectory (self,setting):
    '''Return the value of @directory setting, or None if the directory does not exist.'''
    return g.app.config.getDirectory(self.c,setting)

def getFloat (self,setting):
    '''Return the value of @float setting.'''
    return g.app.config.getFloat(self.c,setting)

def getFontFromParams (self,family,size,slant,weight,defaultSize=12):

    '''Compute a font from font parameters.

    Arguments are the names of settings to be use.
    Default to size=12, slant="roman", weight="normal".

    Return None if there is no family setting so we can use system default fonts.'''

    return g.app.config.getFontFromParams(self.c,
        family, size, slant, weight, defaultSize = defaultSize)

def getInt (self,setting):
    '''Return the value of @int setting.'''
    return g.app.config.getInt(self.c,setting)

def getLanguage (self,setting):
    '''Return the value of @string setting.

    The value of this setting should be a language known to Leo.'''
    return g.app.config.getLanguage(self.c,setting)

def getMenusList (self):
    '''Return the list of entries for the @menus tree.'''
    return g.app.config.getMenusList(self.c) # Changed in Leo 4.5.

def getOpenWith (self):
    '''Return a list of dictionaries corresponding to @openwith nodes.'''
    return g.app.config.getOpenWith(self.c)

def getRatio (self,setting):
    '''Return the value of @float setting.
    Warn if the value is less than 0.0 or greater than 1.0.'''
    return g.app.config.getRatio(self.c,setting)

def getRecentFiles (self):
    '''Return the list of recently opened files.'''
    return g.app.config.getRecentFiles()

def getShortcut (self,shortcutName):
    '''Return the tuple (rawKey,accel) for shortcutName in @shortcuts tree.'''
    return g.app.config.getShortcut(self.c,shortcutName)

def getSettingSource(self,setting):
    '''return the name of the file responsible for setting.'''
    return g.app.config.getSettingSource(self.c,setting)

def getString (self,setting):
    '''Return the value of @string setting.'''
    return g.app.config.getString(self.c,setting)
#@+node:ekr.20041118195812: *6* Setters... (c.configSettings)
def setRecentFiles (self,files):
    '''Update the recent files list.'''
    # Append the files to the global list.
    g.app.config.appendToRecentFiles(files)
#@+node:ekr.20100219083854.5615: *4* Improve caching
#@+node:ekr.20100209160132.5770: *5* cache notes
@nocolor-node

Top-level folder are direct subfolders of .leo/db.
Top-level folders represent file *locations* not file contents.
Exception: the top-level "globals" folder represents minor data.

Only two files are ever needed in a top-level folder:

contents_<key>: the contents of the file.
data_<key>: a dict representing the "minor data" of the file:
    <globals> element stuff, expansion bits, etc.

We write contents_<key> only once.
By definition, its contents never changes, since the contents generates the key.
We can write data_<key> as many times as we like.

To do:
- Simplify or even eliminate the path-manipulation code in PickleShareDB.
- Use g.makeAllNonExistentDirectories to make top-level directories.
- Clear cache should clear all top-level directories.
#@+node:ekr.20100209114432.5751: *6* Cache expansion bits
# Simplify the structure of the cache: put more into the "minor" files.
#@+node:ekr.20100211095442.6201: *5* cache notes 2
@nocolor-node

1. Memory does leak, and that's not ok with me.  And I want just two
files per top-level directory.

2. Strange things can happen with caching, as just happened to me when
I restored qtui_generate.py mistakenly deleted from leo/test.  There
is an @auto node for this file in qtGui.py, and I got improper 'can
not open' messages for this file.

3. It is troubling that the present caching scheme does not use the
full path to a file, only the basename.  This means that two identical
files in two different places will use the same cache entries.  I've
been wondering for the last several days about whether this could
cause problems.  I don't know for sure, but I am uncomfortable.

4. I want the clear-cache and clear-all-caches commands to do what
they say: get rid of everything.  Among other things, this is good for
debugging and recovering from cache problems.

#@+node:ekr.20100223075705.5635: *5* Don't write expansion bits
#@+node:ekr.20100210163813.5748: *5* Caching buglets?
@nocolor-node

This is a recent bug, but imo it has uncovered some other caching buglets. These
buglets are not big enough to delay Leo 4.7, but the new caching scheme would
ensure they never bite.

1. The code that computes what I have been calling the top-level directory is dubious::

    dbdirname = join(g.app.homeLeoDir,'db',
            '%s_%s' % (bname,hashlib.md5(fn).hexdigest()))

The problem is that bname is only the base name of the cached file, not a name
(or key) that depends on the full path. Thus, two copies of the same file in the
same place will be cached in the same directory. Is this ominous?

2. It's not clear what caching to do with the save-to command.
#@+node:ekr.20100225102636.5627: *5* Use the string returned by cacher
# It should be possible to avoid duplicate reads.
#@+node:ekr.20100206074650.5844: *3* Cleanups & features: next
#@+node:ekr.20100223123910.5835: *4* Improve python importer
#@+node:ekr.20070703122141.65: *5* << class baseScannerClass >>
class baseScannerClass (scanUtility):

    '''The base class for all import scanner classes.
    This class contains common utility methods.'''

    @others
#@+node:ekr.20070703122141.66: *6* baseScannerClass.__init__
def __init__ (self,importCommands,atAuto,language):

    ic = importCommands

    self.atAuto = atAuto
    self.c = c = ic.c

    self.atAutoWarnsAboutLeadingWhitespace = c.config.getBool('at_auto_warns_about_leading_whitespace')
    self.classId = None # The identifier containing the class tag: 'class', 'interface', 'namespace', etc.
    self.codeEnd = None
        # The character after the last character of the class, method or function.
        # An error will be given if this is not a newline.
    self.encoding = ic.encoding
    self.errors = 0
    ic.errors = 0
    self.errorLines = []
    self.escapeSectionRefs = True
    self.extraIdChars = ''
    self.fileName = ic.fileName # The original filename.
    self.fileType = ic.fileType # The extension,  '.py', '.c', etc.
    self.file_s = '' # The complete text to be parsed.
    self.fullChecks = c.config.getBool('full_import_checks')
    self.functionSpelling = 'function' # for error message.
    self.importCommands = ic
    self.indentRefFlag = None # None, True or False.
    self.isRst = False
    self.language = language
    self.lastParent = None # The last generated parent node (used only by rstScanner).
    self.methodName = ic.methodName # x, as in < < x methods > > =
    self.methodsSeen = False
    self.mismatchWarningGiven = False
    self.output_newline = ic.output_newline # = c.config.getBool('output_newline')
    self.output_indent = 0 # The minimum indentation presently in effect.
    self.root = None # The top-level node of the generated tree.
    self.rootLine = ic.rootLine # '' or @root + self.fileName
    self.sigEnd = None # The index of the end of the signature.
    self.sigId = None # The identifier contained in the signature, i.e., the function or method name.
    self.sigStart = None
        # The start of the line containing the signature.
        # An error will be given if something other than whitespace precedes the signature.
    self.startSigIndent = None
    self.tab_width = None # Set in run: the tab width in effect in the c.currentPosition.
    self.tab_ws = '' # Set in run: the whitespace equivalent to one tab.
    self.trace = False or ic.trace # = c.config.getBool('trace_import')
    self.treeType = ic.treeType # '@root' or '@file'
    self.webType = ic.webType # 'cweb' or 'noweb'

    # Compute language ivars.
    delim1,junk,junk = g.set_delims_from_language(language)
    self.comment_delim = delim1

    # May be overridden in subclasses.
    self.anonymousClasses = [] # For Delphi Pascal interfaces.
    self.blockCommentDelim1 = None
    self.blockCommentDelim2 = None
    self.blockCommentDelim1_2 = None
    self.blockCommentDelim2_2 = None
    self.blockDelim1 = '{'
    self.blockDelim2 = '}'
    self.blockDelim2Cruft = [] # Stuff that can follow .blockDelim2.
    self.classTags = ['class',] # tags that start a tag.
    self.functionTags = []
    self.hasClasses = True
    self.hasFunctions = True
    self.lineCommentDelim = None
    self.lineCommentDelim2 = None
    self.outerBlockDelim1 = None
    self.outerBlockDelim2 = None
    self.outerBlockEndsDecls = True
    self.sigHeadExtraTokens = [] # Extra tokens valid in head of signature.
    self.sigFailTokens = []
        # A list of strings that abort a signature when seen in a tail.
        # For example, ';' and '=' in C.

    self.strict = False # True if leading whitespace is very significant.
    self.warnAboutUnderindentedLines = True
#@+node:ekr.20070808115837: *6* Checking
#@+node:ekr.20070703122141.102: *7* check
def check (self,unused_s,unused_parent):

    '''Make sure the generated nodes are equivalent to the original file.

    1. Regularize and check leading whitespace.
    2. Check that a trial write produces the original file.

    Return True if the nodes are equivalent to the original file.
    '''

    if self.fullChecks and self.treeType in (None,'@file'):
        return self.checkTrialWrite()
    else:
        return True
#@+node:ekr.20070703122141.104: *7* checkTrialWrite (baseScannerClass)
def checkTrialWrite (self,s1=None,s2=None):

    '''Return True if a trial write produces the original file.'''

    # s1 and s2 are for unit testing.
    c = self.c ; at = c.atFileCommands
    if s1 is None and s2 is None:
        if self.isRst:
            outputFile = StringIO()
            c.rstCommands.writeAtAutoFile(self.root,self.fileName,outputFile,trialWrite=True)
            s1,s2 = self.file_s,outputFile.getvalue()
        else:
            at.write(self.root,
                nosentinels=True,thinFile=False,
                scriptWrite=False,toString=True)
            s1,s2 = self.file_s, at.stringOutput

    s1 = g.toUnicode(s1,self.encoding)
    s2 = g.toUnicode(s2,self.encoding)

    # Make sure we have a trailing newline in both strings.
    s1 = s1.replace('\r','')
    s2 = s2.replace('\r','')
    if not s1.endswith('\n'): s1 = s1 + '\n'
    if not s2.endswith('\n'): s2 = s2 + '\n'

    if s1 == s2: return True

    lines1 = g.splitLines(s1)
    lines2 = g.splitLines(s2)

    if self.isRst:
        lines1 = self.adjustRstLines(lines1)
        lines2 = self.adjustRstLines(lines2)

    n1,n2 = len(lines1), len(lines2)
    ok = True ; bad_i = 0
    for i in range(max(n1,n2)):
        ok = self.compareHelper(lines1,lines2,i,self.strict)
        if not ok:
            bad_i = i
            break

    if g.app.unitTesting:
        d = g.app.unitTestDict
        # g.trace('expected',d.get('expectedMismatchLine'),'actual',d.get('actualMismatchLine'))
        ok = d.get('expectedMismatchLine') == d.get('actualMismatchLine')
        # Unit tests do not generate errors unless the mismatch line does not match.
        if not ok: d['fail'] = g.callers() # 2008/10/3

    if not ok:
        self.reportMismatch(lines1,lines2,bad_i)

    return ok
#@+node:ekr.20070730093735: *7* compareHelper & helpers
def compareHelper (self,lines1,lines2,i,strict):

    '''Compare lines1[i] and lines2[i].
    strict is True if leading whitespace is very significant.'''

    def pr(*args,**keys): #compareHelper
        g.es_print(color='blue',*args,**keys)

    def pr_mismatch(i,line1,line2):
        g.es_print('first mismatched line at line',str(i+1))
        g.es_print('original line: ',line1)
        g.es_print('generated line:',line2)

    d = g.app.unitTestDict
    expectedMismatch = g.app.unitTesting and d.get('expectedMismatchLine')
    enableWarning = not self.mismatchWarningGiven and self.atAutoWarnsAboutLeadingWhitespace
    messageKind = None

    if i >= len(lines1):
        if i != expectedMismatch or not g.unitTesting:
            pr('extra lines')
            for line in lines2[i:]:
                pr(repr(line))
        d ['actualMismatchLine'] = i
        return False

    if i >= len(lines2):
        if i != expectedMismatch or not g.unitTesting:
            g.es_print('missing lines')
            for line in lines2[i:]:
                g.es_print('',repr(line))
        d ['actualMismatchLine'] = i
        return False

    line1,line2 = lines1[i],lines2[i]

    if line1 == line2:
        return True # An exact match.
    elif not line1.strip() and not line2.strip():
        return True # Blank lines compare equal.
    elif self.isRst and self.compareRstUnderlines(line1,line2):
        return True
    elif strict:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(
            s1 == s2 and self.startsComment(s1,0) and self.startsComment(s2,0),
            'comment','error')
    else:
        s1,s2 = line1.lstrip(),line2.lstrip()
        messageKind = g.choose(s1==s2,'warning','error')

    if g.unitTesting:
        d ['actualMismatchLine'] = i+1
        ok = i+1 == expectedMismatch
        if not ok:  pr_mismatch(i,line1,line2)
        return ok
    elif strict:
        if enableWarning:
            self.mismatchWarningGiven = True
            if messageKind == 'comment':
                self.warning('mismatch in leading whitespace before comment')
            else:
                self.error('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind == 'comment' # Only mismatched comment lines are valid.
    else:
        if enableWarning:
            self.mismatchWarningGiven = True
            self.checkLeadingWhitespace(line1)
            self.warning('mismatch in leading whitespace')
            pr_mismatch(i,line1,line2)
        return messageKind in ('comment','warning') # Only errors are invalid.
#@+node:ekr.20091227115606.6468: *8* adjustRstLines
def adjustRstLines(self,lines):

    '''Ignore newlines.

    This fudge allows the rst code generators to insert needed newlines freely.'''

    return [z for z in lines if z.strip() != '']
#@+node:ekr.20090513073632.5735: *8* compareRstUnderlines
def compareRstUnderlines(self,s1,s2):

    s1,s2 = s1.rstrip(),s2.rstrip()
    if s1 == s2:
        return True # Don't worry about trailing whitespace.

    n1, n2 = len(s1),len(s2)
    ch1 = n1 and s1[0] or ''
    ch2 = n2 and s2[0] or ''

    val = (
        n1 >= 2 and n2 >= 2 and # Underlinings must be at least 2 long.
        ch1 == ch2 and # The underlining characters must match.
        s1 == ch1 * n1 and # The line must consist only of underlining characters.
        s2 == ch2 * n2)

    return val
#@+node:ekr.20071110144948: *7* checkLeadingWhitespace
def checkLeadingWhitespace (self,line):

    tab_width = self.tab_width
    lws = line[0:g.skip_ws(line,0)]
    w = g.computeWidth(lws,tab_width)
    ok = (w % abs(tab_width)) == 0

    if not ok:
        self.report('leading whitespace not consistent with @tabwidth %d' % tab_width)
        g.es_print('line:',repr(line),color='red')

    return ok
#@+node:ekr.20070911110507: *7* reportMismatch
def reportMismatch (self,lines1,lines2,bad_i):

    kind = g.choose(self.atAuto,'@auto','import command')
    n1,n2 = len(lines1),len(lines2)
    self.error(
        '%s did not import %s perfectly\nfirst mismatched line: %d' % (
            kind,self.root.h,bad_i))

    aList = []
    for i in range(max(0,bad_i-2),min(bad_i+3,max(n1,n2))):
        for lines,n in ((lines1,n1),(lines2,n2)):
            if i < n: line = repr(lines[i])
            else: line = '<eof>'
            aList.append('%4d %s' % (i,line))

    if not g.unitTesting:
        g.es_print('\n'.join(aList),color='blue')

    return False
#@+node:ekr.20070706084535: *6* Code generation
@ None of these methods should ever need to be overridden in subclasses.

#@+node:ekr.20090512080015.5800: *7* adjustParent
def adjustParent (self,parent,headline):

    '''Return the effective parent.

    This is overridden by the rstScanner class.'''

    return parent
#@+node:ekr.20070707073044.1: *7* addRef
def addRef (self,parent):

    '''Create an unindented @others or section reference in the parent node.'''

    c = self.c

    if self.isRst and not self.atAuto:
        return

    if self.treeType in ('@file',None):
        self.appendStringToBody(parent,'@others\n')

    if self.treeType == '@root' and self.methodsSeen:
        self.appendStringToBody(parent,
            g.angleBrackets(' ' + self.methodName + ' methods ') + '\n\n')
#@+node:ekr.20090122201952.6: *7* appendStringToBody & setBodyString (baseScannerClass)
def appendStringToBody (self,p,s):

    '''Similar to c.appendStringToBody,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.appendStringToBody(p,s)

def setBodyString (self,p,s):

    '''Similar to c.setBodyString,
    but does not recolor the text or redraw the screen.'''

    return self.importCommands.setBodyString(p,s)
#@+node:ekr.20090512153903.5806: *7* computeBody (baseScannerClass)
def computeBody (self,s,start,sigStart,codeEnd):

    trace = False and not g.unitTesting

    body1 = s[start:sigStart]
    # Adjust start backwards to get a better undent.
    if body1.strip():
        while start > 0 and s[start-1] in (' ','\t'):
            start -= 1

    # g.trace(repr(s[sigStart:codeEnd]))

    body1 = self.undentBody(s[start:sigStart],ignoreComments=False)
    body2 = self.undentBody(s[sigStart:codeEnd])
    body = body1 + body2

    if trace: g.trace('body: %s' % repr(body))

    tail = body[len(body.rstrip()):]
    if not '\n' in tail:
        self.warning(
            '%s %s does not end with a newline; one will be added\n%s' % (
            self.functionSpelling,self.sigId,g.get_line(s,codeEnd)))

        # g.trace(repr(s[sigStart:codeEnd]))
        # g.pdb()

    return body
#@+node:ekr.20090513073632.5737: *7* createDeclsNode
def createDeclsNode (self,parent,s):

    '''Create a child node of parent containing s.'''

    # Create the node for the decls.
    headline = '%s declarations' % self.methodName
    body = self.undentBody(s)
    self.createHeadline(parent,body,headline)
#@+node:ekr.20070707085612: *7* createFunctionNode
def createFunctionNode (self,headline,body,parent):

    # Create the prefix line for @root trees.
    if self.treeType == '@root':
        prefix = g.angleBrackets(' ' + headline + ' methods ') + '=\n\n'
        self.methodsSeen = True
    else:
        prefix = ''

    # Create the node.
    return self.createHeadline(parent,prefix + body,headline)

#@+node:ekr.20070703122141.77: *7* createHeadline (baseScannerClass)
def createHeadline (self,parent,body,headline):

    return self.importCommands.createHeadline(parent,body,headline)
#@+node:ekr.20090502071837.1: *7* endGen
def endGen (self,s):

    '''Do any language-specific post-processing.'''
    pass
#@+node:ekr.20070703122141.79: *7* getLeadingIndent
def getLeadingIndent (self,s,i,ignoreComments=True):

    '''Return the leading whitespace of a line.
    Ignore blank and comment lines if ignoreComments is True'''

    width = 0
    i = g.find_line_start(s,i)
    if ignoreComments:
        while i < len(s):
            # g.trace(g.get_line(s,i))
            j = g.skip_ws(s,i)
            if g.is_nl(s,j) or g.match(s,j,self.comment_delim):
                i = g.skip_line(s,i) # ignore blank lines and comment lines.
            else:
                i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                break      
    else:
        i, width = g.skip_leading_ws_with_indent(s,i,self.tab_width)

    # g.trace('returns:',width)
    return width
#@+node:ekr.20070709094002: *7* indentBody
def indentBody (self,s,lws=None):

    '''Add whitespace equivalent to one tab for all non-blank lines of s.'''

    result = []
    if not lws: lws = self.tab_ws

    for line in g.splitLines(s):
        if line.strip():
            result.append(lws + line)
        elif line.endswith('\n'):
            result.append('\n')

    result = ''.join(result)
    return result
#@+node:ekr.20070705085335: *7* insertIgnoreDirective
def insertIgnoreDirective (self,parent):

    self.appendStringToBody(parent,'@ignore')

    if not g.unitTesting:
        g.es_print('inserting @ignore',color='blue')
#@+node:ekr.20070707113832.1: *7* putClass & helpers
def putClass (self,s,i,sigEnd,codeEnd,start,parent):

    '''Creates a child node c of parent for the class,
    and a child of c for each def in the class.'''

    trace = False and not g.unitTesting
    if trace:
        # g.trace('tab_width',self.tab_width)
        g.trace('sig',s[i:sigEnd])

    # Enter a new class 1: save the old class info.
    oldMethodName = self.methodName
    oldStartSigIndent = self.startSigIndent

    # Enter a new class 2: init the new class info.
    self.indentRefFlag = None

    class_kind = self.classId
    class_name = self.sigId
    headline = '%s %s' % (class_kind,class_name)
    headline = headline.strip()
    self.methodName = headline

    # Compute the starting lines of the class.
    prefix = self.createClassNodePrefix()
    if not self.sigId:
        g.trace('Can not happen: no sigId')
        self.sigId = 'Unknown class name'
    classHead = s[start:sigEnd]
    i = self.extendSignature(s,sigEnd)
    extend = s[sigEnd:i]
    if extend:
        classHead = classHead + extend

    # Create the class node.
    class_node = self.createHeadline(parent,'',headline)

    # Remember the indentation of the class line.
    undentVal = self.getLeadingIndent(classHead,0)

    # Call the helper to parse the inner part of the class.
    putRef,bodyIndent,classDelim,decls,trailing = self.putClassHelper(
        s,i,codeEnd,class_node)
    # g.trace('bodyIndent',bodyIndent,'undentVal',undentVal)

    # Set the body of the class node.
    ref = putRef and self.getClassNodeRef(class_name) or ''

    if trace: g.trace('undentVal',undentVal,'bodyIndent',bodyIndent)

    # Give ref the same indentation as the body of the class.
    if ref:
        bodyWs = g.computeLeadingWhitespace (bodyIndent,self.tab_width)
        ref = '%s%s' % (bodyWs,ref)

    # Remove the leading whitespace.
    result = (
        prefix +
        self.undentBy(classHead,undentVal) +
        self.undentBy(classDelim,undentVal) +
        self.undentBy(decls,undentVal) +
        self.undentBy(ref,undentVal) +
        self.undentBy(trailing,undentVal))

    # Append the result to the class node.
    self.appendTextToClassNode(class_node,result)

    # Exit the new class: restore the previous class info.
    self.methodName = oldMethodName
    self.startSigIndent = oldStartSigIndent
#@+node:ekr.20070707190351: *8* appendTextToClassNode
def appendTextToClassNode (self,class_node,s):

    c = self.c

    self.appendStringToBody(class_node,s) 
#@+node:ekr.20070703122141.105: *8* createClassNodePrefix
def createClassNodePrefix (self):

    '''Create the class node prefix.'''

    if  self.treeType == '@root':
        prefix = g.angleBrackets(' ' + self.methodName + ' methods ') + '=\n\n'
        self.methodsSeen = True
    else:
        prefix = ''

    return prefix
#@+node:ekr.20070703122141.106: *8* getClassNodeRef
def getClassNodeRef (self,class_name):

    '''Insert the proper body text in the class_vnode.'''

    if self.treeType in ('@file',None):
        s = '@others'
    else:
        s = g.angleBrackets(' class %s methods ' % (class_name))

    return '%s\n' % (s)
#@+node:ekr.20070707171329: *8* putClassHelper
def putClassHelper(self,s,i,end,class_node):

    '''s contains the body of a class, not including the signature.

    Parse s for inner methods and classes, and create nodes.'''

    trace = False and not g.unitTesting

    # Increase the output indentation (used only in startsHelper).
    # This allows us to detect over-indented classes and functions.
    old_output_indent = self.output_indent
    self.output_indent += abs(self.tab_width)

    # Parse the decls.
    j = i ; i = self.skipDecls(s,i,end,inClass=True)
    decls = s[j:i]

    # Set the body indent if there are real decls.
    bodyIndent = decls.strip() and self.getIndent(s,i) or None
    if trace: g.trace('bodyIndent',bodyIndent)

    # Parse the rest of the class.
    delim1, delim2 = self.outerBlockDelim1, self.outerBlockDelim2
    if g.match(s,i,delim1):
        # Do *not* use g.skip_ws_and_nl here!
        j = g.skip_ws(s,i + len(delim1))
        if g.is_nl(s,j): j = g.skip_nl(s,j)
        classDelim = s[i:j]
        end2 = self.skipBlock(s,i,delim1=delim1,delim2=delim2)
        start,putRef,bodyIndent2 = self.scanHelper(s,j,end=end2,parent=class_node,kind='class')
    else:
        classDelim = ''
        start,putRef,bodyIndent2 = self.scanHelper(s,i,end=end,parent=class_node,kind='class')

    if bodyIndent is None: bodyIndent = bodyIndent2

    # Restore the output indentation.
    self.output_indent = old_output_indent

    # Return the results.
    trailing = s[start:end]
    return putRef,bodyIndent,classDelim,decls,trailing
#@+node:ekr.20070707082432: *7* putFunction (baseScannerClass)
def putFunction (self,s,sigStart,codeEnd,start,parent):

    '''Create a node of parent for a function defintion.'''

    trace = False and not g.unitTesting
    verbose = False

    # if trace: g.trace(start,sigStart,self.sigEnd,codeEnd)

    # Enter a new function: save the old function info.
    oldStartSigIndent = self.startSigIndent

    if self.sigId:
        headline = self.sigId
    else:
        g.trace('Can not happen: no sigId')
        headline = 'unknown function'

    body = self.computeBody(s,start,sigStart,codeEnd)

    if trace:
        g.trace('parent',parent.h)
        if verbose: g.trace('**body...\n',body)

    parent = self.adjustParent(parent,headline)
    self.lastParent = self.createFunctionNode(headline,body,parent)

    # Exit the function: restore the function info.
    self.startSigIndent = oldStartSigIndent
#@+node:ekr.20070705094630: *7* putRootText
def putRootText (self,p):

    c = self.c

    self.appendStringToBody(p,'%s@language %s\n@tabwidth %d\n' % (
        self.rootLine,self.language,self.tab_width))
#@+node:ekr.20090122201952.5: *7* setBodyString
#@+node:ekr.20070703122141.88: *7* undentBody
def undentBody (self,s,ignoreComments=True):

    '''Remove the first line's leading indentation from all lines of s.'''

    trace = False
    if trace: g.trace('before...\n',g.listToString(g.splitLines(s)))

    if self.isRst:
        return s # Never unindent rst code.

    # Calculate the amount to be removed from each line.
    undentVal = self.getLeadingIndent(s,0,ignoreComments=ignoreComments)
    if undentVal == 0:
        return s
    else:
        result = self.undentBy(s,undentVal)
        if trace: g.trace('after...\n',g.listToString(g.splitLines(result)))
        return result
#@+node:ekr.20081216090156.1: *7* undentBy
def undentBy (self,s,undentVal):

    '''Remove leading whitespace equivalent to undentVal from each line.
    add an underindentEscapeString for underindented line.'''

    trace = False and not g.app.unitTesting

    if self.isRst:
        return s # Never unindent rst code.

    tag = self.c.atFileCommands.underindentEscapeString
    result = [] ; tab_width = self.tab_width
    for line in g.splitlines(s):
        lws_s = g.get_leading_ws(line)
        lws = g.computeWidth(lws_s,tab_width)
        s = g.removeLeadingWhitespace(line,undentVal,tab_width)
        n = lws - undentVal
        if s.strip() and lws < undentVal:
            if trace: g.trace('undentVal: %s, lws: %s, %s' % (
                undentVal,lws,repr(line)))
            result.append("%s%s%s" % (tag,undentVal-lws,s.lstrip()))
        else:
            result.append(s)

    return ''.join(result)

#@+node:ekr.20070801074524: *7* underindentedComment & underindentedLine
def underindentedComment (self,line):

    if self.atAutoWarnsAboutLeadingWhitespace:
        self.warning(
            'underindented python comments.\nExtra leading whitespace will be added\n' + line)

def underindentedLine (self,line):

    if self.warnAboutUnderindentedLines:
        self.error(
            'underindented line.\n' +
            'Extra leading whitespace will be added\n' + line)
#@+node:ekr.20070703122141.78: *6* error, oops, report and warning
def error (self,s):
    self.errors += 1
    self.importCommands.errors += 1
    if g.unitTesting:
        if self.errors == 1:
            g.app.unitTestDict ['actualErrorMessage'] = s
        g.app.unitTestDict ['actualErrors'] = self.errors
        if 0: # For debugging unit tests.
            g.trace(g.callers())
            g.es_print('',s,color='red')
    else:
        g.es_print('error:',s,color='red')

def oops (self):
    g.pr('baseScannerClass oops: %s must be overridden in subclass' % g.callers())

def report (self,message):
    if self.strict: self.error(message)
    else:           self.warning(message)

def warning (self,s):
    if not g.unitTesting:
        g.es_print('warning:',s,color='red')
#@+node:ekr.20070706084535.1: *6* Parsing
@ Scan and skipDecls would typically not be overridden.
#@+node:ekr.20071201072917: *7* adjustDefStart
def adjustDefStart (self,unused_s,i):

    '''A hook to allow the Python importer to adjust the 
    start of a class or function to include decorators.'''

    return i
#@+node:ekr.20070707150022: *7* extendSignature
def extendSignature(self,unused_s,i):

    '''Extend the signature line if appropriate.
    The text *must* end with a newline.

    For example, the Python scanner appends docstrings if they exist.'''

    return i
#@+node:ekr.20071017132056: *7* getIndent
def getIndent (self,s,i):

    j,junk = g.getLine(s,i)
    junk,indent = g.skip_leading_ws_with_indent(s,j,self.tab_width)
    return indent
#@+node:ekr.20070706101600: *7* scan & scanHelper
def scan (self,s,parent):

    '''A language independent scanner: it uses language-specific helpers.

    Create a child of self.root for:
    - Leading outer-level declarations.
    - Outer-level classes.
    - Outer-level functions.
    '''

    # Init the parser status ivars.
    self.methodsSeen = False

    # Create the initial body text in the root.
    self.putRootText(parent)

    # Parse the decls.
    i = self.skipDecls(s,0,len(s),inClass=False)
    decls = s[:i]

    # Create the decls node.
    if decls: self.createDeclsNode(parent,decls)

    # Scan the rest of the file.
    start,junk,junk = self.scanHelper(s,i,end=len(s),parent=parent,kind='outer')

    # Finish adding to the parent's body text.
    self.addRef(parent)
    if start < len(s):
        self.appendStringToBody(parent,s[start:])

    # Do any language-specific post-processing.
    self.endGen(s)
#@+node:ekr.20071018084830: *8* scanHelper
def scanHelper(self,s,i,end,parent,kind):

    '''Common scanning code used by both scan and putClassHelper.'''

    # g.trace(g.callers())
    # g.trace('i',i,g.get_line(s,i))
    assert kind in ('class','outer')
    start = i ; putRef = False ; bodyIndent = None
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif self.startsClass(s,i):  # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            end2 = self.codeEnd # putClass may change codeEnd ivar.
            self.putClass(s,i,self.sigEnd,self.codeEnd,start,parent)
            i = start = end2
        elif self.startsFunction(s,i): # Sets sigStart,sigEnd & codeEnd ivars.
            putRef = True
            if bodyIndent is None: bodyIndent = self.getIndent(s,i)
            self.putFunction(s,self.sigStart,self.codeEnd,start,parent)
            i = start = self.codeEnd
        elif self.startsId(s,i):
            i = self.skipId(s,i)
        elif kind == 'outer' and g.match(s,i,self.outerBlockDelim1): # Do this after testing for classes.
            i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
            # Bug fix: 2007/11/8: do *not* set start: we are just skipping the block.
        else: i += 1
        assert progress < i,'i: %d, ch: %s' % (i,repr(s[i]))

    return start,putRef,bodyIndent
#@+node:ekr.20070712075148: *7* skipArgs
def skipArgs (self,s,i,kind):

    '''Skip the argument or class list.  Return i, ok

    kind is in ('class','function')'''

    start = i
    i = g.skip_ws_and_nl(s,i)
    if not g.match(s,i,'('):
        return start,kind == 'class'

    i = self.skipParens(s,i)
    # skipParens skips the ')'
    if i >= len(s):
        return start,False
    else:
        return i,True 
#@+node:ekr.20070707073859: *7* skipBlock
def skipBlock(self,s,i,delim1=None,delim2=None):

    '''Skip from the opening delim to *past* the matching closing delim.

    If no matching is found i is set to len(s)'''

    trace = False and not g.unitTesting
    verbose = False
    start = i
    if delim1 is None: delim1 = self.blockDelim1
    if delim2 is None: delim2 = self.blockDelim2
    match1 = g.choose(len(delim1)==1,g.match,g.match_word)
    match2 = g.choose(len(delim2)==1,g.match,g.match_word)
    assert match1(s,i,delim1)
    level = 0 ; start = i
    startIndent = self.startSigIndent
    if trace and verbose:
        g.trace('***','startIndent',startIndent,g.callers())
    while i < len(s):
        progress = i
        if g.is_nl(s,i):
            backslashNewline = i > 0 and g.match(s,i-1,'\\\n')
            i = g.skip_nl(s,i)
            if not backslashNewline and not g.is_nl(s,i):
                j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
                line = g.get_line(s,j)
                if trace and verbose: g.trace('indent',indent,line)
                if indent < startIndent and line.strip():
                    # An non-empty underindented line.
                    # Issue an error unless it contains just the closing bracket.
                    if level == 1 and match2(s,j,delim2):
                        pass
                    else:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedLine(line)
        elif s[i] in (' ','\t',):
            i += 1 # speed up the scan.
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
        elif match1(s,i,delim1):
            level += 1 ; i += len(delim1)
        elif match2(s,i,delim2):
            level -= 1 ; i += len(delim2)
            # Skip junk following Pascal 'end'
            for z in self.blockDelim2Cruft:
                i2 = g.skip_ws(s,i)
                if g.match(s,i2,z):
                    i = i2 + len(z)
                    break
            if level <= 0:
                # 2010/09/20
                # Skip a single-line comment if it exists.
                j = g.skip_ws(s,i)
                if (g.match(s,j,self.lineCommentDelim) or
                    g.match(s,j,self.lineCommentDelim2)
                ):
                    i = g.skip_to_end_of_line(s,i)
                if trace: g.trace('returns:',repr(s[start:i]))
                return i

        else: i += 1
        assert progress < i

    self.error('no block: %s' % self.root.h)
    if 1:
        i,j = g.getLine(s,start)
        g.trace(i,s[i:j])
    else:
        if trace: g.trace('** no block')
    return start
#@+node:ekr.20070712091019: *7* skipCodeBlock
def skipCodeBlock (self,s,i,kind):

    '''Skip the code block in a function or class definition.'''

    trace = False
    start = i
    i = self.skipBlock(s,i,delim1=None,delim2=None)

    if self.sigFailTokens:
        i = g.skip_ws(s,i)
        for z in self.sigFailTokens:
            if g.match(s,i,z):
                if trace: g.trace('failtoken',z)
                return start,False

    if i > start:
        i = self.skipNewline(s,i,kind)

    if trace:
        g.trace(g.callers())
        g.trace('returns...\n',g.listToString(g.splitLines(s[start:i])))

    return i,True
#@+node:ekr.20070711104014: *7* skipComment & helper
def skipComment (self,s,i):

    '''Skip a comment and return the index of the following character.'''

    if g.match(s,i,self.lineCommentDelim) or g.match(s,i,self.lineCommentDelim2):
        return g.skip_to_end_of_line(s,i)
    else:
        return self.skipBlockComment(s,i)
#@+node:ekr.20070707074541: *8* skipBlockComment
def skipBlockComment (self,s,i):

    '''Skip past a block comment.'''

    start = i

    # Skip the opening delim.
    if g.match(s,i,self.blockCommentDelim1):
        delim2 = self.blockCommentDelim2
        i += len(self.blockCommentDelim1)
    elif g.match(s,i,self.blockCommentDelim1_2):
        i += len(self.blockCommentDelim1_2)
        delim2 = self.blockCommentDelim2_2
    else:
        assert False

    # Find the closing delim.
    k = s.find(delim2,i)
    if k == -1:
        self.error('Run on block comment: ' + s[start:i])
        return len(s)
    else:
        return k + len(delim2)
#@+node:ekr.20070707080042: *7* skipDecls
def skipDecls (self,s,i,end,inClass):

    '''Skip everything until the start of the next class or function.

    The decls *must* end in a newline.'''

    trace = False or self.trace
    start = i ; prefix = None
    classOrFunc = False
    if trace: g.trace(g.callers())
    while i < end:
        progress = i
        if s[i] in (' ','\t','\n'):
            i += 1 # Prevent lookahead below, and speed up the scan.
        elif self.startsComment(s,i):
            # Add the comment to the decl if it *doesn't* start the line.
            i2,junk = g.getLine(s,i)
            i2 = g.skip_ws(s,i2)
            if i2 == i and prefix is None:
                prefix = i2 # Bug fix: must include leading whitespace in the comment.
            i = self.skipComment(s,i)
        elif self.startsString(s,i):
            i = self.skipString(s,i)
            prefix = None
        elif self.startsClass(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsFunction(s,i):
            # Important: do not include leading ws in the decls.
            classOrFunc = True
            i = g.find_line_start(s,i)
            i = self.adjustDefStart(s,i)
            break
        elif self.startsId(s,i):
            i = self.skipId(s,i)
            prefix = None
        # Don't skip outer blocks: they may contain classes.
        elif g.match(s,i,self.outerBlockDelim1):
            if self.outerBlockEndsDecls:
                break
            else:
                i = self.skipBlock(s,i,delim1=self.outerBlockDelim1,delim2=self.outerBlockDelim2)
        else:
            i += 1 ;  prefix = None
        assert(progress < i)

    if prefix is not None:
        i = g.find_line_start(s,prefix) # i = prefix
    decls = s[start:i]
    if inClass and not classOrFunc:
        # Don't return decls if a class contains nothing but decls.
        if trace and decls.strip(): g.trace('**class is all decls...\n',decls)
        return start
    elif decls.strip(): 
        if trace or self.trace: g.trace('\n'+decls)
        return i
    else: # Ignore empty decls.
        return start
#@+node:ekr.20070707094858.1: *7* skipId
def skipId (self,s,i):

    return g.skip_id(s,i,chars=self.extraIdChars)
#@+node:ekr.20070730134936: *7* skipNewline
def skipNewline(self,s,i,kind):

    '''Skip whitespace and comments up to a newline, then skip the newline.
    Issue an error if no newline is found.'''

    while i < len(s):
        i = g.skip_ws(s,i)
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        else: break

    if i >= len(s):
        return len(s)

    if g.match(s,i,'\n'):
        i += 1
    else:
        self.error(
            '%s %s does not end in a newline; one will be added\n%s' % (
                kind,self.sigId,g.get_line(s,i)))
        # g.trace(g.callers())

    return i
#@+node:ekr.20070712081451: *7* skipParens
def skipParens (self,s,i):

    '''Skip a parenthisized list, that might contain strings or comments.'''

    return self.skipBlock(s,i,delim1='(',delim2=')')
#@+node:ekr.20070707073627.2: *7* skipString
def skipString (self,s,i):

    # Returns len(s) on unterminated string.
    return g.skip_string(s,i,verbose=False)
#@+node:ekr.20070711132314: *7* startsClass/Function (baseClass) & helpers
# We don't expect to override this code, but subclasses may override the helpers.

def startsClass (self,s,i):
    '''Return True if s[i:] starts a class definition.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasClasses and self.startsHelper(s,i,kind='class',tags=self.classTags)
    return val

def startsFunction (self,s,i):
    '''Return True if s[i:] starts a function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''
    val = self.hasFunctions and self.startsHelper(s,i,kind='function',tags=self.functionTags)
    return val
#@+node:ekr.20070711134534: *8* getSigId
def getSigId (self,ids):

    '''Return the signature's id.

    By default, this is the last id in the ids list.'''

    return ids and ids[-1]
#@+node:ekr.20070711140703: *8* skipSigStart
def skipSigStart (self,s,i,kind,tags):

    '''Skip over the start of a function/class signature.

    tags is in (self.classTags,self.functionTags).

    Return (i,ids) where ids is list of all ids found, in order.'''

    trace = False and self.trace # or kind =='function'
    ids = [] ; classId = None
    if trace: g.trace('*entry',kind,i,s[i:i+20])
    start = i
    while i < len(s):
        j = g.skip_ws_and_nl(s,i)
        for z in self.sigFailTokens:
            if g.match(s,j,z):
                if trace: g.trace('failtoken',z,'ids',ids)
                return start, [], None
        for z in self.sigHeadExtraTokens:
            if g.match(s,j,z):
                i += len(z) ; break
        else:
            i = self.skipId(s,j)
            theId = s[j:i]
            if theId and theId in tags: classId = theId
            if theId: ids.append(theId)
            else: break

    if trace: g.trace('*exit ',kind,i,i < len(s) and s[i],ids,classId)
    return i, ids, classId
#@+node:ekr.20070712082913: *8* skipSigTail
def skipSigTail(self,s,i,kind):

    '''Skip from the end of the arg list to the start of the block.'''

    trace = False and self.trace
    start = i
    i = g.skip_ws(s,i)
    for z in self.sigFailTokens:
        if g.match(s,i,z):
            if trace: g.trace('failToken',z,'line',g.skip_line(s,i))
            return i,False
    while i < len(s):
        if self.startsComment(s,i):
            i = self.skipComment(s,i)
        elif g.match(s,i,self.blockDelim1):
            if trace: g.trace(repr(s[start:i]))
            return i,True
        else:
            i += 1
    if trace: g.trace('no block delim')
    return i,False
#@+node:ekr.20070712112008: *8* startsHelper
def startsHelper(self,s,i,kind,tags):
    '''return True if s[i:] starts a class or function.
    Sets sigStart, sigEnd, sigId and codeEnd ivars.'''

    # if not tags: return False

    trace = False or self.trace
    verbose = False # kind=='function'
    self.codeEnd = self.sigEnd = self.sigId = None
    self.sigStart = i

    # Underindented lines can happen in any language, not just Python.
    # The skipBlock method of the base class checks for such lines.
    self.startSigIndent = self.getLeadingIndent(s,i)

    # Get the tag that starts the class or function.
    j = g.skip_ws_and_nl(s,i)
    i = self.skipId(s,j)
    self.sigId = theId = s[j:i] # Set sigId ivar 'early' for error messages.
    if not theId: return False

    if tags:
        if theId not in tags:
            if trace and verbose: g.trace('**** %s theId: %s not in tags: %s' % (kind,theId,tags))
            return False

    if trace and verbose: g.trace('kind',kind,'id',theId)

    # Get the class/function id.
    if kind == 'class' and self.sigId in self.anonymousClasses:
        # A hack for Delphi Pascal: interfaces have no id's.
        # g.trace('anonymous',self.sigId)
        classId = theId
        sigId = ''
    else:
        i, ids, classId = self.skipSigStart(s,j,kind,tags) # Rescan the first id.
        sigId = self.getSigId(ids)
        if not sigId:
            if trace and verbose: g.trace('**no sigId',g.get_line(s,i))
            return False

    if self.output_indent < self.startSigIndent:
        if trace: g.trace('**over-indent',sigId)
            #,'output_indent',self.output_indent,'startSigIndent',self.startSigIndent)
        return False

    # Skip the argument list.
    i, ok = self.skipArgs(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no args',g.get_line(s,i))
        return False
    i = g.skip_ws_and_nl(s,i)

    # Skip the tail of the signature
    i, ok = self.skipSigTail(s,i,kind)
    if not ok:
        if trace and verbose: g.trace('no tail',g.get_line(s,i))
        return False
    sigEnd = i

    # A trick: make sure the signature ends in a newline,
    # even if it overlaps the start of the block.
    if not g.match(s,sigEnd,'\n') and not g.match(s,sigEnd-1,'\n'):
        if trace and verbose: g.trace('extending sigEnd')
        sigEnd = g.skip_line(s,sigEnd)

    if self.blockDelim1:
        i = g.skip_ws_and_nl(s,i)
        if kind == 'class' and self.sigId in self.anonymousClasses:
            pass # Allow weird Pascal unit's.
        elif not g.match(s,i,self.blockDelim1):
            if trace and verbose: g.trace('no block',g.get_line(s,i))
            return False

    i,ok = self.skipCodeBlock(s,i,kind)
    if not ok: return False
        # skipCodeBlock skips the trailing delim.

    # Success: set the ivars.
    self.sigStart = self.adjustDefStart(s,self.sigStart)
    self.codeEnd = i
    self.sigEnd = sigEnd
    self.sigId = sigId
    self.classId = classId

    # Note: backing up here is safe because
    # we won't back up past scan's 'start' point.
    # Thus, characters will never be output twice.
    k = self.sigStart
    if not g.match(s,k,'\n'):
        self.sigStart = g.find_line_start(s,k)

    # Issue this warning only if we have a real class or function.
    if 0: # wrong.
        if s[self.sigStart:k].strip():
            self.error('%s definition does not start a line\n%s' % (
                kind,g.get_line(s,k)))

    if trace: g.trace(kind,'returns\n'+s[self.sigStart:i])
    return True
#@+node:ekr.20070711104014.1: *7* startsComment
def startsComment (self,s,i):

    return (
        g.match(s,i,self.lineCommentDelim) or
        g.match(s,i,self.lineCommentDelim2) or
        g.match(s,i,self.blockCommentDelim1) or
        g.match(s,i,self.blockCommentDelim1_2)
    )
#@+node:ekr.20070707094858.2: *7* startsId
def startsId(self,s,i):

    return g.is_c_id(s[i:i+1])
#@+node:ekr.20070707172732.1: *7* startsString
def startsString(self,s,i):

    return g.match(s,i,'"') or g.match(s,i,"'")
#@+node:ekr.20070707072749: *6* run (baseScannerClass)
def run (self,s,parent):

    c = self.c
    self.root = root = parent.copy()
    self.file_s = s
    self.tab_width = self.importCommands.getTabWidth(p=root)
    # g.trace('tab_width',self.tab_width)
    # Create the ws equivalent to one tab.
    if self.tab_width < 0:
        self.tab_ws = ' '*abs(self.tab_width)
    else:
        self.tab_ws = '\t'

    # Init the error/status info.
    self.errors = 0
    self.errorLines = []
    self.mismatchWarningGiven = False
    changed = c.isChanged()

    # Use @verbatim to escape section references
    if self.escapeSectionRefs: # 2009/12/27
        s = self.escapeFalseSectionReferences(s)

    # Check for intermixed blanks and tabs.
    if self.strict or self.atAutoWarnsAboutLeadingWhitespace:
        if not self.isRst:
            self.checkBlanksAndTabs(s)

    # Regularize leading whitespace for strict languages only.
    if self.strict: s = self.regularizeWhitespace(s) 

    # Generate the nodes, including directive and section references.
    self.scan(s,parent)

    # Check the generated nodes.
    # Return True if the result is equivalent to the original file.
    ok = self.errors == 0 and self.check(s,parent)
    g.app.unitTestDict ['result'] = ok

    # Insert an @ignore directive if there were any serious problems.
    if not ok: self.insertIgnoreDirective(parent)

    if self.atAuto and ok:
        for p in root.self_and_subtree():
            p.clearDirty()
        c.setChanged(changed)
    else:
        root.setDirty(setDescendentsDirty=False)
        c.setChanged(True)
#@+node:ekr.20071110105107: *7* checkBlanksAndTabs
def checkBlanksAndTabs(self,s):

    '''Check for intermixed blank & tabs.'''

    # Do a quick check for mixed leading tabs/blanks.
    blanks = tabs = 0

    for line in g.splitLines(s):
        lws = line[0:g.skip_ws(line,0)]
        blanks += lws.count(' ')
        tabs += lws.count('\t')

    ok = blanks == 0 or tabs == 0

    if not ok:
        self.report('intermixed blanks and tabs')

    return ok
#@+node:ekr.20070808115837.1: *7* regularizeWhitespace
def regularizeWhitespace (self,s):

    '''Regularize leading whitespace in s:
    Convert tabs to blanks or vice versa depending on the @tabwidth in effect.
    This is only called for strict languages.'''

    changed = False ; lines = g.splitLines(s) ; result = [] ; tab_width = self.tab_width

    if tab_width < 0: # Convert tabs to blanks.
        for line in lines:
            i, w = g.skip_leading_ws_with_indent(line,0,tab_width)
            s = g.computeLeadingWhitespace(w,-abs(tab_width)) + line [i:] # Use negative width.
            if s != line: changed = True
            result.append(s)
    elif tab_width > 0: # Convert blanks to tabs.
        for line in lines:
            s = g.optimizeLeadingWhitespace(line,abs(tab_width)) # Use positive width.
            if s != line: changed = True
            result.append(s)

    if changed:
        action = g.choose(self.tab_width < 0,'tabs converted to blanks','blanks converted to tabs')
        message = 'inconsistent leading whitespace. %s' % action
        self.report(message)

    return ''.join(result)
#@+node:ekr.20070703122141.100: *5* class pythonScanner
class pythonScanner (baseScannerClass):

    @others
#@+node:ekr.20070703122141.101: *6*  __init__
def __init__ (self,importCommands,atAuto):

    # Init the base class.
    baseScannerClass.__init__(self,importCommands,atAuto=atAuto,language='python')

    # Set the parser delims.
    self.lineCommentDelim = '#'
    self.classTags = ['class',]
    self.functionTags = ['def',]
    self.blockDelim1 = self.blockDelim2 = None
        # Suppress the check for the block delim.
        # The check is done in skipSigTail.
    self.strict = True

#@+node:ekr.20071201073102.1: *6* adjustDefStart (python)
def adjustDefStart (self,s,i):

    '''A hook to allow the Python importer to adjust the 
    start of a class or function to include decorators.'''

    if i == 0 or s[i-1] != '\n':
        return i

    while i > 0:
        progress = i

        start = j = g.find_line_start(s,i-2)
        j = g.skip_ws(s,j)
        if not g.match(s,j,'@'):
            return i

        j += 1
        k = g.skip_id(s,j)
        word = s[j:k]

        if word and word not in g.globalDirectiveList:
            # g.trace(repr(word),repr(s[start:i]))
            i = start
            assert i < progress
        else:
            return i
#@+node:ekr.20070707113839: *6* extendSignature
def extendSignature(self,s,i):

    '''Extend the text to be added to the class node following the signature.

    The text *must* end with a newline.'''

    # Add a docstring to the class node,
    # And everything on the line following it
    j = g.skip_ws_and_nl(s,i)
    if g.match(s,j,'"""') or g.match(s,j,"'''"):
        j = g.skip_python_string(s,j)
        if j < len(s): # No scanning error.
            # Return the docstring only if nothing but whitespace follows.
            j = g.skip_ws(s,j)
            if g.is_nl(s,j):
                return j + 1

    return i
#@+node:ekr.20070707073627.4: *6* skipString
def skipString (self,s,i):

    # Returns len(s) on unterminated string.
    return g.skip_python_string(s,i,verbose=False)
#@+node:ekr.20070712090019.1: *6* skipCodeBlock (python) & helpers
def skipCodeBlock (self,s,i,kind):

    trace = False ; verbose = True
    # if trace: g.trace('***',g.callers())
    startIndent = self.startSigIndent
    if trace: g.trace('startIndent',startIndent)
    assert startIndent is not None
    i = start = g.skip_ws_and_nl(s,i)
    parenCount = 0
    underIndentedStart = None # The start of trailing underindented blank or comment lines.
    while i < len(s):
        progress = i
        ch = s[i]
        if g.is_nl(s,i):
            i = g.skip_nl(s,i)
            j = g.skip_ws(s,i)
            if g.is_nl(s,j):
                pass # We have already made progress.
            else:
                if trace and verbose: g.trace(g.get_line(s,i))
                backslashNewline = (i > 0 and g.match(s,i-1,'\\\n'))
                if not backslashNewline:
                    i,underIndentedStart,breakFlag = self.pythonNewlineHelper(
                        s,i,parenCount,startIndent,underIndentedStart)
                    if breakFlag: break
        elif ch == '#':
            i = g.skip_to_end_of_line(s,i)
        elif ch == '"' or ch == '\'':
            i = g.skip_python_string(s,i)
        elif ch in '[{(':
            i += 1 ; parenCount += 1
            # g.trace('ch',ch,parenCount)
        elif ch in ']})':
            i += 1 ; parenCount -= 1
            # g.trace('ch',ch,parenCount)
        else: i += 1
        assert(progress < i)

    # The actual end of the block.
    if underIndentedStart is not None:
        i = underIndentedStart
        if trace: g.trace('***backtracking to underindent range')
        if trace: g.trace(g.get_line(s,i))

    if 0 < i < len(s) and not g.match(s,i-1,'\n'):
        g.trace('Can not happen: Python block does not end in a newline.')
        g.trace(g.get_line(s,i))
        return i,False

    # 2010/02/19: Include all following material
    # until the next 'def' or 'class'
    i = self.skipToTheNextClassOrFunction(s,i,startIndent)

    if (trace or self.trace) and s[start:i].strip():
        g.trace('%s returns\n' % (kind) + s[start:i])
    return i,True
#@+node:ekr.20070801080447: *7* pythonNewlineHelper
def pythonNewlineHelper (self,s,i,parenCount,startIndent,underIndentedStart):

    trace = False
    breakFlag = False
    j, indent = g.skip_leading_ws_with_indent(s,i,self.tab_width)
    if trace: g.trace(
        'startIndent',startIndent,'indent',indent,'parenCount',parenCount,
        'line',repr(g.get_line(s,j)))
    if indent <= startIndent and parenCount == 0:
        # An underindented line: it ends the block *unless*
        # it is a blank or comment line or (2008/9/1) the end of a triple-quoted string.
        if g.match(s,j,'#'):
            if trace: g.trace('underindent: comment')
            if underIndentedStart is None: underIndentedStart = i
            i = j
        elif g.match(s,j,'\n'):
            if trace: g.trace('underindent: blank line')
            # Blank lines never start the range of underindented lines.
            i = j
        else:
            if trace: g.trace('underindent: end of block')
            breakFlag = True # The actual end of the block.
    else:
        if underIndentedStart and g.match(s,j,'\n'):
            # Add the blank line to the underindented range.
            if trace: g.trace('properly indented blank line extends underindent range')
        elif underIndentedStart and g.match(s,j,'#'):
            # Add the (properly indented!) comment line to the underindented range.
            if trace: g.trace('properly indented comment line extends underindent range')
        elif underIndentedStart is None:
            pass
        else:
            # A properly indented non-comment line.
            # Give a message for all underindented comments in underindented range.
            if trace: g.trace('properly indented line generates underindent errors')
            s2 = s[underIndentedStart:i]
            lines = g.splitlines(s2)
            for line in lines:
                if line.strip():
                    junk, indent = g.skip_leading_ws_with_indent(line,0,self.tab_width)
                    if indent <= startIndent:
                        if j not in self.errorLines: # No error yet given.
                            self.errorLines.append(j)
                            self.underindentedComment(line)
            underIndentedStart = None
    if trace: g.trace('breakFlag',breakFlag,'returns',i,'underIndentedStart',underIndentedStart)
    return i,underIndentedStart,breakFlag
#@+node:ekr.20100223094350.5834: *7* skipToTheNextClassOrFunction (New in 4.8)
def skipToTheNextClassOrFunction(self,s,i,lastIndent):

    '''Skip to the next python def or class.
    Return the original i if nothing more is found.
    This allows the "if __name__ == '__main__' hack
    to appear at the top level.'''

    return i ### A rewrite may be needed.

    trace = False # and not g.unitTesting
    c,found,i1 = self.c,False,i
    at_line_start,last_comment,last_nl = True,None,-1
    while i < len(s):
        progress = i
        if self.startsComment(s,i):
            # Break at underindented comments.
            if at_line_start:
                if i == last_nl:
                    n = 0
                else:
                    ws = s[last_nl+1:i]
                    n = g.computeWidth (ws,c.tab_width)
                if n < lastIndent:
                    if trace: g.trace('underindented comment',
                        'ws',repr(ws),'n',n,'lastIndent',lastIndent)
                    found = True ; break
                else:
                    # Remember the start of a range of comments and whitespace.
                    if last_comment is None:
                        last_comment = i
                    last_nl = i = self.skipComment(s,i)
                    at_line_start = True
            else:
                # An interior comment.
                assert last_comment is None
                last_nl = i = self.skipComment(s,i)
                at_line_start = True
        elif self.startsString(s,i):
            at_line_start = False
            last_comment = None
            i = self.skipString(s,i)
        elif at_line_start and (
            g.match_word(s,i,'def') or
            g.match_word(s,i,'class')
        ):
            # Do not break for over-indent matches.
            # This allows something reasonable to happen for::
            # if 0:
            #     def spam():
            #         pass
            ws = s[last_nl+1:i]
            # g.trace('ws',repr(ws))
            n = g.computeWidth (ws,c.tab_width)
            if (not ws or ws.isspace()) and n <= lastIndent:
                found = True ; break
            else: # Ignore the over-indented def.
                if trace: g.trace('overindented','ws',repr(ws),
                    'n',n,'lastIndent',lastIndent)
                last_comment = None
                last_nl = i = g.skip_to_end_of_line(s,i)
                at_line_start = True
        elif s[i] == '@':
            # Leo directives will look like comments,
            # so we can safely assume we have a decorator
            if at_line_start and last_comment is None:
                last_comment = i
            last_nl = i = g.skip_to_end_of_line(s,i)
            at_line_start = True
        elif s[i] ==  '\n':
            at_line_start = True
            last_nl = i
            i += 1
        elif s[i].isspace():
            i += 1
        else:
            at_line_start = False
            last_comment = None
            i += 1
        assert progress < i

    if found:
        if last_comment is None:
            return i
        else:
            return last_comment
    else:
        return i1
#@+node:ekr.20070803101619: *6* skipSigTail
# This must be overridden in order to handle newlines properly.

def skipSigTail(self,s,i,kind):

    '''Skip from the end of the arg list to the start of the block.'''

    while i < len(s):
        ch = s[i]
        if ch == '\n':
            break
        elif ch in (' ','\t',):
            i += 1
        elif self.startsComment(s,i):
            i = self.skipComment(s,i)
        else:
            break

    return i,g.match(s,i,':')
#@+node:ekr.20090131200406.11: *4* Remove remaining tk-isms from Leo's core
@nocolor-node

Eliminate all tk-indices from leoEditCommands.py

These are marked with ###

(found) wordend, wordstart
(found) lineend, linestart
(found) sel.first, sel.last
(found) w.insert, w.delete
#@+node:ekr.20100108101415.6196: *4* Create insert-tab commands
insert-tab-or-indent-region, insert-hard-tab, insert-soft-tab.
#@+node:ekr.20100122104234.6168: *4* Keystroke for add-nocolor-node ?
Generalize?
#@+node:ekr.20070624135822: *5* Templates for common code fragments
@
Use completion to show fragments.
Allow settings to create fragments:
    - @fragments
        - @fragment name
            body contains actual fragment.

@c

# Invent a way for simple keystrokes to insert fragments, such as:

Fragment 1:

c.beginUpdate()
try:
    pass
finally:
    endUpdate()

Fragment 2:

for p in c.all_positions():
    pass
#@+node:ekr.20090201122309.5: *4* Improve macro commands: and really use them!
@nocolor-node

- The recording logic now returns the entire event.
- The leoKeyEvent ctor now gets the stroke from self.actualEvent.
- Recording ends with ctrl-g: a small changed to k.masterKeyHandler.
- Playing back the macro just calls k.masterKeyHandler.
- Pickle the minimal representation of a key event, namely the stroke.

#@+node:ekr.20100211072044.5754: *4* Dubious usages of .unitTesting
#@+node:ekr.20031218072017.1723: *5* createMenuEntries
def createMenuEntries (self,menu,table,dynamicMenu=False):

    '''Create a menu entry from the table.
    New in 4.4: this method shows the shortcut in the menu,
    but this method **never** binds any shortcuts.'''

    c = self.c ; f = c.frame ; k = c.k
    if g.app.unitTesting: return

    trace = False
    for data in table:
        << get label & command or continue >>
        << compute commandName & accel from label & command >>
        # Bug fix: 2009/09/30: use canonical stroke.
        accelerator = k.shortcutFromSetting(accel,addKey=False) or ''
        stroke = k.shortcutFromSetting(accel,addKey=True) or ''
        if accelerator:
            accelerator = g.stripBrackets(k.prettyPrintKey(accelerator))
        if trace: # and commandName == 'add-comments':
            g.trace(bunch.val,repr(stroke),repr(accelerator),commandName)
        def masterMenuCallback (c=c,k=k,stroke=stroke,command=command,commandName=commandName,event=None):
            # if trace: g.trace('stroke',stroke)
            return k.masterMenuHandler(stroke,command,commandName)

        realLabel = self.getRealMenuName(label)
        amp_index = realLabel.find("&")
        realLabel = realLabel.replace("&","")
        if sys.platform == 'darwin':
            << clear accelerator if it is a plain key >>

        # c.add_command ensures that c.outerUpdate is called.
        if menu:
            c.add_command(menu,label=realLabel,
                accelerator=accelerator,
                command=masterMenuCallback,
                underline=amp_index)
#@+node:ekr.20051021091958: *6* << get label & command or continue >>
if g.isString(data):
    # New in Leo 4.4.2: Can use the same string for both the label and the command string.
    ok = True
    s = data
    removeHyphens = s and s[0]=='*'
    if removeHyphens: s = s[1:]
    label = self.capitalizeMinibufferMenuName(s,removeHyphens)
    command = s.replace('&','').lower()
    if label == '-':
        self.add_separator(menu)
        continue # That's all.
else:
    ok = type(data) in (type(()), type([])) and len(data) in (2,3)
    if ok:
        if len(data) == 2:
            # New in 4.4b2: command can be a minibuffer-command name (a string)
            label,command = data
        else:
            # New in 4.4: we ignore shortcuts bound in menu tables.
            label,junk,command = data

        if label in (None,'-'):
            self.add_separator(menu)
            continue # That's all.
    else:
        g.trace('bad data in menu table: %s' % repr(data))
        continue # Ignore bad data
#@+node:ekr.20031218072017.1725: *6* << compute commandName & accel from label & command >>
# New in 4.4b2: command can be a minibuffer-command name (a string)
minibufferCommand = type(command) == type('')
accel = None
if minibufferCommand:
    commandName = command 
    command = c.commandsDict.get(commandName)
    if command:
        rawKey,bunchList = c.config.getShortcut(commandName)
        # Pick the first entry that is not a mode.
        for bunch in bunchList:
            if not bunch.pane.endswith('-mode'):
                accel = bunch and bunch.val
                if bunch.pane  == 'text': break # New in Leo 4.4.2: prefer text bindings.
    else:
        if not g.app.unitTesting and not dynamicMenu:
            # Don't warn during unit testing.
            # This may come from a plugin that normally isn't enabled.
            if trace: g.trace('No inverse for %s' % commandName)
        continue # There is no way to make this menu entry.
else:
    # First, get the old-style name.
    commandName = self.computeOldStyleShortcutKey(label)
    rawKey,bunchList = c.config.getShortcut(commandName)
    for bunch in bunchList:
        if not bunch.pane.endswith('-mode'):
            if trace: g.trace('2','%20s' % (bunch.val),commandName)
            accel = bunch and bunch.val ; break
    # Second, get new-style name.
    if not accel:
        << compute emacs_name >>
            # Contains the not-so-horrible kludge.
        if emacs_name:
            commandName = emacs_name
            rawKey,bunchList = c.config.getShortcut(emacs_name)
            # Pick the first entry that is not a mode.
            for bunch in bunchList:
                if not bunch.pane.endswith('-mode'):
                    accel = bunch.val
                    if trace: g.trace('3','%20s' % (bunch.val),commandName)
                    break
        elif not dynamicMenu:
            g.trace('No inverse for %s' % commandName)
#@+node:ekr.20051021100806.1: *7* << compute emacs_name >>
@ One not-so-horrible kludge remains.

The cut/copy/paste commands in the menu tables are not the same as the methods
actually bound to cut/copy/paste-text minibuffer commands, so we must do a bit
of extra translation to discover whether the user has overridden their
bindings.
@c

if command in (f.OnCutFromMenu,f.OnCopyFromMenu,f.OnPasteFromMenu):
    emacs_name = '%s-text' % commandName
else:
    try: # User errors in the table can cause this.
        emacs_name = k.inverseCommandsDict.get(command.__name__)
    except Exception:
        emacs_name = None
#@+node:ekr.20060216110502: *6* << clear accelerator if it is a plain key >>
for z in ('Alt','Ctrl','Command'):
    if accelerator.find(z) != -1:
        break # Found.
else:
    accelerator = ''
#@+node:ekr.20051022043608.1: *5* createOpenWithMenuItemsFromTable
def createOpenWithMenuItemsFromTable (self,menu,table):

    '''Create an entry in the Open with Menu from the table.

    Each entry should be a sequence with 2 or 3 elements.'''

    c = self.c ; k = c.k

    if g.app.unitTesting: return

    for data in table:
        << get label, accelerator & command or continue >>
        # g.trace(label,accelerator)
        realLabel = self.getRealMenuName(label)
        underline=realLabel.find("&")
        realLabel = realLabel.replace("&","")
        callback = self.defineOpenWithMenuCallback(openWithData)

        c.add_command(menu,label=realLabel,
            accelerator=accelerator or '',
            command=callback,underline=underline)
#@+node:ekr.20051022043713.1: *6* << get label, accelerator & command or continue >>
ok = (
    type(data) in (type(()), type([])) and
    len(data) in (2,3)
)

if ok:
    if len(data) == 2:
        label,openWithData = data ; accelerator = None
    else:
        label,accelerator,openWithData = data
        accelerator = k.shortcutFromSetting(accelerator)
        accelerator = accelerator and g.stripBrackets(k.prettyPrintKey(accelerator))
else:
    g.trace('bad data in Open With table: %s' % repr(data))
    continue # Ignore bad data
#@+node:ekr.20031218072017.1725: *5* << compute commandName & accel from label & command >>
# New in 4.4b2: command can be a minibuffer-command name (a string)
minibufferCommand = type(command) == type('')
accel = None
if minibufferCommand:
    commandName = command 
    command = c.commandsDict.get(commandName)
    if command:
        rawKey,bunchList = c.config.getShortcut(commandName)
        # Pick the first entry that is not a mode.
        for bunch in bunchList:
            if not bunch.pane.endswith('-mode'):
                accel = bunch and bunch.val
                if bunch.pane  == 'text': break # New in Leo 4.4.2: prefer text bindings.
    else:
        if not g.app.unitTesting and not dynamicMenu:
            # Don't warn during unit testing.
            # This may come from a plugin that normally isn't enabled.
            if trace: g.trace('No inverse for %s' % commandName)
        continue # There is no way to make this menu entry.
else:
    # First, get the old-style name.
    commandName = self.computeOldStyleShortcutKey(label)
    rawKey,bunchList = c.config.getShortcut(commandName)
    for bunch in bunchList:
        if not bunch.pane.endswith('-mode'):
            if trace: g.trace('2','%20s' % (bunch.val),commandName)
            accel = bunch and bunch.val ; break
    # Second, get new-style name.
    if not accel:
        << compute emacs_name >>
            # Contains the not-so-horrible kludge.
        if emacs_name:
            commandName = emacs_name
            rawKey,bunchList = c.config.getShortcut(emacs_name)
            # Pick the first entry that is not a mode.
            for bunch in bunchList:
                if not bunch.pane.endswith('-mode'):
                    accel = bunch.val
                    if trace: g.trace('3','%20s' % (bunch.val),commandName)
                    break
        elif not dynamicMenu:
            g.trace('No inverse for %s' % commandName)
#@+node:ekr.20051021100806.1: *6* << compute emacs_name >>
@ One not-so-horrible kludge remains.

The cut/copy/paste commands in the menu tables are not the same as the methods
actually bound to cut/copy/paste-text minibuffer commands, so we must do a bit
of extra translation to discover whether the user has overridden their
bindings.
@c

if command in (f.OnCutFromMenu,f.OnCopyFromMenu,f.OnPasteFromMenu):
    emacs_name = '%s-text' % commandName
else:
    try: # User errors in the table can cause this.
        emacs_name = k.inverseCommandsDict.get(command.__name__)
    except Exception:
        emacs_name = None
#@+node:ekr.20061031131434.49: *5* scan
def scan (self,event=None,verbose=True,thread=True):

    c = self.c
    if not c or not c.exists or c.frame.isNullFrame: return
    if g.app.unitTesting: return

    # g.trace('autocompleter')

    if 0: # thread:
        # Use a thread to do the initial scan so as not to interfere with the user.            
        def scan ():
            #g.es("This is for testing if g.es blocks in a thread", color = 'pink' )
            # During unit testing c gets destroyed before the scan finishes.
            if not g.app.unitTesting:
                self.scanOutline(verbose=True)

        t = threading.Thread(target=scan)
        t.setDaemon(True)
        t.start()
    else:
        self.scanOutline(verbose=verbose)
#@+node:ekr.20060127052111.1: *5* cutStack
def cutStack (self):

    u = self ; n = u.max_undo_stack_size

    if n > 0 and u.bead >= n and not g.app.unitTesting:

        # Do nothing if we are in the middle of creating a group.
        i = len(u.beads)-1
        while i >= 0:
            bunch = u.beads[i]
            if hasattr(bunch,'kind') and bunch.kind == 'beforeGroup':
                return
            i -= 1

        # This work regardless of how many items appear after bead n.
        # g.trace('Cutting undo stack to %d entries' % (n))
        u.beads = u.beads[-n:]
        u.bead = n-1
        # g.trace('bead:',u.bead,'len(u.beads)',len(u.beads),g.callers())
#@+node:ekr.20061024075542.1: *5* open
def open (fileName=None):

    global g

    init()

    if g.app.unitTesting:
        return

    if not fileName:
        g.es_print('','leoPymacs.open:','no file name')
        return None

    # openWithFileName checks to see if the file is already open.
    ok, frame = g.openWithFileName(
        fileName,
        old_c=None,
        enableLog=False,
        readAtFileNodesFlag=True)

    c = ok and frame.c or None
    if c:
        g.es_print('','leoPymacs.open:',c)
    else:
        g.es_print('','leoPymacs.open:','can not open',fileName)

    return c
#@+node:ekr.20040715155607: *5* g.scanForAtIgnore
def scanForAtIgnore(c,p):

    """Scan position p and its ancestors looking for @ignore directives."""

    if g.app.unitTesting:
        return False # For unit tests.

    for p in p.self_and_parents():
        d = g.get_directives_dict(p)
        if 'ignore' in d:
            return True

    return False
#@+node:tbrown.20090219095555.61: *5* g.handleUrlInUrlNode
def handleUrlInUrlNode(url):

    # Note 1: the UNL plugin has its own notion of what a good url is.

    # Note 2: tree.OnIconDoubleClick now uses the body text of an @url
    #         node if it exists.

    if g.unitTesting: return
    << check the url; return if bad >>
    << pass the url to the web browser >>
#@+node:tbrown.20090219095555.62: *6* << check the url; return if bad >>
@ A valid url is (according to D.T.Hein):

3 or more lowercase alphas, followed by,
one ':', followed by,
one or more of: (excludes !"#;<>[\]^`|)
  $%&'()*+,-./0-9:=?@A-Z_a-z{}~
followed by one of: (same as above, except no minus sign or comma).
  $%&'()*+/0-9:=?@A-Z_a-z}~
@c

urlPattern = "[a-z]{3,}:[\$-:=?-Z_a-z{}~]+[\$-+\/-:=?-Z_a-z}~]"

if not url or len(url) == 0:
    g.es("no url following @url")
    return

# Add http:// if required.
if not re.match('^([a-z]{3,}:)',url):
    url = 'http://' + url
if not re.match(urlPattern,url):
    g.es("invalid url:",url)
    return
#@+node:tbrown.20090219095555.63: *6* << pass the url to the web browser >>
@ Most browsers should handle the following urls:
  ftp://ftp.uu.net/public/whatever.
  http://localhost/MySiteUnderDevelopment/index.html
  file://home/me/todolist.html
@c

try:
    import os
    os.chdir(g.app.loadDir)
    if g.match(url,0,"file:") and url[-4:]==".leo":
        ok,frame = g.openWithFileName(url[5:],None)
    else:
        import webbrowser
        # Mozilla throws a weird exception, then opens the file!
        try: webbrowser.open(url)
        except: pass
except:
    g.es("exception opening",url)
    g.es_exception()
#@+node:ekr.20050920084036.229: *5* yankRectangle
def yankRectangle (self,event,killRect=None):

    '''Yank into the rectangle defined by the start and end of selected text.'''

    c = self.c ; k = self.k
    w = self.editWidget(event)
    if not w: return

    killRect = killRect or self.theKillRectangle
    if g.app.unitTesting:
        # This value is used by the unit test.
        killRect = ['Y1Y','Y2Y','Y3Y','Y4Y']
    elif not killRect:
        k.setLabelGrey('No kill rect') ; return

    w,r1,r2,r3,r4 = self.beginCommand('yank-rectangle')

    n = 0
    for r in range(r1,r3+1):
        # g.trace(n,r,killRect[n])
        if n >= len(killRect): break
        w.delete('%s.%s' % (r,r2), '%s.%s' % (r,r4))
        w.insert('%s.%s' % (r,r2), killRect[n])
        n += 1

    i = '%s.%s' % (r1,r2)
    j = '%s.%s' % (r3,r2+len(killRect[n-1]))
    w.setSelectionRange(i,j,insert=j)

    self.endCommand()
#@+node:ekr.20050920084036.232: *5* stringRectangle
def stringRectangle (self,event):

    '''Prompt for a string, then replace the contents of a rectangle
    with a string on each line.'''

    c = self.c ; k = self.k ; state = k.getState('string-rect')
    if g.app.unitTesting:
        state = 1 ; k.arg = 's...s' # This string is known to the unit test.
        w = self.editWidget(event)
        self.stringRect = self.getRectanglePoints(w)
    if state == 0:
        w = self.editWidget(event) # sets self.w
        if not w or not self.check(event): return
        self.stringRect = self.getRectanglePoints(w)
        k.setLabelBlue('String rectangle: ',protect=True)
        k.getArg(event,'string-rect',1,self.stringRectangle)
    else:
        k.clearState()
        k.resetLabel()
        c.bodyWantsFocus()
        w = self.w
        self.beginCommand('string-rectangle')
        r1, r2, r3, r4 = self.stringRect
        s = w.getAllText()
        for r in range(r1,r3+1):
            i = g.convertRowColToPythonIndex(s,r-1,r2)
            j = g.convertRowColToPythonIndex(s,r-1,r4)
            s = s[:i] + k.arg + s[j:]
        w.setAllText(s)
        i = g.convertRowColToPythonIndex(s,r1-1,r2)
        j = g.convertRowColToPythonIndex(s,r3-1,r2+len(k.arg))
        w.setSelectionRange(i,j)
        self.endCommand()
        # 2010/1/1: Fix bug 480422:
        # string-rectangle kills syntax highlighting.
        c.frame.body.recolor(c.p,incremental=False)

#@+node:ekr.20051218133207: *5* backwardParagraphHelper
def backwardParagraphHelper (self,event,extend):

    w = self.editWidget(event)
    if not w: return

    s = w.getAllText()
    i,j = w.getSelectionRange()
    # A hack for wx gui: set the insertion point to the end of the selection range.
    if g.app.unitTesting:
        w.setInsertPoint(j)
    i,j = g.getLine(s,j)
    line = s[i:j]

    if line.strip():
        # Find the start of the present paragraph.
        while i > 0:
            i,j = g.getLine(s,i-1)
            line = s[i:j]
            if not line.strip(): break

    # Find the end of the previous paragraph.
    while i > 0:
        i,j = g.getLine(s,i-1)
        line = s[i:j]
        if line.strip():
            i = j-1 ; break

    self.moveToHelper(event,i,extend)
#@+node:ekr.20090103070824.11: *5* c.checkFileTimeStamp
def checkFileTimeStamp (self,fn):

    '''
    Return True if the file given by fn has not been changed
    since Leo read it or if the user agrees to overwrite it.
    '''

    trace = False and not g.unitTesting
    c = self

    # Don't assume the file still exists.
    if not g.os_path_exists(fn):
        if trace: g.trace('file no longer exists',fn)
        return True

    timeStamp = c.timeStampDict.get(fn)
    if not timeStamp:
        if trace: g.trace('no time stamp',fn)
        return True

    timeStamp2 = os.path.getmtime(fn)
    if timeStamp == timeStamp2:
        if trace: g.trace('time stamps match',fn,timeStamp)
        return True

    if g.app.unitTesting:
        return False

    if trace:
        g.trace('mismatch',timeStamp,timeStamp2)

    message = '%s\n%s\n%s' % (
        fn,
        g.tr('has been modified outside of Leo.'),
        g.tr('Overwrite this file?'))
    ok = g.app.gui.runAskYesNoCancelDialog(c,
        title = 'Overwrite modified file?',
        message = message)

    return ok == 'yes'
#@+node:ekr.20031218072017.2817: *5*  doCommand
command_count = 0

def doCommand (self,command,label,event=None):

    """Execute the given command, invoking hooks and catching exceptions.

    The code assumes that the "command1" hook has completely handled the command if
    g.doHook("command1") returns False.
    This provides a simple mechanism for overriding commands."""

    c = self ; p = c.p
    commandName = command and command.__name__
    c.setLog()

    self.command_count += 1
    if not g.app.unitTesting and c.config.getBool('trace_doCommand'):
        g.trace(commandName)

    # The presence of this message disables all commands.
    if c.disableCommandsMessage:
        g.es(c.disableCommandsMessage,color='blue')
        return 'break' # Inhibit all other handlers.

    if c.exists and c.inCommand and not g.unitTesting:
        # g.trace('inCommand',c)
        g.app.commandInterruptFlag = True
        g.es('ignoring command: already executing a command.',color='red')
        return 'break'

    g.app.commandInterruptFlag = False

    if label and event is None: # Do this only for legacy commands.
        if label == "cantredo": label = "redo"
        if label == "cantundo": label = "undo"
        g.app.commandName = label

    if not g.doHook("command1",c=c,p=p,v=p,label=label):
        try:
            c.inCommand = True
            val = command(event)
            if c and c.exists: # Be careful: the command could destroy c.
                c.inCommand = False
                c.k.funcReturn = val
            # else: g.pr('c no longer exists',c)
        except Exception:
            c.inCommand = False
            if g.app.unitTesting:
                raise
            else:
                g.es_print("exception executing command")
                g.es_exception(c=c)

        if c and c.exists:
            if c.requestCloseWindow:
                g.trace('Closing window after command')
                c.requestCloseWindow = False
                g.app.closeLeoWindow(c.frame)
            else:
                c.outerUpdate()

    # Be careful: the command could destroy c.
    if c and c.exists:
        p = c.p
        g.doHook("command2",c=c,p=p,v=p,label=label)

    return "break" # Inhibit all other handlers.
#@+node:ekr.20090712050729.6017: *5* promptForDangerousWrite
def promptForDangerousWrite (self,fileName,kind):

    c = self.c

    if g.app.unitTesting:
        val = g.app.unitTestDict.get('promptForDangerousWrite')
        return val in (None,True)

    # g.trace(timeStamp, timeStamp2)
    message = '%s %s\n%s\n%s' % (
        kind, fileName,
        g.tr('already exists.'),
        g.tr('Overwrite this file?'))

    ok = g.app.gui.runAskYesNoCancelDialog(c,
        title = 'Overwrite existing file?',
        message = message)

    return ok == 'yes'
#@+node:ekr.20070529083836: *5* cleanLines
def cleanLines (self,p,s):

    '''Return a copy of s, with all trailing whitespace removed.
    If a change was made, update p's body text and set c dirty.'''

    c = self.c ; cleanLines = [] ; changed = False
    lines = g.splitLines(s)
    for line in lines:
        if line.strip():
            cleanLines.append(line)
        elif line.endswith('\n'):
            cleanLines.append('\n')
            if line != '\n': changed = True
        else:
            cleanLines.append('')
            if line != '': changed = True
    s = g.joinLines(cleanLines)

    if changed and not g.app.unitTesting:
        p.setBodyString(s)
        c.setChanged(True)

    return s
#@+node:ekr.20080711093251.5: *5* at.writeOneAtShadowNode & helpers
def writeOneAtShadowNode(self,p,toString,force):

    '''Write p, an @shadow node.

    File indices *must* have already been assigned.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; root = p.copy() ; x = c.shadowController

    fn = p.atShadowFileNodeName()
    if trace: g.trace(p.h,fn)
    if not fn:
        g.es_print('can not happen: not an @shadow node',p.h,color='red')
        return False

    # A hack to support unknown extensions.
    self.adjustTargetLanguage(fn) # May set c.target_language.

    fn = at.fullPath(p)
    at.default_directory = g.os_path_dirname(fn)
    exists = g.os_path_exists(fn)
    if trace: g.trace('exists %s fn %s' % (exists,fn))

    # Bug fix 2010/01/18: Make sure we can compute the shadow directory.
    private_fn = x.shadowPathName(fn)
    if not private_fn:
        return False

    if not toString and not hasattr(root.v,'at_read') and exists:
        # Prompt if writing a new @shadow node would overwrite the existing public file.
        ok = self.promptForDangerousWrite(fn,kind='@shadow')
        if ok:
            root.v.at_read = True # Create the attribute for all clones.
        else:
            g.es("not written:",fn)
            return

    c.endEditing() # Capture the current headline.

    at.initWriteIvars(root,targetFileName=None, # Not used.
        atShadow=True,
        nosentinels=None, # set below.  Affects only error messages (sometimes).
        thinFile=True, # New in Leo 4.5 b2: private files are thin files.
        scriptWrite=False,
        toString=False, # True: create a fileLikeObject.  This is done below.
        forcePythonSentinels=True) # A hack to suppress an error message.
            # The actual sentinels will be set below.

    # Bug fix: Leo 4.5.1: use x.markerFromFileName to force the delim to match
    #                     what is used in x.propegate changes.
    marker = x.markerFromFileName(fn)
    at.startSentinelComment,at.endSentinelComment=marker.getDelims()

    if g.app.unitTesting: ivars_dict = g.getIvarsDict(at)

    # Write the public and private files to public_s and private_s strings.
    data = []
    for sentinels in (False,True):
        theFile = at.openStringFile(fn)
        at.sentinels = sentinels
        at.writeOpenFile(root,
            nosentinels=not sentinels,toString=False)
            # nosentinels only affects error messages, and then only if atAuto is True.
        s = at.closeStringFile(theFile)
        data.append(s)

    # Set these new ivars for unit tests.
    at.public_s, at.private_s = data

    if g.app.unitTesting:
        exceptions = ('public_s','private_s','sentinels','stringOutput')
        assert g.checkUnchangedIvars(at,ivars_dict,exceptions),'writeOneAtShadowNode'

    if at.errors == 0 and not toString:
        # Write the public and private files.
        if trace: g.trace('writing',fn)
        x.makeShadowDirectory(fn) # makeShadowDirectory takes a *public* file name.
        at.replaceFileWithString(private_fn,at.private_s)
        at.replaceFileWithString(fn,at.public_s)

    self.checkPythonCode(root,s=at.private_s,targetFn=fn)

    if at.errors == 0:
        root.clearOrphan()
        root.clearDirty()
    else:
        g.es("not written:",at.outputFileName,color='red')
        root.setDirty() # New in Leo 4.4.8.

    return at.errors == 0
#@+node:ekr.20080819075811.13: *6* adjustTargetLanguage
def adjustTargetLanguage (self,fn):

    """Use the language implied by fn's extension if
    there is a conflict between it and c.target_language."""

    at = self ; c = at.c

    if c.target_language:
        junk,target_ext = g.os_path_splitext(fn)  
    else:
        target_ext = ''

    junk,ext = g.os_path_splitext(fn)

    if ext:
        if ext.startswith('.'): ext = ext[1:]

        language = g.app.extension_dict.get(ext)
        if language:
            c.target_language = language
        else:
            # An unknown language.
            pass # Use the default language, **not** 'unknown_language'
#@+node:bwmulder.20050101094804: *5* at.openForWrite
def openForWrite (self, filename, wb='wb'):

    '''Open a file for writes, handling shadow files.'''

    trace = False and not g.unitTesting
    at = self ; c = at.c ; x = c.shadowController

    try:
        shadow_filename = x.shadowPathName(filename)
        self.writing_to_shadow_directory = os.path.exists(shadow_filename)
        open_file_name       = g.choose(self.writing_to_shadow_directory,shadow_filename,filename)
        self.shadow_filename = g.choose(self.writing_to_shadow_directory,shadow_filename,None)

        if self.writing_to_shadow_directory:
            if trace: g.trace(filename,shadow_filename)
            x.message('writing %s' % shadow_filename)
            return 'shadow',open(open_file_name,wb)
        else:
            ok = c.checkFileTimeStamp(at.targetFileName)
            return 'check',ok and open(open_file_name,wb)

    except IOError:
        if not g.app.unitTesting:
            g.es_print('openForWrite: exception opening file: %s' % (open_file_name),color='red')
            g.es_exception()
        return 'error',None
#@+node:ekr.20031218072017.2609: *5* app.closeLeoWindow
def closeLeoWindow (self,frame):

    """Attempt to close a Leo window.

    Return False if the user veto's the close."""

    c = frame.c

    # g.trace('frame',frame,g.callers(4))

    c.endEditing() # Commit any open edits.

    if c.promptingForClose:
        # There is already a dialog open asking what to do.
        return False

    g.app.config.writeRecentFilesFile(c)
        # Make sure .leoRecentFiles.txt is written.

    if c.changed:
        c.promptingForClose = True
        veto = frame.promptForSave()
        c.promptingForClose = False
        if veto: return False

    g.app.setLog(None) # no log until we reactive a window.

    g.doHook("close-frame",c=c)
        # This may remove frame from the window list.

    if frame in g.app.windowList:
        g.app.destroyWindow(frame)

    if g.app.windowList:
        # Pick a window to activate so we can set the log.
        frame = g.app.windowList[0]
        frame.deiconify()
        frame.lift()
        frame.c.setLog()
        frame.c.bodyWantsFocus()
        frame.c.outerUpdate()
    elif not g.app.unitTesting:
        g.app.finishQuit()

    return True # The window has been closed.
#@+node:ekr.20041113113140: *5* loadOnePlugin
def loadOnePlugin (moduleOrFileName,tag='open0',verbose=False):

    trace = False # and not g.unitTesting

    global loadedModules,loadingModuleNameStack

    # Prevent Leo from crashing if .leoID.txt does not exist.
    if g.app.config is None:
        print ('No g.app.config, making stub...')
        class StubConfig(g.nullObject):
            pass
        g.app.config = StubConfig()

    # Fixed reversion: do this after possibly creating stub config class.
    verbose = False or verbose or g.app.config.getBool(c=None,setting='trace_plugins')
    warn_on_failure = g.app.config.getBool(c=None,setting='warn_when_plugins_fail_to_load')

    if moduleOrFileName.startswith('@'):
        if trace: g.trace('ignoring Leo directive')
        return False # Allow Leo directives in @enabled-plugins nodes.

    if moduleOrFileName.endswith('.py'):
        moduleName = 'leo.plugins.' + moduleOrFileName [:-3]
    elif moduleOrFileName.startswith('leo.plugins.'):
        moduleName = moduleOrFileName
    else:
        moduleName = 'leo.plugins.' + moduleOrFileName

    if isLoaded(moduleName):
        module = loadedModules.get(moduleName)
        if trace or verbose:
            g.trace('plugin',moduleName,'already loaded',color="blue")
        return module

    assert g.app.loadDir

    moduleName = g.toUnicode(moduleName)

    # This import will typically result in calls to registerHandler.
    # if the plugin does _not_ use the init top-level function.
    loadingModuleNameStack.append(moduleName)

    try:
        toplevel = __import__(moduleName)
        # need to look up through sys.modules, __import__ returns toplevel package
        result = sys.modules[moduleName]

    except g.UiTypeException:
        if not g.unitTesting and not g.app.batchMode:
            g.es_print('Plugin %s does not support %s gui' % (
                moduleName,g.app.gui.guiName()))
        result = None

    except ImportError:
        if trace or tag == 'open0': # Just give the warning once.
            g.es_print('plugin does not exist:',moduleName,color='red')
        result = None

    except Exception as e:
        g.es_print('exception importing plugin ' + moduleName,color='red')
        g.es_exception()
        result = None

    loadingModuleNameStack.pop()

    if result:
        loadingModuleNameStack.append(moduleName)

        if tag == 'unit-test-load':
            pass # Keep the result, but do no more.
        elif hasattr(result,'init'):
            try:
                # Indicate success only if init_result is True.
                init_result = result.init()
                # g.trace('result',result,'init_result',init_result)
                if init_result:
                    loadedModules[moduleName] = result
                    loadedModulesFilesDict[moduleName] = g.app.config.enabledPluginsFileName
                else:
                    if verbose and not g.app.initing:
                        g.es_print('loadOnePlugin: failed to load module',moduleName,color="red")
                    result = None
            except Exception:
                g.es_print('exception loading plugin',color='red')
                g.es_exception()
                result = None
        else:
            # No top-level init function.
            # Guess that the module was loaded correctly,
            # but do *not* load the plugin if we are unit testing.

            if g.app.unitTesting:
                result = None
                loadedModules[moduleName] = None
            else:
                g.trace('no init()',moduleName)
                loadedModules[moduleName] = result
        loadingModuleNameStack.pop()

    if g.app.batchMode or g.app.inBridge: # or g.unitTesting
        pass
    elif result:
        if trace or verbose:
            g.trace('loaded plugin:',moduleName,color="blue")
    else:
        if trace or warn_on_failure or (verbose and not g.app.initing):
            if trace or tag == 'open0':
                g.trace('can not load enabled plugin:',moduleName,color="red")

    return result
#@+node:ekr.20031218072017.2829: *5* c.openTempFileInExternalEditor
def openTempFileInExternalEditor(self,arg,fn,openType,testing=False):

    '''Open the closed mkstemp file fn in an external editor.
    The arg and openType args come from the data arg to c.openWith.
    '''

    trace = False and not g.unitTesting
    testing = testing or g.unitTesting
    if arg is None: arg = ''

    try:
        if trace: g.trace(repr(openType),repr(arg),repr(fn))
        command = '<no command>'
        if openType == 'os.system':
            if 1:
                # This works, *provided* that arg does not contain blanks.  Sheesh.
                command = 'os.system(%s)' % (arg+fn)
                if trace: g.trace(command)
                if not testing: os.system(arg+fn)
            else:
                # XP does not like this format!
                command = 'os.system("%s %s")' % (arg,fn)
                if not testing: os.system('"%s" "%s"' % (arg,fn))
        elif openType == 'os.startfile':
            command = 'os.startfile(%s)' % (arg+fn)
            if trace: g.trace(command)
            if not testing: os.startfile(arg+fn)
        elif openType == 'exec':
            command = 'exec(%s)' % (arg+fn)
            if trace: g.trace(command)
            if not testing: exec(arg+fn,{},{})
        elif openType == 'os.spawnl':
            filename = g.os_path_basename(arg)
            command = 'os.spawnl(%s,%s,%s)' % (arg,filename,fn)
            if trace: g.trace(command)
            if not testing: os.spawnl(os.P_NOWAIT,arg,filename,fn)
        elif openType == 'os.spawnv':
            filename = os.path.basename(arg[0]) 
            vtuple = arg[1:]
            vtuple.insert(0, filename)
                # add the name of the program as the first argument.
                # Change suggested by Jim Sizelove.
            vtuple.append(fn)
            command = 'os.spawnv(%s,%s)' % (arg[0],repr(vtuple))
            if trace: g.trace(command)
            if not testing: os.spawnv(os.P_NOWAIT,arg[0],vtuple)
        elif openType == 'subprocess.Popen':
            use_shell = True
            if g.isString(arg):
                if arg:
                    vtuple = arg + ' ' + fn
                else:
                    vtuple = fn
            elif isinstance(arg,(list, tuple)):
                vtuple = arg[:]
                vtuple.append(fn)
                use_shell = False
            command = 'subprocess.Popen(%s)' % repr(vtuple)
            if trace: g.trace(command)
            if not testing:
                try:
                    subprocess.Popen(vtuple,shell=use_shell)
                except OSError:
                    g.es_print('vtuple',repr(vtuple))
                    g.es_exception()
        elif g.isCallable(openType):
            # Invoke openWith like this:
            # c.openWith(data=[f,None,None])
            # f will be called with one arg, the filename
            if trace: g.trace('%s(%s)' % (openType,fn))
            command = '%s(%s)' % (openType,fn)
            if not testing: openType(fn)
        else:
            command='bad command:'+str(openType)
            if not testing: g.trace(command)
        return command # for unit testing.
    except Exception:
        g.es('exception executing open-with command:',command)
        g.es_exception()
        return 'oops: %s' % command
#@+node:ekr.20031218072017.1151: *5* tangle.put_all_roots
@
This is the top level method of the second pass. It creates a separate derived file
for each @root directive in the outline. The file is actually written only if
the new version of the file is different from the old version,or if the file did
not exist previously. If changed_only_flag FLAG is True only changed roots are
actually written.
@c

def put_all_roots(self):

    c = self.c ; outline_name = c.mFileName

    for section in self.root_list:

        # g.trace(section.name)
        file_name = c.os_path_finalize_join(self.tangle_directory,section.name)
        mode = c.config.output_newline
        textMode = mode == 'platform'
        if g.unitTesting:
            self.output_file = g.fileLikeObject()
            temp_name = 'temp-file'
        else:
            self.output_file,temp_name = g.create_temp_file(textMode=textMode)
        if not temp_name:
            g.es("can not create temp file")
            break
        <<Get root specific attributes>>
        <<Put @first lines>>
        if self.use_header_flag and self.print_mode == "verbose":
            << Write a banner at the start of the output file >>
        for part in section.parts:
            if part.is_root:
                self.tangle_indent = 0 # Initialize global.
                self.put_part_node(part,False) # output first lws
        self.onl() # Make sure the file ends with a cr/lf
        << unit testing fake files>>
        self.output_file.close()
        self.output_file = None
        << unit testing set result and continue >>
        if self.errors + g.app.scanErrors == 0:
            g.update_file_if_changed(c,file_name,temp_name)
        else:
            g.es("unchanged:",file_name)
            << Erase the temporary file >>
#@+node:ekr.20031218072017.1152: *6* <<Get root specific attributes>>
# Stephen Schaefer, 9/2/02
# Retrieve the full complement of state for the root node
self.language = section.root_attributes.language
self.use_header_flag = section.root_attributes.use_header_flag
self.print_mode = section.root_attributes.print_mode
self.path = section.root_attributes.path
self.page_width = section.root_attributes.page_width
self.tab_width = section.root_attributes.tab_width
# Stephen P. Schaefer, 9/13/2002
self.first_lines = section.root_attributes.first_lines
#@+node:ekr.20031218072017.1153: *6* <<Put @first lines>>
# Stephen P. Schaefer 9/13/2002
if self.first_lines:
    self.os(self.first_lines)
#@+node:ekr.20031218072017.1154: *6* <<Write a banner at the start of the output file>>
# a root section must have at least one part
assert len(section.parts)>0
delims=section.parts[0].delims
if delims[0]:
    self.os(delims[0])
    self.os(" Created by Leo from: ")
    self.os(outline_name)
    self.onl() ; self.onl()
elif delims[1] and delims[2]:
    self.os(delims[1])
    self.os(" Created by Leo from: ")
    self.os(outline_name)
    self.oblank() ; self.os(delims[2])
    self.onl() ; self.onl()
#@+node:ekr.20031218072017.1155: *6* << Erase the temporary file >>
try: # Just delete the temp file.
    os.remove(temp_name)
except: pass
#@+node:sps.20100608083657.20937: *6* << unit testing fake files>>
if g.unitTesting:
    # complications to handle testing of multiple @root directives together with
    # @path directives
    file_name_path = file_name
    if (file_name_path.find(c.openDirectory) == 0):
        relative_path = file_name_path[len(c.openDirectory):]
        # don't confuse /u and /usr as having common prefixes
        if (relative_path[:len(os.sep)] == os.sep):
             file_name_path = relative_path[len(os.sep):]
    self.tangle_output[file_name_path] = self.output_file.get()
#@+node:sps.20100608083657.20938: *6* << unit testing set result and continue >>
if g.unitTesting:
    assert self.errors == 0
    g.app.unitTestDict ['tangle'] = True
    g.app.unitTestDict ['tangle_directory'] = self.tangle_directory
    if g.app.unitTestDict.get('tangle_output_fn'):
        g.app.unitTestDict['tangle_output_fn'] += "\n" + file_name
    else:
        g.app.unitTestDict ['tangle_output_fn'] = file_name
    continue
#@+node:ekr.20041005105605.15: *5* at.initWriteIvars
def initWriteIvars(self,root,targetFileName,
    atAuto=False,
    atEdit=False,
    atShadow=False,
    nosentinels=False,
    thinFile=False,
    scriptWrite=False,
    toString=False,
    forcePythonSentinels=None,
):

    self.initCommonIvars()
    << init ivars for writing >>

    if forcePythonSentinels is None:
        forcePythonSentinels = scriptWrite

    if root:
        self.scanAllDirectives(root,
            scripting=scriptWrite,
            forcePythonSentinels=forcePythonSentinels,
            issuePathWarning=True)
        # Sets the following ivars:
            # at.explicitLineEnding
            # at.output_newline
            # at.encoding
            # at.language
            # at.page_width
            # at.default_directory  *** path ***
            # at.tab_width

    # g.trace(forcePythonSentinels,
    #    self.startSentinelComment,self.endSentinelComment)

    if forcePythonSentinels:
        # Force Python comment delims for g.getScript.
        self.startSentinelComment = "#"
        self.endSentinelComment = None

    # Init state from arguments.
    self.targetFileName = targetFileName
    self.sentinels = not nosentinels
    self.thinFile = thinFile
    self.toString = toString
    self.root = root

    # Ignore config settings for unit testing.
    if toString and g.app.unitTesting: self.output_newline = '\n'

    # Init all other ivars even if there is an error.
    if not self.errors and self.root:
        if hasattr(self.root.v,'tnodeList'):
            delattr(self.root.v,'tnodeList')
        self.root.v._p_changed = True
#@+node:ekr.20041005105605.16: *6* << init ivars for writing >>>
@
When tangling, we first write to a temporary output file. After tangling is
temporary file. Otherwise we delete the old target file and rename the
temporary file to be the target file.
@c

self.docKind = None
self.explicitLineEnding = False
    # True: an @lineending directive specifies the ending.
self.fileChangedFlag = False # True: the file has actually been updated.
self.atAuto = atAuto
self.atEdit = atEdit
self.atShadow = atShadow
self.shortFileName = "" # short version of file name used for messages.
self.thinFile = False
self.writeVersion5 = self.new_write and not atShadow

self.force_newlines_in_at_nosent_bodies = self.c.config.getBool(
    'force_newlines_in_at_nosent_bodies')

if toString:
    self.outputFile = g.fileLikeObject()
    self.stringOutput = ""
    self.targetFileName = self.outputFileName = "<string-file>"
else:
    self.outputFile = None # The temporary output file.
    self.stringOutput = None
    self.targetFileName = self.outputFileName = g.u('')
#@+node:ekr.20100206173123.5801: *4* Fix or eliminate check python syntax commands
@nocolor-node

Directives and section references are not the problem. Rather, the problems are
thinks like 'return' in a node that doesn't look it is in a function.

The solution would likely be to check the entire file at once in checkPython
code. But this won't work for the check-all-python-code command.

Do we really need these checks? I think not, because the automatic checks work
so well.
#@+node:ekr.20100206142026.5967: *5* To do: use g.checkPythonNode as the base of all syntax checking
#@+node:ekr.20040723094220.5: *6* c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@+node:EKR.20040614071102.1: *6* g.getScript
def getScript (c,p,useSelectedText=True,forcePythonSentinels=True,useSentinels=True):

    '''Return the expansion of the selected text of node p.
    Return the expansion of all of node p's body text if there
    is p is not the current node or if there is no text selection.'''

    # New in Leo 4.6 b2: use a pristine atFile handler
    # so there can be no conflict with c.atFileCommands.
    # at = c.atFileCommands
    import leo.core.leoAtFile as leoAtFile
    at = leoAtFile.atFile(c)

    w = c.frame.body.bodyCtrl
    p1 = p and p.copy()
    if not p:
        p = c.p
    try:
        if g.app.inBridge:
            s = p.b
        elif p1:
            s = p.b # Bug fix: Leo 8.8.4.
        elif p == c.p:
            if useSelectedText and w.hasSelection():
                s = w.getSelectedText()
            else:
                s = w.getAllText()
        else:
            s = p.b
        # Remove extra leading whitespace so the user may execute indented code.
        s = g.removeExtraLws(s,c.tab_width)
        if s.strip():
            g.app.scriptDict["script1"]=s
            # Important: converts unicode to utf-8 encoded strings.
            script = at.writeFromString(p.copy(),s,
                forcePythonSentinels=forcePythonSentinels,
                useSentinels=useSentinels)
            script = script.replace("\r\n","\n") # Use brute force.
            # Important, the script is an **encoded string**, not a unicode string.
            g.app.scriptDict["script2"]=script
        else: script = ''
    except Exception:
        g.es_print("unexpected exception in g.getScript")
        g.es_exception()
        script = ''

    # g.trace(type(script),repr(script))
    return script
#@+node:ekr.20050506084734: *6* at.writeFromString
# This is at.write specialized for scripting.

def writeFromString(self,root,s,forcePythonSentinels=True,useSentinels=True):

    """Write a 4.x derived file from a string.

    This is used by the scripting logic."""

    at = self ; c = at.c
    c.endEditing() # Capture the current headline, but don't change the focus!

    at.initWriteIvars(root,"<string-file>",
        nosentinels=not useSentinels,thinFile=False,scriptWrite=True,toString=True,
        forcePythonSentinels=forcePythonSentinels)

    try:
        ok = at.openFileForWriting(root,at.targetFileName,toString=True)
        if g.app.unitTesting: assert ok,'writeFromString' # string writes never fail.
        # Simulate writing the entire file so error recovery works.
        at.writeOpenFile(root,nosentinels=not useSentinels,toString=True,fromString=s)
        at.closeWriteFile()
        # Major bug: failure to clear this wipes out headlines!
        # Minor bug: sometimes this causes slight problems...
        if root:
            if hasattr(self.root.v,'tnodeList'):
                delattr(self.root.v,'tnodeList')
            root.v._p_changed = True
    except Exception:
        at.exception("exception preprocessing script")

    return at.stringOutput
#@+node:ekr.20100206142026.5839: *6* g.checkPythonNode & helper (NEW)
def checkPythonNode (c,s,fn=None,p=None,
    munge=False,suppressErrors=False,
    tabNanny=False,unittest=False,
    suppressErrors=False,
):

    '''The future base of all syntax checking'''

    if not s.strip():
        return
    if munge:
        at = c.atFileCommands
        s = g.toUnicode(s)
        at.writeFromString(p=None,s=s,
            forcePythonSentinels=True,useSentinels=True)
    if not s.strip():
        return
    if fn:
        pass
    elif p:
        fn = '<node: %s>' % p.h
    else:
        fn = '<string'>
    try:
        if not g.isPython3:
            s = g.toEncodedString(s)
        s = s.replace('\r','')
        compile(s+'\n',fn,'exec')
        if tabNanny:
            c.tabNannyNode(p,h,s,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=True,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise
#@+node:ekr.20100206142026.5840: *7* checkPythonNodeHelper
def checkPythonNodeHelper (c,s):




    return g.toUnicode(
        .writeFromString(p = None,s=s,
        forcePythonSentinels=True,useSentinels=True)
#@+node:ekr.20060624085200: *6* g.handleScriptException
def handleScriptException (c,p,script,script1):

    g.es("exception executing script",color='blue')

    full = c.config.getBool('show_full_tracebacks_in_scripts')

    fileName, n = g.es_exception(full=full)

    if p and not script1 and fileName == "<string>":
        c.goToScriptLineNumber(p,script,n)

    << dump the lines near the error >>
#@+node:EKR.20040612215018: *7* << dump the lines near the error >>
if g.os_path_exists(fileName):
    f = open(fileName)
    lines = f.readlines()
    f.close()
else:
    lines = g.splitLines(script)

s = '-' * 20
g.es_print('',s)

# Print surrounding lines.
i = max(0,n-2)
j = min(n+2,len(lines))
while i < j:
    ch = g.choose(i==n-1,'*',' ')
    s = "%s line %d: %s" % (ch,i+1,lines[i])
    g.es('',s,newline=False)
    i += 1
#@+node:ekr.20040723094220: *5* Check Outline commands & allies
#@+node:ekr.20040723094220.1: *6* c.checkAllPythonCode
def checkAllPythonCode(self,event=None,unittest=False,ignoreAtIgnore=True):

    '''Check all nodes in the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    for p in c.all_unique_positions():
        count += 1
        if not unittest:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not g.scanForAtSettings(p) and (
                not ignoreAtIgnore or not g.scanForAtIgnore(c,p)
            ):
                try:
                    c.checkPythonNode(p,unittest)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort
                if unittest and result != "ok":
                    g.pr("Syntax error in %s" % p.cleanHeadString())
                    return result # End the unit test: it has failed.

    if not unittest:
        g.es("check complete",color="blue")

    return result
#@+node:ekr.20040723094220.2: *7* << print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@+node:ekr.20040723094220.3: *6* c.checkPythonCode
def checkPythonCode (self,event=None,
    unittest=False,ignoreAtIgnore=True,
    suppressErrors=False,checkOnSave=False):

    '''Check the selected tree for syntax and tab errors.'''

    c = self ; count = 0 ; result = "ok"

    if not unittest:
        g.es("checking Python code   ")

    for p in c.p.self_and_subtree():

        count += 1
        if not unittest and not checkOnSave:
            << print dots >>

        if g.scanForAtLanguage(c,p) == "python":
            if not ignoreAtIgnore or not g.scanForAtIgnore(c,p):
                try:
                    c.checkPythonNode(p,unittest,suppressErrors)
                except (SyntaxError,tokenize.TokenError,tabnanny.NannyNag):
                    result = "error" # Continue to check.
                except Exception:
                    return "surprise" # abort

    if not unittest:
        g.es("check complete",color="blue")

    # We _can_ return a result for unit tests because we aren't using doCommand.
    return result
#@+node:ekr.20040723094220.4: *7* << print dots >>
if count % 100 == 0:
    g.es('','.',newline=False)

if count % 2000 == 0:
    g.enl()
#@+node:ekr.20040723094220.5: *6* c.checkPythonNode
def checkPythonNode (self,p,unittest=False,suppressErrors=False):

    c = self ; h = p.h

    # Call getScript to ignore directives and section references.
    body = g.getScript(c,p.copy())
    if not body: return

    try:
        fn = '<node: %s>' % p.h
        if not g.isPython3:
            body = g.toEncodedString(body)
        compile(body+'\n',fn,'exec')
        c.tabNannyNode(p,h,body,unittest,suppressErrors)
    except SyntaxError:
        if not suppressErrors:
            s = "Syntax error in: %s" % h
            g.es_print(s,color="blue")
            g.es_exception(full=False,color="black")
        if unittest: raise
    except Exception:
        g.es_print('unexpected exception')
        g.es_exception()
        if unittest: raise

#@+node:ekr.20040723094220.6: *6* c.tabNannyNode
# This code is based on tabnanny.check.

def tabNannyNode (self,p,headline,body,unittest=False,suppressErrors=False):

    """Check indentation using tabnanny."""

    c = self

    try:
        readline = g.readLinesClass(body).next
        tabnanny.process_tokens(tokenize.generate_tokens(readline))

    except IndentationError:
        junk,msg,junk = sys.exc_info()
        if not suppressErrors:
            g.es("IndentationError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tokenize.TokenError:
        junk, msg, junk = sys.exc_info()
        if not suppressErrors:
            g.es("TokenError in",headline,color="blue")
            g.es('',msg)
        if unittest: raise

    except tabnanny.NannyNag:
        junk, nag, junk = sys.exc_info()
        if not suppressErrors:
            badline = nag.get_lineno()
            line    = nag.get_line()
            message = nag.get_msg()
            g.es("indentation error in",headline,"line",badline,color="blue")
            g.es(message)
            line2 = repr(str(line))[1:-1]
            g.es("offending line:\n",line2)
        if unittest: raise

    except Exception:
        g.trace("unexpected exception")
        g.es_exception()
        if unittest: raise
#@+node:ekr.20090811141250.5955: *3* Most important features
@ Important: There is another features list for 4.9.
#@+node:ekr.20100520070413.5878: *4* Drag and drop for qt gui
#@+node:ekr.20090801103907.6018: *4* Add entries to global dicts for more languages
http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780

Especially languages in leo/modes.
#@+node:ekr.20090816125009.5993: *5* @url http://groups.google.com/group/leo-editor/browse_thread/thread/b41ddfeb3c84e780
#@+node:ekr.20090814190307.5983: *5* print all modes/*.py files
import glob

theDir = g.os_path_finalize_join(g.app.loadDir,'..','modes','*.py')

aList = glob.glob(theDir)

for z in aList:
    print g.os_path_basename(z)

@
Exist:

    "ada"   : "ada",
    "adb"   : "ada",
    "ahk"   : "autohotkey",  # EKR: 2009-01-30.
    "as"    : "actionscript",
    "bas"   : "rapidq",
    "bat"   : "batch",
    "c"     : "c",
    "cfg"   : "config",
    "cpp"   : "cpp",
    "css"   : "css",
    "el"    : "elisp",
    "forth" : "forth",
    "f"     : "fortran",
    "f90"   : "fortran90",
    "h"     : "c",
    "html"  : "html",
    "ini"   : "ini",
    "java"  : "java",
    "ksh"   : "kshell", # Leo 4.5.1.
    "lua"   : "lua",  # ddm 13/02/06
    "nw"    : "noweb",
    "otl"   : "vimoutline",  #TL 8/25/08 Vim's outline plugin
    "p"     : "pascal",
    "pl"    : "perl",   # 11/7/05
    "pod"   : "perlpod", # 11/7/05
    "php"   : "php",
    "py"    : "python",
    "sql"   : "plsql", # qt02537 2005-05-27
    "r"     : "rebol",
    "rb"    : "ruby", # thyrsus 2008-11-05
    "rest"  : "rst",
    "rst"   : "rst",
    "sh"    : "shell",
    "tex"   : "tex",
    "txt"   : "plain",
    "tcl"   : "tcltk",
    "vim"   : "vim",
"w"     : "cweb",
"xml"   : "xml",
"xsl"   : "xslt",

Add first:


ada95.py
antlr.py
apacheconf.py
apdl.py
applescript.py
asp.py
aspect_j.py
assembly_macro32.py
assembly_mcs51.py
assembly_parrot.py
assembly_r2000.py
assembly_x86.py
awk.py
b.py
batch.py
bbj.py
bcel.py
bibtex.py
c.py
chill.py
cobol.py
coldfusion.py
cplusplus.py
csharp.py
css.py
cvs_commit.py
d.py
doxygen.py
dsssl.py
eiffel.py
embperl.py
erlang.py
factor.py
forth.py
fortran.py
fortran90.py
foxpro.py
freemarker.py
gettext.py
groovy.py
haskell.py
hex.py
html.py
i4gl.py
icon.py
idl.py
inform.py
ini.py
inno_setup.py
interlis.py
io.py
java.py
javascript.py
jcl.py
jhtml.py
jmk.py
jsp.py
latex.py
lilypond.py
lisp.py
lotos.py
lua.py
mail.py
makefile.py
maple.py
matlab.py
ml.py
modula3.py
moin.py
mqsc.py
netrexx.py
nqc.py
nsis2.py
objective_c.py
objectrexx.py
occam.py
omnimark.py
pascal.py
patch.py
perl.py
php.py
phpsection.py
pike.py
pl1.py
plain.py
plsql.py
pop11.py
postscript.py
povray.py
powerdynamo.py
progress.py
prolog.py
props.py
psp.py
ptl.py
pvwave.py
pyrex.py
python.py
r.py
rebol.py
redcode.py
relax_ng_compact.py
rest.py
rhtml.py
rib.py
rpmspec.py
rtf.py
ruby.py
rview.py
sas.py
scheme.py
sdl_pr.py
sgml.py
shell.py
shellscript.py
shtml.py
smalltalk.py
smi_mib.py
splus.py
sqr.py
squidconf.py
ssharp.py
svn_commit.py
swig.py
tcl.py
tex.py
texinfo.py
text.py
tpl.py
tsql.py
uscript.py
vbscript.py
velocity.py
verilog.py
vhdl.py
xml.py
xsl.py
zpt.py
__init__.py
#@+node:ekr.20090601083544.6051: *4* Add expand_noweb_references for rst3 plugin
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/3cd5cb06d32264d

> What would work for me is if named sections in a @rst subtree
> would work exactly as they work for other derived files: they
> get inserted at the place where they are referenced.

- Add support for the following options:
    - expand_noweb_references: default False for compatibility.
    - ignore_noweb definitions: default False for compatibility.

- When expand_noweb_references is True, definitions (typically clones)
  must be descendants of the referencing node (in the @rst tree)
#@+node:ekr.20090601083544.6052: *5* post
@nocolor-node

I want to write the documentation for the source program in a @rst3 subtree. In
this @rst3 subtree I want to refer to fragments of the program, like:

In the following code fragment::

  <<code fragment>>

Unfortunately, <<code fragment>> will not be expanded. Furthermore, in order to
get to this work, I should have <<code fragment>> under the @rst3 subtree as
well, but this is then also treated as @rst3 input (which in this case, is not
what I want).
#@+node:ekr.20080918164844.12: *4* Improve headline navigation
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/bce1065d9a332fcd

Now that the leo is more "modeless" (I'm speaking of switching between
outline navigation and body editing modes), which btw is a clear improvement
to how leo used to behave, here are some things that still feel a bit
un-intuitive:

- ctrl+H (edit-headline) "locks" the user into the mode way too much.

   * The headline editing mode should be cancelled when the user does:
      - cursor up/down
      - ESC

   * Even better alternative: I find myself constantly thinking that "ok,
now I need to edit a headline (typically not the current headline), so now
I'll press ctrl+H". I think perhaps pressing up/down should cancel the
current headline editing, and select the next/previous headline for editing.
That is, I wouldn't need to navigate to the headline I want to edit before I
start editing it.

  - cut-node (ctrl+shift+x) selects the wrong node after the cut. The
intuitive assumption is that cut will select the node that "took the place
of the
    current node", instead of starting to travel upwards the set of nodes.

   * Typical use case is the way you usually start deleting a set of items.
You move to the first item and start cutting repeatedly. This wont work with
the current behaviour. 
#@+node:ekr.20080730212711.7: *4* Improve plugins handling
@nocolor-node

- Don't repeat "can not load <plugin>" messages.

- Unify print-plugins and print-plugins-info commands, and make them more informative.

- Fix the plugin mess.

    - Create a way to unload a plugin.  This should be relatively easy.
#@+node:ekr.20090804105939.5993: *5* Possibly redo how plugins are loaded
#@+node:ekr.20080313032655.2: *5* Once a plugin is enabled, it is always enabled
#@+node:ekr.20080923200153.1: *5* Support scan-directives hook again?
# This affects the add_directives plugin.
# Also, the color_markup plugin doesn't work with the threading colorizer.
#@+node:ekr.20080421140032.1: *5* Fix multiple controllers problem in all plugins
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/663e1f9d8e2d1c24

@color
#@+node:ekr.20090724081340.5987: *4* Improve recursive import script and @auto
@nocolor-node

Instead of adding an @ignore directive, it might be better
to change @auto to @@auto.

Should @auto be more lenient with C files?

Improve the recursive import script.
    - Minimize the path names
    - Option to include/exclude the @auto itself

#@+node:ekr.20090907080624.6081: *4* Spell checker should check headlines
#@+node:ekr.20071001052501: *4* Versioning for nodes
@nocolor

One feature I have not seen in SCS system is something which might be called
"history compression": I might be interested in having both version 5 and 6
in my source tree, when the current version is 7, but I am not really interested
in the 2000 steps which transformed 5 into 6 (just suggested this feature to
the bazaar people). This happens actually quite often to me, since I use the
SCS as a back-up system, saving many (uninteresting) intermediate steps while
implementing a new feature.
#@+node:ekr.20100206074650.5843: ** 4.10 Autocompletion
#@+node:ekr.20100827095120.5861: *3* Improve format of .leo files?
http://groups.google.com/group/leo-editor/browse_thread/thread/be5052957b21ad97

Maybe for Leo 4.9.
#@+node:ekr.20090131200406.14: *3* autocompletion
#@+node:ekr.20100506062734.5756: *4* Ville post re autocompleter
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/ee84e52fba476950

> Some of the UI's I've worked with involved going into a state where
> you picked from a numbered, or lettered list of possibilities
> generated based on the currently typed "trigger".  e.g. and expansion
> of trigger "ct" puts a ine like the following in, say, the status
> line:

Note that all design work is unnecessary - this is basically a simple
matter of bugfixing.

qtGui has this method:

http://pastebin.com/GmhZJqDd

Once you can call

w.showCompleter(['hello', 'helloworld'], mycallback )

and select the correct alternative naturally with keyboard (now you
need mouse), almost all of the work is done.

The rest can be provided by codewisecompleter, or any other kind of
completer we may wish to add (e.g. hippie-expand, abbrev expand...).

All discussion regarding the ui design only helps to sidetrack us from
getting a completer that behaves the way completers are "supposed to
behave" on 2010, i.e. the way provided by QCompleter.

-- 
Ville M. Vainio 
#@+node:ekr.20081005065934.12: *4* Links from Ville re Scintilla
@nocolor-node

It seems Scintilla relies on externally generated api description
files to provide autocompletion. Links that may be of interest:

http://www.riverbankcomputing.co.uk/static/Docs/QScintilla2/classQsciAPIs.html#b0f824492bb0f3ca54edb4d46945a3de

http://www.burgaud.com/scite-java-api/

http://scintilla.sourceforge.net/tags2api.py

http://www.koders.com/python/fid7000B9C96CF2C6FB5BCE9DF700365C5B2A1F36A7.aspx?s=gtk#L53
#@+node:ekr.20080113165010: *4* About auto completion
@nocolor

Summary: inspect when possible, ask for types otherwise.

    os.? gives a list of all instances of os module.
    x.? gives a list of all known classes.
    x.# gives list of all known functions.
    self.? gives all known methods and ivars of the enclosing class.
    The user will be able to specify type conventsions, like Leo's c,g,p,t,v vars.

Completed (mostly): user interface stuff.

Performance isn't too hard:
    - Do all scanning in separate threads.
    - Associate node info with tnodes.
    - Update node info when deselecting a node (in tree base class)

Parsing:
    - Forgiving parser is essentially complete.
    - It's easy to parse python def lines.
#@+node:ekr.20080110082845: *4* pyxides: code completion
@nocolor

Python code completion module


From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 20:57:18 +0300

I've been developing IDLE over the past 2 years or so. Even before
that, I helped a friend of mine, Noam Raphael, write IDLE's
auto-completion, which is included in recent versions of IDLE.

Noam wrote the original completion code from scratch, and AFAIK every
Python IDE which features code completion has done the same. Surely
there is -some- functionality which could be useful cross-IDE?
Retrieving possible completions from the namespace, for example. And
we should be learning from each-others' ideas and experiences.

So how about we design a generic Python completion module, that
each IDE could extend, and use for the completion logic?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:06:01 +0100

I am very keen for this. I will help where it is required. PIDA
currently has no code completion (outside what vim/emacs provide),



From: "phil jones" <inters...@gmail.com>
Date: Wed, 6 Jun 2007 11:07:33 -0700

What functions would we ask for a code completion module?

Presumably recognition of the beginnings of
- a) python keywords
- b) classes and functions defined earlier in this file?
- c) in scope variables?

As python is dynamically typed, I guess we can't expect to know the
names of methods of objects?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:13:10 +0100

> Presumably recognition of the beginnings of
> - a) python keywords
> - b) classes and functions defined earlier in this file?
> - c) in scope variables?

does c) include: d) imported modules



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 20:17:30 +0200

> >Presumably recognition of the beginnings of
> >- a) python keywords
> >- b) classes and functions defined earlier in this file?
> >- c) in scope variables?

> does c) include: d) imported modules

For code-completion, I suppose astng[1] could be useful.

1: http://www.logilab.org/project/eid/856



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:48:41 +0200

A good point. I think we all have been thinking about this. Important
issues for the design is the extraction method and the sources.

*the method*
Importing is a lazy, but accurate way of importing, but is security wise
not such a good idea. Parsing throught an AST compiler is better,
however more difficult. Here are two options.

From version 2.5 the standard Python compiler converts internally the
source code to an abstract syntax tree (AST) before producing the
bytecode. So probably that is a good way to go as every python
distribution has this battery included.

As Nicolas suggested earlier on this mailing list, there is another
option: the AST compiler in python or PyPy:

On Mar 14 2006, 12:16 am, Nicolas Chauvat <nicolas.chau...@logilab.fr>
wrote:

> > WingIDE use anASTgenerator written in C (but cross-platform),
> > lightningly quick, and open sourced. This could be a potential
> > starting point.

> > Additionally isn't Python2.5 planned to have a C-written compiler?

> PyPy also produced an improved parser/compiler.

> http://codespeak.net/pypy/dist/pypy/doc/index.html
> http://codespeak.net/pypy/dist/pypy/module/recparser/

But if it could be done with the standard one it is one dependency less.

*the sources*
In the design we could define first the sources:
1 external imported modules from the pythonpath
2 local modules relative to the current file or context dependent
(Blender, Gimp, ...)
3 inner code

For 1:
It might be a good idea to have a function which scans all the modules
from the pythonpath or one specific module to cache all autocompletion
and calltip information of all classes, methods and doc strings. Why?
Modules in the pythonpath don't change so often. With some criteria
(file name, time stamp, size, ...) you could check if updates are
necessary at startup. Having a readymade 'database' (could be python
dictionary or sqlite database) for autocompletion/call tips would speed
up things (and is also more secure if you are importing rather than
parsing. For example trying to provide gtk autocompletion in a wxPython
by importing is problematic).

For 2:
Here you load the parser on demand. Autocompletion/calltip information
can be added to the database.

For 3:
A different kind of parser needs to be used here as per definition code
you edit contains errors while typing. External modules are retrieved
from 1 and 2, for internal code you can scan all the words and add them
to the autocomplete database. As a refinement you can give special
attention to 'self'. Also for calltips you can inherit when there are
assignments, eg
frame = Frame()
than frame inherits autocomplete & calltip information from Frame.

So autocompletion & calltips deals with two steps: extraction and
'database'. If someone has a good parser already, we could use it.
Otherwise we can define an API for the extraction and maybe lazily
implement it first with importing and concentrate first on the
'database'. When the database is ready we can implement the parsing. You
could also implement the parsing first, but than it takes longer before
you have results. Of course the library is GUI independent, it only
works with strings or lists.

What concerns SPE, it uses importing for autocompletion (1+2) and does
internal code analysis for local code (however without the inheriting).

Tal, how does IDLE's autocompletion works?

Stani



From: Stani's Python Editor <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 20:53:10 +0200

Nicolas Chauvat wrote:
> On Wed, Jun 06, 2007 at 07:13:10PM +0100, Ali Afshar wrote:
>>> Presumably recognition of the beginnings of
>>> - a) python keywords
>>> - b) classes and functions defined earlier in this file?
>>> - c) in scope variables?
>> does c) include: d) imported modules

> For code-completion, I suppose astng[1] could be useful.

> 1: http://www.logilab.org/project/eid/856

How dependent/independent is this from the standard AST compiler or
PyPy? Is it more IDE friendly? Is it based on it or a total independent
implementation?



From: "Ali Afshar" <aafs...@gmail.com>
Date: Wed, 6 Jun 2007 19:59:13 +0100

> A good point. I think we all have been thinking about this. Important
> issues for the design is the extraction method and the sources.

> *the method*
> Importing is a lazy, but accurate way of importing, but is security wise
> not such a good idea. Parsing throught an AST compiler is better,
> however more difficult. Here are two options.

> From version 2.5 the standard Python compiler converts internally the
> source code to an abstract syntax tree (AST) before producing the
> bytecode. So probably that is a good way to go as every python
> distribution has this battery included.

> As Nicolas suggested earlier on this mailing list, there is another
> option: the AST compiler in python or PyPy:

What concerns me about these is whether they would work in a module
which has a syntax error.

I believe Wing's compiler bit of their code completion is open source.
I remember having seen the code.



From: Stani <spe.stani...@gmail.com>
Date: Wed, 06 Jun 2007 12:08:00 -0700

> What concerns me about these is whether they would work in a module
> which has a syntax error.

> I believe Wing's compiler bit of their code completion is open source.
> I remember having seen the code.

It is indeed, but is implemented in C, which means an extra dependency
and not a 100% python solution. Normally modules (especially in the
pythonpath) which you import don't have syntax errors. Maybe logilabs
implementation handles syntax errors well as it is developed for
PyLint. Nicolas?



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:34:41 +0300

> As python is dynamically typed, I guess we can't expect to know the
> names of methods of objects?

Well, the dir() builtin does just that, though there can be attributes
which won't be included therein. However, the builtin dir() can be
overridden... and ignoring it can break libraries like RPyC which
define a custom dir() function just for this purpose.

This issue has already been run in to by RPyC (an Python RPC lib). The
main developr went ahead and suggested adding a __dir__ method which
will return a list of attributes, and IIRC he has already implemented
a patch for this, and it will likely enter Python2.6.

Until then, I guess we're going to have to rely on dir for this.



From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 6 Jun 2007 12:42:01 -0700

For reference, PyPE auto-parses source code in the background, generating
(among other things) a function/class/method hierarchy.  Its autocomplete
generally sticks to global functions and keywords, but when doing
self.method lookups, it checks the current source code line, looks up in its
index of classes/methods, and trims the results based on known methods in
the current class in the current source file.

It certainly isn't complete (it should try to check base classes of the
class in the same file, it could certainly pay attention to names assigned
in the current scope, the global scope, imports, types of objects as per
WingIDE's assert isinstance(obj, type), etc.), but it also makes the
computation fairly straightforward, fast, and only in reference to the
current document.



From: "Tal Einat" <talei...@gmail.com>
Date: Wed, 6 Jun 2007 22:52:08 +0300

> Tal, how does IDLE's autocompletion works?

Much like Stani said, since Python is interpreted, collection of
possible completions splits into two methods:
1) source code analysis
2) dynamic introspection

Of course, we could do either or a combination of both.

IDLE just uses introspection: since IDLE always has a python shell
running, it just completes according to the shell's state (plus
built-in keywords and modules). This is a very simple method,
obviously lacking. It does allow the user some control of the
completion, though - just import whatever you want to be completable
in the shell. However, introspection is all that is needed in a Python
shell, which is the major reason this is the method used in IDLE.



From: Nicolas Chauvat <nicolas.chau...@logilab.fr>
Date: Wed, 6 Jun 2007 23:59:32 +0200


> How dependent/independent is this from the standard AST compiler or
> PyPy? Is it more IDE friendly? Is it based on it or a total independent
> implementation?

It is independent from PyPy.

The above web page says:

"""
Python Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.Python
Abstract Syntax Tree New Generation

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentialy
governed by pylint's needs.

It extends class defined in the compiler.ast [1] module with some
additional methods and attributes. Instance attributes are added by a
builder object, which can either generate extended ast (let's call
them astng ;) by visiting an existant ast tree or by inspecting living
object. Methods are added by monkey patching ast classes.
"""

From: "Sylvain Thnault" <thena...@gmail.com>
Date: Wed, 13 Jun 2007 10:51:04 +0200

> Please let me involve Sylvain in the discussion. As the main author of
> pylint and astng, he will provide better answers.

well logilab-astng is basically a big monkey patching of the compiler
package from the stdlib, so you can't get an astng representation from a
module with syntax errors in. However inference and most others
navigation methods (which are basically the value added by astng) are
"syntax error resilient" : if a dependency module (direct or indirect)
contains a syntax error, you don't get any exception, though since some
information is missing you can miss some results you'ld get if the
faulting module were parseable.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:33:33 +0300

Since astng already does some inference (which we definitely want!)
and is based on the standard Python AST compiler, it sounds like our
#1 candidate. I think we should give the code a serious once-over and
see how well it fits our requirements, and if it can be adapted to
better handle errors. Any volunteers?

Also, has anyone used astng for completion, calltips, or something
similar? Or the standard AST compiler, for that matter?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 10:40:11 +0300

How does PyPE parse code? Home-rolled, standard AST compiler, something else?

It seems to me we should try to come up with an algorithm for parsing,
before getting to the code. All of the details you mentioned -
noticing assignments, using base-class methods, etc. - could be better
defined and organized this way. Perhaps we could brainstorm on this in
a wiki?



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 11:38:40 +0300

Sorry for being away for such a long time. I hope we can get this
conversation rolling again, and get started with the actual work.

I'll try to sum up what has been said so far, and how I see things.

== Top Priorities ==
* Can we implement a parser based on the standard Python AST compiler
(or astng)? For example, can syntax errors be handled well?
* Is importing reasonable security-wise? If not, can it be made secure?

== General issues ==
* Do we aim for just completion, or also calltips? Perhaps also other
meta-data, e.g. place defined, source code, ... (see IPython's '??')
* Dependencies - do we want to allow C-extensions, or are we going for
a Python-only solution? (IDLE would only use such a Python-only tool.)
It seems that we want to pre-process most of the data in the
background, so I don't see why we would want to do this in C for
efficiency reasons.

== Completion sources ==
1) Importing "external" modules
2) Importing/Parsing "local" modules
3) Parsing the current file
4) Using objects/modules from the shell (e.g. IDLE has both editor
windows and a Python shell)

== Importing ==
* Stani mentioned that importing is problematic from a security point
of view. What are the security issues? Are they really an issue for an
IDE? If so, perhaps we could overcome this by importing in some kind
of "sandbox"?
* What are the pros and cons of Importing vs. Parsing?
* If importing is always preferable to parsing unless there's a syntax
error, perhaps try to import and parse on failure?

== Parsing ==
* This is going to be the most complex method - I think we should have
a general idea of how this should work before starting an
implementation. I suggest hashing ideas out on a wiki, since there a
lot of details to consider.
* Can a parser based on the standard AST compiler (or astng) work? Is
there a way to deal with errors? (HIGH PRIORITY!)
* There are other existing, open-source implementations out there -
WingIDE, PyPE have been mentioned. Any others? We should collect these
so we can use the code for learning, and perhaps direct use (if
possible license-wise).

== Shell ==
This is relatively straight-forward - just use dir(). This should be
optional, for use by IDEs which have a shell (support multiple
shells?).

Some known issues from IDLE and PyCrust:
* Handle object proxies such as RPC proxies (e.g. RPyC)
* Handle ZODB "ghost" objects
* Watch out for circular references
* Watch out for objects with special __getattr__/__hasattr__
implementations (for example xmlrpc, soap)

== Persistence ==
* Stani mentioned a 'database'. I feel Sqlite should be at most
optional, to reduce dependencies.
* Do we really want to have the data persistent (between IDE
sessiosns)? If so, we need to support simultaneous instances of the
IDE so they don't corrupt the data. Any other issues? (I have a
feeling this would better be left for later stages of development.)



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 12:22:59 +0300

One more note: We should distinguish between completion in an editor
and completion in a shell. The conversation up until now has focused
on editors, which is reasonable since that is the problematic scene. I
think a generic Python completion library should support completion in
both contexts, especially if it uses can use a shell's namespace for
completion in the editor.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 11:20:19 +0100

I have just implemented a completion mockup using Rope (which is a
refactoring library). It works quite nicely, and definitely worth a
look.

http://rope.sourceforge.net/

It even achieves this kind of completion:

class Banana(object):
    def do_something(self):
         return

def foo():
    return [Banana(), Banana()]

foo()[0].<complete> includes do_something

Which seems pretty impressive to me.



From: "Tal Einat" <talei...@gmail.com>
Date: Tue, 31 Jul 2007 20:12:50 +0300

Wow, Rope does look very impressive! A quick look at the code tells me
that a lot of work has been invested in it.

So we have one existing Python-only solution. We should evaluate it -
see what it can and can't do, and perhaps take a look at the overall
design.

I'm CC-ing Rope's developer, Ali. Hopefully Ali can help us quickly
understand Rope's code analysis capabilities.

Ali, could you elaborate a bit on what kinds of completion Rope can
do, and the methods it uses? We would especially like to know how your
static and dynamic inference work, what they can accomplish, and what
their limitations are.



From: "Ali Afshar" <aafs...@gmail.com>
Date: Tue, 31 Jul 2007 19:45:15 +0100

> Ali, could you elaborate a bit on what kinds of completion Rope can
> do, and the methods it uses? We would especially like to know how your
> static and dynamic inference work, what they can accomplish, and what
> their limitations are.

Well, I haven't really looked at the code. But I can tell you this:

from rope.ide.codeassist import PythonCodeAssist
from rope.base.project import Project
for compl in PythonCodeAssist(Project(package_root)).assist(buffer,
offset).completions:
    print compl

And that is as far as I really got. I expect to get a better look at
it later in the week though...


From: "Josiah Carlson" <josiah.carl...@gmail.com>
Date: Wed, 1 Aug 2007 00:26:14 -0700

> How does PyPE parse code? Home-rolled, standard AST compiler, something else?

The compiler for syntactically correct Python, a line-based compiler
for broken Python.  TO generate a method list for self.methods, using
the current line number, I discover the enclosing class, check the
listing of methods for that class (generated by the compiler or
line-based parsers), and return a valid list for the specified prefix.
 It doesn't walk the inheritance tree, it doesn't do imports, etc.

> It seems to me we should try to come up with an algorithm for parsing,
> before getting to the code. All of the details you mentioned -
> noticing assignments, using base-class methods, etc. - could be better
> defined and organized this way. Perhaps we could brainstorm on this in
> a wiki?

A wiki would be fine, the one for this mailing list would likely be
best (if it is still up and working).  Then again, Rope looks quite
nifty.  I may have to borrow some of that source ;)


Discussion subject changed to "Fwd: Python code completion module" by Tal Einat

From: Ali Gholami Rudi <aligr...@gmail.com>
Date: Aug 1, 2007 5:50 PM

First of all I should note that rope's main goal was being a
refactoring tool and a refactoring tool needs to know a lot about
python modules.  `rope.base` package provides information about python
modules.

Actually what ropeide provides as auto-completion is defined in
`rope.ide.codeassist` module.  This module almost does nothing but use
`rope.base`.  Since `rope.ide` package is not included in the rope
library (which has been separated from ropeide since 0.6m4) it lacks
good documentation and the API might not be easy to use (most of it is
written in the first months of rope's birth).

> ..., could you elaborate a bit on what kinds of completion Rope can
> do, ...

I don't know what to say here.  Well, actually it tries to use the
source code as much as possible and infer things from it.  So I can
say that it can complete any obvious thing that can be inferred by a
human.  Like this is the first parameter of a method and after dots
its attributes can appear or these modules are imported so their names
and contents are available or this is an instance of some known type
and we know its attributes and ... .  Try ropeide (it uses emacs-like
keybinding, C-/ for completion; see ~/.rope if you want to change
that); it completes common cases (and sometimes completes things you
don't expect it to!).

> ..., and the methods it uses?

Rope analyzes python source code and AST.  Rope used to use the
`compiler` module till 0.5 and now it uses `_ast` module.

> We would especially like to know how your
> static and dynamic inference work, what they can accomplish

There are a few examples in docs/overview.txt.  Unit-test modules like
`ropetest.base.objectinfertest` and `advanced_oi_test` might help,
too.  Also have a look at `rope.base.oi.__init__` pydoc for an
overview of how they work; (I'm afraid it is a bit out of date and
carelessly written.)  The idea behind rope's object inference is to
guess what references (names in source-code) hold.  They collect
information about code when they can and use them later.

>..., and what their limitations are.

Many things in rope are approximations that might be exact if some
conditions hold.  For instance rope might assume that every normal
reference in module scope holds only one kind of object.  Apart from
these assumptions both SOI and DOI have their own disadvantages; For
instance SOI fails when dynamic code is evaluated while DOI does not.
Or DOI is slower than SOI.  (Well, after recent enhancements to rope's
SOI I rarely use DOI).

I tried to answer as short as possible.  If there are questions on
specific parts of rope, I'll be happy to answer.

By the way, I tried to reply this mail to the group, but it seems that
your group requires subscription for posting, so I've sent it to you,
instead.
#@+node:ekr.20060927173836.1: *4* Make calltips and autocompleter 'stateless'
@nocolor

Disabled these binding:

auto-complete-force = None # This command needs work before it is useful. Ctrl-period
show-calltips-force = None # This command needs work before it is useful. Alt-parenleft

The problem is that autocompletion depends on state: self.leadinWord,
prevObjects, etc. Thus, it's not presently possible to start the proces
anywhere. Similar remarks apply to calltips, which relies on autocompleter
state.

This is a complex problem, and not very serious now that there is an easy way of
toggling autocompleter and calltips on and off.

@color
#@+node:ekr.20071106083149: *4* Recent post
@killcolor

In general, autocompletion is a tricky problem. Consider:

- There may be no 'clean' version of the source code that you want to
auto-complete: you may be creating a new node, or a new file, and the source
code, being incomplete, will not parse correctly.

- Except in special circumstances, there is no 'real' object corresponding to s,
so there is no way to use Python's inspect module on s. Modules are an
exception: the autocompleter can handle existing modules fairly well. Try "os."
or "os.path." for example.


It might be possible to generalize c.k.defineObjectDict so that the user
could specify autocompleter conventions, say in an @autocompleter node in an
@settings tree.
#@+node:ekr.20091005145253.6058: *3* Features
#@+node:ekr.20090131200406.15: *4* Optional file features
#@+node:ekr.20090622020908.6058: *5* Add lite sentinels
http://groups.google.com/group/leo-editor/browse_thread/thread/c4f2cf250600e4a9
#@+node:ekr.20080311135649.2: *5* Allow different .leo formats
@nocolor

On Tue, Mar 11, 2008 at 7:03 AM, Kent Tenney <kten...@gmail.com> wrote:

> On 3/11/08, derwisch <johannes.hues...@med.uni-heidelberg.de> wrote:

> >  On 11 Mrz., 08:03, "Ville M. Vainio" <vivai...@gmail.com> wrote:
> >  > It could also be argued that

> >  > - Referring to previous cloned vnodes explicitly in XML does not
> >  > necessarily obscure DAG - it follows the "do not repeat yourself"
> rule
> >  > - It will speed up reading
> >  > - Wouldn't it be better for preserving the integrity of the XML file?

> > I would lean towards this line of argumentation. A couple of days I
> >  had my Leo extension destroy the Leo ODM file (which was still valid
> >  according to Leo, but unreadable wrt the extension and broken uAs). I
> >  resorted to editing the Leo file with Emacs, and was quite surprised
> >  to see that the headStrings were attributes of vnodes.

> I'll chime in with my pet peeve re: .leo file structure::

> I think that putting the headstrings on vnodes and body strings on tnodes
> obscures the informational content of the .leo file, and makes the .leo
> file
> format less attractive as a generalized solution to the problem of how to
> manage head/body pairs which live in a hierarchal structure.

> Thanks,
> Kent

> >  I think that
> >  editing the file might have been a bit easier if there had been no
> >  such redundancy. But this is more a feeling rather than a qualified
> >  opinion.

Thanks for all these comments.  I'll respond to them all here.

Clearly, we should be using a standard xml parser to read .leo files.

My present thoughts:

- I personally like human-readable headlines in <v> elements.

- I am open to putting headlines in <t> elements, as an indication that
tnodes do indeed contain headlines and body text.

- I am willing to consider only writing shared subtrees once.

Oh! (An Aha)  All these are preferences.  We can allow any combination of
these provided that headlines appear somewhere.

So that's clean.  This will happen in Leo 4.5. 
#@+node:ekr.20061002093442: *5* Add opml support to new,open, save commands
#@+node:ekr.20071003104917: *5* Make http://edreamleo.org/namespaces/leo-python-editor/1.1 Leo's official namespace
xmlns:leo="http://edreamleo.org/namespaces/leo-python-editor/1.1"
#@+node:ekr.20090218115025.3: *5* Why are attributes pickled by default?
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/326a221f4c698f7a

> On Wed, Feb 18, 2009 at 12:12 PM, Kent Tenney <ktenney@gmail.com> wrote:
>>
>> Currently, Leo pickles the value of unknown attributes unless
>> the name starts with 'str_'
>>
>> Running the following code in node 'UA'
>>
>> p = c.currentPosition()
>> p.v.u = {'hello':'world', 'str_hello':'world'}
>>
>> results in the following in the .leo file:
>>
>> <v t="ktenney.20090218114928.367" str_hello="world"
>> hello="5505776f726c6471002e"><vh>UA</vh></v>
>>
>> I think this is surprising, Python-centric and contrary to the
>> spirit of Leo as a flexible data management platform.
>
> I suppose your point is that you can't create an arbitrarily named attribute
> with a string value. Does that create a real problem?

It requires a translation layer, either to (un)munge the name or
(un)pickle. Real problem?

Let's say each time I think 'I can use UAs to store that' I change
my mind when I realize my values will be in a pickle. (I really don't
want to name all my attributes str_xxx)

> As far as being Python-centric, can you suggest any other way of converting
> arbitrary data to a text string?

How is it done in any other XML file?
I've not used XML for arbitrary data, but it probably can be done.

> Why would that way be better than pickle?

My suspicion is that UAs would be used more for
storing text and numbers (as seems common for XML files)
than Python data objects.

Does Leo use UAs to store pickles?

I'm sure pickling capability is great, but I'm not convinced
it should be the _default._

No big deal.
#@+node:ekr.20080626081829.2: *5* Allow headline comments for @nosent files
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/eb718b4c6d478ac0

I'm just getting started learning how to use Leo. Now, I'd like to use
it for some of my projects, but there's no chance that I can convert
everyone at work to using it, so putting sentinel-filled files in our
repository is out of the question. At the same time, my code looks
awfully bare without sentinels because the documentation ends up in
the section names, not the comments!

So, I was wondering if there's a convenient way to pull the section
names into a comment at the start of each section?

===============

Interesting question.  Am I correct in assuming you are using @nosent trees
to generate your files?  If so, it would be easy to add support for the
following options:

@bool write_section_comments_in_at_nosent_trees
@bool write_node_name_comments_in_at_nosent_trees

The first would write a sentinel consisting of only the section name;
the second would write a sentinel consisting only of the node's headline
(for nodes whose headline is not a section name).

These seem like they would be useful additions.  One can even imagine
corresponding Leo directives so that the comments could be turned on or off
within an @nosent tree.

What do you think?

=====================

> Interesting question.  Am I correct in assuming you are using @nosent trees
> to generate your files?  If so, it would be easy to add support for the
> following options:

> @bool write_section_comments_in_at_nosent_trees
> @bool write_node_name_comments_in_at_nosent_trees

> The first would write a sentinel consisting of only the section name;
> the second would write a sentinel consisting only of the node's headline
> (for nodes whose headline is not a section name).

> These seem like they would be useful additions.  One can even imagine
> corresponding Leo directives so that the comments could be turned on or off
> within an @nosent tree.

That sounds like an excellent solution. Particularly the last bit --
if you could turn section-comments on and off as required, it would
become very convenient to use Leo to produce source that is intended
to also be read by non Leo users. 
#@+node:ekr.20080919085541.3: *5* Use sqlite data base as an alternative representation for .leo files
http://groups.google.com/group/leo-editor/browse_thread/thread/dff0c165e2211691
#@+node:ekr.20090210093316.1: *4* Optional features
#@+node:ekr.20080922115725.1: *5* Finish @shadow
# Allow block comments in private shadow files.
# Compute delims using the private shadow file, not the file extension!
# Can @shadow mark externally changed nodes?
#@+node:ekr.20081004102201.2: *6* Log file for @shadow
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/5e7bd3af2d1fbf51

How about a shadow.log file which Leo told what it thought of the relationship
between the node, file and shadow? It might provide useful clues.
#@+node:ekr.20081001062423.1: *6* Can @shadow mark externally changed nodes?
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/c46eabe8a9fe6e8

@color
#@+node:ekr.20080708094444.38: *7* x.propagate_changed_lines
def propagate_changed_lines(self,new_public_lines,old_private_lines,marker,p=None):

    '''Propagate changes from 'new_public_lines' to 'old_private_lines.

    We compare the old and new public lines, create diffs and
    propagate the diffs to the new private lines, copying sentinels as well.

    We have two invariants:
    1. We *never* delete any sentinels.
       New at 2010/01/07: Replacements preserve sentinel locations.
    2. Insertions that happen at the boundary between nodes will be put at
       the end of a node.  However, insertions must always be done within sentinels.
    '''

    trace = False and not g.unitTesting
    verbose = True
    x = self
    # mapping tells which line of old_private_lines each line of old_public_lines comes from.
    old_public_lines, mapping = self.strip_sentinels_with_map(old_private_lines,marker)

    << init vars >>
    << define print_tags >>

    delim1,delim2 = marker.getDelims()
    sm = difflib.SequenceMatcher(None,old_public_lines,new_public_lines)
    prev_old_j = 0 ; prev_new_j = 0

    for tag,old_i,old_j,new_i,new_j in sm.get_opcodes():

        << About this loop >>

        # Verify that SequenceMatcher never leaves gaps.
        if old_i != prev_old_j: # assert old_i == prev_old_j
            x.error('can not happen: gap in old: %s %s' % (old_i,prev_old_j))
        if new_i != prev_new_j: # assert new_i == prev_new_j
            x.error('can not happen: gap in new: %s %s' % (new_i,prev_new_j))

        << Handle the opcode >>

        # Remember the ends of the previous tag ranges.
        prev_old_j = old_j
        prev_new_j = new_j

    # Copy all unwritten sentinels.
    self.copy_sentinels(
        old_private_lines_rdr,
        new_private_lines_wtr,
        marker,
        limit = old_private_lines_rdr.size())

    # Get the result.
    result = new_private_lines_wtr.getlines()
    if 1:
        << do final correctness check>>
    return result
#@+node:ekr.20080708094444.40: *8* << init vars >>
new_private_lines_wtr = self.sourcewriter(self)
# collects the contents of the new file.

new_public_lines_rdr = self.sourcereader(self,new_public_lines)
    # Contains the changed source code.

old_public_lines_rdr = self.sourcereader(self,old_public_lines)
    # this is compared to new_public_lines_rdr to find out the changes.

old_private_lines_rdr = self.sourcereader(self,old_private_lines) # lines_with_sentinels)
    # This is the file which is currently produced by Leo, with sentinels.

# Check that all ranges returned by get_opcodes() are contiguous
old_old_j, old_i2_modified_lines = -1,-1

tag = old_i = old_j = new_i = new_j = None
#@+node:ekr.20080708094444.39: *8* << define print_tags >>
def print_tags(tag, old_i, old_j, new_i, new_j, message):

    sep1 = '=' * 10 ; sep2 = '-' * 20

    g.pr('\n',sep1,message,sep1,p and p.h)

    g.pr('\n%s: old[%s:%s] new[%s:%s]' % (tag,old_i,old_j,new_i,new_j))

    g.pr('\n',sep2)

    table = (
        (old_private_lines_rdr,'old private lines'),
        (old_public_lines_rdr,'old public lines'),
        (new_public_lines_rdr,'new public lines'),
        (new_private_lines_wtr,'new private lines'),
    )

    for f,tag in table:
        f.dump(tag)
        g.pr(sep2)


#@+node:ekr.20080708192807.2: *8* << about this loop >>
@ This loop writes all output lines using a single writer:
new_private_lines_wtr.

The output lines come from two, and *only* two readers:

1. old_private_lines_rdr delivers the complete original sources. All
   sentinels and unchanged regular lines come from this reader.

2. new_public_lines_rdr delivers the new, changed sources. All inserted or
   replacement text comes from this reader.

Each time through the loop, the following are true:

- old_i is the index into old_public_lines of the start of the present
  SequenceMatcher opcode.

- mapping[old_i] is the index into old_private_lines of the start of
  the same opcode.

At the start of the loop, the call to copy_sentinels effectively skips
(deletes) all previously unwritten non-sentinel lines in
old_private_lines_rdr whose index is less than mapping[old_i].

As a result, the opcode handlers do not need to delete elements from
the old_private_lines_rdr explicitly. This explains why opcode
handlers for the 'insert' and 'delete' opcodes are identical.
#@+node:ekr.20080708192807.5: *8* << Handle the opcode >>
# Do not copy sentinels if a) we are inserting and b) limit is at the end of the old_private_lines.
# In this special case, we must do the insert before the sentinels.
limit=mapping[old_i]

if trace: g.trace('tag',tag,'old_i',old_i,'limit',limit)

if tag == 'equal':
    # Copy sentinels up to the limit = mapping[old_i]
    self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)

    # Copy all lines (including sentinels) from the old private file to the new private file.
    start = old_private_lines_rdr.index() # Only used for tag.
    while old_private_lines_rdr.index() <= mapping[old_j-1]:
        line = old_private_lines_rdr.get()
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (
            tag,start,mapping[old_j-1]))

    # Ignore all new lines up to new_j: the same lines (with sentinels) have just been written.
    new_public_lines_rdr.sync(new_j)

elif tag == 'insert':
    if limit < old_private_lines_rdr.size():
        self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)
    # All unwritten lines from old_private_lines_rdr up to mapping[old_i] have already been ignored.
    # Copy lines from new_public_lines_rdr up to new_j.
    start = new_public_lines_rdr.index() # Only used for tag.
    while new_public_lines_rdr.index() < new_j:
        line = new_public_lines_rdr.get()
        if marker.isSentinel(line):
            new_private_lines_wtr.put(
                '%s@verbatim%s\n' % (delim1,delim2),
                tag='%s %s:%s' % ('new sent',start,new_j))
        new_private_lines_wtr.put(line,tag='%s %s:%s' % (tag,start,new_j))

elif tag == 'replace':
    # 2010/01/07: This case is new: it was the same as the 'insert' case.
    start = old_private_lines_rdr.index() # Only used for tag.
    while old_private_lines_rdr.index() <= mapping[old_j-1]:
        old_line = old_private_lines_rdr.get()
        if marker.isSentinel(old_line):
            # Important: this should work for @verbatim sentinels
            # because the next line will also be replaced.
            new_private_lines_wtr.put(old_line,tag='%s %s:%s' % (
                'replace: copy sentinel',start,new_j))
        else:
            new_line = new_public_lines_rdr.get()
            new_private_lines_wtr.put(new_line,tag='%s %s:%s' % (
                'replace: new line',start,new_j))

elif tag=='delete':
    # Copy sentinels up to the limit = mapping[old_i]
    self.copy_sentinels(old_private_lines_rdr,new_private_lines_wtr,marker,limit=limit)
    # Leave new_public_lines_rdr unchanged.

else: g.trace('can not happen: unknown difflib.SequenceMather tag: %s' % repr(tag))

if trace and verbose:
    print_tags(tag, old_i, old_j, new_i, new_j, "After tag")
#@+node:ekr.20080708094444.45: *8* << do final correctness check >>
t_sourcelines, t_sentinel_lines = self.separate_sentinels(
    new_private_lines_wtr.lines, marker)

self.check_the_final_output(
    new_private_lines   = result,
    new_public_lines    = new_public_lines,
    sentinel_lines      = t_sentinel_lines,
    marker              = marker)
#@+node:ekr.20090402072059.13: *6* Create a general mechanism for aux (shadow, _db) files
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/4ec30df3f1db8db3

On Sat, Mar 28, 2009 at 3:24 AM, VR <viktor.ransmayr@gmail.com> wrote:


    When I tried to de-install Leo-4.6b1 I succeeded, but the program
    reported that 5 directories
    were not removed.

    Three of the directories where

    1) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\config
    2) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\doc
    3) C:\Python26\Lib\site-packages\Leo-4-6-b1\leo\plugins

    [containing]


    a) .leoSettings.leo_db
    b) .leoDocs.leo_db
    c) .leo_shadow
    d) .leoPluginsRef.leo_db


Thanks for this report. I think it is important, and needs a good solution.

I dislike all these files being sprayed around the file system. I'd like to see
these files placed somewhere the ~/.leo directory. Is there a reason why this
would be a bad idea?

Similarly, we might also prefer to have shadow files place in, say,
~/.leo/shadow_files.

In both cases, I think we want to create files that indicate their location.
Either that, or mirror their location in (subdirectories) ~/.leo. In other
words, this is a general problem, and it would be good to have a robust, general
solution.
#@+node:ekr.20090601083544.6067: *5* Make all commands available to all commanders
@nocolor-node

http://groups.google.com/group/leo-editor/browse_thread/thread/a83082cec5ad3df8

QQQ (Ville)
So to create command you would do

import leoPlugins

def mycmd(c,p, event):
  print c,p

leoPlugins.expose_command('my-command', mycmd)
leoPlugins.expose_button('press-this',mycmd)

[EKR: I would rather use g.app.exposeCommand, g.app.exposeButton].

These would be available on *all* new commanders, and the current
commander as well (for easy testing). Plugins would not have to
contain more code than what is presented above.

The idea is to have a global command dict, [EKR: g.app.commandsDict]
and global button dict.
There is one after-create-frame handler that introduces all the
entries in this dict to the commander command dict.
QQQ

============


QQQ
g.app.global_commands_dict, which gets copied to c on commander
creation. it's rev 1889, you'll note that it's a simple
implementation. I didn't add g.button yet. An example:

@g.command('bookmark')
def bookmark(event):
    c = event.get('c')
    p = c.currentPosition()
    bookmarks.append(p.gnx)
    g.es('bookmarked') 
QQQ
#@+node:ekr.20081119132758.2: *5* Support @ifgui in settings trees
#@+node:ekr.20080803063553.4: *5* Allow translation/abbreviation for any Leo directive, including headline directives
#@+node:ekr.20080727122007.1: *5* Allow user to set background colors of nodes
What uA should be used to specify node colors?

if the foreground / background color API uses uAs,
would/should the uAs use the reserved "leo_&lt;something&gt;" namespace?
#@+node:ekr.20080813064908.8: *5* Find a way to limit length of lines in indented nodes
#@+node:ekr.20080802070659.11: *5* Make node attributes visible, and supported by Leo's core
#@+node:ekr.20080806054207.3: *5* Auto scroll outline pane if headline would become invisible
@nocolor

http://groups.google.com/group/leo-editor/browse_thread/thread/76789df8aac08c70

When using leo as outliner, I often use only node headlines to write
down some data. If the headline string is too long, the cursor goes
beyond the visible area. When modifying a node headline, is it
possible to make leo to auto-scroll, so the cursor is always visible? 
#@+node:ekr.20070521105645: *5* Improve api docs with epydoc?
@nocolor
http://sourceforge.net/forum/message.php?msg_id=4319363
By: ktenney

I think there is room for improvement in documenting Leo's
API, making it easier to write these kind of scripts.
I'm not sure of the best way to do that.

Epydoc seems to be the most active project in this realm.
http://epydoc.sourceforge.net/epydoc.html
#@+node:ekr.20061116054917.6: *5* Remove blanks in calltips
#@+node:ekr.20080628095358.1: *5* Make each Leo command a class
http://groups.google.com/group/leo-editor/browse_thread/thread/5688ed9aaa39be2e#

@nocolor

The main difficulty I see in the migration is creating the tables in the getPublicCommands methods in the various classes in leoEditCommands.py.  At present, these tables associate command names (strings) with corresponding methods.  The form of getPublicCommands is always:

def getPublicCommands (self):
  return {
    'command-name1': self.methodName1,
    'command-name2': self.methodName2,
    ...
  }

Thinking out loud, let's see whether the migration can be done easily.  We would change the entry:

    'command-name1': self.methodNameN,

to:

    'command-name1': self.classNameN(self),

That is, the table creates an instance of the class by calling the class's ctor, with self (the container object) as the ctor's only argument.  To make this work, all we need to do is give the class a __call__ method whose signature matches the signature of methodNameN, that is, the signature used to call methods previously.

Well, isn't this nice.  We can transition gradually, as needed.  No need *ever* to do a mass migration.  It should be easy to verify this scheme with one or two examples.  Please report your experiences if you decide to play around with this.

Edward

P.S.  I think it would be good style to append "Class" to the name of each command class. This makes it clear that self.myCommandClass(self) is a ctor.
#@+node:ekr.20090714085914.5994: *4* Optional new commands
#@+node:ekr.20071004120359.2: *5* Do expand-region-abbrevs from
See: regionalExpandAbbrev.
#@+node:ekr.20090402072059.2: *5* clone-find-all-once
@

First do a normal clone-find-all for the word "clone". Then click the script
button and do it again. Notice that children of previously found nodes don't get
added again in the modified version.
#@+node:ekr.20090402072059.4: *6* @@@button my clone find all
import leo.core.leoFind as leoFind 

def new_find_all(self):
    << do some initial stuff >>


    while 1:
        pos, newpos = self.findNextMatch()
        if pos is None: break

        if count % 10 == 0 and count > 0:
            g.es("still searching, matches found: ", count)

        << Skip node if it's a child of a previously found node >>

        count += 1

        s = w.getAllText()
        i,j = g.getLine(s,pos)
        line = s[i:j]
        if not self.clone_find_all:
            self.printLine(line,allFlag=True)
        if self.clone_find_all and self.p.v.t not in clones:
            # g.trace(self.p.v.t,self.p.h)
            if not clones:
                undoData = u.beforeInsertNode(c.p)
                << create the found node >>
            clones.append(self.p.v.t)
            positions.append(self.p)
            << create a clone of p under the find node >>

    if self.clone_find_all and clones:
        u.afterInsertNode(found,undoType,undoData,dirtyVnodeList=[])
        c.selectPosition(found)
        c.setChanged(True)

    self.restore(data)
    c.redraw()
    g.es("found",count,"matches")


leoFind.leoFind.findAll = new_find_all

c.executeMinibufferCommand("clone-find-all") 
#@+node:ekr.20090402072059.5: *7* << do some initial stuff >>
g.es("findAll..., self: ", self)

c = self.c ; w = self.s_ctrl ; u = c.undoer
undoType = 'Clone Find All'
if not self.checkArgs():
    return
self.initInHeadline()
if self.clone_find_all:
    self.p = None # Restore will select the root position.
data = self.save()
self.initBatchCommands()
count = 0 ; clones = []; positions = []
#@+node:ekr.20090402072059.6: *7* << create the found node >>
oldRoot = c.rootPosition()
found = oldRoot.insertAfter()
found.moveToRoot(oldRoot)
c.setHeadString(found,'Found: ' + self.find_text)
c.setRootPosition(found) # New in Leo 4.5.
#@+node:ekr.20090402072059.7: *7* << create a clone of p under the find node >>
q = self.p.clone()
q.moveToLastChildOf(found)
#@+node:ekr.20090402072059.8: *7* << Skip node if it's a child of a previously found node >>
<< def: is a child of b >>

is_child_of_previous = False
for previously_found in positions:
    if is_a_child_of_b(self.p, previously_found):
        is_child_of_previous = True
        break

if is_child_of_previous:
    continue
#@+node:ekr.20090402072059.9: *8* << def: is a child of b >>

def is_a_child_of_b(a, b):
    for child in b.children_iter():
        if a.t == child.t:
            return True
        if is_a_child_of_b(a, child):
            return True
    return False
#@-all
#@-leo
