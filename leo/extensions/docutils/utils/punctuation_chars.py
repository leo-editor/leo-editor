#!/usr/bin/env python
# -*- coding: utf8 -*-
# :Copyright: Â© 2011 GÃ¼nter Milde.
# :License: Released under the terms of the `2-Clause BSD license`_, in short:
#
#    Copying and distribution of this file, with or without modification,
#    are permitted in any medium without royalty provided the copyright
#    notice and this notice are preserved.
#    This file is offered as-is, without any warranty.
#
# .. _2-Clause BSD license: http://www.spdx.org/licenses/BSD-2-Clause

# :Id: $Id: punctuation_chars.py 7463 2012-06-22 19:49:51Z milde $

import sys, re
import unicodedata

# punctuation characters around inline markup
# ===========================================
#
# This module provides the lists of characters for the implementation of
# the `inline markup recognition rules`_ in the reStructuredText parser
# (states.py)
#
# .. _inline markup recognition rules:
#     ../../../docs/ref/rst/restructuredtext.html#inline-markup

# Docutils punctuation category sample strings
# --------------------------------------------
#
# The sample strings are generated by punctuation_samples() and put here
# literal to avoid the time-consuming generation with every Docutils
# run. Running this file as a standalone module checks the definitions below
# against a re-calculation.

openers = ur"""\"\'\(\<\[\{à¼ºà¼¼áš›â…â½â‚âŒ©â¨âªâ¬â®â°â²â´âŸ…âŸ¦âŸ¨âŸªâŸ¬âŸ®â¦ƒâ¦…â¦‡â¦‰â¦‹â¦â¦â¦‘â¦“â¦•â¦—â§˜â§šâ§¼â¸¢â¸¤â¸¦â¸¨ã€ˆã€Šã€Œã€ã€ã€”ã€–ã€˜ã€šã€ã€ï´¾ï¸—ï¸µï¸·ï¸¹ï¸»ï¸½ï¸¿ï¹ï¹ƒï¹‡ï¹™ï¹›ï¹ï¼ˆï¼»ï½›ï½Ÿï½¢Â«â€˜â€œâ€¹â¸‚â¸„â¸‰â¸Œâ¸œâ¸ â€šâ€Â»â€™â€â€ºâ¸ƒâ¸…â¸Šâ¸â¸â¸¡â€›â€Ÿ"""
closers = ur"""\"\'\)\>\]\}à¼»à¼½ášœâ†â¾â‚âŒªâ©â«â­â¯â±â³âµâŸ†âŸ§âŸ©âŸ«âŸ­âŸ¯â¦„â¦†â¦ˆâ¦Šâ¦Œâ¦â¦â¦’â¦”â¦–â¦˜â§™â§›â§½â¸£â¸¥â¸§â¸©ã€‰ã€‹ã€ã€ã€‘ã€•ã€—ã€™ã€›ã€ã€Ÿï´¿ï¸˜ï¸¶ï¸¸ï¸ºï¸¼ï¸¾ï¹€ï¹‚ï¹„ï¹ˆï¹šï¹œï¹ï¼‰ï¼½ï½ï½ ï½£Â»â€™â€â€ºâ¸ƒâ¸…â¸Šâ¸â¸â¸¡â€›â€ŸÂ«â€˜â€œâ€¹â¸‚â¸„â¸‰â¸Œâ¸œâ¸ â€šâ€"""
delimiters = ur"\-\/\:ÖŠÖ¾á€á †â€â€‘â€’â€“â€”â€•â¸—â¸šã€œã€°ã‚ ï¸±ï¸²ï¹˜ï¹£ï¼Â¡Â·Â¿Í¾Î‡ÕšÕ›ÕœÕÕÕŸÖ‰×€×ƒ×†×³×´Ø‰ØŠØŒØØ›ØØŸÙªÙ«Ù¬Ù­Û”Ü€ÜÜ‚ÜƒÜ„Ü…Ü†Ü‡ÜˆÜ‰ÜŠÜ‹ÜŒÜß·ß¸ß¹à °à ±à ²à ³à ´à µà ¶à ·à ¸à ¹à ºà »à ¼à ½à ¾à¥¤à¥¥à¥°à·´à¹à¹šà¹›à¼„à¼…à¼†à¼‡à¼ˆà¼‰à¼Šà¼‹à¼Œà¼à¼à¼à¼à¼‘à¼’à¾…à¿à¿‘à¿’à¿“à¿”áŠá‹áŒááááƒ»á¡á¢á£á¤á¥á¦á§á¨á™­á™®á›«á›¬á›­áœµáœ¶áŸ”áŸ•áŸ–áŸ˜áŸ™áŸšá €á á ‚á ƒá „á …á ‡á ˆá ‰á Šá¥„á¥…á§á§Ÿá¨á¨Ÿáª áª¡áª¢áª£áª¤áª¥áª¦áª¨áª©áªªáª«áª¬áª­á­šá­›á­œá­á­á­Ÿá­ á°»á°¼á°½á°¾á°¿á±¾á±¿á³“â€–â€—â€ â€¡â€¢â€£â€¤â€¥â€¦â€§â€°â€±â€²â€³â€´â€µâ€¶â€·â€¸â€»â€¼â€½â€¾ââ‚âƒâ‡âˆâ‰âŠâ‹âŒâââââ‘â“â•â–â—â˜â™âšâ›âœâââ³¹â³ºâ³»â³¼â³¾â³¿â¸€â¸â¸†â¸‡â¸ˆâ¸‹â¸â¸â¸â¸‘â¸’â¸“â¸”â¸•â¸–â¸˜â¸™â¸›â¸â¸Ÿâ¸ªâ¸«â¸¬â¸­â¸®â¸°â¸±ã€ã€‚ã€ƒã€½ãƒ»ê“¾ê“¿ê˜ê˜ê˜ê™³ê™¾ê›²ê›³ê›´ê›µê›¶ê›·ê¡´ê¡µê¡¶ê¡·ê£ê£ê£¸ê£¹ê£ºê¤®ê¤¯ê¥Ÿê§ê§‚ê§ƒê§„ê§…ê§†ê§‡ê§ˆê§‰ê§Šê§‹ê§Œê§ê§ê§Ÿê©œê©ê©ê©Ÿê«ê«Ÿê¯«ï¸ï¸‘ï¸’ï¸“ï¸”ï¸•ï¸–ï¸™ï¸°ï¹…ï¹†ï¹‰ï¹Šï¹‹ï¹Œï¹ï¹‘ï¹’ï¹”ï¹•ï¹–ï¹—ï¹Ÿï¹ ï¹¡ï¹¨ï¹ªï¹«ï¼ï¼‚ï¼ƒï¼…ï¼†ï¼‡ï¼Šï¼Œï¼ï¼ï¼šï¼›ï¼Ÿï¼ ï¼¼ï½¡ï½¤ï½¥ğ„€ğ„ğŸğğ¡—ğ¤Ÿğ¤¿ğ©ğ©‘ğ©’ğ©“ğ©”ğ©•ğ©–ğ©—ğ©˜ğ©¿ğ¬¹ğ¬ºğ¬»ğ¬¼ğ¬½ğ¬¾ğ¬¿ğ‘‚»ğ‘‚¼ğ‘‚¾ğ‘‚¿ğ‘ƒ€ğ‘ƒğ’‘°ğ’‘±ğ’‘²ğ’‘³"
closing_delimiters = ur"\.\,\;\!\?"


# Unicode punctuation character categories
# ----------------------------------------

unicode_punctuation_categories = {
    # 'Pc': 'Connector', # not used in Docutils inline markup recognition
    'Pd': 'Dash',
    'Ps': 'Open',
    'Pe': 'Close',
    'Pi': 'Initial quote', # may behave like Ps or Pe depending on usage
    'Pf': 'Final quote', # may behave like Ps or Pe depending on usage
    'Po': 'Other'
    }
"""Unicode character categories for punctuation"""


# generate character pattern strings
# ==================================

def unicode_charlists(categories, cp_min=0, cp_max=None):
    """Return dictionary of Unicode character lists.

    For each of the `catagories`, an item contains a list with all Unicode
    characters with `cp_min` <= code-point <= `cp_max` that belong to the
    category. (The default values check every code-point supported by Python.)
    """
    # Determine highest code point with one of the given categories
    # (may shorten the search time considerably if there are many
    # categories with not too high characters):
    if cp_max is None:
        cp_max = max(x for x in xrange(sys.maxunicode + 1)
                     if unicodedata.category(unichr(x)) in categories)
        # print cp_max # => 74867 for unicode_punctuation_categories
    charlists = {}
    for cat in categories:
        charlists[cat] = [unichr(x) for x in xrange(cp_min, cp_max+1)
                          if unicodedata.category(unichr(x)) == cat]
    return charlists


# Character categories in Docutils
# --------------------------------

def punctuation_samples():

    """Docutils punctuation category sample strings.

    Return list of sample strings for the categories "Open", "Close",
    "Delimiters" and "Closing-Delimiters" used in the `inline markup
    recognition rules`_.
    """

    # Lists with characters in Unicode punctuation character categories
    cp_min = 160 # ASCII chars have special rules for backwards compatibility
    ucharlists = unicode_charlists(unicode_punctuation_categories, cp_min)

    # match opening/closing characters
    # --------------------------------
    # Rearange the lists to ensure matching characters at the same
    # index position.

    # low quotation marks are also used as closers (e.g. in Greek)
    # move them to category Pi:
    ucharlists['Ps'].remove(u'â€š') # 201A  SINGLE LOW-9 QUOTATION MARK
    ucharlists['Ps'].remove(u'â€') # 201E  DOUBLE LOW-9 QUOTATION MARK
    ucharlists['Pi'] += [u'â€š', u'â€']

    ucharlists['Pi'].remove(u'â€›') # 201B  SINGLE HIGH-REVERSED-9 QUOTATION MARK
    ucharlists['Pi'].remove(u'â€Ÿ') # 201F  DOUBLE HIGH-REVERSED-9 QUOTATION MARK
    ucharlists['Pf'] += [u'â€›', u'â€Ÿ']

    # 301F  LOW DOUBLE PRIME QUOTATION MARK misses the opening pendant:
    ucharlists['Ps'].insert(ucharlists['Pe'].index(u'\u301f'), u'\u301d')

    # print u''.join(ucharlists['Ps']).encode('utf8')
    # print u''.join(ucharlists['Pe']).encode('utf8')
    # print u''.join(ucharlists['Pi']).encode('utf8')
    # print u''.join(ucharlists['Pf']).encode('utf8')

    # The Docutils character categories
    # ---------------------------------
    #
    # The categorization of ASCII chars is non-standard to reduce both
    # false positives and need for escaping. (see `inline markup recognition
    # rules`_)

    # matching, allowed before markup
    openers = [re.escape('"\'(<[{')]
    for cat in ('Ps', 'Pi', 'Pf'):
        openers.extend(ucharlists[cat])

    # matching, allowed after markup
    closers = [re.escape('"\')>]}')]
    for cat in ('Pe', 'Pf', 'Pi'):
        closers.extend(ucharlists[cat])

    # non-matching, allowed on both sides
    delimiters = [re.escape('-/:')]
    for cat in ('Pd', 'Po'):
        delimiters.extend(ucharlists[cat])

    # non-matching, after markup
    closing_delimiters = [re.escape('.,;!?')]

    # # Test open/close matching:
    # for i in range(min(len(openers),len(closers))):
    #     print '%4d    %s    %s' % (i, openers[i].encode('utf8'),
    #                                closers[i].encode('utf8'))

    return [u''.join(chars)
            for chars in (openers, closers, delimiters, closing_delimiters)]


# Matching open/close quotes
# --------------------------

# Rule (5) requires determination of matching open/close pairs. However,
# the pairing of open/close quotes is ambigue due to  different typographic
# conventions in different languages.

quote_pairs = {u'\xbb': u'\xbb', # Swedish
               u'\u2018': u'\u201a', # Greek
               u'\u2019': u'\u2019', # Swedish
               u'\u201a': u'\u2018\u2019', # German, Polish
               u'\u201c': u'\u201e', # German
               u'\u201e': u'\u201c\u201d',
               u'\u201d': u'\u201d', # Swedish
               u'\u203a': u'\u203a', # Swedish
              }

def match_chars(c1, c2):
    try:
        i = openers.index(c1)
    except ValueError:  # c1 not in openers
        return False
    return c2 == closers[i] or c2 in quote_pairs.get(c1, '')




# print results
# =============

if __name__ == '__main__':

    # (re) create and compare the samples:
    (o, c, d, cd) = punctuation_samples()
    if o != openers:
        print '- openers = ur"""%s"""' % openers.encode('utf8')
        print '+ openers = ur"""%s"""' % o.encode('utf8')
    if c != closers:
        print '- closers = ur"""%s"""' % closers.encode('utf8')
        print '+ closers = ur"""%s"""' % c.encode('utf8')
    if d != delimiters:
        print '- delimiters = ur"%s"' % delimiters.encode('utf8')
        print '+ delimiters = ur"%s"' % d.encode('utf8')
    if cd != closing_delimiters:
        print '- closing_delimiters = ur"%s"' % closing_delimiters.encode('utf8')
        print '+ closing_delimiters = ur"%s"' % cd.encode('utf8')

    # # test prints
    # print 'openers = ', repr(openers)
    # print 'closers = ', repr(closers)
    # print 'delimiters = ', repr(delimiters)
    # print 'closing_delimiters = ', repr(closing_delimiters)

    # ucharlists = unicode_charlists(unicode_punctuation_categories)
    # for cat, chars in ucharlists.items():
    #     # print cat, chars
    #     # compact output (visible with a comprehensive font):
    #     print (u":%s: %s" % (cat, u''.join(chars))).encode('utf8')
