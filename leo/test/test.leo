<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet ekr_test?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.5">
	<global_window_position top="28" left="241" height="987" width="1049"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20070416075121" str_leo_pos="8"><vh>Startup</vh>
<v t="ekr.20070529172620"><vh>@chapters</vh>
<v t="ekr.20070529173219"><vh>@chapter abc</vh>
<v t="ekr.20070529173219.1"><vh>abc node 1</vh></v>
<v t="ekr.20071206070207"><vh>cross-chapter-clone-test</vh></v>
</v>
<v t="ekr.20070603190944"><vh>@chapter xyz</vh>
<v t="ekr.20070603190944.1"><vh>xyz node 1</vh></v>
<v t="ekr.20071206070207"></v>
</v>
</v>
<v t="ekr.20070224123943"><vh>@settings</vh>
<v t="ekr.20080922164255.1"><vh>@string test = c:\leo.repo\trunk\leo\test</vh></v>
<v t="ekr.20070701090143"><vh>@@bool force_newlines_in_at_nosent_bodies = False</vh></v>
<v t="ekr.20080610144053.1"><vh>@bool body_pane_wraps = True</vh></v>
<v t="ekr.20070504080933"><vh>@bool create_nonexistent_directories = True</vh></v>
<v t="ekr.20080412082246.1"><vh>@bool fixedWindow = False</vh></v>
<v t="ekr.20070604100125"><vh>@bool use_chapter_tabs = True</vh></v>
<v t="ekr.20070503085527"><vh>@bool use_chapters = True</vh></v>
<v t="ekr.20071025193940"><vh>@enabled-plugins</vh></v>
<v t="ekr.20080811112727.1"><vh>@@@bool suppress_import_parsing = True</vh></v>
<v t="ekr.20080529111617.1"><vh>plugins</vh>
<v t="ekr.20070723091227"><vh>http plugin</vh>
<v t="ekr.20070723091227.1"><vh>@bool http_active = True</vh></v>
<v t="ekr.20070723091227.2"><vh>@int  port = 8080</vh></v>
<v t="ekr.20070723091227.3"><vh>@string rst_http_attributename = 'rst_http_attribute'</vh></v>
</v>
<v t="ekr.20070305085403"><vh>vim plugin</vh>
<v t="ekr.20070305085403.1"><vh>@string vim_cmd = c:\vim\vim63\gvim --servername LEO</vh></v>
<v t="ekr.20070305085403.2"><vh>@string vim_exe = c:\vim\vim63\gvim</vh></v>
</v>
<v t="ekr.20080529111617.2"><vh>cleo</vh>
<v t="ekr.20080529111617.3"><vh>@color cleo_color_prog_green =</vh></v>
<v t="ekr.20080529111617.4"><vh>@color cleo_color_prog_red =</vh></v>
<v t="ekr.20080529111617.5"><vh>@data cleo_color_file_node_list</vh></v>
<v t="ekr.20080529111617.6"><vh>@int cleo_prog_width = 18</vh></v>
<v t="ekr.20080529111617.7"><vh>@float cleo_time_init = 1.0</vh></v>
<v t="ekr.20080529111617.8"><vh>@int cleo_prog_scale = 1</vh></v>
<v t="ekr.20080529111617.9"><vh>@float cleo_prog_extra = 4</vh></v>
<v t="ekr.20080529111617.10"><vh>@string cleo_time_name = 'days'</vh></v>
</v>
</v>
<v t="ekr.20080604104453.5"><vh>@strings [command,insert, overwrite] top_level_unbound_key_action = insert</vh></v>
<v t="ekr.20080729153237.1"><vh>Gc settings</vh>
<v t="ekr.20080729153237.2"><vh>@bool trace_gc = False</vh></v>
<v t="ekr.20080729153237.3"><vh>@bool trace_gc_calls = False</vh></v>
<v t="ekr.20080729153237.4"><vh>@bool trace_gc_verbose = False</vh></v>
</v>
<v t="ekr.20080822153619.1"><vh>@string shadow_subdir = .leo/shadow</vh></v>
</v>
<v t="ekr.20041001211817"><vh>Buttons</vh>
<v t="ekr.20061030041450"><vh>Run Iron Python scripts</vh>
<v t="ekr.20061030041356"><vh>@url c:\prog\IronPython-1.0.1\Doc\IronPythonApiReference.chm</vh></v>
</v>
<v t="ekr.20070531102813"><vh>Disabled buttons</vh>
<v t="ekr.20060814111542"><vh>@@button add-e</vh></v>
<v t="ekr.20080813100905.1"><vh>@@button args-test @args = a,b,c</vh></v>
<v t="ekr.20060918083159"><vh>@@button Clear uAs</vh></v>
<v t="ekr.20071002150320"><vh>@@button create-canvas</vh></v>
<v t="ekr.20060809084033"><vh>@@button cvt to g.et</vh>
<v t="ekr.20060809104405"><vh>&lt;&lt; version history &gt;&gt;</vh></v>
<v t="ekr.20060809092023"><vh>test</vh>
<v t="ekr.20060809103738"><vh>test1</vh></v>
<v t="ekr.20060809103738.1"><vh>test2</vh></v>
</v>
<v t="ekr.20060809090508"><vh>replace</vh>
<v t="ekr.20060809091749.72"><vh>&lt;&lt; handle string &gt;&gt;</vh></v>
<v t="ekr.20060809091749.73"><vh>&lt;&lt; handle g.es &gt;&gt;</vh></v>
</v>
</v>
<v t="ekr.20070531104646"><vh>@@button da-comp</vh></v>
<v t="ekr.20070531103315"><vh>@@button da-expand</vh></v>
<v t="ekr.20070530072113"><vh>@@button hide-ch</vh></v>
<v t="ekr.20061030041200"><vh>@@button iron-py @key=Alt-5</vh></v>
<v t="ekr.20071025192258"><vh>@@button local-tests @key=Alt+4</vh></v>
<v t="ekr.20071006084354"><vh>@@button print tk line number</vh></v>
<v t="ekr.20080105115712"><vh>@@button pylint</vh>
<v t="ekr.20080115085447"><vh>harmless warnings, errors</vh></v>
<v t="ekr.20080105130903"><vh>warnings</vh></v>
<v t="ekr.20080105120559"><vh>&lt;&lt; define data &gt;&gt;</vh></v>
</v>
<v t="ekr.20070515073111"><vh>@@button sep</vh></v>
<v t="ekr.20060427103457"><vh>@@button settings.leo</vh></v>
<v t="ekr.20080310111916.1"><vh>@@button Translate "can not" to "can't"</vh></v>
<v t="ekr.20070115092430"><vh>@@button winpdb</vh></v>
<v t="ekr.20080815073750.1"><vh>@@button write-nosent-files</vh></v>
<v t="ekr.20071128122043"><vh>@@command create-shell-tab @key = Alt+5</vh></v>
<v t="ekr.20070604095313"><vh>Chapter buttons</vh>
<v t="ekr.20070530072113.1"><vh>@@button show-ch</vh></v>
<v t="ekr.20070603175054.1"><vh>@@button ch-main</vh></v>
<v t="ekr.20070603175054"><vh>@@button ch-abc</vh></v>
<v t="ekr.20070603190713.1"><vh>@@button ch-xyz</vh></v>
<v t="ekr.20070603190713"><vh>@@button ch-add-xyz</vh></v>
</v>
<v t="ekr.20060904110922"><vh>OPML buttons</vh>
<v t="ekr.20060904111037.1"><vh>@@button opml-write</vh></v>
<v t="ekr.20060904111037"><vh>@@button opml-read</vh></v>
</v>
</v>
<v t="ekr.20080915095329.1"><vh>@button rst3</vh></v>
</v>
<v t="ekr.20070410063214"><vh>Commands</vh>
<v t="ekr.20060924180049"><vh>@@command clones-tab</vh>
<v t="ekr.20060924180049.1"><vh>class cloneNavigator</vh>
<v t="ekr.20060924180049.2"><vh>init</vh></v>
<v t="ekr.20060924180049.3"><vh>getAllClones</vh></v>
<v t="ekr.20060924180049.4"><vh>displayClones</vh>
<v t="ekr.20060924180049.5"><vh>&lt;&lt;Fill listbox with clone parent headlines&gt;&gt;</vh></v>
<v t="ekr.20060924180049.6"><vh>&lt;&lt;Goto selected position when listbox selection changes&gt;&gt;</vh></v>
</v>
</v>
</v>
<v t="ekr.20080214091706.2"><vh>@@command ekr-command</vh></v>
<v t="ekr.20080823154546.1"><vh>@@command parse-python @key = Alt-5</vh></v>
</v>
<v t="ekr.20071026102420.3"><vh>Scripts</vh>
<v t="ekr.20071129103842"><vh>create-at-auto-nodes</vh></v>
<v t="ekr.20070223164126"><vh>Recursive import script</vh>
<v t="ekr.20070223164126.1"><vh>importFiles</vh></v>
<v t="ekr.20070223164126.2"><vh>importDir</vh></v>
<v t="ekr.20070223164126.3"><vh>createLastChildOf</vh></v>
</v>
<v t="ekr.20070517070854"><vh>run script in nullGui</vh></v>
<v t="ekr.20070517071510"><vh>run script with leoBridge</vh></v>
<v t="ekr.20080206055658"><vh>Script to print font settings</vh></v>
</v>
</v>
<v t="ekr.20071025193940" annotate="7d71002855087072696f7269747971015504393939397102550870726f67726573737103550071045509617263686574797065710568045502666771066804752e"></v>
<v t="ekr.20070517160058.1"><vh>Prototypes</vh>
<v t="ekr.20070929062147"><vh>Prototype of networkx graph tools</vh>
<v t="ekr.20070929122956"><vh>Data trees</vh>
<v t="ekr.20070929114617"><vh>@graph-target</vh></v>
<v t="ekr.20070929072043"><vh>@networkx</vh>
<v t="ekr.20070929072506.1"><vh>@nodes</vh></v>
<v t="ekr.20070929072506"><vh>@edges</vh></v>
</v>
<v t="ekr.20070929070257"><vh>@graph</vh>
<v t="ekr.20070929070257.1"><vh>@node child1</vh>
<v t="ekr.20070929070632"><vh>@link ('ekr', '20070929070257', 2): @node child2</vh></v>
</v>
<v t="ekr.20070929070257.2"><vh>@node child2</vh>
<v t="ekr.20070929070632.1"><vh>@link ('ekr', '20070929070257', 1): @node child1</vh></v>
</v>
</v>
<v t="ekr.20070928095102"><vh>root-node</vh>
<v t="ekr.20070928095102.1"><vh>child1</vh></v>
<v t="ekr.20070928095102.2"><vh>child2</vh></v>
</v>
</v>
<v t="ekr.20070929122956.1"><vh>buttons</vh>
<v t="ekr.20070929070426"><vh>@@button print link</vh></v>
<v t="ekr.20070927175908"><vh>@@button leo2graph</vh></v>
<v t="ekr.20070929062147.1"><vh>@@button at-graph2graph</vh></v>
<v t="ekr.20070929062147.2"><vh>@@button at-networkx2graph</vh>
<v t="ekr.20070929081505"><vh>error</vh></v>
<v t="ekr.20070929074830"><vh>parse</vh></v>
<v t="ekr.20070929072506.2"><vh>parseNodes</vh></v>
<v t="ekr.20070929074830.1"><vh>parseEdges</vh></v>
</v>
<v t="ekr.20070929082546"><vh>@@button at-networkx2at-graph</vh>
<v t="ekr.20070929120541"><vh>createEdges</vh></v>
<v t="ekr.20070929120541.1"><vh>createNodes</vh></v>
<v t="ekr.20070929115302"><vh>createTree</vh></v>
<v t="ekr.20070929114410.2"><vh>error</vh></v>
<v t="ekr.20070929114410.3"><vh>parse</vh></v>
<v t="ekr.20070929114410.5"><vh>parseEdges</vh></v>
<v t="ekr.20070929114410.4"><vh>parseNodes</vh></v>
</v>
</v>
</v>
<v t="ekr.20070630142904"><vh>Prototype of pyrex</vh>
<v t="ekr.20070630142904.2"><vh>gcc build docs</vh></v>
<v t="ekr.20070630142904.3"><vh>pyrexc command-line options</vh></v>
<v t="ekr.20070630142904.4"><vh>@@file myModule.pyx</vh></v>
<v t="ekr.20070630142904.5"><vh>Make myModule.c</vh></v>
</v>
<v t="ekr.20071026102420.2"><vh>Screen capture with Wink</vh>
<v t="ekr.20070528111805"><vh>FrontWindowCapture.pyw</vh></v>
<v t="ekr.20070609085533"><vh>@@url c:\prog\wink\ChangeViewMenu.htm</vh></v>
</v>
<v t="edreamleo.20080110083531"><vh>gtk stuff</vh>
<v t="edreamleo.20080110130828"><vh>createWindow</vh></v>
<v t="bob.20080111200056"><vh>@@thin gtkOutlineDemo.py</vh>
<v t="bob.20080111194559"><vh>GtkLeoTreeDemo</vh>
<v t="bob.20080113184034"><vh>__init__</vh></v>
<v t="bob.20080113183321"><vh>onButtonPress</vh></v>
<v t="bob.20080113183321.1"><vh>onButtonRelease</vh></v>
</v>
<v t="bob.20080113170657"><vh>loadIcon</vh></v>
<v t="bob.20080113133525"><vh>loadIcons</vh></v>
<v t="bob.20080113141134"><vh>name2Color</vh></v>
<v t="bob.20080113170041"><vh>getImage</vh></v>
<v t="bob.20080114060133"><vh>getHeadlineFont</vh></v>
<v t="bob.20080111201957.77"><vh>class OutlineCanvasPanel</vh>
<v t="bob.20080111201957.78"><vh>__init__</vh></v>
<v t="bob.20080111201957.79"><vh>showEntry</vh></v>
<v t="bob.20080111201957.80"><vh>hideEntry</vh></v>
<v t="bob.20080111201957.81"><vh>getPositions</vh></v>
<v t="bob.20080111201957.87"><vh>onScrollVertical</vh></v>
<v t="bob.20080113090336"><vh>onScrollHorizontal</vh></v>
<v t="bob.20080111201957.88"><vh>onScrollRelative</vh></v>
<v t="bob.20080111201957.90"><vh>vscrollUpdate</vh></v>
<v t="bob.20080111201957.91"><vh>hscrollUpdate</vh></v>
<v t="bob.20080111201957.92"><vh>update</vh></v>
<v t="bob.20080111201957.93"><vh>redraw</vh></v>
<v t="bob.20080111201957.94"><vh>refresh</vh></v>
<v t="bob.20080111201957.95"><vh>GetName</vh></v>
</v>
<v t="bob.20080111201957.96"><vh>class OutlineCanvas</vh>
<v t="bob.20080111201957.97"><vh>__init__</vh>
<v t="bob.20080111201957.98"><vh>&lt;&lt; define ivars &gt;&gt;</vh></v>
<v t="bob.20080111201957.99"><vh>&lt;&lt; create bindings &gt;&gt;</vh></v>
</v>
<v t="bob.20080111201957.101"><vh>hitTest</vh></v>
<v t="bob.20080111201957.102"><vh>_createNewBuffer</vh></v>
<v t="bob.20080111201957.103"><vh>vscrollTo</vh></v>
<v t="bob.20080113073006"><vh>hscrollTo</vh></v>
<v t="bob.20080111201957.104"><vh>resize</vh></v>
<v t="bob.20080112173505"><vh>redraw</vh></v>
<v t="bob.20080111201957.106"><vh>update</vh>
<v t="bob.20080111201957.107"><vh>&lt;&lt; find height of tree and position of currentNode &gt;&gt;</vh></v>
</v>
<v t="bob.20080111201957.109"><vh>onPaint</vh></v>
<v t="bob.20080112090335"><vh>onMap</vh></v>
<v t="bob.20080112224841"><vh>onSize</vh></v>
<v t="bob.20080111201957.105"><vh>refresh</vh></v>
<v t="bob.20080111201957.110"><vh>contextChanged</vh></v>
<v t="bob.20080111201957.111"><vh>requestLineHeight</vh></v>
<v t="bob.20080111201957.112"><vh>def draw</vh>
<v t="bob.20080111201957.113"><vh>&lt;&lt; draw tree &gt;&gt;</vh>
<v t="bob.20080111201957.114"><vh>&lt;&lt; set up object &gt;&gt;</vh></v>
<v t="bob.20080111201957.115"><vh>&lt;&lt; draw text &gt;&gt;</vh>
<v t="bob.20080111201957.116"><vh>&lt;&lt; draw user icons &gt;&gt;</vh></v>
</v>
<v t="bob.20080111201957.117"><vh>&lt;&lt; draw lines &gt;&gt;</vh></v>
<v t="bob.20080111201957.118"><vh>&lt;&lt; draw bitmaps &gt;&gt;</vh></v>
<v t="bob.20080111201957.119"><vh>&lt;&lt; draw focus &gt;&gt;</vh></v>
</v>
</v>
</v>
</v>
</v>
<v t="ekr.20080503202744.3"><vh>Rope</vh></v>
<v t="ekr.20080531131542.1"><vh>mxTextTools proto</vh>
<v t="ekr.20080531141227.1"><vh>&lt;&lt; define s &gt;&gt;</vh></v>
<v t="ekr.20080531131542.2"><vh>&lt;&lt; define scan4 tables &gt;&gt;</vh></v>
<v t="ekr.20080531131542.4"><vh>printItem</vh></v>
</v>
<v t="ekr.20080806145258.12"><vh>Prototype of Leo in Ajax</vh>
<v t="ekr.20080806145258.13"><vh>To do</vh></v>
<v t="ekr.20080806145258.14"><vh>@button Leo2DHTML</vh>
<v t="ekr.20080806145258.15"><vh>&lt;&lt; about LeoToHTML &gt;&gt;</vh></v>
<v t="ekr.20080806145258.16"><vh>&lt;&lt; define dhtml stuff &gt;&gt;</vh></v>
<v t="ekr.20080806145258.17"><vh>escape</vh></v>
<v t="ekr.20080806145258.18"><vh>writeAll</vh></v>
<v t="ekr.20080806145258.19"><vh>writeBody</vh></v>
<v t="ekr.20080806145258.20"><vh>writeHead</vh></v>
<v t="ekr.20080806145258.21"><vh>writeContents</vh></v>
<v t="ekr.20080806145258.22"><vh>writePreamble</vh></v>
<v t="ekr.20080806145258.23"><vh>writePostamble</vh></v>
</v>
<v t="ekr.20080806145258.24"><vh>@@file server.py</vh></v>
<v t="ekr.20080806145258.25"><vh>@@file hello.html</vh></v>
<v t="ekr.20080806145258.26"><vh>@@file cgi-bin/edward.py</vh>
<v t="ekr.20080806145702.1"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080806145258.27"><vh>&lt;&lt; define dhtml stuff &gt;&gt;</vh></v>
<v t="ekr.20080806145258.28"><vh>escape</vh></v>
<v t="ekr.20080806145258.29"><vh>print_all</vh></v>
<v t="ekr.20080806145258.30"><vh>print_body</vh></v>
<v t="ekr.20080806145258.31"><vh>print_head</vh></v>
<v t="ekr.20080806145258.32"><vh>print_leo_dot_js</vh></v>
<v t="ekr.20080806145258.33"><vh>print_tree</vh></v>
</v>
<v t="ekr.20080806145258.1"><vh>@@thin cgi-bin/leo.js</vh>
<v t="ekr.20080806145258.2"><vh>getElementbyClass</vh></v>
<v t="ekr.20080806145258.3"><vh>contractcontent</vh></v>
<v t="ekr.20080806145258.4"><vh>expandcontent</vh></v>
<v t="ekr.20080806145258.5"><vh>revivecontent</vh></v>
<v t="ekr.20080806145258.6"><vh>get_cookie</vh></v>
<v t="ekr.20080806145258.7"><vh>getselectedItem</vh></v>
<v t="ekr.20080806145258.8"><vh>saveswitchstate</vh></v>
<v t="ekr.20080806145258.9"><vh>do_onload</vh></v>
<v t="ekr.20080806145258.10"><vh>format</vh></v>
<v t="ekr.20080806145258.11"><vh>formatText</vh></v>
</v>
<v t="ekr.20080806145258.34"><vh>@@thin jqueryTest.html</vh></v>
</v>
<v t="ekr.20080811113441.2"><vh>Running body text as a windows script</vh>
<v t="ekr.20080807115344.1"><vh>Windows script</vh></v>
<v t="ekr.20080807114145.2"><vh>@button run-windows-script</vh>
<v t="ekr.20080807115344.5"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080807115344.2"><vh>class MySite</vh></v>
<v t="ekr.20080807115344.3"><vh>class Application</vh></v>
<v t="ekr.20080807115344.4"><vh>RunCode</vh></v>
</v>
</v>
<v t="ekr.20080929112400.1"><vh>qt proto</vh></v>
</v>
<v t="ekr.20071105085941"><vh>Tests</vh>
<v t="ekr.20080531080812.1"><vh>tracer test</vh></v>
<v t="ekr.20080604101239.1"><vh>Test misspelled word at index 0</vh></v>
<v t="ekr.20080610144233.1"><vh>Wrap test</vh></v>
<v t="ekr.20080617170334.1"><vh>Determining key values</vh></v>
<v t="ekr.20080628094340.1"><vh>Decorator test</vh></v>
<v t="ekr.20080701130406.1"><vh>plugins</vh></v>
<v t="ekr.20080920101658.1"><vh>getInput</vh></v>
<v t="ekr.20080923173133.1"><vh>scan-directives hook</vh></v>
<v t="ekr.20080930114036.1"><vh>icon stuff</vh>
<v t="ekr.20080930080501.1"><vh>Add icon row</vh></v>
<v t="ekr.20080930083052.1"><vh>hide icon rows</vh></v>
<v t="ekr.20080930083052.2"><vh>show icon rows</vh></v>
<v t="ekr.20080930085514.1"><vh>clear icon bar</vh></v>
</v>
<v t="ekr.20080917063615.1"><vh>getSettingSource</vh></v>
<v t="ekr.20080924081821.1"><vh>test of autoCompleter.getExternalCompletions</vh></v>
<v t="ekr.20081003094737.1"><vh>Unicode tests</vh>
<v t="ekr.20080701101740.1"><vh>locale tests</vh></v>
<v t="ekr.20080821111715.1"><vh>Standard print test (only works for Latin-1 and ascii)</vh></v>
</v>
<v t="ekr.20080922164656.1"><vh>Tests of path expressions</vh>
<v t="ekr.20080921144924.1"><vh>Tests of g.os_path_finalize</vh></v>
<v t="ekr.20080922142953.1"><vh>test os_pathExpression</vh></v>
<v t="ekr.20080922164255.1"></v>
<v t="ekr.20080922164255.2"><vh>@@shadow {{c.config.getString('test')}}/eval-shadow-test.txt</vh></v>
<v t="ekr.20080923073240.2"><vh>@path {{c.config.getString('test')}}</vh>
<v t="ekr.20080923073240.1"><vh>@@thin eval-thin-test.txt</vh></v>
</v>
</v>
<v t="ekr.20080813080809.1"><vh>Tests for @shadow</vh>
<v t="ekr.20080807091001.1"><vh>@@shadow python-import-test.py</vh>
<v t="ekr.20080807091201.7"><vh>python-import-test declarations</vh></v>
<v t="ekr.20080807091201.8"><vh>class Person</vh>
<v t="ekr.20080807091201.9"><vh>talk</vh></v>
<v t="ekr.20080807091201.10"><vh>class Meta</vh></v>
</v>
</v>
<v t="ekr.20080812112440.1"><vh>@@shadow at-shadow-test.ini</vh></v>
<v t="ekr.20080812135254.1"><vh>@@shadow at-unknown-shadow-test.xyzzy</vh></v>
<v t="ekr.20080801160915.1"><vh>@@shadow TerryBrownTest.py</vh>
<v t="ekr.20080803120643.1"><vh>spam</vh></v>
</v>
<v t="ekr.20080812102914.1"><vh>@@nosent at-nosent-test.py</vh>
<v t="ekr.20080812102914.2"><vh>child</vh></v>
</v>
<v t="ekr.20080813080627.1"><vh>@@shadow at-shadow-attributes-test.py</vh>
<v t="ekr.20080813080627.2"><vh>spam</vh>
<v t="ekr.20080813080729.1"><vh>child</vh></v>
</v>
<v t="ekr.20080813080627.3"><vh>eggs</vh></v>
</v>
<v t="ekr.20080819095720.1"><vh>@@shadow huh_extension_test.huh</vh></v>
<v t="ekr.20080909075224.1"><vh>@@shadow ekr-shadow-test.html</vh></v>
<v t="ekr.20080911080311.1"><vh>@@shadow dummy.conf</vh></v>
<v t="ekr.20080924033317.1"><vh>@@shadow weird-extension.C</vh>
<v t="ekr.20080924033317.2"><vh>spam</vh></v>
</v>
<v t="ekr.20081001110047.1"><vh>@@shadow mark-changed-nodes-test.py</vh>
<v t="ekr.20081001110047.2"><vh>spam</vh></v>
<v t="ekr.20081001110047.3"><vh>eggs</vh></v>
</v>
</v>
<v t="ekr.20081006070847.2"><vh>path convenience methods</vh></v>
<v t="ekr.20081025105942.1"><vh>@button dir</vh></v>
<v t="ekr.20081020082611.1"><vh>Calling a base class method</vh></v>
</v>
<v t="ekr.20081124102740.1"><vh>Accented characters</vh></v>
<v t="edward.20081127113749.1"><vh>@commands</vh>
<v t="edward.20081127113749.2"><vh>@command complete-previous</vh>
<v t="edward.20081127113749.3"><vh>WordCompleter</vh>
<v t="edward.20081127113749.4"><vh>complete_word</vh>
<v t="edward.20081127113749.5"><vh>&lt;&lt;backward search&gt;&gt;</vh>
<v t="edward.20081127113749.6"><vh>&lt;&lt;counter check&gt;&gt;</vh></v>
</v>
<v t="edward.20081127113749.7"><vh>&lt;&lt;forward search&gt;&gt;</vh>
<v t="edward.20081127113749.6"></v>
</v>
<v t="edward.20081127113749.8"><vh>&lt;&lt;clean up and exit&gt;&gt;</vh></v>
</v>
<v t="edward.20081127113749.9"><vh>acceptable_word</vh></v>
<v t="edward.20081127113749.10"><vh>undo_replacement</vh></v>
<v t="edward.20081127113749.11"><vh>redo_replacement</vh></v>
<v t="edward.20081127113749.12"><vh>exit</vh></v>
<v t="edward.20081127113749.13"><vh>run</vh></v>
<v t="edward.20081127113749.14"><vh>adjust</vh></v>
</v>
<v t="edward.20081127113749.15"><vh>getCurrentWord</vh></v>
</v>
<v t="edward.20081127113749.16"><vh>@command complete-next</vh>
<v t="edward.20081127113749.3"></v>
<v t="edward.20081127113749.15"></v>
</v>
</v>
<v t="ekr.20081202095209.1"><vh>Put minibuffer in a toolbar</vh></v>
<v t="ekr.20071129103842"></v>
<v t="ekr.20081202140932.1"><vh>pythoscope &amp; lib2to3</vh>
<v t="ekr.20081202141453.1"><vh>@path c:\leo.repo\pythoscope\pythoscope</vh>
<v t="ekr.20081202141210.1"><vh>@@auto\pythoscope\astvisitor.py</vh>
<v t="ekr.20081202141453.2"><vh>astvisitor declarations</vh></v>
<v t="ekr.20081202141453.3"><vh>clone</vh></v>
<v t="ekr.20081202141453.4"><vh>create_import</vh></v>
<v t="ekr.20081202141453.5"><vh>descend</vh></v>
<v t="ekr.20081202141453.6"><vh>find_last_leaf</vh></v>
<v t="ekr.20081202141453.7"><vh>get_starting_whitespace</vh></v>
<v t="ekr.20081202141453.8"><vh>remove_trailing_whitespace</vh></v>
<v t="ekr.20081202141453.9"><vh>parse</vh></v>
<v t="ekr.20081202141453.10"><vh>parse_fragment</vh></v>
<v t="ekr.20081202141453.11"><vh>regenerate</vh></v>
<v t="ekr.20081202141453.12"><vh>class ASTError</vh></v>
<v t="ekr.20081202141453.13"><vh>is_leaf_of_type</vh></v>
<v t="ekr.20081202141453.14"><vh>is_node_of_type</vh></v>
<v t="ekr.20081202141453.15"><vh>leaf_value</vh></v>
<v t="ekr.20081202141453.16"><vh>remove_commas</vh></v>
<v t="ekr.20081202141453.17"><vh>remove_defaults</vh></v>
<v t="ekr.20081202141453.18"><vh>derive_class_name</vh></v>
<v t="ekr.20081202141453.19"><vh>derive_class_names</vh></v>
<v t="ekr.20081202141453.20"><vh>derive_argument</vh></v>
<v t="ekr.20081202141453.21"><vh>derive_arguments</vh></v>
<v t="ekr.20081202141453.22"><vh>derive_import_name</vh></v>
<v t="ekr.20081202141453.23"><vh>derive_import_names</vh></v>
<v t="ekr.20081202141453.24"><vh>class ASTVisitor</vh>
<v t="ekr.20081202141453.25"><vh>__init__</vh></v>
<v t="ekr.20081202141453.26"><vh>register_pattern</vh></v>
<v t="ekr.20081202141453.27"><vh>visit</vh></v>
<v t="ekr.20081202141453.28"><vh>visit_leaf</vh></v>
<v t="ekr.20081202141453.29"><vh>visit_node</vh></v>
<v t="ekr.20081202141453.30"><vh>visit_class</vh></v>
<v t="ekr.20081202141453.31"><vh>visit_function</vh></v>
<v t="ekr.20081202141453.32"><vh>visit_import</vh></v>
<v t="ekr.20081202141453.33"><vh>visit_lambda_assign</vh></v>
<v t="ekr.20081202141453.34"><vh>visit_main_snippet</vh></v>
<v t="ekr.20081202141453.35"><vh>_visit_all</vh></v>
<v t="ekr.20081202141453.36"><vh>_visit_class</vh></v>
<v t="ekr.20081202141453.37"><vh>_visit_function</vh></v>
<v t="ekr.20081202141453.38"><vh>_visit_import</vh></v>
<v t="ekr.20081202141453.39"><vh>_visit_lambda_assign</vh></v>
<v t="ekr.20081202141453.40"><vh>_visit_main_snippet</vh></v>
</v>
</v>
<v t="ekr.20081202141210.2"><vh>@@auto logger.py</vh>
<v t="ekr.20081202141453.41"><vh>logger declarations</vh></v>
<v t="ekr.20081202141453.42"><vh>path2modname</vh></v>
<v t="ekr.20081202141453.43"><vh>class LogFormatter</vh>
<v t="ekr.20081202141453.44"><vh>format</vh></v>
</v>
<v t="ekr.20081202141453.45"><vh>setup_logger</vh></v>
<v t="ekr.20081202141453.46"><vh>get_output</vh></v>
<v t="ekr.20081202141453.47"><vh>set_output</vh></v>
</v>
<v t="ekr.20081202141210.3"><vh>@@auto serializer.py</vh>
<v t="ekr.20081202141453.48"><vh>serializer declarations</vh></v>
<v t="ekr.20081202141453.49"><vh>can_be_constructed</vh></v>
<v t="ekr.20081202141453.50"><vh>string2id</vh></v>
<v t="ekr.20081202141453.51"><vh>get_type_name</vh></v>
<v t="ekr.20081202141453.52"><vh>get_module_name</vh></v>
<v t="ekr.20081202141453.53"><vh>get_partial_reconstructor</vh></v>
<v t="ekr.20081202141453.54"><vh>get_human_readable_id</vh></v>
<v t="ekr.20081202141453.55"><vh>is_parsable</vh></v>
<v t="ekr.20081202141453.56"><vh>get_reconstructor_with_imports</vh></v>
<v t="ekr.20081202141453.57"><vh>class SerializedObject</vh>
<v t="ekr.20081202141453.58"><vh>__init__</vh></v>
<v t="ekr.20081202141453.59"><vh>__eq__</vh></v>
<v t="ekr.20081202141453.60"><vh>__hash__</vh></v>
<v t="ekr.20081202141453.61"><vh>__repr__</vh></v>
</v>
<v t="ekr.20081202141453.62"><vh>serialize</vh></v>
<v t="ekr.20081202141453.63"><vh>serialize_call_arguments</vh></v>
</v>
<v t="ekr.20081202141210.4"><vh>@@auto store.py</vh>
<v t="ekr.20081202141453.64"><vh>store declarations</vh></v>
<v t="ekr.20081202141453.65"><vh>class ModuleNeedsAnalysis</vh>
<v t="ekr.20081202141453.66"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202141453.67"><vh>class ModuleNotFound</vh>
<v t="ekr.20081202141453.68"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202141453.69"><vh>class ModuleSaveError</vh>
<v t="ekr.20081202141453.70"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202141453.71"><vh>get_pythoscope_path</vh></v>
<v t="ekr.20081202141453.72"><vh>get_pickle_path</vh></v>
<v t="ekr.20081202141453.73"><vh>get_points_of_entry_path</vh></v>
<v t="ekr.20081202141453.74"><vh>get_test_objects</vh></v>
<v t="ekr.20081202141453.75"><vh>class Project</vh>
<v t="ekr.20081202141453.76"><vh>from_directory</vh></v>
<v t="ekr.20081202141453.77"><vh>__init__</vh></v>
<v t="ekr.20081202141453.78"><vh>_get_pickle_path</vh></v>
<v t="ekr.20081202141453.79"><vh>_get_points_of_entry_path</vh></v>
<v t="ekr.20081202141453.80"><vh>_find_new_tests_directory</vh></v>
<v t="ekr.20081202141453.81"><vh>save</vh></v>
<v t="ekr.20081202141453.82"><vh>find_module_by_full_path</vh></v>
<v t="ekr.20081202141453.83"><vh>ensure_point_of_entry</vh></v>
<v t="ekr.20081202141453.84"><vh>remove_point_of_entry</vh></v>
<v t="ekr.20081202141453.85"><vh>create_module</vh></v>
<v t="ekr.20081202141453.86"><vh>create_test_module_from_name</vh></v>
<v t="ekr.20081202141453.87"><vh>remove_module</vh></v>
<v t="ekr.20081202141453.88"><vh>_replace_references_to_module</vh></v>
<v t="ekr.20081202141453.89"><vh>_extract_point_of_entry_subpath</vh></v>
<v t="ekr.20081202141453.90"><vh>_extract_subpath</vh></v>
<v t="ekr.20081202141453.91"><vh>iter_test_cases</vh></v>
<v t="ekr.20081202141453.92"><vh>_path_for_test</vh></v>
<v t="ekr.20081202141453.93"><vh>__getitem__</vh></v>
<v t="ekr.20081202141453.94"><vh>get_modules</vh></v>
<v t="ekr.20081202141453.95"><vh>iter_modules</vh></v>
<v t="ekr.20081202141453.96"><vh>iter_classes</vh></v>
<v t="ekr.20081202141453.97"><vh>iter_functions</vh></v>
<v t="ekr.20081202141453.98"><vh>iter_generator_objects</vh></v>
<v t="ekr.20081202141453.99"><vh>find_object</vh></v>
</v>
<v t="ekr.20081202141453.100"><vh>class Call</vh>
<v t="ekr.20081202141453.101"><vh>__init__</vh></v>
<v t="ekr.20081202141453.102"><vh>add_subcall</vh></v>
<v t="ekr.20081202141453.103"><vh>raised_exception</vh></v>
<v t="ekr.20081202141453.104"><vh>set_output</vh></v>
<v t="ekr.20081202141453.105"><vh>set_exception</vh></v>
<v t="ekr.20081202141453.106"><vh>clear_exception</vh></v>
<v t="ekr.20081202141453.107"><vh>is_testable</vh></v>
<v t="ekr.20081202141453.108"><vh>__eq__</vh></v>
<v t="ekr.20081202141453.109"><vh>__hash__</vh></v>
<v t="ekr.20081202141453.110"><vh>__repr__</vh></v>
</v>
<v t="ekr.20081202141453.111"><vh>class FunctionCall</vh>
<v t="ekr.20081202141453.112"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202141453.113"><vh>class MethodCall</vh></v>
<v t="ekr.20081202141453.114"><vh>class Definition</vh>
<v t="ekr.20081202141453.115"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202141453.116"><vh>class Callable</vh>
<v t="ekr.20081202141453.117"><vh>__init__</vh></v>
<v t="ekr.20081202141453.118"><vh>add_call</vh></v>
<v t="ekr.20081202141453.119"><vh>get_generator_object</vh></v>
<v t="ekr.20081202141453.120"><vh>remove_calls_from</vh></v>
</v>
<v t="ekr.20081202141453.121"><vh>class Function</vh>
<v t="ekr.20081202141453.122"><vh>__init__</vh></v>
<v t="ekr.20081202141453.123"><vh>is_testable</vh></v>
<v t="ekr.20081202141453.124"><vh>get_unique_calls</vh></v>
<v t="ekr.20081202141453.125"><vh>__repr__</vh></v>
</v>
<v t="ekr.20081202141453.126"><vh>class Method</vh></v>
<v t="ekr.20081202141453.127"><vh>class GeneratorObject</vh>
<v t="ekr.20081202141453.128"><vh>__init__</vh></v>
<v t="ekr.20081202141453.129"><vh>set_output</vh></v>
<v t="ekr.20081202141453.130"><vh>is_testable</vh></v>
<v t="ekr.20081202141453.131"><vh>__hash__</vh></v>
<v t="ekr.20081202141453.132"><vh>__repr__</vh></v>
</v>
<v t="ekr.20081202141453.133"><vh>class LiveObject</vh>
<v t="ekr.20081202141453.134"><vh>__init__</vh></v>
<v t="ekr.20081202141453.135"><vh>get_init_call</vh></v>
<v t="ekr.20081202141453.136"><vh>get_external_calls</vh></v>
<v t="ekr.20081202141453.137"><vh>__repr__</vh></v>
</v>
<v t="ekr.20081202141453.138"><vh>class Class</vh>
<v t="ekr.20081202141453.139"><vh>__init__</vh></v>
<v t="ekr.20081202141453.140"><vh>is_testable</vh></v>
<v t="ekr.20081202141453.141"><vh>add_live_object</vh></v>
<v t="ekr.20081202141453.142"><vh>remove_live_objects_from</vh></v>
<v t="ekr.20081202141453.143"><vh>get_traced_method_names</vh></v>
<v t="ekr.20081202141453.144"><vh>get_untraced_methods</vh></v>
<v t="ekr.20081202141453.145"><vh>find_method_by_name</vh></v>
</v>
<v t="ekr.20081202141453.146"><vh>class TestCase</vh>
<v t="ekr.20081202141453.147"><vh>__init__</vh></v>
<v t="ekr.20081202141453.148"><vh>replace_itself_with</vh></v>
</v>
<v t="ekr.20081202141453.149"><vh>class TestSuite</vh>
<v t="ekr.20081202141453.150"><vh>__init__</vh></v>
<v t="ekr.20081202141453.151"><vh>add_test_cases</vh></v>
<v t="ekr.20081202141453.152"><vh>add_test_case</vh></v>
<v t="ekr.20081202141453.153"><vh>replace_test_case</vh></v>
<v t="ekr.20081202141453.154"><vh>mark_as_changed</vh></v>
<v t="ekr.20081202141453.155"><vh>ensure_imports</vh></v>
<v t="ekr.20081202141453.156"><vh>_ensure_import</vh></v>
<v t="ekr.20081202141453.157"><vh>_contains_import</vh></v>
<v t="ekr.20081202141453.158"><vh>_check_test_case_type</vh></v>
</v>
<v t="ekr.20081202141453.159"><vh>class TestMethod</vh></v>
<v t="ekr.20081202141453.160"><vh>class TestClass</vh>
<v t="ekr.20081202141453.161"><vh>__init__</vh></v>
<v t="ekr.20081202141453.162"><vh>_append_test_case_code</vh></v>
<v t="ekr.20081202141453.163"><vh>find_method_by_name</vh></v>
<v t="ekr.20081202141453.164"><vh>is_testable</vh></v>
</v>
<v t="ekr.20081202141453.165"><vh>class Localizable</vh>
<v t="ekr.20081202141453.166"><vh>__init__</vh></v>
<v t="ekr.20081202141453.167"><vh>_get_locator</vh></v>
<v t="ekr.20081202141453.168"><vh>is_out_of_sync</vh></v>
<v t="ekr.20081202141453.169"><vh>is_up_to_date</vh></v>
<v t="ekr.20081202141453.170"><vh>get_path</vh></v>
<v t="ekr.20081202141453.171"><vh>write</vh></v>
<v t="ekr.20081202141453.172"><vh>exists</vh></v>
</v>
<v t="ekr.20081202141453.173"><vh>class Module</vh>
<v t="ekr.20081202141453.174"><vh>__init__</vh></v>
<v t="ekr.20081202141453.175"><vh>_get_testable_objects</vh></v>
<v t="ekr.20081202141453.176"><vh>_get_classes</vh></v>
<v t="ekr.20081202141453.177"><vh>_get_functions</vh></v>
<v t="ekr.20081202141453.178"><vh>_get_test_classes</vh></v>
<v t="ekr.20081202141453.179"><vh>add_test_case</vh></v>
<v t="ekr.20081202141453.180"><vh>get_content</vh></v>
<v t="ekr.20081202141453.181"><vh>get_test_cases_for_module</vh></v>
<v t="ekr.20081202141453.182"><vh>_ensure_main_snippet</vh></v>
<v t="ekr.20081202141453.183"><vh>_ensure_import</vh></v>
<v t="ekr.20081202141453.184"><vh>_add_import</vh></v>
<v t="ekr.20081202141453.185"><vh>_append_test_case_code</vh></v>
<v t="ekr.20081202141453.186"><vh>_insert_before_main_snippet</vh></v>
<v t="ekr.20081202141453.187"><vh>save</vh></v>
</v>
<v t="ekr.20081202141453.188"><vh>class PointOfEntry</vh>
<v t="ekr.20081202141453.189"><vh>__init__</vh></v>
<v t="ekr.20081202141453.190"><vh>get_path</vh></v>
<v t="ekr.20081202141453.191"><vh>get_content</vh></v>
<v t="ekr.20081202141453.192"><vh>clear_previous_run</vh></v>
<v t="ekr.20081202141453.193"><vh>create_method_call</vh></v>
<v t="ekr.20081202141453.194"><vh>create_function_call</vh></v>
<v t="ekr.20081202141453.195"><vh>finalize_inspection</vh></v>
<v t="ekr.20081202141453.196"><vh>_retrieve_live_object_for_method</vh></v>
<v t="ekr.20081202141453.197"><vh>_retrieve_generator_object</vh></v>
<v t="ekr.20081202141453.198"><vh>_retrieve_live_object</vh></v>
<v t="ekr.20081202141453.199"><vh>_preserve</vh></v>
<v t="ekr.20081202141453.200"><vh>_fix_generator_objects</vh></v>
</v>
</v>
<v t="ekr.20081202141210.5"><vh>@@auto util.py</vh>
<v t="ekr.20081202141453.201"><vh>util declarations</vh></v>
<v t="ekr.20081202141453.202"><vh>camelize</vh></v>
<v t="ekr.20081202141453.203"><vh>underscore</vh></v>
<v t="ekr.20081202141453.204"><vh>read_file_contents</vh></v>
<v t="ekr.20081202141453.205"><vh>write_string_to_file</vh></v>
<v t="ekr.20081202141453.206"><vh>all_of_type</vh></v>
<v t="ekr.20081202141453.207"><vh>max_by_not_zero</vh></v>
<v t="ekr.20081202141453.208"><vh>python_modules_below</vh></v>
<v t="ekr.20081202141453.209"><vh>rlistdir</vh></v>
<v t="ekr.20081202141453.210"><vh>get_names</vh></v>
<v t="ekr.20081202141453.211"><vh>class DirectoryException</vh></v>
<v t="ekr.20081202141453.212"><vh>ensure_directory</vh></v>
<v t="ekr.20081202141453.213"><vh>get_last_modification_time</vh></v>
<v t="ekr.20081202141453.214"><vh>extract_subpath</vh></v>
<v t="ekr.20081202141453.215"><vh>directories_under</vh></v>
<v t="ekr.20081202141453.216"><vh>findfirst</vh></v>
<v t="ekr.20081202141453.217"><vh>contains_active_generator</vh></v>
<v t="ekr.20081202141453.218"><vh>is_generator_code</vh></v>
<v t="ekr.20081202141453.219"><vh>compile_without_warnings</vh></v>
<v t="ekr.20081202141453.220"><vh>quoted_block</vh></v>
<v t="ekr.20081202141453.221"><vh>cname</vh></v>
<v t="ekr.20081202141453.222"><vh>module_path_to_name</vh></v>
<v t="ekr.20081202141453.223"><vh>regexp_flags_as_string</vh></v>
</v>
<v t="ekr.20081202141210.6"><vh>@@auto __init__.py</vh>
<v t="ekr.20081202141453.224"><vh>__init__ declarations</vh></v>
<v t="ekr.20081202141453.225"><vh>class PythoscopeDirectoryMissing</vh></v>
<v t="ekr.20081202141453.226"><vh>find_project_directory</vh></v>
<v t="ekr.20081202141453.227"><vh>init_project</vh></v>
<v t="ekr.20081202141453.228"><vh>generate_tests</vh></v>
<v t="ekr.20081202141453.229"><vh>main</vh></v>
</v>
<v t="ekr.20081202141453.230"><vh>@@auto generator\adder.py</vh>
<v t="ekr.20081202142943.1"><vh>adder declarations</vh></v>
<v t="ekr.20081202142943.2"><vh>add_test_case_to_project</vh></v>
<v t="ekr.20081202142943.3"><vh>find_test_class_by_name</vh></v>
<v t="ekr.20081202142943.4"><vh>merge_test_classes</vh></v>
<v t="ekr.20081202142943.5"><vh>find_place_for_test_class</vh></v>
<v t="ekr.20081202142943.6"><vh>find_test_module</vh></v>
<v t="ekr.20081202142943.7"><vh>find_associate_test_module_by_name</vh></v>
<v t="ekr.20081202142943.8"><vh>find_associate_test_module_by_test_classs</vh></v>
<v t="ekr.20081202142943.9"><vh>test_module_name_for_test_case</vh></v>
<v t="ekr.20081202142943.10"><vh>create_test_module</vh></v>
<v t="ekr.20081202142943.11"><vh>module_path_to_test_path</vh></v>
<v t="ekr.20081202142943.12"><vh>possible_test_module_names</vh></v>
<v t="ekr.20081202142943.13"><vh>possible_test_module_paths</vh></v>
</v>
<v t="ekr.20081202141453.231"><vh>@@auto generator\__init__.py</vh>
<v t="ekr.20081202142943.14"><vh>__init__ declarations</vh></v>
<v t="ekr.20081202142943.15"><vh>list_of</vh></v>
<v t="ekr.20081202142943.16"><vh>type_as_string</vh></v>
<v t="ekr.20081202142943.17"><vh>class CallString</vh>
<v t="ekr.20081202142943.18"><vh>__new__</vh></v>
<v t="ekr.20081202142943.19"><vh>extend</vh></v>
</v>
<v t="ekr.20081202142943.20"><vh>constructor_as_string</vh></v>
<v t="ekr.20081202142943.21"><vh>call_as_string</vh></v>
<v t="ekr.20081202142943.22"><vh>object2id</vh></v>
<v t="ekr.20081202142943.23"><vh>objects_list_to_id</vh></v>
<v t="ekr.20081202142943.24"><vh>input_as_string</vh></v>
<v t="ekr.20081202142943.25"><vh>objcall2testname</vh></v>
<v t="ekr.20081202142943.26"><vh>exccall2testname</vh></v>
<v t="ekr.20081202142943.27"><vh>gencall2testname</vh></v>
<v t="ekr.20081202142943.28"><vh>call2testname</vh></v>
<v t="ekr.20081202142943.29"><vh>sorted_test_method_descriptions</vh></v>
<v t="ekr.20081202142943.30"><vh>name2testname</vh></v>
<v t="ekr.20081202142943.31"><vh>in_lambda</vh></v>
<v t="ekr.20081202142943.32"><vh>in_list</vh></v>
<v t="ekr.20081202142943.33"><vh>type_of</vh></v>
<v t="ekr.20081202142943.34"><vh>map_types</vh></v>
<v t="ekr.20081202142943.35"><vh>decorate_call</vh></v>
<v t="ekr.20081202142943.36"><vh>should_ignore_method</vh></v>
<v t="ekr.20081202142943.37"><vh>testable_calls</vh></v>
<v t="ekr.20081202142943.38"><vh>is_builtin_exception</vh></v>
<v t="ekr.20081202142943.39"><vh>class UnknownTemplate</vh>
<v t="ekr.20081202142943.40"><vh>__init__</vh></v>
</v>
<v t="ekr.20081202142943.41"><vh>find_method_code</vh></v>
<v t="ekr.20081202142943.42"><vh>class TestMethodDescription</vh>
<v t="ekr.20081202142943.43"><vh>__init__</vh></v>
<v t="ekr.20081202142943.44"><vh>contains_code</vh></v>
<v t="ekr.20081202142943.45"><vh>_get_code_assertions</vh></v>
<v t="ekr.20081202142943.46"><vh>_has_complete_setup</vh></v>
</v>
<v t="ekr.20081202142943.47"><vh>class TestGenerator</vh>
<v t="ekr.20081202142943.48"><vh>from_template</vh></v>
<v t="ekr.20081202142943.49"><vh>__init__</vh></v>
<v t="ekr.20081202142943.50"><vh>ensure_import</vh></v>
<v t="ekr.20081202142943.51"><vh>ensure_imports</vh></v>
<v t="ekr.20081202142943.52"><vh>add_tests_to_project</vh></v>
<v t="ekr.20081202142943.53"><vh>create_test_class</vh></v>
<v t="ekr.20081202142943.54"><vh>comment_assertion</vh></v>
<v t="ekr.20081202142943.55"><vh>equal_stub_assertion</vh></v>
<v t="ekr.20081202142943.56"><vh>raises_stub_assertion</vh></v>
<v t="ekr.20081202142943.57"><vh>_add_tests_for_module</vh></v>
<v t="ekr.20081202142943.58"><vh>_generate_test_cases</vh></v>
<v t="ekr.20081202142943.59"><vh>_generate_test_case</vh></v>
<v t="ekr.20081202142943.60"><vh>_generate_test_method_descriptions</vh></v>
<v t="ekr.20081202142943.61"><vh>_generate_test_method_descriptions_for_function</vh></v>
<v t="ekr.20081202142943.62"><vh>_generate_test_method_descriptions_for_class</vh></v>
<v t="ekr.20081202142943.63"><vh>_generate_test_method_description_for_method</vh></v>
<v t="ekr.20081202142943.64"><vh>_method_descriptions_from_function</vh></v>
<v t="ekr.20081202142943.65"><vh>_method_description_from_live_object</vh></v>
<v t="ekr.20081202142943.66"><vh>_create_assertion</vh></v>
</v>
<v t="ekr.20081202142943.67"><vh>class UnittestTestGenerator</vh>
<v t="ekr.20081202142943.68"><vh>test_class_header</vh></v>
<v t="ekr.20081202142943.69"><vh>equal_assertion</vh></v>
<v t="ekr.20081202142943.70"><vh>raises_assertion</vh></v>
<v t="ekr.20081202142943.71"><vh>missing_assertion</vh></v>
</v>
<v t="ekr.20081202142943.72"><vh>class NoseTestGenerator</vh>
<v t="ekr.20081202142943.73"><vh>test_class_header</vh></v>
<v t="ekr.20081202142943.74"><vh>equal_assertion</vh></v>
<v t="ekr.20081202142943.75"><vh>raises_assertion</vh></v>
<v t="ekr.20081202142943.76"><vh>missing_assertion</vh></v>
</v>
<v t="ekr.20081202142943.77"><vh>add_tests_to_project</vh></v>
</v>
<v t="ekr.20081202142943.78"><vh>@@auto inspector\dynamic.py</vh>
<v t="ekr.20081202143139.1"><vh>dynamic declarations</vh></v>
<v t="ekr.20081202143139.2"><vh>class CallStack</vh>
<v t="ekr.20081202143139.3"><vh>__init__</vh></v>
<v t="ekr.20081202143139.4"><vh>called</vh></v>
<v t="ekr.20081202143139.5"><vh>returned</vh></v>
<v t="ekr.20081202143139.6"><vh>raised</vh></v>
</v>
<v t="ekr.20081202143139.7"><vh>compact</vh></v>
<v t="ekr.20081202143139.8"><vh>find_variable</vh></v>
<v t="ekr.20081202143139.9"><vh>callable_type</vh></v>
<v t="ekr.20081202143139.10"><vh>is_class_definition</vh></v>
<v t="ekr.20081202143139.11"><vh>class NotMethodFrame</vh></v>
<v t="ekr.20081202143139.12"><vh>get_method_information</vh></v>
<v t="ekr.20081202143139.13"><vh>resolve_args</vh></v>
<v t="ekr.20081202143139.14"><vh>input_from_argvalues</vh></v>
<v t="ekr.20081202143139.15"><vh>is_ignored_code</vh></v>
<v t="ekr.20081202143139.16"><vh>create_call</vh></v>
<v t="ekr.20081202143139.17"><vh>tracer</vh></v>
<v t="ekr.20081202143139.18"><vh>start_tracing</vh></v>
<v t="ekr.20081202143139.19"><vh>stop_tracing</vh></v>
<v t="ekr.20081202143139.20"><vh>trace_function</vh></v>
<v t="ekr.20081202143139.21"><vh>trace_exec</vh></v>
<v t="ekr.20081202143139.22"><vh>setup_tracing</vh></v>
<v t="ekr.20081202143139.23"><vh>teardown_tracing</vh></v>
<v t="ekr.20081202143139.24"><vh>inspect_point_of_entry</vh></v>
</v>
<v t="ekr.20081202142943.79"><vh>@@auto inspector\static.py</vh>
<v t="ekr.20081202143139.25"><vh>static declarations</vh></v>
<v t="ekr.20081202143139.26"><vh>is_test_class</vh></v>
<v t="ekr.20081202143139.27"><vh>unindent</vh></v>
<v t="ekr.20081202143139.28"><vh>function_code_from_definition</vh></v>
<v t="ekr.20081202143139.29"><vh>is_generator_definition</vh></v>
<v t="ekr.20081202143139.30"><vh>create_definition</vh></v>
<v t="ekr.20081202143139.31"><vh>class ModuleVisitor</vh>
<v t="ekr.20081202143139.32"><vh>__init__</vh></v>
<v t="ekr.20081202143139.33"><vh>visit_class</vh></v>
<v t="ekr.20081202143139.34"><vh>visit_function</vh></v>
<v t="ekr.20081202143139.35"><vh>visit_lambda_assign</vh></v>
<v t="ekr.20081202143139.36"><vh>visit_import</vh></v>
<v t="ekr.20081202143139.37"><vh>visit_main_snippet</vh></v>
</v>
<v t="ekr.20081202143139.38"><vh>class ClassVisitor</vh>
<v t="ekr.20081202143139.39"><vh>__init__</vh></v>
<v t="ekr.20081202143139.40"><vh>visit_class</vh></v>
<v t="ekr.20081202143139.41"><vh>visit_function</vh></v>
</v>
<v t="ekr.20081202143139.42"><vh>inspect_module</vh></v>
<v t="ekr.20081202143139.43"><vh>inspect_code</vh></v>
</v>
<v t="ekr.20081202142943.80"><vh>@@auto inspector\__init__.py</vh>
<v t="ekr.20081202143139.44"><vh>__init__ declarations</vh></v>
<v t="ekr.20081202143139.45"><vh>inspect_project</vh></v>
<v t="ekr.20081202143139.46"><vh>remove_deleted_modules</vh></v>
<v t="ekr.20081202143139.47"><vh>add_and_update_modules</vh></v>
<v t="ekr.20081202143139.48"><vh>remove_deleted_points_of_entry</vh></v>
<v t="ekr.20081202143139.49"><vh>add_and_update_points_of_entry</vh></v>
<v t="ekr.20081202143139.50"><vh>inspect_project_dynamically</vh></v>
</v>
</v>
<v t="ekr.20081203091734.1"><vh>@path c:\leo.repo\pythoscope\lib2to3</vh>
<v t="ekr.20081204111623.1"><vh>test of path directives</vh></v>
<v t="ekr.20081203091734.11"><vh>@@auto patcomp.py</vh>
<v t="ekr.20081203092030.7"><vh>patcomp declarations</vh></v>
<v t="ekr.20081203092030.8"><vh>tokenize_wrapper</vh></v>
<v t="ekr.20081203092030.9"><vh>class PatternCompiler</vh>
<v t="ekr.20081203092030.10"><vh>__init__</vh></v>
<v t="ekr.20081203092030.11"><vh>compile_pattern</vh></v>
<v t="ekr.20081203092030.12"><vh>compile_node</vh></v>
<v t="ekr.20081203092030.13"><vh>compile_basic</vh></v>
<v t="ekr.20081203092030.14"><vh>get_int</vh></v>
</v>
<v t="ekr.20081203092030.15"><vh>pattern_convert</vh></v>
<v t="ekr.20081203092030.16"><vh>compile_pattern</vh></v>
</v>
<v t="ekr.20081203091734.12"><vh>@@auto pygram.py</vh>
<v t="ekr.20081203092030.17"><vh>pygram declarations</vh></v>
<v t="ekr.20081203092030.18"><vh>class Symbols</vh>
<v t="ekr.20081203092030.19"><vh>__init__</vh></v>
</v>
<v t="ekr.20081203092030.20"><vh>parenthesize</vh></v>
</v>
<v t="ekr.20081203091734.13"><vh>@@auto pytree.py</vh>
<v t="ekr.20081203092030.21"><vh>pytree declarations</vh></v>
<v t="ekr.20081203092030.22"><vh>type_repr</vh></v>
<v t="ekr.20081203092030.23"><vh>class Base</vh>
<v t="ekr.20081203092030.24"><vh>__new__</vh></v>
<v t="ekr.20081203092030.25"><vh>__eq__</vh></v>
<v t="ekr.20081203092030.26"><vh>__ne__</vh></v>
<v t="ekr.20081203092030.27"><vh>_eq</vh></v>
<v t="ekr.20081203092030.28"><vh>clone</vh></v>
<v t="ekr.20081203092030.29"><vh>post_order</vh></v>
<v t="ekr.20081203092030.30"><vh>pre_order</vh></v>
<v t="ekr.20081203092030.31"><vh>set_prefix</vh></v>
<v t="ekr.20081203092030.32"><vh>get_prefix</vh></v>
<v t="ekr.20081203092030.33"><vh>replace</vh></v>
<v t="ekr.20081203092030.34"><vh>get_lineno</vh></v>
<v t="ekr.20081203092030.35"><vh>changed</vh></v>
<v t="ekr.20081203092030.36"><vh>remove</vh></v>
<v t="ekr.20081203092030.37"><vh>get_next_sibling</vh></v>
<v t="ekr.20081203092030.38"><vh>get_prev_sibling</vh></v>
<v t="ekr.20081203092030.39"><vh>get_suffix</vh></v>
</v>
<v t="ekr.20081203092030.40"><vh>class Node</vh>
<v t="ekr.20081203092030.41"><vh>__init__</vh></v>
<v t="ekr.20081203092030.42"><vh>__repr__</vh></v>
<v t="ekr.20081203092030.43"><vh>__str__</vh></v>
<v t="ekr.20081203092030.44"><vh>_eq</vh></v>
<v t="ekr.20081203092030.45"><vh>clone</vh></v>
<v t="ekr.20081203092030.46"><vh>post_order</vh></v>
<v t="ekr.20081203092030.47"><vh>pre_order</vh></v>
<v t="ekr.20081203092030.48"><vh>set_prefix</vh></v>
<v t="ekr.20081203092030.49"><vh>get_prefix</vh></v>
<v t="ekr.20081203092030.50"><vh>set_child</vh></v>
<v t="ekr.20081203092030.51"><vh>insert_child</vh></v>
<v t="ekr.20081203092030.52"><vh>append_child</vh></v>
</v>
<v t="ekr.20081203092030.53"><vh>class Leaf</vh>
<v t="ekr.20081203092030.54"><vh>__init__</vh></v>
<v t="ekr.20081203092030.55"><vh>__repr__</vh></v>
<v t="ekr.20081203092030.56"><vh>__str__</vh></v>
<v t="ekr.20081203092030.57"><vh>_eq</vh></v>
<v t="ekr.20081203092030.58"><vh>clone</vh></v>
<v t="ekr.20081203092030.59"><vh>post_order</vh></v>
<v t="ekr.20081203092030.60"><vh>pre_order</vh></v>
<v t="ekr.20081203092030.61"><vh>set_prefix</vh></v>
<v t="ekr.20081203092030.62"><vh>get_prefix</vh></v>
</v>
<v t="ekr.20081203092030.63"><vh>convert</vh></v>
<v t="ekr.20081203092030.64"><vh>class BasePattern</vh>
<v t="ekr.20081203092030.65"><vh>__new__</vh></v>
<v t="ekr.20081203092030.66"><vh>__repr__</vh></v>
<v t="ekr.20081203092030.67"><vh>optimize</vh></v>
<v t="ekr.20081203092030.68"><vh>match</vh></v>
<v t="ekr.20081203092030.69"><vh>match_seq</vh></v>
<v t="ekr.20081203092030.70"><vh>generate_matches</vh></v>
</v>
<v t="ekr.20081203092030.71"><vh>class LeafPattern</vh>
<v t="ekr.20081203092030.72"><vh>__init__</vh></v>
<v t="ekr.20081203092030.73"><vh>match</vh></v>
<v t="ekr.20081203092030.74"><vh>_submatch</vh></v>
</v>
<v t="ekr.20081203092030.75"><vh>class NodePattern</vh>
<v t="ekr.20081203092030.76"><vh>__init__</vh></v>
<v t="ekr.20081203092030.77"><vh>_submatch</vh></v>
</v>
<v t="ekr.20081203092030.78"><vh>class WildcardPattern</vh>
<v t="ekr.20081203092030.79"><vh>__init__</vh></v>
<v t="ekr.20081203092030.80"><vh>optimize</vh></v>
<v t="ekr.20081203092030.81"><vh>match</vh></v>
<v t="ekr.20081203092030.82"><vh>match_seq</vh></v>
<v t="ekr.20081203092030.83"><vh>generate_matches</vh></v>
<v t="ekr.20081203092030.84"><vh>_bare_name_matches</vh></v>
<v t="ekr.20081203092030.85"><vh>_recursive_matches</vh></v>
</v>
<v t="ekr.20081203092030.86"><vh>class NegatedPattern</vh>
<v t="ekr.20081203092030.87"><vh>__init__</vh></v>
<v t="ekr.20081203092030.88"><vh>match</vh></v>
<v t="ekr.20081203092030.89"><vh>match_seq</vh></v>
<v t="ekr.20081203092030.90"><vh>generate_matches</vh></v>
</v>
<v t="ekr.20081203092030.91"><vh>generate_matches</vh></v>
</v>
<v t="ekr.20081203091734.14"><vh>@@auto __init__.py</vh></v>
</v>
<v t="ekr.20081203091734.15"><vh>@path c:\leo.repo\pythoscope\lib2to3\pgen2</vh>
<v t="ekr.20081203092326.1"><vh>Comments from parse.c</vh></v>
<v t="ekr.20081203091734.16"><vh>@@auto conv.py</vh>
<v t="ekr.20081203092030.92"><vh>conv declarations</vh></v>
<v t="ekr.20081203092030.93"><vh>class Converter</vh>
<v t="ekr.20081203092030.94"><vh>run</vh></v>
<v t="ekr.20081203092030.95"><vh>parse_graminit_h</vh></v>
<v t="ekr.20081203092030.96"><vh>parse_graminit_c</vh></v>
<v t="ekr.20081203092030.97"><vh>finish_off</vh></v>
</v>
</v>
<v t="ekr.20081203091734.17"><vh>@@auto driver.py</vh>
<v t="ekr.20081203092030.98"><vh>driver declarations</vh></v>
<v t="ekr.20081203092030.99"><vh>class Driver</vh>
<v t="ekr.20081203092030.100"><vh>__init__</vh></v>
<v t="ekr.20081203092030.101"><vh>parse_tokens</vh></v>
<v t="ekr.20081203092030.102"><vh>parse_stream_raw</vh></v>
<v t="ekr.20081203092030.103"><vh>parse_stream</vh></v>
<v t="ekr.20081203092030.104"><vh>parse_file</vh></v>
<v t="ekr.20081203092030.105"><vh>parse_string</vh></v>
</v>
<v t="ekr.20081203092030.106"><vh>generate_lines</vh></v>
<v t="ekr.20081203092030.107"><vh>load_grammar</vh></v>
<v t="ekr.20081203092030.108"><vh>_newer</vh></v>
</v>
<v t="ekr.20081203091734.18"><vh>@@auto grammar.py </vh>
<v t="ekr.20081203092030.1"><vh>grammar declarations</vh></v>
<v t="ekr.20081203092030.2"><vh>class Grammar</vh>
<v t="ekr.20081203092030.3"><vh>__init__</vh></v>
<v t="ekr.20081203092030.4"><vh>dump</vh></v>
<v t="ekr.20081203092030.5"><vh>load</vh></v>
<v t="ekr.20081203092030.6"><vh>report</vh></v>
</v>
</v>
<v t="ekr.20081203091734.19"><vh>@@auto literals.py</vh>
<v t="ekr.20081203092030.109"><vh>literals declarations</vh></v>
<v t="ekr.20081203092030.110"><vh>escape</vh></v>
<v t="ekr.20081203092030.111"><vh>evalString</vh></v>
<v t="ekr.20081203092030.112"><vh>test</vh></v>
</v>
<v t="ekr.20081203091734.20"><vh>@@auto parse.py</vh>
<v t="ekr.20081203092030.113"><vh>parse declarations</vh></v>
<v t="ekr.20081203092030.114"><vh>class ParseError</vh>
<v t="ekr.20081203092030.115"><vh>__init__</vh></v>
<v t="ekr.20081203092030.116"><vh>__reduce__</vh></v>
</v>
<v t="ekr.20081203092030.117"><vh>class Parser</vh>
<v t="ekr.20081203092030.118"><vh>__init__</vh></v>
<v t="ekr.20081203092030.119"><vh>setup</vh></v>
<v t="ekr.20081203092030.120"><vh>addtoken</vh></v>
<v t="ekr.20081203092030.121"><vh>classify</vh></v>
<v t="ekr.20081203092030.122"><vh>shift</vh></v>
<v t="ekr.20081203092030.123"><vh>push</vh></v>
<v t="ekr.20081203092030.124"><vh>pop</vh></v>
</v>
</v>
<v t="ekr.20081203091734.21"><vh>@@auto pgen.py</vh>
<v t="ekr.20081203092030.125"><vh>pgen declarations</vh></v>
<v t="ekr.20081203092030.126"><vh>class PgenGrammar</vh></v>
<v t="ekr.20081203092030.127"><vh>class ParserGenerator</vh>
<v t="ekr.20081203092030.128"><vh>__init__</vh></v>
<v t="ekr.20081203092030.129"><vh>make_grammar</vh></v>
<v t="ekr.20081203092030.130"><vh>make_first</vh></v>
<v t="ekr.20081203092030.131"><vh>make_label</vh></v>
<v t="ekr.20081203092030.132"><vh>addfirstsets</vh></v>
<v t="ekr.20081203092030.133"><vh>calcfirst</vh></v>
<v t="ekr.20081203092030.134"><vh>parse</vh></v>
<v t="ekr.20081203092030.135"><vh>make_dfa</vh></v>
<v t="ekr.20081203092030.136"><vh>dump_nfa</vh></v>
<v t="ekr.20081203092030.137"><vh>dump_dfa</vh></v>
<v t="ekr.20081203092030.138"><vh>simplify_dfa</vh></v>
<v t="ekr.20081203092030.139"><vh>parse_rhs</vh></v>
<v t="ekr.20081203092030.140"><vh>parse_alt</vh></v>
<v t="ekr.20081203092030.141"><vh>parse_item</vh></v>
<v t="ekr.20081203092030.142"><vh>parse_atom</vh></v>
<v t="ekr.20081203092030.143"><vh>expect</vh></v>
<v t="ekr.20081203092030.144"><vh>gettoken</vh></v>
<v t="ekr.20081203092030.145"><vh>raise_error</vh></v>
</v>
<v t="ekr.20081203092030.146"><vh>class NFAState</vh>
<v t="ekr.20081203092030.147"><vh>__init__</vh></v>
<v t="ekr.20081203092030.148"><vh>addarc</vh></v>
</v>
<v t="ekr.20081203092030.149"><vh>class DFAState</vh>
<v t="ekr.20081203092030.150"><vh>__init__</vh></v>
<v t="ekr.20081203092030.151"><vh>addarc</vh></v>
<v t="ekr.20081203092030.152"><vh>unifystate</vh></v>
<v t="ekr.20081203092030.153"><vh>__eq__</vh></v>
</v>
<v t="ekr.20081203092030.154"><vh>generate_grammar</vh></v>
</v>
<v t="ekr.20081203091734.22"><vh>@@auto token.py</vh>
<v t="ekr.20081203092030.155"><vh>token declarations</vh></v>
<v t="ekr.20081203092030.156"><vh>ISTERMINAL</vh></v>
<v t="ekr.20081203092030.157"><vh>ISNONTERMINAL</vh></v>
<v t="ekr.20081203092030.158"><vh>ISEOF</vh></v>
</v>
<v t="ekr.20081203091734.23"><vh>@@auto tokenize.py</vh>
<v t="ekr.20081203092030.159"><vh>tokenize declarations</vh></v>
<v t="ekr.20081203092030.160"><vh>group</vh></v>
<v t="ekr.20081203092030.161"><vh>any</vh></v>
<v t="ekr.20081203092030.162"><vh>maybe</vh></v>
<v t="ekr.20081203092030.163"><vh>class TokenError</vh></v>
<v t="ekr.20081203092030.164"><vh>class StopTokenizing</vh></v>
<v t="ekr.20081203092030.165"><vh>printtoken</vh></v>
<v t="ekr.20081203092030.166"><vh>tokenize</vh></v>
<v t="ekr.20081203092030.167"><vh>tokenize_loop</vh></v>
<v t="ekr.20081203092030.168"><vh>class Untokenizer</vh>
<v t="ekr.20081203092030.169"><vh>__init__</vh></v>
<v t="ekr.20081203092030.170"><vh>add_whitespace</vh></v>
<v t="ekr.20081203092030.171"><vh>untokenize</vh></v>
<v t="ekr.20081203092030.172"><vh>compat</vh></v>
</v>
<v t="ekr.20081203092030.173"><vh>untokenize</vh></v>
<v t="ekr.20081203092030.174"><vh>generate_tokens</vh></v>
</v>
<v t="ekr.20081203091734.24"><vh>@@auto __init__.py</vh>
<v t="ekr.20081203092030.175"><vh>__init__ declarations</vh></v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="bob.20080111194559">@first


class GtkLeoTreeDemo(object):


    @others</t>
<t tx="bob.20080111200056">@first #!/usr/bin/python
import sys, os



import pygtk
pygtk.require('2.0')
import gtk

import pango
import cairo

@others

def abspath(*args):
    return os.path.abspath(os.path.join(*args))



if __name__ == "__main__": 

    leoDir = abspath(sys.path[0],'..')
    sys.path[1:1] = [abspath(leoDir, '..')]

    import leo.core.leoGlobals as g
    g.g = g

    import leo.core.leoBridge as leoBridge

    controller = leoBridge.controller(gui='nullGui')
    c = controller.openLeoFile(abspath(leoDir, 'test', 'unitTest.leo'))

    outlineFont = ''

    colors = g.importExtension('colors')

    GtkLeoTreeDemo()

    gtk.main()


</t>
<t tx="bob.20080111201957.77">
class OutlineCanvasPanel(object):
    """A class to mimic a scrolled window to contain an OutlineCanvas."""

    @others
</t>
<t tx="bob.20080111201957.78">
def __init__(self, parent, leoTree, name):
    """Create an OutlineCanvasPanel instance."""

    #g.trace('OutlineCanvasPanel')

    #self._leoTree = leoTree
    #self.c = leoTree.c
    self.c = c

    self._x = 0
    self._y = 0

    self._canvas = canvas = OutlineCanvas(self)
    #canvas.resize(400, 300)

    self._table = gtk.Table(2,2)

    self._hscrollbar = gtk.HScrollbar()
    self._vscrollbar = gtk.VScrollbar()

    self._hadj = h = self._hscrollbar.get_adjustment()
    self._vadj = v = self._vscrollbar.get_adjustment()

    self._hscrollbar.set_range(0, 10)
    self._vscrollbar.set_range(0, 20)


    v.connect('value-changed', self.onScrollVertical)
    h.connect('value-changed', self.onScrollHorizontal)

    self._table.attach(self._hscrollbar, 0, 1, 1, 2, yoptions=0)
    self._table.attach(self._vscrollbar, 1, 2, 0, 1, xoptions=0)


    options = gtk.SHRINK | gtk.FILL | gtk.EXPAND
    self._table.attach(self._canvas, 0, 1, 0, 1, options, options)

    parent.add(self._table)

    self._canvas.set_events(
        gtk.gdk.POINTER_MOTION_MASK |
                gtk.gdk.POINTER_MOTION_HINT_MASK
    )


    #self._entry = wx.TextCtrl(self._canvas,
    #    style = wx.SIMPLE_BORDER | wx.WANTS_CHARS
    #)

    #self._entry._virtualTop = -1000
    #self._entry.Hide()
    #self._canvas._widgets.append(self._entry)

    #self._canvas.update()


    # self.Bind(wx.EVT_SIZE, self.onSize)


    #self.SetBackgroundColour(self._leoTree.outline_pane_background_color)

    #self.Bind(wx.EVT_CHAR,
    #    lambda event, self=self._leoTree: onGlobalChar(self, event)
    #)

    #self.onScroll(wx.HORIZONTAL, 0)

</t>
<t tx="bob.20080111201957.79">showcount = 0
def showEntry(self):

    # self.showcount +=1

    # print
    # g.trace(self.showcount, g.callers(20))
    # print

    entry = self._entry
    canvas = self._canvas

    ep = self._leoTree.editPosition()

    if not ep:
        return self.hideEntry()


    for sp in canvas._positions:
        if ep == sp:
            break
    else:
        return self.hideEntry()

    x, y, width, height = sp._textBoxRect
    #g.pr('	', x, y, width , height)

    entry._virtualTop = canvas._virtualTop + y -2

    entry.MoveXY(x - 2, y -2)
    entry.SetSize((max(width + 4, 100), -1))

    tw = self._leoTree.headlineTextWidget

    range = tw.getSelectionRange()
    tw.setInsertPoint(0)
    #tw.setInsertPoint(len(sp.headString()))
    tw.setSelectionRange(*range)
    entry.Show()
</t>
<t tx="bob.20080111201957.80">
def hideEntry(self):

    entry = self._entry
    entry._virtualTop = -1000
    entry.MoveXY(0, -1000)

    entry.Hide()
</t>
<t tx="bob.20080111201957.81">
def getPositions(self):
    return self._canvas._positions</t>
<t tx="bob.20080111201957.87">def onScrollVertical(self, adjustment):
    """Scroll the outline vertically to a new position."""

    self._canvas.vscrollTo(int(adjustment.value))</t>
<t tx="bob.20080111201957.88">
def onScrollRelative(self, orient, value):

    return self.onScroll(orient, self.GetScrollPos(orient) + value)
</t>
<t tx="bob.20080111201957.90">
def vscrollUpdate(self):
    """Set the vertical scroll bar to match current conditions."""

    canvas = self._canvas

    oldtop = top = canvas._virtualTop
    canvasHeight = canvas.get_allocation().height
    treeHeight = canvas._treeHeight

    if (treeHeight - top) &lt; canvasHeight:
        top = treeHeight - canvasHeight

    if top &lt; 0 :
        top = 0

    if oldtop != top:
        canvas._virtualTop = top
        canvas.redraw()
        top = canvas._virtualTop

    #self.showEntry()

    self._vadj.set_all(
        top, #value
        0, #lower
        treeHeight, #upper
        canvasHeight * 0.1, #step_increment
        canvasHeight * 0.9, #page_increment
        canvasHeight #page-size
    )


</t>
<t tx="bob.20080111201957.91">
def hscrollUpdate(self):
    """Set the vertical scroll bar to match current conditions."""

    canvas = self._canvas

    oldleft = left = canvas._virtualLeft
    canvasWidth = canvas.get_allocation().width
    treeWidth = canvas._treeWidth

    if (treeWidth - left) &lt; canvasWidth:
        left = treeWidth - canvasWidth

    if left &lt; 0 :
        left = 0

    if oldleft != left:
        canvas._virtualLeft = left
        canvas.redraw()
        left = canvas._virtualLeft

    #self.showEntry()

    self._hadj.set_all(
        left, #value
        0, #lower
        treeWidth, #upper
        canvasWidth * 0.1, #step_increment
        canvasWidth * 0.9, #page_increment
        canvasWidth #page-size
    )

</t>
<t tx="bob.20080111201957.92">
def update(self):
    self._canvas.update()


</t>
<t tx="bob.20080111201957.93">
def redraw(self):
    self._canvas.redraw()</t>
<t tx="bob.20080111201957.94">def refresh(self):
    self._canvas.refresh()</t>
<t tx="bob.20080111201957.95">def GetName(self):
    return 'canvas'

getName = GetName</t>
<t tx="bob.20080111201957.96">class OutlineCanvas(gtk.DrawingArea):
    """Implements a virtual view of a leo outline tree.

    The class uses an off-screen buffer for drawing which it
    blits to the window during paint calls for expose events, etc,

    A redraw is only required when the size of the canvas changes,
    a scroll event occurs, or if the outline changes.

    """
    @others
</t>
<t tx="bob.20080111201957.97">def __init__(self, parent):
    """Create an OutlineCanvas instance."""

    #g.trace('OutlineCanvas')

    self.c = c = parent.c

    self._parent = parent
    #self.leoTree = parent.leoTree


    &lt;&lt; define ivars &gt;&gt;

    gtk.DrawingArea.__init__(self)
    self._pangoLayout = self.create_pango_layout("Wq")


    # g.trace()


    self._font = pango.FontDescription(outlineFont)

    self._pangoLayout.set_font_description(self._font)


    self._buffer = None

    self.contextChanged()

    #self.Bind(wx.EVT_PAINT, self.onPaint)

    self.connect('map-event', self.onMap)


    #for o in (self, parent):
    #    &lt;&lt; create  bindings &gt;&gt;

@
self.box_padding = 5 # extra padding between box and icon
self.box_width = 9 + self.box_padding
self.icon_width = 20
self.text_indent = 4 # extra padding between icon and tex

self.hline_y = 7 # Vertical offset of horizontal line
self.root_left = 7 + self.box_width
self.root_top = 2

self.default_line_height = 17 + 2 # default if can't set line_height from font.
self.line_height = self.default_line_height

</t>
<t tx="bob.20080111201957.98">#self._icons = icons

self._widgets = []

self.drag_p = None

self._size =  [1000, 1000]

self._virtualTop = 0
self._virtualLeft = 0

self._textIndent = 30

self._xPad = 30
self._yPad = 2

self._treeHeight = 500
self._treeWidth = 500

self._positions = []

self._fontHeight = None
self._iconSize = [20, 11]

self._clickBoxSize = None
self._lineHeight =  10
self._requestedLineHeight = 10

self._yTextOffset = None
self._yIconOffset = None

self._clickBoxCenterOffset = None

self._clickBoxOffset = None


</t>
<t tx="bob.20080111201957.99"># onmouse = self._leoTree.onMouse

# for e, s in (
   # ( wx.EVT_LEFT_DOWN,     'LeftDown'),
   # ( wx.EVT_LEFT_UP,       'LeftUp'),
   # ( wx.EVT_LEFT_DCLICK,   'LeftDoubleClick'),
   # ( wx.EVT_MIDDLE_DOWN,   'MiddleDown'),
   # ( wx.EVT_MIDDLE_UP,     'MiddleUp'),
   # ( wx.EVT_MIDDLE_DCLICK, 'MiddleDoubleClick'),
   # ( wx.EVT_RIGHT_DOWN,    'RightDown'),
   # ( wx.EVT_RIGHT_UP,      'RightUp'),
   # ( wx.EVT_RIGHT_DCLICK,  'RightDoubleClick'),
   # ( wx.EVT_MOTION,        'Motion')
# ):
    # o.Bind(e, lambda event, type=s: onmouse(event, type))



# #self.Bind(wx.EVT_KEY_UP, self._leoTree.onChar)
# #self.Bind(wx.EVT_KEY_DOWN, lambda event: self._leoTree.onKeyDown(event))

# self.Bind(wx.EVT_CHAR,
    # lambda event, self=self._leoTree: onGlobalChar(self, event)
# )

</t>
<t tx="bob.20080111201957.101">def hitTest(self, x, y):
    result = self._hitTest(point)
    g.trace(result)
    return result

def hitTest(self, xx, yy):

    for sp in self._positions:

        if yy &lt; (sp._top + self._lineHeight):

            x, y, w, h = sp._clickBoxRect
            if xx &gt; x  and xx &lt; (x + w) and yy &gt; y and yy &lt; (y + h):
                return sp, 'ClickBox'

            x, y, w, h = sp._iconBoxRect
            if xx &gt; x  and xx &lt; (x + w) and yy &gt; y and yy &lt; (y + h):
                return sp, 'IconBox'

            x, y, w, h = sp._textBoxRect
            if xx &gt; x  and xx &lt; (x + w) and yy &gt; y and yy &lt; (y + h): 
                return sp, 'TextBox'

            i = -1  
            for x, y, w, h in sp._headStringIcons:
                i += 1
                if xx &gt; x  and xx &lt; (x + w) and yy &gt; y and yy &lt;(y + h):
                   return sp, i

            return sp, 'Headline'

    return None, 'Canvas'

</t>
<t tx="bob.20080111201957.102">def _createNewBuffer(self):
    """Create a new buffer for drawing."""


    if not self.window:
        g.trace('no window !!!!!!!!!!!!!!!!')
        g.trace(g.callers())
        return


    w, h = self.window.get_size()
    #g.trace(g.callers())


    if self._buffer:
        bw, bh = self._buffer.get_size()
        if bw &gt;= w and bh &gt;= h:
            return

    self._buffer = gtk.gdk.Pixmap(self.window, w, h)





</t>
<t tx="bob.20080111201957.103">
def vscrollTo(self, pos):
    """Scroll the canvas vertically to the specified position."""

    canvasHeight = self.get_allocation().height
    if (self._treeHeight - canvasHeight) &lt; pos :
        pos = self._treeHeight - canvasHeight

    pos = max(0, pos)

    self._virtualTop = pos

    self.redraw()
</t>
<t tx="bob.20080111201957.104">
def resize(self):
    """Resize the outline canvas and, if required, create and draw on a new buffer."""

    c = self.c

    #c.beginUpdate()     #lock out events
    if 1: #try:

        self._createNewBuffer()

        #self._parent.hscrollUpdate()


        self.draw()
        self.refresh()


    #finally:
    #    c.endUpdate(False)


    return True





</t>
<t tx="bob.20080111201957.105">
#def refresh(self):
    # """Renders the offscreen buffer to the outline canvas."""
    # return

    # #g.pr('refresh')
    # wx.ClientDC(self).BlitPointSize((0,0), self._size, self._buffer, (0, 0))

refresh = onPaint</t>
<t tx="bob.20080111201957.106">
def update(self):
    """Do a full update assuming the tree has been changed."""

    c = self.c

    canvasHeight = self.get_allocation().height

    hoistFlag = bool(self.c.hoistStack)

    if hoistFlag:
        stk = [self.c.hoistStack[-1].p]
    else:
        stk = [self.c.rootPosition()]

    &lt;&lt; find height of tree and position of currentNode &gt;&gt;

    if (self._treeHeight - self._virtualTop) &lt; canvasHeight:
        self._virtualTop = self._treeHeight - canvasHeight

    # if (self._treeHeight - self._virtualTop) &lt; canvasHeight:
        # self._virtualTop = self._treeHeight - canvasHeight

    self.contextChanged()

    self.redraw()
    self._parent.vscrollUpdate()
    self._parent.hscrollUpdate()


</t>
<t tx="bob.20080111201957.107">
# Find the number of visible nodes in the outline.

cp = c.currentPosition().copy()
cpCount = None

count = 0
while stk:

    p = stk.pop()

    while p:


        if stk or not hoistFlag:
            newp = p.next()
        else:
            newp = None

        if cp and cp == p:
            cpCount = count
            cp = False

        count += 1

        if p.isExpanded() and p.hasFirstChild():
            stk.append(newp)
            p = p.firstChild()
            continue

        p = newp

lineHeight = self._lineHeight

self._treeHeight = count * lineHeight
g.trace( 'treeheight ', self._treeHeight)

if cpCount is not None:
    cpTop = cpCount * lineHeight

    if cpTop &lt; self._virtualTop:
        self._virtualTop = cpTop

    elif cpTop + lineHeight &gt; self._virtualTop + canvasHeight:
        self._virtualTop += (cpTop + lineHeight) - (self._virtualTop + canvasHeight)



</t>
<t tx="bob.20080111201957.109">
def onPaint(self, *args):
    """Renders the off-screen buffer to the outline canvas."""

    # w, h are needed because the buffer may be bigger than the window.

    w, h = self.window.get_size()

    # We use self.style.black_gc only because we need a gc, it has no relavence.

    self.window.draw_drawable(self.style.black_gc ,self._buffer, 0, 0, 0, 0, w, h)
</t>
<t tx="bob.20080111201957.110">def contextChanged(self):
    """Adjust canvas attributes after a change in context.

    This should be called after setting or changing fonts or icon size or
    anything that effects the tree display.

    """

    self._pangoLayout.set_text('Wy')
    self._fontHeight = self._pangoLayout.get_pixel_size()[1]
    self._iconSize = (20, 11) #(icons[0].GetWidth(), icons[0].GetHeight())

    self._clickBoxSize = (9, 9) #(plusBoxIcon.GetWidth(), plusBoxIcon.GetHeight())

    self._lineHeight = max(
        self._fontHeight,
        self._iconSize[1],
        self._requestedLineHeight
    ) + 2 * self._yPad

    # y offsets

    self._yTextOffset = (self._lineHeight - self._fontHeight)//2

    self._yIconOffset = (self._lineHeight - self._iconSize[1])//2

    self._clickBoxCenterOffset = (
        -self._textIndent*2 + self._iconSize[0]//2,
        self._lineHeight//2
    )

    self._clickBoxOffset = (
        self._clickBoxCenterOffset[0] - self._clickBoxSize[0]//2,
        (self._lineHeight  - self._clickBoxSize[1])//2
    )


</t>
<t tx="bob.20080111201957.111">def requestLineHeight(height):
    """Request a minimum height for lines."""

    assert int(height) and height &lt; 200
    self.requestedHeight = height
    self.beginUpdate()
    self.endUpdate()
</t>
<t tx="bob.20080111201957.112">
def draw(self, *args):
    """Draw the outline on the off-screen buffer."""

    r, g, b = colors.getColorRGB('leoyellow')
    r, g, b = r/255.0, g/255.0, b/255.0

    x, y, canvasWidth, canvasHeight = self.get_allocation()


    pangoLayout = self._pangoLayout


    cr = self._buffer.cairo_create()


    cr.set_source_rgb(r, g, b)
    cr.rectangle(x, y, canvasWidth, canvasHeight)
    cr.fill()

    c = self.c


    top = self._virtualTop
    if top &lt; 0:
        self._virtualTop = top = 0

    left = self._virtualLeft
    if left &lt; 0:
        self._virtualLeft = left = 0   


    bottom = top + canvasHeight


    textIndent = self._textIndent
    treeWidth = self._treeWidth

    yPad = self._yPad
    xPad = self._xPad - left

    yIconOffset = self._yIconOffset

    yTextOffset = self._yTextOffset

    clickBoxOffset_x, clickBoxOffset_y = self._clickBoxOffset

    clickBoxCenterOffset_x, clickBoxCenterOffset_y = \
        self._clickBoxCenterOffset

    clickBoxSize_w, clickBoxSize_h = self._clickBoxSize

    iconSize_w, iconSize_h = self._iconSize

    lineHeight = self._lineHeight
    halfLineHeight = lineHeight//2

    &lt;&lt; draw tree &gt;&gt;

    #self._parent.showEntry()

    return True






</t>
<t tx="bob.20080111201957.113">y = 0

hoistFlag = bool(c.hoistStack)

if hoistFlag:
    stk = [c.hoistStack[-1].p]
else:
    stk = [c.rootPosition()]

self._positions = positions = []

@
My original reason for writing the loop this way was to make it as fast as
possible. Perhaps I was being a bit too paranoid and we should change back to
more conventional iterations, on the other hand if it ain't broke don't fix it.
@c


while stk:

    p = stk.pop()

    while p:

        if stk or not hoistFlag:
            newp = p.next()
        else:
            newp = None

        mytop = y
        y = y + lineHeight

        if mytop &gt; bottom:
            stk = []
            p = None
            break

        if y &gt; top:

            sp = p.copy()

            &lt;&lt; setup object &gt;&gt;

            positions.append(sp)

            treeWidth = max(
                treeWidth,
                textSize_w + xTextOffset + left
            )

        if p.isExpanded() and p.hasFirstChild():
            stk.append(newp)
            p = p.firstChild()
            continue

        p = newp

if treeWidth &gt; self._treeWidth:
    # theoretically this could be recursive
    # but its unlikely ...
    self._treeWidth = treeWidth
    self._parent.hscrollUpdate()

if not positions:
    #g.trace('No positions!')
    return

self._virtualTop =  positions[0]._virtualTop


# try:
    # result = self._leoTree.drawTreeHook(self)
    # g.pr('result =', result)
# except:
    # result = False
    # g.pr('result is False')

# if hasattr(self._leoTree, 'drawTreeHook'):
    # try:
        # result = self._leoTree.drawTreeHook(self)
    # except:
        # result = False
# else:
    # #g.pr('drawTreeHook not known')
    # result = None

# if not result:
if 1:
    &lt;&lt; draw text &gt;&gt;
    &lt;&lt; draw lines &gt;&gt;
    &lt;&lt; draw bitmaps &gt;&gt;

    &lt;&lt; draw focus &gt;&gt;




</t>
<t tx="bob.20080111201957.114"># depth: the depth of indentation relative to the current hoist.
sp._depth = len(stk)

# virtualTop: top of the line in virtual canvas coordinates
sp._virtualTop =  mytop

# top: top of the line in real canvas coordinates
sp._top = mytop - top


pangoLayout.set_text(sp.headString())

textSize_w, textSize_h = pangoLayout.get_pixel_size()

xTextOffset = ((sp._depth +1) * textIndent) + xPad

textPos_x = xTextOffset # - self._hadj.value
textPos_y =  sp._top + yTextOffset

iconPos_x = textPos_x - textIndent
iconPos_y = textPos_y + yIconOffset

clickBoxPos_x = textPos_x + clickBoxOffset_x
clickBoxPos_y = textPos_y + clickBoxOffset_y

sp._clickBoxCenter_x = clickBoxPos_x + clickBoxCenterOffset_x
sp._clickBoxCenter_y = clickBoxPos_y + clickBoxCenterOffset_y

sp._textBoxRect = [textPos_x, textPos_y, textSize_w, textSize_h]
sp._iconBoxRect = [iconPos_x, iconPos_y, iconSize_w, iconSize_h]
sp._clickBoxRect = [clickBoxPos_x, clickBoxPos_y, clickBoxSize_w, clickBoxSize_h]

sp._icon = icons[p.v.computeIcon()]


if sp.hasFirstChild():
    sp._clickBoxIcon = plusBoxIcon
    if sp.isExpanded():
        sp._clickBoxIcon = minusBoxIcon
else:
    sp._clickBoxIcon = None

sp._clickRegions = []

</t>
<t tx="bob.20080111201957.115">
current = c.currentPosition()



for sp in positions:

    &lt;&lt; draw user icons &gt;&gt;

    # if current and current == sp:
        # dc.SetBrush(wx.LIGHT_GREY_BRUSH)
        # dc.SetPen(wx.LIGHT_GREY_PEN)
        # dc.DrawRectangleRect(
            # wx.Rect(*sp._textBoxRect).Inflate(3, 3)
        # )
        # current = False
        # #dc.SetBrush(wx.TRANSPARENT_BRUSH)
        # #dc.SetPen(wx.BLACK_PEN)


    pangoLayout.set_text(sp.headString())
    x, y, w, h = sp._textBoxRect
    cr.set_source_rgb(0, 0, 0)
    cr.move_to(x, y)
    #cr.update_layout(pangoLayout)
    cr.show_layout(pangoLayout)


</t>
<t tx="bob.20080111201957.116">

try:
    headStringIcons = sp.v.t.unknownAttributes.get('icons', [])
except:
    headStringIcons = None

sp._headStringIcons = hsi = []

if headStringIcons:

    for headStringIcon in headStringIcons:
        try:
            image = globalImages[headStringIcon['relPath']]
        except KeyError:
            path = headStringIcon['relPath']
            image = getImage(path)
            if image is None:
                return


        x, y, w, h = sp._textBoxRect

        hsi.append((x, y, image.get_width(), image.get_height()))       

        cr.set_source_pixbuf(image, x, y)
        cr.paint()

        sp._textBoxRect[0] = x + image.get_width() + 5

</t>
<t tx="bob.20080111201957.117"></t>
<t tx="bob.20080111201957.118">
for sp in positions:

    x, y, w, h = sp._iconBoxRect

    cr.set_source_pixbuf(sp._icon,x,y)
    cr.paint()
    #cr.stroke()

    if sp._clickBoxIcon:
        x, y, w, h = sp._clickBoxRect
        cr.set_source_pixbuf(sp._clickBoxIcon, x, y)
        cr.paint()

@
  ctx = da.window.cairo_create()
  # You can put ctx.scale(..) or ctx.rotate(..) here, if you need some
  ct = gtk.gdk.CairoContext(ctx)
  ct.set_source_pixbuf(pixbuf,0,0)
  ctx.paint()
  ctx.stroke()




</t>
<t tx="bob.20080111201957.119">if 0:
    dc.SetBrush(wx.TRANSPARENT_BRUSH)
    if self._leoTree.hasFocus():
        dc.SetPen(wx.BLACK_PEN)
    #else:
    #    dc.SetPen(wx.GREEN_PEN)
        dc.DrawRectanglePointSize( (0,0), self.GetSize())</t>
<t tx="bob.20080112090335">def onMap(self, *args):
    self._createNewBuffer()
    self.update()
    self.connect('expose-event', self.onPaint)
    self.connect("size-allocate", self.onSize)
</t>
<t tx="bob.20080112173505">def redraw(self):
    self.draw()
    self.refresh()
</t>
<t tx="bob.20080112224841">def onSize(self, *args):
    """React to changes in the size of the outlines display area."""


    c = self.c
    c.beginUpdate()
    try:
        self.resize()
        self._parent.vscrollUpdate()
        self._parent.hscrollUpdate()
    finally:
        c.endUpdate(False)


</t>
<t tx="bob.20080113073006">def hscrollTo(self, pos):
    """Scroll the canvas vertically to the specified position."""

    canvasWidth = self.get_allocation().width

    #g.trace(pos)

    if (self._treeWidth - canvasWidth) &lt; pos :
        pos = min(0, self._treeWidth - canvasWidth)

    pos = max( 0, pos)

    self._virtualLeft = pos

    self.redraw()
</t>
<t tx="bob.20080113090336">def onScrollHorizontal(self, adjustment):
    """Scroll the outline horizontally to a new position.

    """
    self._canvas.hscrollTo(int(adjustment.value))
</t>
<t tx="bob.20080113133525">def loadIcons():

    global icons, plusBoxIcon, minusBoxIcon, appIcon, namedIcons, globalImages

    import cStringIO



    icons = []
    namedIcons = {}


    path = g.os_path_abspath(g.os_path_join(g.app.loadDir, '..', 'Icons'))
    if g.os_path_exists(g.os_path_join(path, 'box01.GIF')):
        ext = '.GIF'
    else:
        ext = '.gif'

    for i in range(16):
        icon = loadIcon(g.os_path_join(path, 'box%02d'%i + ext))
        icons.append(icon)



    for name in (
        'lt_arrow_enabled',
        'rt_arrow_enabled',
        'lt_arrow_disabled',
        'rt_arrow_disabled',
        'plusnode',
        'minusnode'
    ):
        icon = loadIcon(g.os_path_join(path, name + '.gif'))
        if icon:
            namedIcons[name] = icon

    plusBoxIcon = namedIcons['plusnode']
    minusBoxIcon = namedIcons['minusnode']

    globalImages = {}

</t>
<t tx="bob.20080113141134">

def name2color(name, default=None, cairo=False):




    if isinstance(name, cls ):
        return name

    color = colors.getColorRGB(name)

    if color is None:
        if default:
            return name2color(default)
        else:
            return None

    r, g, b = color

    if cairo:
        return r/255.0, g/255.0, b/255.0 

    return gtk.gdk.Color(r,g,b)
</t>
<t tx="bob.20080113170041">def getImage (relPath, force=False):


    if not force and relPath in globalImages:
        image = globalImages[relPath]
        g.es('cach ', image, image.get_height(), getColor('magenta'))
        return image, image.get_height()

    try:
        path = g.os_path_normpath(g.os_path_join(g.app.loadDir,"..","Icons", relPath))
        globalImages[relPath] = image = loadIcon(path)
        return image

    except Exception:
        pass

    try:
        path = g.os_path_normpath(relPath)
        localImages[relPath] =  image = loadIcon(path)
        return image
    except Exception:
        pass

    return None
</t>
<t tx="bob.20080113170657">def loadIcon(fname):

    try:
        icon = gtk.gdk.pixbuf_new_from_file(fname)
    except:
        icon = None

    if icon and icon.get_width()&gt;0:
        return icon

    g.pr('Can not load icon from', fname)
</t>
<t tx="bob.20080113183321">def onButtonPress(self, w, event, *args):

    codes = {
        gtk.gdk.BUTTON_PRESS: 'click',
        gtk.gdk._2BUTTON_PRESS: 'double_click',
        gtk.gdk._3BUTTON_PRESS: 'triple_click',
        gtk.gdk.BUTTON_RELEASE: 'release'
    }


    sp, item = self.canvas.hitTest(event.x, event.y)
    g.pr(
        codes[event.type], '%s[%s]: %s'%(
            g.choose(isinstance(item, int), 'headStringIcon[%s]'%item, item),
            'button-%s'%event.button,
            sp.headString()
        ))

    if item == 'ClickBox' and event.button == 1:
        if sp.isExpanded():
            sp.contract()
        else:
            sp.expand()

        self.canvas.update()
</t>
<t tx="bob.20080113183321.1"></t>
<t tx="bob.20080113184034">def __init__(self):

    #for n in c.allNodes_iter():
    #    g.pr(n.headString())


    window = gtk.Window(gtk.WINDOW_TOPLEVEL)
    window.set_title("gtkLeo Outline Widget Demo")
    window.connect("destroy", lambda w: gtk.main_quit())
    window.set_size_request(10, 10)
    window.resize(400, 300)

    loadIcons()

    self.panel = OutlineCanvasPanel(window, c, 'canvas')

    self.canvas = canvas = self.panel._canvas
    g.trace(canvas)

    canvas.set_events(gtk.gdk.ALL_EVENTS_MASK)
    canvas.connect('button_press_event', self.onButtonPress)
    #canvas.connect('button_release_event', self.onButtonPress)

    window.show_all()



</t>
<t tx="bob.20080114060133"></t>
<t tx="edreamleo.20080110083531">import gtk

@others

createWindow()

gtk.main()</t>
<t tx="edreamleo.20080110130828">def createWindow():

    def onKeyUp(w,event):
        g.trace(event.state,event.keyval,event.string)

    window = gtk.Window()
    window.set_title("Hello World")

    # button = gtk.Button("-----Press me-----")
    # button.connect("clicked",onButtonPressed)
    # window.add(button)

    splitter1 = gtk.VPaned()
    window.add(splitter1)

    tree = gtk.TextView()
    buf1 = tree.get_buffer()
    buf1.set_text("tree")

    body = gtk.TextView()
    buf2 = body.get_buffer()
    buf2.set_text("body")
    body.connect("key_release_event",onKeyUp)

    splitter1.add(tree)
    splitter1.add2(body)

    window.connect("delete-event",gtk.main_quit)
    window.show_all()
    return window
</t>
<t tx="edward.20081127113749.1"></t>
<t tx="edward.20081127113749.2">wordsep = u'., -+\n\r[]{}&lt;&gt;=-+*&amp;%$#@!"\'?/\\|^()~`:;'
word_completer_key = 'back_word_completer'
@others
completer = g.app.config.get(c,word_completer_key,'WordCompleter')
if completer is None:
    completer = WordCompleter(p,c,back=True)
    g.app.config.set(c,word_completer_key,'WordCompleter',completer)
    completer.run()
else:
    completer.adjust(p, c.frame.body.getInsertPoint())
    completer.complete_word()
</t>
<t tx="edward.20081127113749.3">class WordCompleter:
    def __init__(self, p, c, back=True):
        self.p = p.copy()
        self.c = c
        self.back = back
        self.pos = -1
    @others
</t>
<t tx="edward.20081127113749.4">def complete_word(self):
    txt = self.chunk
    word = self.word
    try:
        if self.back:
            &lt;&lt;backward search&gt;&gt;
        else:
            &lt;&lt;forward search&gt;&gt;
        &lt;&lt;clean up and exit&gt;&gt;
    except:
        self.exit()
        g.es_exception()</t>
<t tx="edward.20081127113749.5">p = self.search_pos
start = -1
counter = 0
while p:
    &lt;&lt;counter check&gt;&gt;
    i = txt.rfind(word, 0, start)
    if i == -1:
        p.moveToThreadBack()
        if p:self.chunk = txt = p.bodyString()
        start = -1
    else:
        if self.acceptable_word(i, txt, word):
            self.chunk = txt[:i+len(word)-1]
            return
        start = i+len(word)-1</t>
<t tx="edward.20081127113749.6">counter+=1
if counter &gt; 10000:
    g.es_trace("counter max")
    break</t>
<t tx="edward.20081127113749.7">p = self.search_pos
start = 0
counter = 0
while p:
    &lt;&lt;counter check&gt;&gt;
    i = txt.find(word, start)
    if i == -1:
        p.moveToThreadNext()
        if p:self.chunk = txt = p.bodyString()
        start = 0
    else:
        if self.acceptable_word(i, txt, word):
            self.chunk = txt[i+1:]
            return
        start = i+1</t>
<t tx="edward.20081127113749.8">if len(self.tried) &gt; 1:
    # there was some tries so we need to restore
    self.c.setBodyString(self.p, self.before+self.word+self.after)
    self.c.frame.body.setInsertPoint(self.pos)
return self.exit()</t>
<t tx="edward.20081127113749.9">@ if found word for the first time then try it
@c
def acceptable_word(self, i, txt, word):
    if i == 0 or wordsep.find(txt[i-1]) != -1:
        j = i+len(word)
        while j &lt; len(txt) and wordsep.find(txt[j]) &lt; 0:
            j += 1
        nword = txt[i:j]
        if nword not in self.tried:
            self.tried[nword] = 1
            u = self.c.undoer
            bunch = u.createCommonBunch(p)
            bunch.oldBody = p.bodyString()
            bunch.insertPos = self.pos
            # Set the type &amp; helpers.
            bunch.kind = 'node'
            bunch.undoType = 'complete word'
            bunch.undoHelper = self.undo_replacement
            bunch.redoHelper = self.redo_replacement
            bunch.newBody = newBody = self.before+nword+self.after

            self.c.setBodyString(self.p, newBody)
            self.c.frame.body.setInsertPoint(self.pos)

            bunch.dirtyVnodeList = [p.v]
            bunch.newChanged = u.c.isChanged()
            bunch.newDirty = p.isDirty()
            bunch.newMarked = p.isMarked()

            u.pushBead(bunch)

            return True
    return False
</t>
<t tx="edward.20081127113749.10">def undo_replacement(self):
    u = self.c.undoer; c=self.c; p=u.p
    bunch = u.getBead(u.bead)
    c.setBodyString(p, bunch.oldBody)
    c.frame.body.setInsertPoint(bunch.insertPos)</t>
<t tx="edward.20081127113749.11">def redo_replacement(self):
    c = self.c; u=c.undoer; bunch=u.getBead(u.bead+1)
    c.setBodyString(bunch.p, bunch.newBody)
    c.frame.body.setInsertPoint(bunch.insertPos)</t>
<t tx="edward.20081127113749.12">def exit(self):
    #g.app.config.set(c,word_completer_key,'WordCompleter',None)
    #g.app.config.set(c,'next_word_completer','WordCompleter',None)
    self.pos = -1</t>
<t tx="edward.20081127113749.13">def run(self):
    self.adjust(self.p, c.frame.body.getInsertPoint())
    self.complete_word()
</t>
<t tx="edward.20081127113749.14">def adjust(self, p, pos):
    if p != self.p or pos != self.pos:
        self.p = p.copy()
        self.pos = pos
        bs = p.bodyString()
        word = getCurrentWord(bs, pos)
        self.word = word
        self.before = bs[:pos-len(word)]
        self.after = bs[pos:]
        self.search_pos = p.copy()
        if self.back:
            self.chunk = self.before
        else:
            self.chunk = self.after
        self.tried = {word:1}</t>
<t tx="edward.20081127113749.15">def getCurrentWord(s, pos):
    i = pos-1
    while i&gt;=0 and wordsep.find(s[i]) &lt; 0:
         i -= 1
    return s[i+1:pos]</t>
<t tx="edward.20081127113749.16">wordsep = u'., -+\n\r[]{}&lt;&gt;=-+*&amp;%$#@!"\'?/\\|^()~`:;'
word_completer_key = 'next_word_completer'
@others
completer = g.app.config.get(c,word_completer_key,'WordCompleter')
if completer is None:
    completer = WordCompleter(p, c, back=False)
    g.app.config.set(c, word_completer_key, 'WordCompleter', completer)
    completer.run()
else:
    completer.adjust(p, c.frame.body.getInsertPoint())
    completer.complete_word()

</t>
<t tx="ekr.20041001211817">import os

g.pr(os.path.exists(os.path.normpath("C:\\Progra~1\\Eclipse")))</t>
<t tx="ekr.20060427103457"># Open leoSettings.leo
c.openLeoSettings()</t>
<t tx="ekr.20060809084033">'''A script to convert calls to g.es to g.et, and raw strings s to g._(s)'''

__version__ = 0.2
&lt;&lt; version history &gt;&gt;

@others

trace = False # For debugging.
doReplace = True # True: actually replace the body text.

if not doReplace: g.es_print('-' * 40)
c.beginUpdate()
try:
    u = c.undoer
    undoType = 'Convert g.es'
    u.beforeChangeGroup (p,undoType)
    for p in c.currentPosition().self_and_subtree_iter():
        replace(p)
    u.afterChangeGroup(p,undoType,reportFlag=True)
finally:
    c.endUpdate()</t>
<t tx="ekr.20060809090508"># Based on leoImport.scanPythonText.
def replace(p):
    '''Replace g.es by g.et and strings s by g._(s)'''
    s = p.bodyString()
    if not s.strip(): return
    result = [] ;  i = 0 ; count = 0
    while i &lt; len(s):
        progress = j = i
        ch = s[i]
        if ch == '\n' or ch == '\r':
            i = g.skip_nl(s,i)
            result.append(s[j:i])
        elif ch == '#':
            i = g.skip_to_end_of_line(s,i)
            result.append(s[j:i])
        elif ch == '"' or ch == "'":
            &lt;&lt; handle string &gt;&gt;
        elif g.is_c_id(ch):
            if g.match_word(s,i,'g.es'):
                &lt;&lt; handle g.es &gt;&gt;
            else:
                i = g.skip_c_id(s,i)
                result.append(s[j:i])
        else:
            i += 1
            result.append(s[j:i])
        assert(progress &lt; i)
    if count:
        result = ''.join(result)
        if doReplace:
            undoData = u.beforeChangeNodeContents(p)
            p.setBodyStringOrPane(result)
            p.v.t.setDirty()
            u.afterChangeNodeContents(p,'Change Body',undoData)
        else:
            g.trace('result...\n',result)</t>
<t tx="ekr.20060809091749.72">i = g.skip_python_string(s,i)
s2 = s[j:i].strip()
result.append('g._(%s)' % s2)
if trace: g.trace('string:',s2)
count += 1</t>
<t tx="ekr.20060809091749.73">i += 4 ; k1 = i
i = g.skip_ws(s,i)
found = False
if g.match(s,i,'('):
    k2 = i
    k3 = g.skip_parens(s,i)
    if g.match(s,k3,')'):
        # Only translate if there are exactly one string in the parens.
        s2 = s[k2+1:k3]
        if (
            s2 and s2.count(',') == 0 and
            (s2.count('"') == 2 or s2.count("'") == 2)
        ):
            i = k3
            if trace: g.trace('call g.es:',g.get_line(s,i))
            result.append('g.et')
            result.append(s[k1:i])
            count += 1 ; found = True
if not found:
    result.append(s[j:i])</t>
<t tx="ekr.20060809092023"></t>
<t tx="ekr.20060809103738">def test1():
    
    g.es('abc')
    g.es('abc',xyz)
    g.es(xyz)</t>
<t tx="ekr.20060809103738.1">def test2():

    x = 'abc' + 'xyz'
    y = abc</t>
<t tx="ekr.20060809104405">@nocolor
@
0.1 EKR: Initial version.
0.2 EKR: Support doReplace and made script fully undoable.</t>
<t tx="ekr.20060814111542"># Add an editor to the body pane.
c.frame.body.addEditor()</t>
<t tx="ekr.20060904110922"></t>
<t tx="ekr.20060904111037">if hasattr(c,'opmlCommands'):
    c.opmlCommands.readOpmlCommand()
else:
    g.es_print('opml plugin not loaded')</t>
<t tx="ekr.20060904111037.1">if hasattr(c,'opmlCommands'):
    c.opmlCommands.writeOpmlCommand()
else:
    g.es_print('opml plugin not loaded')</t>
<t tx="ekr.20060918083159">put = g.es_print

for p in c.allNodes_iter():

    if hasattr(p.v,"unknownAttributes"):
        put("deleting v.unknownAttributes:",
            p.headString(),
            g.listToString(p.v.unknownAttributes.keys()))
        delattr(p.v,"unknownAttributes")

    if hasattr(p.v.t,"unknownAttributes"):
        put("deleting t.unknownAttributes:",
            p.headString(),
            g.listToString(p.v.t.unknownAttributes.keys()))
        delattr(p.v.t,"unknownAttributes")
           
put('done') 
c.redraw()</t>
<t tx="ekr.20060924180049">@
Ever have a clone that is difficult to understand outside the context of its
original parent? Here's some code to help. It displays the headline of the
current node plus the headlines of all the parents of all the clones of the
current node. Selecting a displayed parent headline moves the current node to
the corresponding clone in the outline.

The idea is to be able to quickly see the context of all the clones of the
current node and to be able to easily navigate from one clone instance to the
next.
@c

@others
c.cn = cloneNavigator(c)
c.cn.displayClones(c)
</t>
<t tx="ekr.20060924180049.1">class cloneNavigator:
    '''
       Displays the headline of the current node plus the headlines of
       all the parents of all the clones of the current node.  Selecting
       a displayed parent headline moves the current node to the
       corresponding clone in the outline.
       
       The idea is to be able to quickly see the context of all the clones
       of the current node and to be able to easily navigate from one clone
       instance to the next.
    '''
    @others</t>
<t tx="ekr.20060924180049.2">def __init__ (self,c):
    self.c = c
    import Tkinter as Tk
    if 0:
        f = Tk.Toplevel()
    else:
        log = c.frame.log
        log.selectTab('Clones')
        f = log.tabFrame
        for w in f.winfo_children():
            w.destroy()
    
    # Create and pack empty label and listbox
    self.title = Tk.Label(f)
    self.title.pack(anchor="nw")
    self.lb = Tk.Listbox(f)
    self.lb.pack(expand=1,fill="both")</t>
<t tx="ekr.20060924180049.3">def getAllClones(self,p):
    c = self.c
    def clonesOf(p,p1=p):
        return p.v.t == p1.v.t
    return filter(clonesOf, c.allNodes_iter(copy=True))</t>
<t tx="ekr.20060924180049.4">def displayClones(self,c):
    '''Displays the parent headline for all the clones of the current position'''
    cp = c.currentPosition()
    
    # "Title" is the headline of the current node
    self.title.configure(text=cp.headString())
    
    # Initialize listbox and clone list
    clones = self.getAllClones(cp)
    self.lb.delete(0,self.lb.size()-1)
    
    &lt;&lt;Fill listbox with clone parent headlines&gt;&gt;    
    &lt;&lt;Goto selected position when listbox selection changes&gt;&gt;
</t>
<t tx="ekr.20060924180049.5"># Add the headlines of all the clone parents to the listbox
for p in clones:
    if p.parent():
        text = p.parent().headString()
    else:
        text = "&lt;root&gt;"
    self.lb.insert(self.lb.size(),text)
    
    # Initial listbox selection corresponds to current position
    if p.v == cp.v:
        self.lb.selection_set(self.lb.size()-1)</t>
<t tx="ekr.20060924180049.6"># Callback for when a listbox entry is selected            
def gotoSelectedPosition(event,lb=self.lb,c=c,positions=clones):
    idx = int(lb.curselection()[0])
    p = positions[idx]
    c.frame.tree.expandAllAncestors(p)
    c.selectPosition(p)
    return
self.lb.bind(g.angleBrackets("ListboxSelect"), gotoSelectedPosition)</t>
<t tx="ekr.20061030041200">import os, sys

if 1: # Executes Iron Python in the console. (But not from the tutorials directory).
    path = r'c:\prog\IronPython-1.0.1\ipy.exe'
    args = ['-i']
        
    if 1: # Use present environment.
        os.spawnv(os.P_NOWAIT, path, args)
    else: # Use a pristine environment.
        os.spawnve(os.P_NOWAIT, path, args, os.environ)</t>
<t tx="ekr.20061030041356"></t>
<t tx="ekr.20061030041450"></t>
<t tx="ekr.20070115092430"># Invoke winpdb for general scripts **not** containing the predefined g, p or d constants.

# This is essentially the same as using the debug command.

import os,subprocess,sys

# Important: scriptFile2 must be different from scriptFile.
filename = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','test','scriptFile2'))
f = open(filename,'w') 
f.write(p.bodyString()) 
f.close() 
python = sys.executable
pythonDir = g.os_path_dirname(python) 
#winpdb = g.os_path_join(pythonDir,'Scripts','_winpdb.py') # For older versions of winpdb.
winpdb = g.os_path_join(pythonDir,'Lib','site-packages','winpdb.py') # For version 1.1.2 and newer.
os.chdir(g.app.loadDir)
cmdline = '%s %s -t %s' % (python,winpdb,filename) 
subprocess.Popen(cmdline)
</t>
<t tx="ekr.20070223164126"># An example of running this script:
    
import os

@others

types = (".py",) #,".c",".html",".txt")

dir = r'C:\prog\Notabene'

c.beginUpdate()
try:
    importFiles(dir,types,recursive=True)
finally:
    c.endUpdate()

g.es("done",color="blue")
</t>
<t tx="ekr.20070223164126.1">def importFiles (dir,type=None,kind="@file",recursive=False):
    
    v = c.currentVnode()

    # Check the params.
    if kind != "@file" and kind != "@root":
        g.es("kind must be @file or @root: " + kind)
        return

    if not g.os_path_exists(dir):
        g.es("directory does not exist: " + dir)
        return
    
    c.beginUpdate()
    try:
        root = createLastChildOf(v,"imported files")
        try:
            importDir (dir,type,kind,recursive,root)
            root.contract()
        except:
            g.es_exception()
    finally:
        c.endUpdate()</t>
<t tx="ekr.20070223164126.2">def importDir (dir,types,kind,recursive,root):

    g.es("dir: " + dir,color="blue")
    
    try:
        files = os.listdir(dir)
        files2 = [] ; dirs =[]
        for f in files:
            path = g.os_path_join(dir,f)
            if g.os_path_isfile(path):
                name, ext = g.os_path_splitext(f)
                if not types or ext in types:
                    files2.append(path)
            elif recursive:
                dirs.append(path)
        if len(files2) &gt; 0 or len(dirs) &gt; 0:
            child = createLastChildOf(root,dir)
            c.selectVnode(child)
        if len(files2) &gt; 0:
            c.importCommands.importFilesCommand(files2,kind)
        if len(dirs) &gt; 0:
            dirs.sort()
            for dir in dirs:
                importDir(dir,types,kind,recursive,child)
    except:
        g.es("exception in importFiles script")
        g.es_exception()
</t>
<t tx="ekr.20070223164126.3">def createLastChildOf (v,headline):
    
    child = v.insertAsLastChild()
    child.initHeadString(headline)
    return child
</t>
<t tx="ekr.20070224123943"></t>
<t tx="ekr.20070305085403">For MacOS X (darwin) the following are typical defaults:

vim_cmd = /Applications/gvim.app/Contents/MacOS/gvim --servername LEO
vim_exe = /Applications/gvim.app/Contents/MacOS/gvim
</t>
<t tx="ekr.20070305085403.1"></t>
<t tx="ekr.20070305085403.2"></t>
<t tx="ekr.20070410063214"></t>
<t tx="ekr.20070416075121">g.app.gui.set_focus(c,w)</t>
<t tx="ekr.20070503085527"></t>
<t tx="ekr.20070504080933">This option applies to directories specified in filenames in all kinds of @file trees, and to filenames specified in the @path directive.

True:  Leo attempts to create directories if they do not exist.
False: Leo never attempts to create directories.</t>
<t tx="ekr.20070515073111">g.pr('=' * 50)</t>
<t tx="ekr.20070517070854">import leoGui
oldGui = g.app.gui
g.app.gui = leoGui.nullGui(guiName='testGui')
try:
    fileName = g.os_path_abspath(g.os_path_join(
        g.app.loadDir,'..','doc','LeoDocs.leo'))
    ok,frame = g.openWithFileName(fileName,old_c=c)
    if ok:
        c2 = frame.c
        for p in c2.allNodes_iter():
            g.pr('.'*p.level(),p.headString())
        g.app.closeLeoWindow(frame)
finally:
    g.app.gui = oldGui</t>
<t tx="ekr.20070517071510">import leoBridge

path = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','doc','LeoDocs.leo'))

if 0: # This can not be run locally: leoBridge.controller starts a Tk event loop.

    controller = leoBridge.controller(gui='nullGui')
    g = controller.globals()
    c = controller.openLeoFile(path)
    n = 0
    for p in c.allNodes_iter():
        n += 1
    g.pr('%d nodes in %s' % (n,path))
    # g.app.closeLeoWindow(c.frame)</t>
<t tx="ekr.20070517160058.1"></t>
<t tx="ekr.20070528111805"># FrontWindowCapture.pyw
# Version 0.1
# Date    20070526
# Author  Roger Erens (roger AT erens-krekels.net)
"""
        Purpose:
        Capture the image of the front-most window into a fixed-name
        (_front_window), max-size (default MAX_WIDTH is 640 pixels), and
        fixed-format (PNG) file that can easily be used when creating
        documentation for an application on a wiki or in some HTML-docs.
        This script does _not_ copy the captured image to the clipboard (handy
        when creating MS Word or OpenOffice documents) since MS Windows already
        has ALT-PRTSCR to do so.

        Dependencies:
        Fairly recent versions of Python, wxPython, and PIL should be installed

        Start:
        Double click FrontWindowCapture.pyw; an icon appears in the Task Bar (lower right of
        the screen).

        Use:
        Bring a window to the front and then left-click on the
        icon in the Task Bar. A file named '_front_window.png' will be saved
        in the current directory.
        A pictures wider than MAXWIDTH is scaled down in order to make it easily
        used in wikis or HTML-documentation.
        Usually, human intelligence is needed to rename that file; this is also
        why this script does not copy the image to the clipboard.

        End:
        Close the application by right-clicking the icon in the Task Bar.

        Note:
        Make sure that your system is fast enough to find the frontmost
        window. That is, when a virusscanner is running or virtual memory is
        low, this script will choke. You can see what happens by enabling the
        print statements and running this script from a console (change the
        extension from .pyw to .py).
"""
import wx
import sys
import win32ui
import win32gui
import win32con
import time
from PIL import Image, ImageGrab

Image.init()

MAX_WIDTH = 640
BLINK_STATE = 0

class TaskBarApp(wx.Frame):
    def __init__(self, parent, id, title):
        wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
            style=wx.FRAME_NO_TASKBAR| wx.NO_FULL_REPAINT_ON_RESIZE)
        self.tbicon = wx.TaskBarIcon()
        icon = wx.Icon('LeoApp16.ico', wx.BITMAP_TYPE_ICO)
        self.tbicon.SetIcon(icon, 'Click to capture the foremost window')
        self.tbicon.Bind(wx.EVT_TASKBAR_LEFT_UP, self.OnTaskBarLeftClick)
        self.tbicon.Bind(wx.EVT_TASKBAR_RIGHT_UP, self.OnTaskBarRightClick)
        self.Show(True)

    def OnTaskBarLeftClick(self, evt):

        self.FlashIcon(evt)

        def _MyCallback(hwnd, extra ):
            extra.append(hwnd)

        windows = []
        win32gui.EnumWindows(_MyCallback, windows)

        winList = []
        for i in windows:
            if win32gui.IsWindowVisible(i):
                winList.append(i)
                #g.pr(i)

        win32gui.SetForegroundWindow(winList[1])    # found by trial and error
                                                    # that I need the second
                                                    # window from the list
        time.sleep(0.1)  # give the previous command some time to finish

        fgwindow = win32ui.GetForegroundWindow()
        #g.pr("(C)lick!")

        bbox = fgwindow.GetWindowRect()
        img = ImageGrab.grab( bbox)
        width = bbox[2] - bbox[0]
        if width &gt; MAX_WIDTH:
            coeff = MAX_WIDTH * 1. / width
            height = bbox[3] - bbox[1]
            newHeight = int( coeff * height)
            #g.pr(width, height, "scaled down to", MAX_WIDTH, newHeight)
            img = img.resize((MAX_WIDTH,newHeight), Image.ANTIALIAS)
        img = img.convert("P", dither=Image.NONE,
                              palette=Image.ADAPTIVE, colors=256)
        img.save("_front_window.png", "PNG", optimize=1)
        #img.show() # show the image in an image viewer

        self.FlashIcon(evt)

    def OnTaskBarRightClick(self, evt):
        #g.pr("Auta..." # that's about it...)
        self.tbicon.Destroy()
        self.Close(True)
        wx.GetApp().ProcessIdle()

    def FlashIcon(self, evt):
        global BLINK_STATE
        if BLINK_STATE == 0:
            icon = wx.Icon('LeoApp16lick.ico', wx.BITMAP_TYPE_ICO)
            self.tbicon.SetIcon(icon, 'Window is being captured...')
            BLINK_STATE = 1
            return
        else:
            icon = wx.Icon('LeoApp16.ico', wx.BITMAP_TYPE_ICO)
            self.tbicon.SetIcon(icon, 'Click to capture the foremost window')
            BLINK_STATE = 0
            return

class MyApp(wx.App):
    def OnInit(self):
        frame = TaskBarApp(None, -1, ' ')
        frame.Center(wx.BOTH)
        frame.Show(False)
        return True

def main():
    app = MyApp(0)
    app.MainLoop()

if __name__ == '__main__':
    main()

""" CREDITS

    Thanks to
    Roger Upole:
    http://groups.google.com/group/comp.lang.python/
    browse_thread/thread/ff39ec79f7c3248a/
    e600c892772bf52a?lnk=gst&amp;q=screen+capture&amp;rnum=6#e600c892772bf52a
    for his time.sleep() Aha (This took me a year and a half to note!)

    Christian Wyglendowski, Werner Bruhin, and Xavier Morel for the
    http://wiki.wxpython.org/index.cgi/FlashingTaskbarIcon
    discussion

    'Rob aspn at msolutionsinc.com '
    http://mail.python.org/pipermail/python-win32/2003-June/001129.html
    for his suggestion to find out the foremost window

    and of course the usual suspects that created/maintain
    wxPython,
    PIL,
    pywin32,
    LEO,
    gvim,
    and Python itself.
"""</t>
<t tx="ekr.20070529172620"></t>
<t tx="ekr.20070529173219"></t>
<t tx="ekr.20070529173219.1"></t>
<t tx="ekr.20070530072113">c.chapterController.hideChapters()</t>
<t tx="ekr.20070530072113.1">c.chapterController.showChapters()</t>
<t tx="ekr.20070531102813"></t>
<t tx="ekr.20070531103315">c.abbrevCommands.dynamicExpansion(event=None)</t>
<t tx="ekr.20070531104646">c.abbrevCommands.dynamicCompletion()</t>
<t tx="ekr.20070603175054">cc = c.chapterController
cc.selectChapterByName('abc')</t>
<t tx="ekr.20070603175054.1">cc = c.chapterController
cc.selectChapterByName('main')</t>
<t tx="ekr.20070603190713">cc = c.chapterController
cc.createChapterByName('xyz')</t>
<t tx="ekr.20070603190713.1">cc = c.chapterController
cc.selectChapterByName('xyz')</t>
<t tx="ekr.20070603190944"></t>
<t tx="ekr.20070603190944.1"></t>
<t tx="ekr.20070604095313"></t>
<t tx="ekr.20070604100125"></t>
<t tx="ekr.20070609085533"></t>
<t tx="ekr.20070630142904"></t>
<t tx="ekr.20070630142904.2">@nocolor

To build your module using GCC is a three step process on Unix:

1. Use Pyrex to translate mymodule.pyx to mymodule.c::

    python pyrexc mymodule.pyx

mymodule.pyx is the name of the Pyrex module you are writing.

2. Compile mymodule.c to mymodule.o::

    gcc -c -fPIC -I/usr/include/python2.2/ mymodule.c

-c  Produces a .o file instead of an executable. 
-fPIC Produces position independent code, so we can dynamically link against it later. 
-I/usr/include/python2.2/ is the location of the Python 2.2 include file.
 The location of your Python include file may differ from /usr/include/python2.2/. 

3 Link the mymodule.o into a mymodule.so::
    
    gcc -shared mymodule.o -lxosd -o mymodule.so

-shared produces a shared-object file, instead of an executable. 
-lxosd links against a C-library, with the name of the library given as the argument. 
</t>
<t tx="ekr.20070630142904.3">@nocolor

The pyrexc command supports the following options:

  Short Long              Argument    Description
  ----- ----              --------    -----------
  -v    --version                     Display version number of pyrex compiler
  -l    --create-listing              Write error messages to a .lis file
  -I    --include-dir     &lt;directory&gt; Search for include files in named 
                                      directory (may be repeated)
  -o    --output-file     &lt;filename&gt;  Specify name of generated C file (only
                                      one source file allowed if this is used)

Anything else is taken as the name of a Pyrex source file and compiled
to a C source file. Multiple Pyrex source files can be specified
(unless -o is used), in which case each source file is treated as the
source of a distinct extension module and compiled separately to
produce its own C file.
</t>
<t tx="ekr.20070630142904.4">def spam(int i, char *s):
    if 1:
        g.pr(i,s)</t>
<t tx="ekr.20070630142904.5"># Use pyrexc to create myModule.c from myModule.pyx.

import os,sys
python = sys.executable
theFile = r'C:\prog\tigris-cvs\leo\test\myModule.pyx'
pyrexc = r'c:\prog\Pyrex-0.9.6.4\pyrexc.py'
os.system(r'%s %s %s' % (python,pyrexc,theFile))

# Use pyrex/Demos/setup.py to create module on Linux.</t>
<t tx="ekr.20070701090143"></t>
<t tx="ekr.20070723091227">
        
        
        </t>
<t tx="ekr.20070723091227.1"></t>
<t tx="ekr.20070723091227.2"></t>
<t tx="ekr.20070723091227.3"></t>
<t tx="ekr.20070927175908">'''Convert a normal Leo tree to a networkx graph'''
import networkx as nx
import sys

x = nx.Graph()

def node_id(p):
    return '%s: %s' % (id(p.v.t),p.headString())

def addTree(p):
    x.add_node(node_id(p))
    for child in p.children_iter():
        addTree(child)
        x.add_edge(node_id(p),node_id(child))

addTree(p)

g.pr('nodes...\n', g.listToString(x.nodes(),sort=True))
g.pr('edges...\n', g.listToString(x.edges(),sort=True))
g.pr('yaml...\n')
nx.write_yaml(x,sys.stdout) # 'graph.yaml')
</t>
<t tx="ekr.20070928095102">@ This is a plain Leo tree.

You can convert it to a networkx graph using the leo2graph button.
</t>
<t tx="ekr.20070928095102.1"></t>
<t tx="ekr.20070928095102.2"></t>
<t tx="ekr.20070929062147">@nocolor

The following scripts convert between Leo trees and NetworkX graphs.

- leo2graph:            convert a normal Leo tree to a NetworkX graph.
- at-graph2graph:       convert an @graph tree to a Networkx graph.
- at-networkx2graph:    convert an @networkx tree to a Networkx graph
- at-networkx2at-graph: create an @graph tree from an @networkx tree.

Not ready yet:

- tree2pict: convert a Leo @graph tree to a picture of the corresponding graph.

@color</t>
<t tx="ekr.20070929062147.1">'''Convert an @graph tree to a networkx graph.'''
import networkx as nx
import sys

x = nx.Graph()

def node_id(p):
    return '%s: %s' % (str(p.v.t.fileIndex),p.headString())

def addTree(p):
    tag = '@link'
    h = p.headString()
    if h.startswith('@graph'):
        for child in p.children_iter():
            addTree(child)
    elif h.startswith('@node'):
        x.add_node(node_id(p))
        for child in p.children_iter():
            h = child.headString()
            if h.startswith(tag):
                link = h[len(tag):].strip()
                if link: x.add_edge(node_id(p),link)
            elif child.headString().startswith('@node'):
                addTree(child)
                x.add_edge(node_id(p),node_id(child))

addTree(p)

g.pr('nodes...\n', g.listToString(x.nodes(),sort=True))
g.pr('edges...\n', g.listToString(x.edges(),sort=True))
g.pr('yaml...\n')
nx.write_yaml(x,sys.stdout) # 'graph.yaml')</t>
<t tx="ekr.20070929062147.2">'''Convert an @networkx node to a networkx graph.'''
import networkx as nx
import sys

@others

x = nx.Graph()

edges,nodes = parse(p)

for z in nodes:
    x.add_node(z)

for z in edges:
    a,b = z
    x.add_edge(a,b)

g.pr('\nnodes...\n', g.listToString(x.nodes(),sort=True))
g.pr('\nedges...\n', g.listToString(x.edges(),sort=True))
g.pr('\nyaml...\n')
nx.write_yaml(x,sys.stdout) # 'graph.yaml')
</t>
<t tx="ekr.20070929070257">@ This is an @graph tree.

You can convert it to a networkx graph using the at-graph2graph button.</t>
<t tx="ekr.20070929070257.1"></t>
<t tx="ekr.20070929070257.2"></t>
<t tx="ekr.20070929070426">g.es('@link %s: %s' % (str(p.v.t.fileIndex),p.headString()))</t>
<t tx="ekr.20070929070632"></t>
<t tx="ekr.20070929070632.1"></t>
<t tx="ekr.20070929072043">@ This node defines a networkx graph using nodes and edges.

You can create an @graph tree from this node using the graph2at-graph button.
</t>
<t tx="ekr.20070929072506"># Each edge is represented as two lines.

# child1 --&gt; child2
('ekr', '20070929070257', 1): @node child1
('ekr', '20070929070257', 2): @node child2

# child2 --&gt; child1
('ekr', '20070929070257', 2): @node child2
('ekr', '20070929070257', 1): @node child1

</t>
<t tx="ekr.20070929072506.1"># Each node is on a separate line.

('ekr', '20070929070257', 1): @node child1
('ekr', '20070929070257', 2): @node child2
</t>
<t tx="ekr.20070929072506.2">def parseNodes (p):

    s = p.bodyString()
    lines = [str(z).strip() for z in g.splitLines(s) if z.strip() and not z.startswith('#')]
    # g.trace(g.listToString(lines))
    return lines
</t>
<t tx="ekr.20070929074830">def parse (p):

    tag = '@networkx'
    if not p.headString().startswith(tag):
        p = g.findNodeAnywhere(c,tag)
        if not p.headString().startswith(tag):
            error('No %s node in the outline' % tag)
            return [],[]

    nodes = []
    for tag in ('@edges','@nodes'):
        node = g.findNodeInTree(c,p,tag)
        if node:
            nodes.append(node)
        else:
            error('No %s node in @networkx tree' % tag)
            return [],[]
    edgesNode,nodesNode = nodes
    edges = parseEdges(edgesNode)
    nodes = parseNodes(nodesNode)
    return edges,nodes
</t>
<t tx="ekr.20070929074830.1">def parseEdges (p):

    s = p.bodyString()
    lines = [str(z).strip() for z in g.splitLines(s) if z.strip() and not z.startswith('#')]
    # g.trace(len(lines),lines)
    if (len(lines) % 2) == 0:
        i = 0 ; edges = []
        while i &lt; len(lines):
            data = lines[i],lines[i+1]
            edges.append(data)
            i += 2
        # g.trace(g.listToString(edges))
        return edges
    else:
        error('edges node must have even number of lines')
        return []

</t>
<t tx="ekr.20070929081505">def error (s):

    g.es_print(s,color='red')
</t>
<t tx="ekr.20070929082546">'''Convert an @networkx node to an @graph tree.
Create the tree as the child of the @graph-target node,
or the current position if no such node.'''

import networkx as nx
import sys

@others

g.pr('=' * 10)

p,edges,nodes = parse(p)

createTree(p,edges,nodes)
</t>
<t tx="ekr.20070929114410.2">def error (s):

    g.es_print(s,color='red')
</t>
<t tx="ekr.20070929114410.3">def parse (p):

    tag = '@graph-target'
    if not p.headString().startswith(tag):
        p = g.findNodeAnywhere(c,tag)
    if not (p and p.headString().startswith(tag)):
        p = c.currentPosition() # Use the presently selected node.

    nodes = [] ; tag = '@networkx'
    data = g.findNodeAnywhere(c,tag)
    if not data:
        error('No %s tree' % tag)
        return None,[],[]
    for tag in ('@edges','@nodes'):
        node = g.findNodeInTree(c,data,tag)
        if node:
            nodes.append(node)
        else:
            error('No %s node in @networkx tree' % tag)
            return None,[],[]
    edgesNode,nodesNode = nodes
    edges = parseEdges(edgesNode)
    nodes = parseNodes(nodesNode)
    return p,edges,nodes
</t>
<t tx="ekr.20070929114410.4">def parseNodes (p):

    s = p.bodyString()
    lines = [str(z).strip() for z in g.splitLines(s) if z.strip() and not z.startswith('#')]
    # g.trace(g.listToString(lines))
    return lines
</t>
<t tx="ekr.20070929114410.5">def parseEdges (p):

    s = p.bodyString()
    lines = [str(z).strip() for z in g.splitLines(s) if z.strip() and not z.startswith('#')]
    # g.trace(len(lines),lines)
    if (len(lines) % 2) == 0:
        i = 0 ; edges = []
        while i &lt; len(lines):
            data = lines[i],lines[i+1]
            edges.append(data)
            i += 2
        # g.trace(g.listToString(edges))
        return edges
    else:
        error('edges node must have even number of lines')
        return []

</t>
<t tx="ekr.20070929114617">@ This will be the root node for the @graph tree produced by the at-networkx2at-graph button.</t>
<t tx="ekr.20070929115302">def createTree (parent,edges,nodes):

    if 0:
        g.trace('nodes...\n', g.listToString(nodes,sort=True))
        g.trace('edges...\n', g.listToString(edges,sort=True))

    c.beginUpdate()
    try:
        p = parent.insertAsLastChild()
        p.setHeadString('@graph')
        d = createNodes(p,nodes)
        createEdges(d,edges)
        c.selectPosition(p)
    finally:
        c.endUpdate()
</t>
<t tx="ekr.20070929120541">def createEdges (d,edges):

    for edge in edges:
        a,b = edge
        g.trace('\n%s --&gt; %s' % (a,b))
        p = d.get(a)
        if p:
            p2 = p.insertAsLastChild()
            p2.setHeadString('@link %s' % (b))
        else:
            error('@node not found: %s' % (a))
</t>
<t tx="ekr.20070929120541.1">def createNodes (parent,nodes):

    d = {}

    for node in nodes:
        # g.trace(node)
        p = parent.insertAsLastChild()
        p.setHeadString('@node %s' % (node))
        d[node] = p.copy()

    return d
</t>
<t tx="ekr.20070929122956"></t>
<t tx="ekr.20070929122956.1"></t>
<t tx="ekr.20071002150320">log = c.frame.log
tag = 'my-canvas'

w = log.canvasDict.get(tag)
if not w:
    w = log.createCanvas(tag)
    w.configure(bg='yellow')

log.selectTab(tag)
</t>
<t tx="ekr.20071006084354">w = c.frame.body.bodyCtrl
s = w.getAllText()
ins = w.getInsertPoint()
row,col = g.convertPythonIndexToRowCol(s,ins)
g.pr('row',row,'col',col)</t>
<t tx="ekr.20071025192258">import leoTest
leoTest.doTests (c,all=False)</t>
<t tx="ekr.20071025193940">
# Caution: you will have to disable cursesGui in an external editor
# if you enable the cursesGui plugin it here

# qtGui.py
# tkGui.py

plugins_menu.py

leoOPML.py
# base64Packager.py
# searchbox.py

# active_path.py
# open_shell.py
ipython.py
# cleo.py
# open_with.py
rClick.py
toolbar.py
# autotrees.py

# add_directives.py # scan-directives hook not ready.
# color_markup.py # Does not work with threading colorizer.
threading_colorizer.py
rst3.py
UNL.py
open_with.py
mod_scripting.py

nav_buttons.py
nodenavigator.py
# hoist.py
image.py
leo_to_html.py

# vim.py
# print_cp.py
</t>
<t tx="ekr.20071026102420.2"></t>
<t tx="ekr.20071026102420.3"></t>
<t tx="ekr.20071105085941"></t>
<t tx="ekr.20071128122043">log = c.frame.log ; tag = 'Shell'
frame1 = log.frameDict.get(tag)
shellKind = 'text' # in ('plain','text','canvas')

if frame1:
    log.selectTab(tag)
elif shellKind == 'plain':
    log.selectTab (tag,createText=False)
    frame = log.frameDict.get(tag)
elif shellKind == 'text':
    log.selectTab (tag,createText=True)
    frame = log.textDict.get(tag)
elif shellKind == 'canvas':
    log.createCanvas(tag)
    log.selectTab(tag)
    frame = log.canvasDict.get(tag)
else:
    frame = None
    g.es('bad shellKind',shellKind)

if frame and not frame1:
    frame.configure(bg='white')
    g.pr('logFrame',log.frameDict.get(tag))
</t>
<t tx="ekr.20071129103842"># A script to create @auto nodes from all .py files in a directory.

import glob,os

reallyCreate = True
baseDir = r'c:\leo.repo\pythoscope\lib2to3\pgen2'
dirs = (r'',)
g.pr('-----')

for theDir in dirs:
    pattern = g.os_path_join(baseDir,theDir,'*.py')
    files = glob.glob(pattern)
    g.pr(pattern)
    # g.pr(g.listToString(files))
    for name in files:
        h = '@auto %s' % (name[len(baseDir) + 1:].strip())
        g.pr('creating',h)
        if reallyCreate:
            child = p.insertAsLastChild()
            child.initHeadString(h)</t>
<t tx="ekr.20071206070207"></t>
<t tx="ekr.20080105115712"># This hangs Leo while pylint is running.
import pylint.lint as lint
import sys

rcFile = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','test','pylint-leo-rc.txt'))
rcArg = '--rcfile=%s' % rcFile
&lt;&lt; define data &gt;&gt;

# We expect only one W104 error, in leoGlobals.py
g.pr('\n','=' * 40)
for name,s in data:
    name2 = g.os_path_abspath(g.os_path_join(g.app.loadDir,name))
    args = [name2,rcArg]
    if s.strip():
        args.append('--disable-msg=%s' % s)
    g.pr(name,s)
    lint.Run(args)
g.pr('\n' + 'End of pylint run')</t>
<t tx="ekr.20080105120559">data = (
    ('leoAtFile.py',''), 
    ('leoChapters.py',''),
    ('leoCommands.py',''), 
    ('leoEditCommands.py','E1101'),
    ('leoFileCommands.py',''), 
    ('leoFind.py',''),
    ('leoFrame.py',''),
    ('leoGlobals.py','E0602,E1101'),
    ('leoGui.py',''),
    ('leoImport.py',''),
    ('leoMenu.py',''),
    ('leoNodes.py',''),
    ('leoPlugins.py',''),
    ('leoTangle.py',''),
    ('leoUndo.py','W0102'),
    ('leoTkinterDialog.py',''),
    ('leoTkinterFind.py',''),
    ('leoTkinterGui.py',''),
    ('leoTkinterFrame.py','W0221'),
    ('leoTkinterKeys.py',''), 
    ('leoTkinterMenu.py',''), 
    ('leoTkinterTree.py',''),
)
</t>
<t tx="ekr.20080105130903">@nocolor
@
C0111 Missing docstring
C0301 Line too long
C0311 Bad indentation
C0321 More than one statement on a single line
C0322 Operator not preceded by a space
C0323 Operator not followed by a space
C0324 Comma not followed by a space

R0201 Method could be a function.
R0903 Too few public methods (0/1)

W0102 Dangerous default value [] as argument
W0104 Statement seems to have no effect
W0106 Unnecessary semicolon
W0107 Unnecessary pass statement
W0122 Use of the exec statement
W0141 Used builtin function 'map'
W0142 Used * or * magic*
W0201 Attribute defined outside __init__
W0212 Access to a protected member of a client class
W0231 __init__ method from base class is not called
W0232 Class has no __init__ method
W0401 Wildcard import (pychecker)
W0402 Uses of a deprecated module (like string)
W0404 Reimport &lt;module&gt;: let pychecker do this.
W0406 Module import itself
W0602 Using global for x but no assigment is done (leoEditCommands defines classList after all classes).
W0603 Using the global statement
W0612 Unused variable
W0613 Unused argument (sometimes used for debugging)
W0621 Redefining &lt;name&gt; from outer scope: especially __pychecker__
W0622 Redefining built-in
W0631 Using possibly undefined loop variable
W0702 No exception type specified
W0703 Catch "Exception"
W0704 Except doesn't do anything (Except: pass)
W1111 Assigning to a function call that only returns None</t>
<t tx="ekr.20080115085447">@nocolor
@

************* Module leoGlobals
W0104:3871: Statement seems to have no effect
</t>
<t tx="ekr.20080206055658">g.pr('settings...')
for z in ('body','button','headline','log','menu','outline'):
    for z2 in ('family','size','slant','weight',):
        setting = '%s_text_font_%s' % (z,z2)
        g.pr(setting,c.config.get(setting,z2))

g.pr('default sizes...')
for z in ('Body','Log','Menu','Tree'):
    setting = 'default%sFontSize' % z
    g.pr(setting,getattr(c.config,setting))

g.pr('actual fonts...')
for z in ('body','button','headline','log','menu','outline'):
    kind = ('family','size','slant','weight')
    arg0,arg1,arg2,arg3 = args = ['%s_text_font_%s' % (z,z2) for z2 in kind]
    setting = '%s_text_font' % (z)
    g.pr('%20s' % (setting),c.config.getFontFromParams(arg0,arg1,arg2,arg3,defaultSize=12))
</t>
<t tx="ekr.20080214091706.2">g.pr('hello from ekr')</t>
<t tx="ekr.20080310111916.1">def myTranslateString (s):

    i = s.lower().find('can not')
    if i == -1:
        return s
    else:
        return s[:i+1] + "an't" + s[i+7:]

g.translateString = myTranslateString

</t>
<t tx="ekr.20080412082246.1"></t>
<t tx="ekr.20080503202744.3">import rope.base.project
import rope.contrib.codeassist as codeassist
import leo.core.leoGlobals as g
import leo.core.leoCommands as leoCommands
c2 = leoCommands.Commands(frame=c.frame,fileName='xyz-file')

class leoFSCommands (object):
    def create_file(self,path):         g.trace(path)
    def create_folder(self,path):       g.trace(path)
    def move (self,path,new_location):  g.trace(path,new_location)
    def remove (self,path):             g.trace(path)
    def write (self,path,data):         g.trace(path,data)

path = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','..'))
    # Make the trunk folder a project
project = rope.base.project.Project(path,fscommands=leoFSCommands)
s = p.bodyString() # Could simulate a write to allow @others.

g.pr('*' * 40)
for pattern in (
    # 'g.', # works.
    # 'g.trace(', # weird.
    # 'rope.base.', # works.
    'g.list', # works: gives g.listToString
    'c2.de', # works.
):
    i = s.find(pattern)
    if i &gt; -1:
        proposals = codeassist.code_assist(project,s,i+len(pattern))
        g.pr('-' * 20)
        g.pr('pattern:',pattern)
        g.pr(g.listToString(proposals))</t>
<t tx="ekr.20080529111617.1"></t>
<t tx="ekr.20080529111617.2"></t>
<t tx="ekr.20080529111617.3">The colour used instead of green in progress bars</t>
<t tx="ekr.20080529111617.4">The colour used instead of red in progress bars</t>
<t tx="ekr.20080529111617.5"># list of @file node types to color.
# Uncomment these to enable coloring for these kinds of nodes.
# @asis
# @file
# @auto
# @thin
@auto</t>
<t tx="ekr.20080529111617.6">The base width of progress bars, in pixels.</t>
<t tx="ekr.20080529111617.7">The default number of time units.</t>
<t tx="ekr.20080529111617.8">0: no progress bars
1: unscaled progress bars
2: scaled progress bars</t>
<t tx="ekr.20080529111617.9">pixels per time unit to add to width of scaled progress bars</t>
<t tx="ekr.20080529111617.10">The name of time unit (e.g. days, weeks, hours)</t>
<t tx="ekr.20080531080812.1">def eggs():
    g.trace()

def spam():
    g.trace()
    eggs()

t = g.startTracer()
spam()
t.stop()
</t>
<t tx="ekr.20080531131542.1">import mx.TextTools as tt

&lt;&lt; define scan4 tables &gt;&gt;
&lt;&lt; define s &gt;&gt;

@others

g.pr('*' * 60)
ok,taglist,nextindex = tt.tag(s,lineTable)
# g.pr(g.listToString(taglist))
for z in taglist:
    printItem(z,level=0)
g.pr('ok:',ok)
</t>
<t tx="ekr.20080531131542.2">from mx.TextTools import * # Required for tags.

ws_charset   = CharSet(' \t')
name_charset = CharSet(alpha)

gnxTable = (
    (None,Is,':',MatchFail),
    (None,AllNotIn,':',MatchFail),
    (None,Is,':',MatchFail,MatchOk),
)

sentinelNameTable = (
    (None,Is,'@',+1,+3),
    (None,Is,'+',+1,+2),
    (None,Is,'-',+1),
    (None,AllInCharSet,name_charset,MatchFail,MatchOk),
)

sentinelTable = (
    # Start of another line.
    # Skip ws.
    (None,AllInCharSet,ws_charset,+1),
    # Require sentinel comment.
    (None,Word,'#@',MatchFail),
    ('kind',Table,sentinelNameTable,MatchFail),
    ('gnx',Table,gnxTable,+1),
    # Everything else is the sentinel value
    ('extra',AllNotIn,'\n',+1),
    (None,Is,'\n',MatchOk,MatchOk),
)

normalLineTable = (
    (None,AllNotIn,'\n',+1),
    (None,Is,'\n',MatchOk,MatchOk),
)

lineTable = (
    ('sent',Table,sentinelTable,+1,+2),
    ('line',Table,normalLineTable,+1,+1),
    ('eof',EOF,Here,-2),
)</t>
<t tx="ekr.20080531131542.4">def printItem(aList,level):

    obj,lt_index,rt_index,subtag = aList
    g.pr('  '*level,obj,repr(s[lt_index:rt_index]))
    if subtag:
        for z in subtag:
            printItem(z,level+1)
</t>
<t tx="ekr.20080531141227.1">path = r'c:\leo.repo\trunk\leo\core\runLeo.py'
f = file(path)
s = f.read()
f.close()</t>
<t tx="ekr.20080604101239.1">Martin Lwis and friends.</t>
<t tx="ekr.20080604104453.5">@nocolor

This setting determines the initial binding for otherwise-unbound keystrokes
when no mode is in effect.  Note: the keyboard-quit command exits all modes.

The valid values are::

command:  Leo ignores the key (like Vim).
insert:  Leo inserts the key at the cursor (like Emacs)
overwrite: Leo replaces the character at the cursor.</t>
<t tx="ekr.20080610144053.1">True: Wrap body text.

</t>
<t tx="ekr.20080610144233.1">aaaaaaaaaaaa bbbbbbbbbbbbbbbbbb cccccccccccccccc ddddddddddddddddddd eeeeeeeeeeeeeee ffffffffffffffffff ggggggggggggggggggggg hhhhhhhhhhhhhhhh iiiiiiiiiiiii jjjjjjjjjjjjjjjj kkkkkkkkkkkkkk llllllllllllll mmmmmmmmmmmmmmmmm nnnnnnnnnnnn ooooooooo</t>
<t tx="ekr.20080617170334.1">@first # -*- coding: utf-8 -*-

import Tkinter as Tk

top = Tk.Toplevel()
w = Tk.Text(top)
w.pack()

def key(event):
    if event.char: g.pr('state',event.state,'char', repr(event.char), repr(event.keysym))

def after():
    g.trace()
    w.event_generate('&lt;Key&gt;',keysym='a')
    w.event_generate('A')
    w.event_generate(g.toEncodedString('',encoding='utf8'))
    # w.event_generate('&lt;Key-Control_L&gt;')
    # w.event_generate('c')
    # w.event_generate('Shift-Control-a')

w.bind('&lt;Key&gt;',key)
w.focus_set()
w.update()
# top.after_idle(after)
top.mainloop()
</t>
<t tx="ekr.20080628094340.1">if 0:
    # Called when func is **defined**
    def leo_command(func):
        g.trace(func.__name__)
        return func
else:
    class leo_command:
        def __init__(self,func,c=c):
            self.c = c
            self.func = func
            self.name = func.__name__
            g.pr("registering",self.name)

        def __call__(__self,*__args,**__kw):
            g.pr("before", __self.name)
            try:
                return __self.func(*__args,**__kw)
            finally:
                g.pr("after ", __self.name)
                g.pr('c',c)
                c.outerUpdate()


@leo_command
def hello():
    g.pr("Hello, world!")

hello()
</t>
<t tx="ekr.20080701101740.1">import locale
aList = dir(locale)
# g.pr(g.listToString(aList))

g.pr(g.getpreferredencoding())
# import os
# g.pr(dir(os))
</t>
<t tx="ekr.20080701130406.1">import glob

aList = glob.glob(r'c:\leo.repo\trunk\leo\plugins\*.py')
for z in aList:
    name = g.shortFileName(z)
    if not name.startswith('_'):
        g.pr('echo .')
        g.pr('echo',name)
        g.pr('call pylint.bat core\%s' % name)</t>
<t tx="ekr.20080729153237.1"></t>
<t tx="ekr.20080729153237.2"># True: calls to the garbage collector.</t>
<t tx="ekr.20080729153237.3"># True (recommended): print a message when Leo calls gc.collect explicitly.</t>
<t tx="ekr.20080729153237.4"># True: verbose trace the garbage collector.</t>
<t tx="ekr.20080801160915.1">@others
</t>
<t tx="ekr.20080803120643.1">def spam():
    pass</t>
<t tx="ekr.20080806145258.1">@language javascript

/**********************************************
* Contractible Headers script-  Dynamic Drive (www.dynamicdrive.com)
* This notice must stay intact for legal use. Last updated Mar 23rd, 2004.
* Visit http://www.dynamicdrive.com/ for full source code
***********************************************/

// alert("start");

var enablepersist="on" //Enable saving state of content structure using session cookies? (on/off)
var collapseprevious="no" //Collapse previously open content when opening present? (yes/no)

if (document.getElementById){
    document.write('&lt;style type="text/css"&gt;')
    document.write('.switchcontent{display:none;}')
    document.write('&lt;\/style&gt;')
}

@others</t>
<t tx="ekr.20080806145258.2">function getElementbyClass(classname){
    ccollect=new Array()
    var inc=0
    var alltags=document.all? document.all : document.getElementsByTagName("*")
    for (i=0; i&lt;alltags.length; i++){
        if (alltags[i].className==classname)
            ccollect[inc++]=alltags[i]
    }
}

</t>
<t tx="ekr.20080806145258.3">function contractcontent(omit){
    var inc=0
    while (ccollect[inc]){
        if (ccollect[inc].id!=omit)
        ccollect[inc].style.display="none"
        inc++
    }
}
</t>
<t tx="ekr.20080806145258.4">function expandcontent(cid){
    if (typeof ccollect!="undefined"){
        if (collapseprevious=="yes")
            contractcontent(cid)
        document.getElementById(cid).style.display=(document.getElementById(cid).style.display!="block")? "block" : "none"
    }
}
</t>
<t tx="ekr.20080806145258.5">function revivecontent(){
    contractcontent("omitnothing")
    selectedItem=getselectedItem()
    selectedComponents=selectedItem.split("|")
    for (i=0; i&lt;selectedComponents.length-1; i++)
        document.getElementById(selectedComponents[i]).style.display="block"
}

</t>
<t tx="ekr.20080806145258.6">function get_cookie(Name) { 
    var search = Name + "="
    var returnvalue = "";
    if (document.cookie.length &gt; 0) {
        offset = document.cookie.indexOf(search)
        if (offset != -1) { 
            offset += search.length
            end = document.cookie.indexOf(";", offset);
            if (end == -1) end = document.cookie.length;
            returnvalue=unescape(document.cookie.substring(offset, end))
        }
    }
    return returnvalue;
}

</t>
<t tx="ekr.20080806145258.7">function getselectedItem(){
    if (get_cookie(window.location.pathname) != ""){
        selectedItem=get_cookie(window.location.pathname)
        return selectedItem
    }
    else
        return ""
}

</t>
<t tx="ekr.20080806145258.8">function saveswitchstate(){
    var inc=0, selectedItem=""
    while (ccollect[inc]){
        if (ccollect[inc].style.display=="block")
            selectedItem+=ccollect[inc].id+"|"
        inc++
    }
    document.cookie=window.location.pathname+"="+selectedItem
}

</t>
<t tx="ekr.20080806145258.9">function do_onload(){
    // alert("do_onload");
    uniqueidn=window.location.pathname+"firsttimeload"
    getElementbyClass("switchcontent")
    if (enablepersist=="on" &amp;&amp; typeof ccollect!="undefined"){
        document.cookie=(get_cookie(uniqueidn)=="")? uniqueidn+"=1" : uniqueidn+"=0" 
        firsttimeload=(get_cookie(uniqueidn)==1)? 1 : 0 //check if this is 1st page load
        if (!firsttimeload)
        revivecontent()
    }
}

if (window.addEventListener)
    window.addEventListener("load", do_onload, false)
else if (window.attachEvent)
    window.attachEvent("onload", do_onload)
else if (document.getElementById)
    window.onload=do_onload

if (enablepersist=="on" &amp;&amp; document.getElementById)
    window.onunload=saveswitchstate

</t>
<t tx="ekr.20080806145258.10">function format() {

    return;

    // var sections = document.getElementsByTagName("pre");  // EKR: was span.
    // //alert("format:" + sections.length + "sections")
    // for(i=0; i &lt; sections.length; i++) {
        // formatText(sections[i]);
    // }
}
</t>
<t tx="ekr.20080806145258.11">function formatText(item) {

    ;
    // alert(item);
}
</t>
<t tx="ekr.20080806145258.12">@nocolor

Notes:
    
- button Leo2dHTML creates leo\test\x.htm, where x is the name of the .leo file
  containing the script. The file contains javascript that allows a browser to
  expand and contract headlines.  Leo2DHTML is *unrelated* to the other files.
    
- leo\test\server.py is a minimal Python server.  Invoke from a console with::
    
    python server.py

To use this server, type this url in a web browser: http://localhost:8080/
The server will print the contents of the directory from which it was invoked.
Choose hello.html to see the 'Hello World' test page.

- leo\test\hello.html is a test page.  It uses leo\test\cgi-bin\edward.py

- leo\test\cgi-bin\edward.py is the script called from hello.leo when the user
  hits the 'Submit Query button.
  This is recompiled (as needed) for every query, which makes testing it easier.
  
  **Important** edward.py returns its result by printing (in a special format):
  Thus, everything you print will be part of the returned form(!). You **can**
  print debug info: just make sure you don't mess up the special conventions:
  the best place to print debugging info is in print_all.

@color</t>
<t tx="ekr.20080806145258.13">@

edward.py:
    
How can we get the content of an input form?</t>
<t tx="ekr.20080806145258.14">@first # -*- coding: utf-8 -*-
@language python
@tabwidth -4

&lt;&lt; about LeoToHTML &gt;&gt;
import leo.core.leoGlobals as g
&lt;&lt; define dhtml stuff &gt;&gt;
@others

fileName = c.frame.shortFileName() # Get current outline file name
if fileName.endswith('.leo'): fileName = fileName[:-4] # Remove .leo suffix
path = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','test',fileName)) + '.htm'

# Write the file.
f=open(path, 'w')
writeAll(f)
f.close() 
g.es('wrote: %s' % (path),color="turquoise4") 
</t>
<t tx="ekr.20080806145258.15">@

LeoToHTML by Dan Rahmel, modified by EKR.

This @button script creates an .htm file containing the contents of the selected tree.
The file is called x.htm, where x is the name of the .leo file containing the script.
This file is written to the leo/test folder.

The script inserts javascript into the page so that nodes can be expanded and contracted.

The script presently works well.  This script may become the basis for a facebook app.

The generated html passes html-tidy: http://www.w3.org/People/Raggett/tidy/
</t>
<t tx="ekr.20080806145258.16">division = """
&lt;div STYLE="margin-left:3em;text-indent:0em;margin-top:0em; margin-bottom:0em;"&gt;
&lt;h3 onClick="expandcontent('sc%d')" style="cursor:hand; cursor:pointer; margin-top:0em; margin-bottom:0em"&gt;+ %s&lt;/h3&gt;
    &lt;div id="sc%d" class="switchcontent" style="margin-top:0em; margin-bottom:0em;"&gt;
"""

javascript  = """
&lt;script src="cgi-bin/leo.js" type="text/javascript"&gt;&lt;/script&gt;
"""

style = '''
&lt;STYLE type="text/css"&gt;
    BODY {font:x-medium 'Verdana'; margin-right:1.5em}
    PRE {margin:0px; display:inline}
&lt;/STYLE&gt;
'''
</t>
<t tx="ekr.20080806145258.17">def escape (s):

    return s.replace('&amp;','&amp;amp;').replace('&lt;','&amp;lt;').replace('&gt;','&amp;gt;')
</t>
<t tx="ekr.20080806145258.18">def writeAll(f):

    f.write('&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2//EN"&gt;')
    f.write('&lt;html&gt;')
    writeHead(f)
    writeBody(f)
    f.write("&lt;/html&gt;")
</t>
<t tx="ekr.20080806145258.19">def writeBody(f):

    f.write('&lt;body class="st" onload="format()"&gt;')
    writeContents(f)
    f.write("&lt;/body&gt;")
</t>
<t tx="ekr.20080806145258.20">def writeHead(f):

    f.write('&lt;head&gt;')
    f.write(style)
    f.write(javascript)
    f.write('&lt;title&gt;%s&lt;/title&gt;' % c.shortFileName())
    f.write('&lt;/head&gt;')
</t>
<t tx="ekr.20080806145258.21">def writeContents(f):

    div = "&lt;div class='c' STYLE='margin-left:4em;margin-top:0em; margin-bottom:0em;'&gt;\n&lt;pre&gt;\n%s\n&lt;/pre&gt;\n&lt;/div&gt;"
    end_div = "&lt;/div&gt;\n&lt;/div&gt;\n"
    n = 1 # The node number
    current = c.currentPosition()
    prev_level = current.level()
    open_divs = 0
    for p in current.self_and_subtree_iter():
        h = p.headString()
        while prev_level &gt;= p.level() and open_divs &gt; 0:
            f.write(end_div)
            prev_level -= 1
            open_divs -= 1
        body = p.bodyString().encode( "utf-8" )
        body = body.rstrip().rstrip("\n")
        f.write(division % (n,escape(h),n))
        open_divs += 1
        if body:
            f.write(div % escape(body))
        prev_level = p.level()
        n += 1

    # Close all divisions.
    while open_divs &gt; 0:
        f.write(end_div)
        open_divs -= 1
</t>
<t tx="ekr.20080806145258.22"># def writePreamble(f):

    # '''Write HTML header information.'''

    # header_start = '''\


# &lt;body class="st" onload="format()"&gt;
# '''

    # for s in (header_start,style,javascript,header_end):
        # # f.write(g.adjustTripleString(s,c.tab_width))
        # f.write(s)
</t>
<t tx="ekr.20080806145258.23"># def writePostamble (f):

    # pass

</t>
<t tx="ekr.20080806145258.24"># A minimal python server for testing.
# To access this server, type this url in a web browser: http://localhost:8080/
# The server will print the contents of the directory from which it was invoked.
# Choose hello.html to see the 'Hello World' test page.

import CGIHTTPServer
import SocketServer

port = 8080

Handler = CGIHTTPServer.CGIHTTPRequestHandler
s = SocketServer.TCPServer(("", port), Handler)

s.server_name = '127.0.0.1' # represents local host.
s.server_port = port

# import os ; print 'cwd', os.getcwd()

print "server.py: serving at port", port
s.serve_forever()
</t>
<t tx="ekr.20080806145258.25">@language html

&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2//EN"&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;&lt;/title&gt;

&lt;!-- Used by edward.old.py
&lt;script language="JavaScript" type="text/javascript"&gt;
   var openImg = new Image();
   openImg.src = "open.gif";
   var closedImg = new Image();
   closedImg.src = "closed.gif";

   function showNode(node) {
      var objBranch = 
         document.getElementById(node).style;
      if(objBranch.display=="block")
         objBranch.display="none";
      else
         objBranch.display="block";
   }

   function swapFolder(img) {
      objImg = document.getElementById(img);
      if(objImg.src.indexOf('closed.gif')&gt;-1)
         objImg.src = openImg.src;
      else
         objImg.src = closedImg.src;
   }
&lt;/script&gt;
--&gt;

&lt;/head&gt;
&lt;body&gt;
&lt;form action="cgi-bin/edward.py" method="GET"&gt;
&lt;input type="submit" name="George"&gt;
&lt;/form&gt;

&lt;p&gt;This is the hello world test page.
The server in server.py should be running when using this page.

&lt;p&gt;The button (form) above should cause the server to send a "GET" request
to the edward.py script, which will respond with a new page.

&lt;/body&gt;
&lt;/html&gt;
</t>
<t tx="ekr.20080806145258.26">@first #! c:\python25\python.exe
@first # -*- coding: utf-8 -*-

'''This is the cgi script called from hello.html when the user hits the button.'''

### Print statements are used to return results (return the form).
### You *can* use print statement for tracing, but only in print_all.
# To do: use cgi.FieldStorage.

@language python
@tabwidth -4
&lt;&lt; imports &gt;&gt;
&lt;&lt; define dhtml stuff &gt;&gt;
@others

if 1: # Open the bridge.
    path = os.path.abspath(os.path.join(leoParentDir,'leo','test','test.leo')) # c does not exist!
    b = leoBridge.controller(gui='nullGui',loadPlugins=False,readSettings=False,verbose=False)
    g = b.globals()
    c = b.openLeoFile(path)
    p = c.rootPosition()
else:
    c = None

# import pdb ; pdb.Pdb() # Doesn't work.
print_all(c)</t>
<t tx="ekr.20080806145258.27">division = """
&lt;div STYLE="margin-left:3em;text-indent:0em;margin-top:0em; margin-bottom:0em;"&gt;
&lt;h3 onClick="expandcontent('sc%d')" style="cursor:hand; cursor:pointer; margin-top:0em; margin-bottom:0em"&gt;+ %s&lt;/h3&gt;
    &lt;div id="sc%d" class="switchcontent" style="margin-top:0em; margin-bottom:0em;"&gt;
"""

style = """
&lt;STYLE type="text/css"&gt;
    BODY {font:x-medium 'Verdana'; margin-right:1.5em}
    PRE {margin:0px; display:inline}
&lt;/STYLE&gt;
"""</t>
<t tx="ekr.20080806145258.28">def escape (s):

    return s.replace('&amp;','&amp;amp;').replace('&lt;','&amp;lt;').replace('&gt;','&amp;gt;')
</t>
<t tx="ekr.20080806145258.29">def print_all(c):

    # This line is required (with extra newline), but does not show on the page.
    print "Content-type:text/html\n"

    print '&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2//EN"&gt;'
    print '&lt;html&gt;'
    if c:
        # Print the page.
        print_head(c)
        print_body(c)
    else:
        # Print the debugging info.
        print '__file__',__file__
        print 'os.getcwd()',os.getcwd()

    print '&lt;/html&gt;'
</t>
<t tx="ekr.20080806145258.30">def print_body(c):

    print '&lt;body class="st" onload="format()"&gt;'

    if 0:
        # Debugging info.
        form = cgi.FieldStorage()
        print repr(form)
        # if form.has_key('name'):
            # print 'name',form['name'].value
        # else:
            # print 'no name'
    print_tree(c)
    print '&lt;/body&gt;'
</t>
<t tx="ekr.20080806145258.31">def print_head(c):

    print '&lt;head&gt;'

    if 1: # Copy the entire leo.js file into the page.
        print '&lt;script type="text/javascript"&gt;'
        print_leo_dot_js(c)
        print '&lt;/script&gt;'

    else: # Possible bug in the python server??
        # The Python says leo.js is not executable(!)
        print '&lt;script src="leo.js" type="text/javascript"&gt;&lt;/script&gt;'

    print '&lt;title&gt;%s&lt;/title&gt;' % (c.shortFileName())
    print '&lt;/head&gt;'
</t>
<t tx="ekr.20080806145258.32">def print_leo_dot_js(c):

    path = g.os_path_abspath(g.os_path_join(g.app.loadDir,'..','test','cgi-bin','leo.js'))

    try:
        f = file(path)
    except IOError:
        print 'can not open',path
        return

    for line in f.readlines():
        print line,

    f.close()
</t>
<t tx="ekr.20080806145258.33">def print_tree(c):

    div = "&lt;div class='c' STYLE='margin-left:4em;margin-top:0em; margin-bottom:0em;'&gt;\n&lt;pre&gt;\n%s\n&lt;/pre&gt;\n&lt;/div&gt;"
    end_div = "&lt;/div&gt;\n&lt;/div&gt;\n"
    n = 1 # The node number
    prev_level = 0
    open_divs = 0
    for p in c.allNodes_iter():
        h = p.headString()
        while prev_level &gt;= p.level() and open_divs &gt; 0:
            print end_div
            prev_level -= 1
            open_divs -= 1
        body = p.bodyString().encode( "utf-8" )
        body = body.rstrip().rstrip("\n")
        print division % (n,escape(h),n)
        open_divs += 1
        if body: print div % escape(body)
        prev_level = p.level()
        n += 1

    # Close all divisions.
    while open_divs &gt; 0:
        print end_div
        open_divs -= 1
</t>
<t tx="ekr.20080806145258.34"></t>
<t tx="ekr.20080806145702.1">import os
import sys

# Add the *parent* of the leo directory to sys.path.
leoParentDir = os.path.abspath(os.path.join(os.path.dirname(__file__),'..','..','..'))

if leoParentDir not in sys.path:
    sys.path.append(leoParentDir)

import leo.core.leoBridge as leoBridge

import cgi
import cgitb ; cgitb.enable()
</t>
<t tx="ekr.20080807091001.1">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080807091201.7">#!/usr/local/bin/python
# -*- coding: utf-8 -*-
"""
module docs
"""

</t>
<t tx="ekr.20080807091201.8">class Person(object):
   '''class docs
   '''
   field1 = 10
   field2 = 20

   @others
</t>
<t tx="ekr.20080807091201.9">def talk(self):
    ''' this is the func doc
    '''
    print 'hello world'

</t>
<t tx="ekr.20080807091201.10">class Meta:
    age = 10</t>
<t tx="ekr.20080807114145.2">@
A script button to run any body text as a Windows Script.
See: http://en.wikipedia.org/wiki/Windows_Script_Host

You need the win32 extensions and you must enable the script engine.
Adapted from Active State examples:ch21_active_scripting:ActiveApp.py
http://python.net/crew/mhammond/win32/
@c

&lt;&lt; imports &gt;&gt;

@others

RunCode("python",p.bodyString())
</t>
<t tx="ekr.20080807115344.1">Application.Echo("Hello from Python")
</t>
<t tx="ekr.20080807115344.2">class MySite(axsite.AXSite):
    # Our error handler will simply print to the console.
    def OnScriptError(self, activeScriptError):
        exc = activeScriptError.GetExceptionInfo()
        print "Exception:", exc[1]
        try:
            sourceText = activeScriptError.GetSourceLineText()
        except pythoncom.com_error:
            sourceText = None
        if sourceText is not None: 
            context, lineNo, charNo = activeScriptError.GetSourcePosition()
            print sourceText
            indent = " " * (charNo-1)
            print indent + "^"
        return winerror.S_OK
</t>
<t tx="ekr.20080807115344.3"># A named object for our namespace
# A normal Python COM object (minus registration info)
class Application:
    _public_methods_ = [ 'Echo' ]
    def Echo(self, *args):
        print string.join(map(str, args))

</t>
<t tx="ekr.20080807115344.4"># Create the site and the engine and runs the code.
def RunCode(engineName, code):

    app = win32com.server.util.wrap( Application() )

    # Create a dictionary holding our object model.
    model = {'Application' : app,}

    # Create the scripting site.
    site = MySite(model)
    # Create the engine and add the code.
    engine = site.AddEngine(engineName)
    engine.AddCode(code)

    # Run the code.
    engine.Start()
</t>
<t tx="ekr.20080807115344.5">import string
import sys
from win32com.axscript import axscript
from win32com.axscript.server import axsite
import pythoncom
import win32com.server.util</t>
<t tx="ekr.20080811112727.1">False: (recommended) Enable import parsing for @shadow and @auto
True: @shadow and @auto create a single node for the entire file.</t>
<t tx="ekr.20080811113441.2"></t>
<t tx="ekr.20080812102914.1">root first line
@others
root last line</t>
<t tx="ekr.20080812102914.2">child line 1
child line 2</t>
<t tx="ekr.20080812112440.1">@language ini
[section]
blah blah
changed
changed2
changed3
changed4
change5</t>
<t tx="ekr.20080812135254.1"># Line one
# line two</t>
<t tx="ekr.20080813080627.1">@others</t>
<t tx="ekr.20080813080627.2">def spam():
    pass</t>
<t tx="ekr.20080813080627.3">def eggs():
    pass</t>
<t tx="ekr.20080813080729.1"></t>
<t tx="ekr.20080813080809.1"></t>
<t tx="ekr.20080813100905.1">import sys
print sys.argv</t>
<t tx="ekr.20080815073750.1">n = 0
for p in c.allNodes_iter():
    if p.isAtNoSentFileNode():
        c.atFileCommands.write(p,nosentinels=True)
        n += 1
g.es('done: %s files written' %(n))</t>
<t tx="ekr.20080819095720.1">@language unknown_language
# huh language .................
changed 7
</t>
<t tx="ekr.20080821111715.1">@first # -*- coding: utf-8 -*-

# Important: see http://webpages.charter.net/edreamleo/FAQ.html#unicode-issues

import sys
        
print '=' * 40

e = sys.getdefaultencoding()
assert e.lower() == 'utf-8'
print 'encoding',e

table = (
    'La Pea',
    unicode('La Pea','utf-8'),
    u'La Pea',
    u'La Pe\xf1a',
    # u'AA \u0102 BB',
)

for s in table:
    print type(s)
    g.es_print('g.es_print',s)
    if type(s) != type(u'a'):
        s = unicode(s,e)
    print      'print     ',s
    print      'repr(s)   ',repr(s)</t>
<t tx="ekr.20080822153619.1"></t>
<t tx="ekr.20080823154546.1">p2 = p.insertAfter()
p2.setHeadString('inserted node')
s = p.bodyString()

# Remove Leo directives.
directives = ['@'+z for z in g.globalDirectiveList]
def isDirective(s):
    for z in directives:
        if s.startswith(z):
            return True
    else: return False
aList = [z for z in g.splitLines(s) if not isDirective(z)]
s = ''.join(aList)
if not s.endswith('\n'): s = s + '\n'

c.importCommands.scanPythonText(s,p2.copy(),atAuto=True)
c.redraw_now()
g.pr('done')</t>
<t tx="ekr.20080909075224.1">@language html
../hex6x -
changed</t>
<t tx="ekr.20080911080311.1">@language conf
; This is a comment
P1 = 0
</t>
<t tx="ekr.20080915095329.1">import leo.core.leoPlugins as leoPlugins

rst3 = leoPlugins.getPluginModule('rst3')

if rst3:
    controller = rst3.controllers.get(c)
    if controller:
        controller.processTopTree(p)
else:
    rst3 = leoPlugins.loadOnePlugin('rst3',verbose=True)
    if rst3:
        g.es('rst3 loaded')
        rst3.onCreate('tag',{'c':c})
    else:
        # Ask to be removed.
        g.app.scriptDict['removeMe'] = True</t>
<t tx="ekr.20080917063615.1">aList = (
'aspellbindir',
'wholeword',
'Whole-Word',
'vimcmd',
'huh',
)

for name in aList:
    kind, val = c.config.getSettingSource(name)
    print '%-20s %-20s %s' % (name,repr(val),kind)
</t>
<t tx="ekr.20080920101658.1">def getInput (event=None):

    '''Evaluate a Python Expression entered in the minibuffer.'''

    stateName = 'get-input'
    k = c.k ; state = k.getState(stateName)

    if state == 0:
        k.setLabelBlue('Input: ',protect=True)
        k.getArg(event,stateName,1,getInput)
    else:
        k.clearState()
        g.es_print('input:',k.arg)

getInput()
</t>
<t tx="ekr.20080921144924.1">print(g.os_path_finalize(r'~/.leo/notebook.leo'))
print(g.os_path_finalize(g.os_path_join(g.app.loadDir,r'~/.leo/notebook.leo')))
print(g.os_path_finalize_join(g.app.loadDir,r'~/.leo/notebook.leo'))</t>
<t tx="ekr.20080922142953.1"># @string default_leo_file = ~/.leo/workbook.leo
path = "{{c.config.getString('default_leo_file')}}"
# print g.os_path_expandExpression(path,c=c)
print g.os_path_finalize(path,c=c)</t>
<t tx="ekr.20080922164255.1"></t>
<t tx="ekr.20080922164255.2"></t>
<t tx="ekr.20080922164656.1"></t>
<t tx="ekr.20080923073240.1">{{c.config.getString('test')}}/eval-test.txt
=
c:\leo.repo\trunk\leo\test\eval-test.txt</t>
<t tx="ekr.20080923073240.2"></t>
<t tx="ekr.20080923173133.1">@markup wiki

@

''text''                # write text in italics</t>
<t tx="ekr.20080924033317.1">@language c

@others</t>
<t tx="ekr.20080924033317.2">int spam():
    ;</t>
<t tx="ekr.20080924081821.1"># c.k.ab

# Test this code using the execute-script command.

s = p.bodyString()
lines = g.splitLines(s)
s = lines[0]

theObject,aList = c.k.autoCompleter.getExternalCompletions(s)

print '='*20
print 'theObject',theObject and theObject.__class__
print 'len(completions)',len(aList)
print g.listToString(aList, tag='completion list', sort=True, indent='')
</t>
<t tx="ekr.20080929112400.1">import PyQt4.Qt as qt
import sys

a=qt.QApplication(sys.argv)
parent = None
w=qt.QPushButton("Hello World",parent) # No parent: top-level.
# a.setMainWidget(w)
w.show()
# print g.listToString(dir(a),sort=True)
a.exec_()
</t>
<t tx="ekr.20080930080501.1">c.frame.iconBar.addRow()
c.frame.addIconButton(text="New")</t>
<t tx="ekr.20080930083052.1">c.frame.hideIconBar()</t>
<t tx="ekr.20080930083052.2">c.frame.showIconBar()</t>
<t tx="ekr.20080930085514.1">c.frame.clearIconBar()</t>
<t tx="ekr.20080930114036.1"></t>
<t tx="ekr.20081001110047.1">@others</t>
<t tx="ekr.20081001110047.2">def spam():
    
    pass # changed</t>
<t tx="ekr.20081001110047.3">def eggs():
    
    pass</t>
<t tx="ekr.20081003094737.1"></t>
<t tx="ekr.20081006070847.2"># aList = g.get_directives_dict_list(p)
# path = c.scanAtPathDirectives(aList)
# filename = p.isAnyAtFileNode()
# print g.os_path_finalize_join(path,filename)

print c.getNodePath (p)

print c.getNodeFileName(p)

</t>
<t tx="ekr.20081020082611.1">class baseClass:

    def foo(self):
        g.trace('baseClass')

class subClass (baseClass):

    def foo(self):
        g.trace('subClass')
        baseClass.foo(self)

z = subClass()
z.foo()
</t>
<t tx="ekr.20081025105942.1">import os
os.system("dir")</t>
<t tx="ekr.20081124102740.1"></t>
<t tx="ekr.20081202095209.1">import PyQt4.QtCore as QtCore
import PyQt4.QtGui as QtGui

ui = c.frame.top.ui

h =ui.horizontalLayout
v= ui.verticalLayout

v.removeItem(h)

hh = QtGui.QHBoxLayout()
hh.setContentsMargins(0,0,0,0)
hh.expandingDirections = QtCore.Qt.Horizontal

# make the minibuffer area a panel
p = ui.miniBufferPanel =QtGui.QWidget()
p.setLayout(hh)
p.setContentsMargins(0,0,0,0)
hh.addWidget(ui.label)
hh.addWidget(ui.lineEdit)

tb = QtGui.QToolBar()

c.frame.top.addToolBar( QtCore.Qt.BottomToolBarArea,tb)

tb.addWidget(p)
tb.setWindowTitle('Minibuffer')</t>
<t tx="ekr.20081202140932.1"></t>
<t tx="ekr.20081202141210.1">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141210.2">@language python
@tabwidth -4
@others
log = logging.getLogger('pythoscope')
setup_logger()
</t>
<t tx="ekr.20081202141210.3">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141210.4">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141210.5">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141210.6">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141453.1"></t>
<t tx="ekr.20081202141453.2">from pythoscope.logger import log
from pythoscope.util import quoted_block

from lib2to3 import pygram
from lib2to3 import pytree
from lib2to3.patcomp import compile_pattern
from lib2to3.pgen2 import driver
from lib2to3.pgen2 import token
from lib2to3.pgen2.parse import ParseError
from lib2to3.pygram import python_symbols as syms
from lib2to3.pytree import Node, Leaf


__all__ = ["EmptyCode", "Newline", "clone", "create_import", "parse",
           "regenerate", "ASTError", "ASTVisitor"]

EmptyCode = lambda: Node(syms.file_input, [])
Newline = lambda: Leaf(token.NEWLINE, "\n")

</t>
<t tx="ekr.20081202141453.3">def clone(tree):
    """Clone the tree, preserving its add_newline attribute.
    """
    if tree is None:
        return None

    new_tree = tree.clone()
    if hasattr(tree, 'added_newline') and tree.added_newline:
        new_tree.added_newline = True
    return new_tree

</t>
<t tx="ekr.20081202141453.4">def create_import(import_desc):
    """Create an AST representing import statement from given description.

    &gt;&gt;&gt; regenerate(create_import("unittest"))
    'import unittest\\n'
    &gt;&gt;&gt; regenerate(create_import(("nose", "SkipTest")))
    'from nose import SkipTest\\n'
    """
    if isinstance(import_desc, tuple):
        package, name = import_desc
        return Node(syms.import_from,
                    [Leaf(token.NAME, 'from'),
                     Leaf(token.NAME, package, prefix=" "),
                     Leaf(token.NAME, 'import', prefix=" "),
                     Leaf(token.NAME, name, prefix=" "),
                     Newline()])
    else:
        return Node(syms.import_name,
                    [Leaf(token.NAME, 'import'),
                     Leaf(token.NAME, import_desc, prefix=" "),
                     Newline()])

</t>
<t tx="ekr.20081202141453.5">def descend(tree, visitor_type):
    """Walk over the AST using a visitor of a given type and return the visitor
    object once done.
    """
    visitor = visitor_type()
    visitor.visit(tree)
    return visitor

</t>
<t tx="ekr.20081202141453.6">def find_last_leaf(node):
    if isinstance(node, Leaf):
        return node
    else:
        return find_last_leaf(node.children[-1])

</t>
<t tx="ekr.20081202141453.7">def get_starting_whitespace(code):
    whitespace = ""
    for child in code.children:
        if is_leaf_of_type(child, token.NEWLINE, token.INDENT):
            whitespace += child.value
        else:
            break
    return whitespace

</t>
<t tx="ekr.20081202141453.8">def remove_trailing_whitespace(code):
    leaf = find_last_leaf(code)
    leaf.prefix = leaf.prefix.replace(' ', '').replace('\t', '')

</t>
<t tx="ekr.20081202141453.9">def parse(code):
    """String -&gt; AST

    Parse the string and return its AST representation. May raise
    a ParseError exception.
    """
    added_newline = False
    if not code.endswith("\n"):
        code += "\n"
        added_newline = True

    try:
        drv = driver.Driver(pygram.python_grammar, pytree.convert)
        result = drv.parse_string(code, True)
    except ParseError:
        log.debug("Had problems parsing:\n%s\n" % quoted_block(code))
        raise

    # Always return a Node, not a Leaf.
    if isinstance(result, Leaf):
        result = Node(syms.file_input, [result])

    result.added_newline = added_newline

    return result

</t>
<t tx="ekr.20081202141453.10">def parse_fragment(code):
    """Works like parse() but returns an object stripped of the file_input
    wrapper. This eases merging this piece of code into other ones.
    """
    parsed_code = parse(code)

    if is_node_of_type(parsed_code, 'file_input') and \
           len(parsed_code.children) == 2 and \
           is_leaf_of_type(parsed_code.children[-1], token.ENDMARKER):
        return parsed_code.children[0]
    return parsed_code

</t>
<t tx="ekr.20081202141453.11">def regenerate(tree):
    """AST -&gt; String

    Regenerate the source code from the AST tree.
    """
    if hasattr(tree, 'added_newline') and tree.added_newline:
        return str(tree)[:-1]
    else:
        return str(tree)

</t>
<t tx="ekr.20081202141453.12">class ASTError(Exception):
    pass

</t>
<t tx="ekr.20081202141453.13">def is_leaf_of_type(leaf, *types):
    return isinstance(leaf, Leaf) and leaf.type in types

</t>
<t tx="ekr.20081202141453.14">def is_node_of_type(node, *types):
    return isinstance(node, Node) and pytree.type_repr(node.type) in types

</t>
<t tx="ekr.20081202141453.15">def leaf_value(leaf):
    return leaf.value

</t>
<t tx="ekr.20081202141453.16">def remove_commas(nodes):
    def isnt_comma(node):
        return not is_leaf_of_type(node, token.COMMA)
    return filter(isnt_comma, nodes)

</t>
<t tx="ekr.20081202141453.17">def remove_defaults(nodes):
    ignore_next = False
    for node in nodes:
        if ignore_next is True:
            ignore_next = False
            continue
        if is_leaf_of_type(node, token.EQUAL):
            ignore_next = True
            continue
        yield node

</t>
<t tx="ekr.20081202141453.18">def derive_class_name(node):
    if is_leaf_of_type(node, token.NAME, token.DOT):
        return node.value
    elif is_node_of_type(node, 'power', 'trailer'):
        return "".join(map(derive_class_name, node.children))
    else:
        raise ASTError("Unknown node type: %r." % node)

</t>
<t tx="ekr.20081202141453.19">def derive_class_names(node):
    if node is None:
        return []
    elif is_node_of_type(node, 'arglist'):
        return map(derive_class_name, remove_commas(node.children))
    else:
        return [derive_class_name(node)]

</t>
<t tx="ekr.20081202141453.20">def derive_argument(node):
    if is_leaf_of_type(node, token.NAME):
        return node.value
    elif is_node_of_type(node, 'tfpdef'):
        return tuple(map(derive_argument,
                         remove_commas(node.children[1].children)))

</t>
<t tx="ekr.20081202141453.21">def derive_arguments(node):
    if node == []:
        return []
    elif is_node_of_type(node, 'typedargslist'):
        return map(derive_argument,
                   remove_defaults(remove_commas(node.children)))
    else:
        return [derive_argument(node)]

</t>
<t tx="ekr.20081202141453.22">def derive_import_name(node):
    if is_leaf_of_type(node, token.NAME):
        return node.value
    elif is_node_of_type(node, 'dotted_as_name'):
        return (derive_import_name(node.children[0]),
                derive_import_name(node.children[2]))
    elif is_node_of_type(node, 'dotted_name'):
        return "".join(map(leaf_value, node.children))

</t>
<t tx="ekr.20081202141453.23">def derive_import_names(node):
    if node is None:
        return None
    elif is_node_of_type(node, 'dotted_as_names', 'import_as_names'):
        return map(derive_import_name,
                   remove_commas(node.children))
    else:
        return [derive_import_name(node)]


</t>
<t tx="ekr.20081202141453.24">class ASTVisitor(object):
    DEFAULT_PATTERNS = [
        ('_visit_all', "file_input&lt; nodes=any* &gt;"),
        ('_visit_all', "suite&lt; nodes=any* &gt;"),
        ('_visit_class', "body=classdef&lt; 'class' name=NAME ['(' bases=any ')'] ':' any &gt;"),
        ('_visit_function', "body=funcdef&lt; 'def' name=NAME parameters&lt; '(' [args=any] ')' &gt; ':' any &gt;"),
        ('_visit_import', "import_name&lt; 'import' names=any &gt; | import_from&lt; 'from' import_from=any 'import' names=any &gt;"),
        ('_visit_lambda_assign', "expr_stmt&lt; name=NAME '=' lambdef&lt; 'lambda' any ':' any &gt; &gt;"),
        ('_visit_main_snippet', "body=if_stmt&lt; 'if' comparison&lt; '__name__' '==' (\"'__main__'\" | '\"__main__\"' ) &gt; ':' any &gt;"),
    ]

    @others
</t>
<t tx="ekr.20081202141453.25">def __init__(self):
    self.patterns = []
    for method, pattern in self.DEFAULT_PATTERNS:
        self.register_pattern(method, pattern)

</t>
<t tx="ekr.20081202141453.26">def register_pattern(self, method, pattern):
    """Register method to handle given pattern.
    """
    self.patterns.append((method, compile_pattern(pattern)))

</t>
<t tx="ekr.20081202141453.27">def visit(self, tree):
    """Main entry point of the ASTVisitor class.
    """
    if isinstance(tree, Leaf):
        self.visit_leaf(tree)
    elif isinstance(tree, Node):
        self.visit_node(tree)
    elif isinstance(tree, list):
        for subtree in tree:
            self.visit(subtree)
    else:
        raise ASTError("Unknown tree type: %r." % tree)

</t>
<t tx="ekr.20081202141453.28">def visit_leaf(self, leaf):
    pass

</t>
<t tx="ekr.20081202141453.29">def visit_node(self, node):
    for method, pattern in self.patterns:
        results = {}
        if pattern.match(node, results):
            getattr(self, method)(results)
            break
    else:
        # For unknown nodes simply descend to their list of children.
        self.visit(node.children)

</t>
<t tx="ekr.20081202141453.30">def visit_class(self, name, bases, body):
    self.visit(body.children)

</t>
<t tx="ekr.20081202141453.31">def visit_function(self, name, args, body):
    self.visit(body.children)

</t>
<t tx="ekr.20081202141453.32">def visit_import(self, names, import_from):
    pass

</t>
<t tx="ekr.20081202141453.33">def visit_lambda_assign(self, name):
    pass

</t>
<t tx="ekr.20081202141453.34">def visit_main_snippet(self, body):
    pass

</t>
<t tx="ekr.20081202141453.35">def _visit_all(self, results):
    self.visit(results['nodes'])

</t>
<t tx="ekr.20081202141453.36">def _visit_class(self, results):
    self.visit_class(name=results['name'].value,
                     bases=derive_class_names(results.get('bases')),
                     body=results['body'])

</t>
<t tx="ekr.20081202141453.37">def _visit_function(self, results):
    self.visit_function(name=results['name'].value,
                        args=derive_arguments(results.get('args', [])),
                        body=results['body'])

</t>
<t tx="ekr.20081202141453.38">def _visit_import(self, results):
    self.visit_import(names=derive_import_names(results['names']),
                      import_from=derive_import_name(results.get('import_from')))

</t>
<t tx="ekr.20081202141453.39">def _visit_lambda_assign(self, results):
    self.visit_lambda_assign(name=results['name'].value)

</t>
<t tx="ekr.20081202141453.40">def _visit_main_snippet(self, results):
    self.visit_main_snippet(body=results['body'])
</t>
<t tx="ekr.20081202141453.41">"""This module defines the logging system.

To change the logging level, assign INFO, DEBUG or ERROR to log.level. Default
is INFO.

To change the output stream, call the set_output() function. Default is
sys.stderr.
"""

import logging
import re

from time import strftime, localtime

from pythoscope.util import module_path_to_name


INFO  = logging.INFO
DEBUG = logging.DEBUG
ERROR = logging.ERROR

</t>
<t tx="ekr.20081202141453.42">def path2modname(path, default=""):
    """Take a path to a pythoscope module and return a module name in dot-style
    notation. Return default if path doesn't point to a pythoscope module.

    &gt;&gt;&gt; path2modname("sth/pythoscope/astvisitor.py")
    'astvisitor'
    &gt;&gt;&gt; path2modname("sth/pythoscope/generator/__init__.py")
    'generator'
    &gt;&gt;&gt; path2modname("sth/pythoscope/generator/adder.py")
    'generator.adder'
    """
    match = re.search(r'.*pythoscope/(.*)$', path)
    if match:
        return module_path_to_name(match.group(1), newsep=".")
    else:
        return default

</t>
<t tx="ekr.20081202141453.43">class LogFormatter(logging.Formatter):
    @others
</t>
<t tx="ekr.20081202141453.44">def format(self, record):
    """Show a message with a loglevel in normal verbosity mode and much more
    in debug mode.
    """
    message = "%s: %s" % (record.levelname, record.getMessage())
    if log.level == DEBUG:
        return "%s.%d %s:%d %s" % \
            (strftime("%H%M%S", localtime(record.created)),
             record.msecs,
             path2modname(record.pathname, default=record.module),
             record.lineno,
             message)
    return message

</t>
<t tx="ekr.20081202141453.45"># Don't call this "setup" or nose will assume this is the fixture setup
# function for this module.
def setup_logger():
    handler = logging.StreamHandler()
    handler.setFormatter(LogFormatter())
    log.addHandler(handler)
    log.level = INFO

</t>
<t tx="ekr.20081202141453.46">def get_output():
    return log.handlers[0].stream

</t>
<t tx="ekr.20081202141453.47">def set_output(stream):
    "Change the output of all the logging calls to go to given stream."
    log.handlers[0].stream = stream

</t>
<t tx="ekr.20081202141453.48">import array
import re
import sets
import types

from pythoscope.astvisitor import parse_fragment, ParseError
from pythoscope.util import RePatternType, all, frozenset, \
    regexp_flags_as_string, set, underscore


</t>
<t tx="ekr.20081202141453.49"># :: SerializedObject | [SerializedObject] -&gt; bool
def can_be_constructed(obj):
    if isinstance(obj, list):
        return all(map(can_be_constructed, obj))
    return obj.reconstructor_with_imports is not None

</t>
<t tx="ekr.20081202141453.50"># :: string -&gt; string
def string2id(string):
    """Remove from string all characters that cannot be used in an identifier.
    """
    return re.sub(r'[^a-zA-Z0-9_]', '', re.sub(r'\s+', '_', string.strip()))

</t>
<t tx="ekr.20081202141453.51"># :: object -&gt; string
def get_type_name(obj):
    """A canonical representation of the type.

    &gt;&gt;&gt; get_type_name([])
    'list'
    &gt;&gt;&gt; get_type_name({})
    'dict'

    May contain dots, if type is not builtin.
        &gt;&gt;&gt; get_type_name(lambda: None)
        'types.FunctionType'
    """
    mapping = {types.FunctionType: 'types.FunctionType',
               types.GeneratorType: 'types.GeneratorType'}
    objtype = type(obj)
    return mapping.get(objtype, objtype.__name__)

</t>
<t tx="ekr.20081202141453.52"># :: object -&gt; string
def get_module_name(obj):
    return type(obj).__module__

</t>
<t tx="ekr.20081202141453.53"># :: object -&gt; string
def get_partial_reconstructor(obj):
    """A string representation of a partial object reconstructor.

    It doesn't have to be parsable, as it will be part of a comment. Partial
    reconstructor should give all possible hints about an object to help
    the user correct the code.
    """
    mapping = {types.FunctionType: 'function',
               types.GeneratorType: 'generator'}
    objtype = type(obj)
    default = "%s.%s" % (objtype.__module__, objtype.__name__)
    return mapping.get(objtype, default)

</t>
<t tx="ekr.20081202141453.54"># :: object -&gt; string
def get_human_readable_id(obj):
    """A human-readable description of an object, suitable to be used as
    an identifier.
    """
    # Get human readable id based on object's value,
    if obj is True:
        return 'true'
    elif obj is False:
        return 'false'

    # ... based on object's type,
    objtype = type(obj)
    mapping = {list: 'list',
               dict: 'dict',
               tuple: 'tuple',
               unicode: 'unicode_string',
               types.GeneratorType: 'generator'}
    objid = mapping.get(objtype)
    if objid:
        return objid

    # ... or based on its supertype.
    if isinstance(obj, Exception):
        return underscore(objtype.__name__)
    elif isinstance(obj, RePatternType):
        return "%s_pattern" % string2id(obj.pattern)
    elif isinstance(obj, types.FunctionType):
        if obj.func_name == '&lt;lambda&gt;':
            return "function"
        return "%s_function" % obj.func_name
    else:
        string = str(obj)
        # Looks like an instance without a custom __str__ defined.
        if string.startswith("&lt;"):
            return "%s_instance" % underscore(objtype.__name__)
        else:
            return string2id(string)

</t>
<t tx="ekr.20081202141453.55"># :: string -&gt; bool
def is_parsable(string):
    try:
        parse_fragment(string)
        return True
    except ParseError:
        return False

</t>
<t tx="ekr.20081202141453.56"># :: object -&gt; (string, set) | None
def get_reconstructor_with_imports(obj):
    """A string representing code that will construct the object plus
    a set of import descriptions needed for that code to work.

    Returns None when given object cannot be reconstructed.

    &gt;&gt;&gt; get_reconstructor_with_imports(array.array('I', [1, 2, 3, 4]))
    ("array.array('I', [1L, 2L, 3L, 4L])", ['array'])
    &gt;&gt;&gt; get_reconstructor_with_imports(array.array('d', [1, 2, 3, 4]))
    ("array.array('d', [1.0, 2.0, 3.0, 4.0])", ['array'])

    &gt;&gt;&gt; get_reconstructor_with_imports(re.compile('abcd'))
    ("re.compile('abcd')", ['re'])
    &gt;&gt;&gt; get_reconstructor_with_imports(re.compile('abcd', re.I | re.M))
    ("re.compile('abcd', re.IGNORECASE | re.MULTILINE)", ['re'])
    """
    if isinstance(obj, RePatternType):
        flags = regexp_flags_as_string(obj.flags)
        if flags:
            return ('re.compile(%r, %s)' % (obj.pattern, flags), ['re'])
        else:
            return ('re.compile(%r)' % obj.pattern, ['re'])
    elif isinstance(obj, types.FunctionType):
        function = obj.func_name
        if function != '&lt;lambda&gt;':
            module = obj.__module__
            return (function, [(module, function)])
    elif isinstance(obj, (int, long, float, str, unicode, types.NoneType)):
        # Bultin types has very convienient representation.
        return repr(obj), []
    elif isinstance(obj, array.array):
        return "array." + repr(obj), ["array"]
    elif isinstance(obj, (dict, frozenset, list, set, sets.ImmutableSet, sets.Set, tuple)):
        imports = set()
        if isinstance(obj, sets.ImmutableSet):
            imports.add(("sets", "ImmutableSet"))
        elif isinstance(obj, sets.Set):
            imports.add(("sets", "Set"))
        # Be careful not to generate wrong code.
        # TODO: Current solution is a hack. Right way to do this is to make
        # composite types call get_reconstructor_with_imports on all of their
        # elements recursively.
        if is_parsable(repr(obj)):
            return repr(obj), imports

</t>
<t tx="ekr.20081202141453.57">class SerializedObject(object):
    __slots__ = ("human_readable_id", "module_name", "partial_reconstructor",
                 "reconstructor_with_imports", "type_import", "type_name")

    @others
</t>
<t tx="ekr.20081202141453.58">def __init__(self, obj):
    self.human_readable_id = get_human_readable_id(obj)
    self.module_name = get_module_name(obj)
    self.partial_reconstructor = get_partial_reconstructor(obj)
    self.reconstructor_with_imports = get_reconstructor_with_imports(obj)
    self.type_name = get_type_name(obj)

    # An import needed for the type to be available in the testing
    # environment.
    self.type_import = (self.module_name, self.type_name)

</t>
<t tx="ekr.20081202141453.59">def __eq__(self, other):
    if not isinstance(other, SerializedObject):
        return False
    for attr in SerializedObject.__slots__:
        if getattr(self, attr) != getattr(other, attr):
            return False
    return True

</t>
<t tx="ekr.20081202141453.60">def __hash__(self):
    return hash(self.partial_reconstructor)

</t>
<t tx="ekr.20081202141453.61">def __repr__(self):
    if self.reconstructor_with_imports is not None:
        return "SerializedObject(%r)" % self.reconstructor_with_imports[0]
    else:
        return "SerializedObject(%r)" % self.partial_reconstructor

</t>
<t tx="ekr.20081202141453.62">def serialize(obj):
    return SerializedObject(obj)

</t>
<t tx="ekr.20081202141453.63">def serialize_call_arguments(input):
    new_input = {}
    for key, value in input.iteritems():
        new_input[key] = serialize(value)
    return new_input
</t>
<t tx="ekr.20081202141453.64">import os
import cPickle
import re
import time

from pythoscope.astvisitor import EmptyCode, Newline, create_import, find_last_leaf, \
     get_starting_whitespace, is_node_of_type, regenerate, \
     remove_trailing_whitespace
from pythoscope.serializer import serialize, serialize_call_arguments, SerializedObject
from pythoscope.util import all_of_type, cname, set, module_path_to_name, \
     write_string_to_file, ensure_directory, DirectoryException, \
     get_last_modification_time, read_file_contents, is_generator_code, \
     extract_subpath, directories_under, findfirst, contains_active_generator


</t>
<t tx="ekr.20081202141453.65">class ModuleNeedsAnalysis(Exception):
    @others
</t>
<t tx="ekr.20081202141453.66">def __init__(self, path, out_of_sync=False):
    Exception.__init__(self, "Destination test module %r needs analysis." % path)
    self.path = path
    self.out_of_sync = out_of_sync

</t>
<t tx="ekr.20081202141453.67">class ModuleNotFound(Exception):
    @others
</t>
<t tx="ekr.20081202141453.68">def __init__(self, module):
    Exception.__init__(self, "Couldn't find module %r." % module)
    self.module = module

</t>
<t tx="ekr.20081202141453.69">class ModuleSaveError(Exception):
    @others
</t>
<t tx="ekr.20081202141453.70">def __init__(self, module, reason):
    Exception.__init__(self, "Couldn't save module %r: %s." % (module, reason))
    self.module = module
    self.reason = reason

</t>
<t tx="ekr.20081202141453.71">def get_pythoscope_path(project_path):
    return os.path.join(project_path, ".pythoscope")

</t>
<t tx="ekr.20081202141453.72">def get_pickle_path(project_path):
    return os.path.join(get_pythoscope_path(project_path), "project.pickle")

</t>
<t tx="ekr.20081202141453.73">def get_points_of_entry_path(project_path):
    return os.path.join(get_pythoscope_path(project_path), "points-of-entry")

</t>
<t tx="ekr.20081202141453.74">def get_test_objects(objects):
    def is_test_object(object):
        return isinstance(object, TestCase)
    return filter(is_test_object, objects)

</t>
<t tx="ekr.20081202141453.75">class Project(object):
    """Object representing the whole project under Pythoscope wings.

    No modifications are final until you call save().
    """
    @others
</t>
<t tx="ekr.20081202141453.76">def from_directory(cls, project_path):
    """Read the project information from the .pythoscope/ directory of
    the given project.

    The pickle file may not exist for project that is analyzed the
    first time and that's OK.
    """
    project_path = os.path.realpath(project_path)
    try:
        fd = open(get_pickle_path(project_path))
        project = cPickle.load(fd)
        fd.close()
        # Update project's path, as the directory could've been moved.
        project.path = project_path
    except IOError:
        project = Project(project_path)
    return project
</t>
<t tx="ekr.20081202141453.77">from_directory = classmethod(from_directory)

def __init__(self, path):
    self.path = path
    self.new_tests_directory = "tests"
    self.points_of_entry = {}
    self._modules = {}

    self._find_new_tests_directory()

</t>
<t tx="ekr.20081202141453.78">def _get_pickle_path(self):
    return get_pickle_path(self.path)

</t>
<t tx="ekr.20081202141453.79">def _get_points_of_entry_path(self):
    return get_points_of_entry_path(self.path)

</t>
<t tx="ekr.20081202141453.80">def _find_new_tests_directory(self):
    for path in directories_under(self.path):
        if re.search(r'[_-]?tests?([_-]|$)', path):
            self.new_tests_directory = path

</t>
<t tx="ekr.20081202141453.81">def save(self):
    # Try pickling the project first, because if this fails, we shouldn't
    # save any changes at all.
    pickled_project = cPickle.dumps(self, cPickle.HIGHEST_PROTOCOL)

    # To avoid inconsistencies try to save all project's modules first. If
    # any of those saves fail, the pickle file won't get updated.
    for module in self.get_modules():
        module.save()

    write_string_to_file(pickled_project, self._get_pickle_path())

</t>
<t tx="ekr.20081202141453.82">def find_module_by_full_path(self, path):
    subpath = self._extract_subpath(path)
    return self[subpath]

</t>
<t tx="ekr.20081202141453.83">def ensure_point_of_entry(self, path):
    name = self._extract_point_of_entry_subpath(path)
    if name not in self.points_of_entry:
        poe = PointOfEntry(project=self, name=name)
        self.points_of_entry[name] = poe
    return self.points_of_entry[name]

</t>
<t tx="ekr.20081202141453.84">def remove_point_of_entry(self, name):
    poe = self.points_of_entry.pop(name)
    poe.clear_previous_run()

</t>
<t tx="ekr.20081202141453.85">def create_module(self, path, **kwds):
    """Create a module for this project located under given path.

    If there already was a module with given subpath, it will get replaced
    with a new instance using the _replace_references_to_module method.

    Returns the new Module object.
    """
    module = Module(subpath=self._extract_subpath(path), project=self, **kwds)

    if module.subpath in self._modules.keys():
        self._replace_references_to_module(module)

    self._modules[module.subpath] = module

    return module

</t>
<t tx="ekr.20081202141453.86">def create_test_module_from_name(self, test_name):
    """Create a module with given name in project tests directory.

    If the test module already exists, ModuleNeedsAnalysis exception will
    be raised.
    """
    test_path = self._path_for_test(test_name)
    if os.path.exists(test_path):
        raise ModuleNeedsAnalysis(test_path)
    return self.create_module(test_path)

</t>
<t tx="ekr.20081202141453.87">def remove_module(self, subpath):
    """Remove a module from this Project along with all references to it
    from other modules.
    """
    module = self[subpath]
    for test_case in self.iter_test_cases():
        try:
            test_case.associated_modules.remove(module)
        except ValueError:
            pass
    del self._modules[subpath]

</t>
<t tx="ekr.20081202141453.88">def _replace_references_to_module(self, module):
    """Remove a module with the same subpath as given module from this
    Project and replace all references to it with the new instance.
    """
    old_module = self[module.subpath]
    for test_case in self.iter_test_cases():
        try:
            test_case.associated_modules.remove(old_module)
            test_case.associated_modules.append(module)
        except ValueError:
            pass

</t>
<t tx="ekr.20081202141453.89">def _extract_point_of_entry_subpath(self, path):
    """Takes the file path and returns subpath relative to the
    points of entry path.

    Assumes the given path is under points of entry path.
    """
    return extract_subpath(path, self._get_points_of_entry_path())

</t>
<t tx="ekr.20081202141453.90">def _extract_subpath(self, path):
    """Takes the file path and returns subpath relative to the
    project.

    Assumes the given path is under Project.path.
    """
    return extract_subpath(path, self.path)

</t>
<t tx="ekr.20081202141453.91">def iter_test_cases(self):
    for module in self.iter_modules():
        for test_case in module.test_cases:
            yield test_case

</t>
<t tx="ekr.20081202141453.92">def _path_for_test(self, test_module_name):
    """Return a full path to test module with given name.
    """
    return os.path.join(self.path, self.new_tests_directory, test_module_name)

</t>
<t tx="ekr.20081202141453.93">def __getitem__(self, module):
    for mod in self.iter_modules():
        if module in [mod.subpath, mod.locator]:
            return mod
    raise ModuleNotFound(module)

</t>
<t tx="ekr.20081202141453.94">def get_modules(self):
    return self._modules.values()

</t>
<t tx="ekr.20081202141453.95">def iter_modules(self):
    return self._modules.values()

</t>
<t tx="ekr.20081202141453.96">def iter_classes(self):
    for module in self.iter_modules():
        for klass in module.classes:
            yield klass

</t>
<t tx="ekr.20081202141453.97">def iter_functions(self):
    for module in self.iter_modules():
        for function in module.functions:
            yield function

</t>
<t tx="ekr.20081202141453.98">def iter_generator_objects(self):
    for module in self.iter_modules():
        for generator in module.generators:
            for gobject in generator.calls:
                yield gobject

</t>
<t tx="ekr.20081202141453.99">def find_object(self, type, name, modulepath):
    modulename = self._extract_subpath(modulepath)
    try:
        for obj in all_of_type(self[modulename].objects, type):
            if obj.name == name:
                return obj
    except ModuleNotFound:
        pass

</t>
<t tx="ekr.20081202141453.100">class Call(object):
    """Stores information about a single function or method call.

    Includes reference to the caller, all call arguments, references to
    other calls made inside this one and finally an output value.

    There's more to function/method call than arguments and outputs.
    They're the only attributes for now, but information on side effects
    will be added later.

    __eq__ and __hash__ definitions provided for Function.get_unique_calls()
    and LiveObject.get_external_calls().
    """
    @others
</t>
<t tx="ekr.20081202141453.101">def __init__(self, definition, input, output=None, exception=None):
    if [value for value in input.values() if not isinstance(value, SerializedObject)]:
        raise ValueError("All input values should be instances of SerializedObject class.")
    if output and exception:
        raise ValueError("Call should have a single point of return.")
    if not isinstance(definition, Definition):
        raise ValueError("Call definition object should be an instance of Definition.")

    self.definition = definition
    self.input = input
    self.output = output
    self.exception = exception

    self.caller = None
    self.subcalls = []

</t>
<t tx="ekr.20081202141453.102">def add_subcall(self, call):
    # Don't add the same GeneratorObject more than once.
    if isinstance(call, GeneratorObject) and call.caller is self:
        return
    if call.caller is not None:
        raise TypeError("This %s of %s already has a caller." % \
                            (cname(call), call.definition.name))
    call.caller = self
    self.subcalls.append(call)

</t>
<t tx="ekr.20081202141453.103">def raised_exception(self):
    return self.exception is not None

</t>
<t tx="ekr.20081202141453.104">def set_output(self, output):
    self.output = serialize(output)

</t>
<t tx="ekr.20081202141453.105">def set_exception(self, exception):
    self.exception = serialize(exception)

</t>
<t tx="ekr.20081202141453.106">def clear_exception(self):
    self.exception = None

</t>
<t tx="ekr.20081202141453.107">def is_testable(self):
    return True

</t>
<t tx="ekr.20081202141453.108">def __eq__(self, other):
    return self.definition == other.definition and \
           self.input == other.input and \
           self.output == other.output and \
           self.exception == other.exception

</t>
<t tx="ekr.20081202141453.109">def __hash__(self):
    return hash((self.definition.name,
                 tuple(self.input.iteritems()),
                 self.output,
                 self.exception))

</t>
<t tx="ekr.20081202141453.110">def __repr__(self):
    return "%s(definition=%s, input=%r, output=%r, exception=%r)" % \
        (cname(self), self.definition.name, self.input, self.output,
         self.exception)

</t>
<t tx="ekr.20081202141453.111">class FunctionCall(Call):
    @others
</t>
<t tx="ekr.20081202141453.112">def __init__(self, point_of_entry, function, input, output=None, exception=None):
    Call.__init__(self, function, input, output, exception)
    self.point_of_entry = point_of_entry

</t>
<t tx="ekr.20081202141453.113">class MethodCall(Call):
    pass

</t>
<t tx="ekr.20081202141453.114">class Definition(object):
    @others
</t>
<t tx="ekr.20081202141453.115">def __init__(self, name, code=None, is_generator=False):
    if code is None:
        code = EmptyCode()
    self.name = name
    self.code = code
    self.is_generator = is_generator

</t>
<t tx="ekr.20081202141453.116">class Callable(object):
    @others
</t>
<t tx="ekr.20081202141453.117">def __init__(self, calls=None):
    if calls is None:
        calls = []
    self.calls = calls

</t>
<t tx="ekr.20081202141453.118">def add_call(self, call):
    # Don't add the same GeneratorObject more than once.
    if isinstance(call, GeneratorObject) and call in self.calls:
        return
    self.calls.append(call)

</t>
<t tx="ekr.20081202141453.119">def get_generator_object(self, unique_id):
    def is_matching_gobject(call):
        return isinstance(call, GeneratorObject) and call.unique_id == unique_id
    return findfirst(is_matching_gobject, self.calls)

</t>
<t tx="ekr.20081202141453.120">def remove_calls_from(self, point_of_entry):
    self.calls = [call for call in self.calls if call.point_of_entry is not point_of_entry]

</t>
<t tx="ekr.20081202141453.121">class Function(Definition, Callable):
    @others
</t>
<t tx="ekr.20081202141453.122">def __init__(self, name, code=None, calls=None, is_generator=False):
    Definition.__init__(self, name, code, is_generator)
    Callable.__init__(self, calls)

</t>
<t tx="ekr.20081202141453.123">def is_testable(self):
    return not self.name.startswith('_')

</t>
<t tx="ekr.20081202141453.124">def get_unique_calls(self):
    return set(self.calls)

</t>
<t tx="ekr.20081202141453.125">def __repr__(self):
    return "Function(name=%r, calls=%r)" % (self.name, self.calls)

</t>
<t tx="ekr.20081202141453.126"># Methods are not Callable, because they cannot be called by itself - they
# need a bound object. We represent this object by LiveObject class, which
# gathers all MethodCalls for given instance.
class Method(Definition):
    pass

</t>
<t tx="ekr.20081202141453.127">class GeneratorObject(Call):
    """Representation of a generator object - a callable with on input and many
    outputs (here called "yields").

    Although a generator object execution is not a single call, but consists of
    a series of suspensions and resumes, we make it conform to the Call interface
    for simplicity.
    """
    @others
</t>
<t tx="ekr.20081202141453.128">def __init__(self, id, generator, point_of_entry, input, yields=None, exception=None):
    if yields is None:
        yields = []
    Call.__init__(self, generator, input, yields, exception)

    self.id = id
    self.point_of_entry = point_of_entry
    self.unique_id = (point_of_entry.name, id)

</t>
<t tx="ekr.20081202141453.129">def set_output(self, output):
    self.output.append(serialize(output))

</t>
<t tx="ekr.20081202141453.130">def is_testable(self):
    return self.raised_exception() or self.output

</t>
<t tx="ekr.20081202141453.131">def __hash__(self):
    return hash((self.definition.name,
                 tuple(self.input.iteritems()),
                 tuple(self.output),
                 self.exception))

</t>
<t tx="ekr.20081202141453.132">def __repr__(self):
    return "GeneratorObject(id=%d, generator=%r, yields=%r)" % \
           (self.id, self.definition.name, self.output)

</t>
<t tx="ekr.20081202141453.133">class LiveObject(Callable):
    """Representation of an object which creation and usage was traced
    during dynamic inspection.

    Note that the LiveObject.id is only unique to a given point of entry.
    In other words, it is possible to have two points of entry holding
    separate live objects with the same id. Use LiveObject.unique_id for
    identification purposes.
    """
    @others
</t>
<t tx="ekr.20081202141453.134">def __init__(self, id, klass, point_of_entry):
    Callable.__init__(self)

    self.id = id
    self.klass = klass
    self.point_of_entry = point_of_entry

    self.unique_id = (point_of_entry.name, id)

</t>
<t tx="ekr.20081202141453.135">def get_init_call(self):
    """Return a call to __init__ or None if it wasn't called.
    """
    return findfirst(lambda call: call.definition.name == '__init__', self.calls)

</t>
<t tx="ekr.20081202141453.136">def get_external_calls(self):
    """Return all calls to this object made from the outside.

    Note: __init__ is considered an internal call.
    """
    def is_not_init_call(call):
        return call.definition.name != '__init__'
    def is_external_call(call):
        return (not call.caller) or (call.caller not in self.calls)
    return filter(is_not_init_call, filter(is_external_call, self.calls))

</t>
<t tx="ekr.20081202141453.137">def __repr__(self):
    return "LiveObject(id=%d, klass=%r, calls=%r)" % (self.id, self.klass.name, self.calls)

</t>
<t tx="ekr.20081202141453.138">class Class(object):
    @others
</t>
<t tx="ekr.20081202141453.139">def __init__(self, name, methods=[], bases=[]):
    self.name = name
    self.methods = methods
    self.bases = bases
    self.live_objects = {}

</t>
<t tx="ekr.20081202141453.140">def is_testable(self):
    ignored_superclasses = ['Exception', 'unittest.TestCase']
    for klass in ignored_superclasses:
        if klass in self.bases:
            return False
    return True

</t>
<t tx="ekr.20081202141453.141">def add_live_object(self, live_object):
    self.live_objects[live_object.unique_id] = live_object

</t>
<t tx="ekr.20081202141453.142">def remove_live_objects_from(self, point_of_entry):
    # We're removing elements, so iterate over a shallow copy.
    for id, live_object in self.live_objects.copy().iteritems():
        if live_object.point_of_entry is point_of_entry:
            del self.live_objects[id]

</t>
<t tx="ekr.20081202141453.143">def get_traced_method_names(self):
    traced_method_names = set()
    for live_object in self.live_objects.values():
        for call in live_object.calls:
            traced_method_names.add(call.definition.name)
    return traced_method_names

</t>
<t tx="ekr.20081202141453.144">def get_untraced_methods(self):
    traced_method_names = self.get_traced_method_names()
    def is_untraced(method):
        return method.name not in traced_method_names
    return filter(is_untraced, self.methods)

</t>
<t tx="ekr.20081202141453.145">def find_method_by_name(self, name):
    for method in self.methods:
        if method.name == name:
            return method

</t>
<t tx="ekr.20081202141453.146">class TestCase(object):
    """A single test object, possibly contained within a test suite (denoted
    as parent attribute).
    """
    @others
</t>
<t tx="ekr.20081202141453.147">def __init__(self, name, code=None, parent=None):
    if code is None:
        code = EmptyCode()
    self.name = name
    self.code = code
    self.parent = parent

</t>
<t tx="ekr.20081202141453.148">def replace_itself_with(self, new_test_case):
    self.parent.replace_test_case(self, new_test_case)

</t>
<t tx="ekr.20081202141453.149">class TestSuite(TestCase):
    """A test objects container.

    Keeps both test cases and other test suites in test_cases attribute.
    """
    allowed_test_case_classes = []

    @others
</t>
<t tx="ekr.20081202141453.150">def __init__(self, name, code=None, parent=None, test_cases=[], imports=None):
    TestCase.__init__(self, name, code, parent)

    if imports is None:
        imports = []

    self.changed = False
    self.test_cases = []
    self.imports = imports

</t>
<t tx="ekr.20081202141453.151">def add_test_cases(self, test_cases, append_code=True):
    for test_case in test_cases:
        self.add_test_case(test_case, append_code)

</t>
<t tx="ekr.20081202141453.152">def add_test_case(self, test_case, append_code=True):
    self._check_test_case_type(test_case)

    test_case.parent = self
    self.test_cases.append(test_case)

    if append_code:
        self._append_test_case_code(test_case.code)
        self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.153">def replace_test_case(self, old_test_case, new_test_case):
    self._check_test_case_type(new_test_case)
    if old_test_case not in self.test_cases:
        raise ValueError("Given test case is not part of this test suite.")

    self.test_cases.remove(old_test_case)

    # The easiest way to get the new code inside the AST is to call
    # replace() on the old test case code.
    # It is destructive, but since we're discarding the old test case
    # anyway, it doesn't matter.
    old_test_case.code.replace(new_test_case.code)

    self.add_test_case(new_test_case, False)
    self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.154">def mark_as_changed(self):
    self.changed = True
    if self.parent:
        self.parent.mark_as_changed()

</t>
<t tx="ekr.20081202141453.155">def ensure_imports(self, imports):
    "Make sure that all required imports are present."
    for imp in imports:
        self._ensure_import(imp)
    if self.parent:
        self.parent.ensure_imports(imports)

</t>
<t tx="ekr.20081202141453.156">def _ensure_import(self, import_desc):
    if not self._contains_import(import_desc):
        self.imports.append(import_desc)

</t>
<t tx="ekr.20081202141453.157">def _contains_import(self, import_desc):
    return import_desc in self.imports

</t>
<t tx="ekr.20081202141453.158">def _check_test_case_type(self, test_case):
    if not isinstance(test_case, tuple(self.allowed_test_case_classes)):
        raise TypeError("Given test case isn't allowed to be added to this test suite.")

</t>
<t tx="ekr.20081202141453.159">class TestMethod(TestCase):
    pass

</t>
<t tx="ekr.20081202141453.160">class TestClass(TestSuite):
    """Testing class, either generated by Pythoscope or hand-writen by the user.

    Each test class contains a set of requirements its surrounding must meet,
    like the list of imports it needs, contents of the "if __name__ == '__main__'"
    snippet or specific setup and teardown instructions.

    associated_modules is a list of Modules which this test class exercises.
    """
    allowed_test_case_classes = [TestMethod]

    @others
</t>
<t tx="ekr.20081202141453.161">def __init__(self, name, code=None, parent=None, test_cases=[],
             imports=None, main_snippet=None, associated_modules=None):
    TestSuite.__init__(self, name, code, parent, test_cases, imports)

    if associated_modules is None:
        associated_modules = []

    self.main_snippet = main_snippet
    self.associated_modules = associated_modules

    # Code of test cases passed to the constructor is already contained
    # within the class code.
    self.add_test_cases(test_cases, False)

</t>
<t tx="ekr.20081202141453.162">def _append_test_case_code(self, code):
    """Append to the right node, so that indentation level of the
    new method is good.
    """
    if self.code.children and is_node_of_type(self.code.children[-1], 'suite'):
        remove_trailing_whitespace(code)
        suite = self.code.children[-1]
        # Prefix the definition with the right amount of whitespace.
        node = find_last_leaf(suite.children[-2])
        ident = get_starting_whitespace(suite)
        # There's no need to have extra newlines.
        if node.prefix.endswith("\n"):
            node.prefix += ident.lstrip("\n")
        else:
            node.prefix += ident
        # Insert before the class contents dedent.
        suite.insert_child(-1, code)
    else:
        self.code.append_child(code)
    self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.163">def find_method_by_name(self, name):
    for method in self.test_cases:
        if method.name == name:
            return method

</t>
<t tx="ekr.20081202141453.164">def is_testable(self):
    return False

</t>
<t tx="ekr.20081202141453.165">class Localizable(object):
    """An object which has a corresponding file belonging to some Project.

    Each Localizable has a 'path' attribute and an information when it was
    created, to be in sync with its file system counterpart. Path is always
    relative to the project this localizable belongs to.
    """
    @others
</t>
<t tx="ekr.20081202141453.166">def __init__(self, project, subpath, created=None):
    self.project = project
    self.subpath = subpath
    if created is None:
        created = time.time()
    self.created = created

</t>
<t tx="ekr.20081202141453.167">def _get_locator(self):
    return module_path_to_name(self.subpath, newsep=".")
</t>
<t tx="ekr.20081202141453.168">locator = property(_get_locator)

def is_out_of_sync(self):
    """Is the object out of sync with its file.
    """
    return get_last_modification_time(self.get_path()) &gt; self.created

</t>
<t tx="ekr.20081202141453.169">def is_up_to_date(self):
    return not self.is_out_of_sync()

</t>
<t tx="ekr.20081202141453.170">def get_path(self):
    """Return the full path to the file.
    """
    return os.path.join(self.project.path, self.subpath)

</t>
<t tx="ekr.20081202141453.171">def write(self, new_content):
    """Overwrite the file with new contents and update its created time.

    Creates the containing directories if needed.
    """
    ensure_directory(os.path.dirname(self.get_path()))
    write_string_to_file(new_content, self.get_path())
    self.created = time.time()

</t>
<t tx="ekr.20081202141453.172">def exists(self):
    return os.path.isfile(self.get_path())

</t>
<t tx="ekr.20081202141453.173">class Module(Localizable, TestSuite):
    allowed_test_case_classes = [TestClass]

    @others
</t>
<t tx="ekr.20081202141453.174">def __init__(self, project, subpath, code=None, objects=None, imports=None,
             main_snippet=None, errors=[]):
    if objects is None:
        objects = []
    test_cases = get_test_objects(objects)

    Localizable.__init__(self, project, subpath)
    TestSuite.__init__(self, self.locator, code, None, test_cases, imports)

    self.objects = objects
    self.main_snippet = main_snippet
    self.errors = errors

    # Code of test cases passed to the constructor is already contained
    # within the module code.
    self.add_test_cases(test_cases, False)

</t>
<t tx="ekr.20081202141453.175">def _get_testable_objects(self):
    return [o for o in self.objects if o.is_testable()]
</t>
<t tx="ekr.20081202141453.176">testable_objects = property(_get_testable_objects)

def _get_classes(self):
    return all_of_type(self.objects, Class)
</t>
<t tx="ekr.20081202141453.177">classes = property(_get_classes)

def _get_functions(self):
    return all_of_type(self.objects, Function)
</t>
<t tx="ekr.20081202141453.178">functions = property(_get_functions)

def _get_test_classes(self):
    return all_of_type(self.objects, TestClass)
</t>
<t tx="ekr.20081202141453.179">test_classes = property(_get_test_classes)

def add_test_case(self, test_case, append_code=True):
    TestSuite.add_test_case(self, test_case, append_code)

    self.ensure_imports(test_case.imports)
    self._ensure_main_snippet(test_case.main_snippet)

</t>
<t tx="ekr.20081202141453.180"># def replace_test_case:
#   Using the default definition. We don't remove imports or main_snippet,
#   because we may unintentionally break something.

def get_content(self):
    return regenerate(self.code)

</t>
<t tx="ekr.20081202141453.181">def get_test_cases_for_module(self, module):
    """Return all test cases that are associated with given module.
    """
    return [tc for tc in self.test_cases if module in tc.associated_modules]

</t>
<t tx="ekr.20081202141453.182">def _ensure_main_snippet(self, main_snippet, force=False):
    """Make sure the main_snippet is present. Won't overwrite the snippet
    unless force flag is set.
    """
    if not main_snippet:
        return

    if not self.main_snippet:
        self.main_snippet = main_snippet
        self.code.append_child(main_snippet)
        self.mark_as_changed()
    elif force:
        self.main_snippet.replace(main_snippet)
        self.main_snippet = main_snippet
        self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.183">def _ensure_import(self, import_desc):
    # Add an extra newline separating imports from the code.
    if not self.imports:
        self.code.insert_child(0, Newline())
        self.mark_as_changed()
    if not self._contains_import(import_desc):
        self._add_import(import_desc)

</t>
<t tx="ekr.20081202141453.184">def _add_import(self, import_desc):
    self.imports.append(import_desc)
    self.code.insert_child(0, create_import(import_desc))
    self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.185">def _append_test_case_code(self, code):
    # If the main_snippet exists we have to put the new test case
    # before it. If it doesn't we put the test case at the end.
    if self.main_snippet:
        self._insert_before_main_snippet(code)
    else:
        self.code.append_child(code)
    self.mark_as_changed()

</t>
<t tx="ekr.20081202141453.186">def _insert_before_main_snippet(self, code):
    for i, child in enumerate(self.code.children):
        if child == self.main_snippet:
            self.code.insert_child(i, code)
            break

</t>
<t tx="ekr.20081202141453.187">def save(self):
    # Don't save the test file unless it has been changed.
    if self.changed:
        if self.is_out_of_sync():
            raise ModuleNeedsAnalysis(self.subpath, out_of_sync=True)
        try:
            self.write(self.get_content())
        except DirectoryException, err:
            raise ModuleSaveError(self.subpath, err.message)
        self.changed = False

</t>
<t tx="ekr.20081202141453.188">class PointOfEntry(Localizable):
    """Piece of code provided by the user that allows dynamic analysis.

    In add_method_call/add_function_call if we can't find a class or function
    in Project, we don't care about it. This way we don't record any information
    about thid-party and dynamically created code.
    """
    @others
</t>
<t tx="ekr.20081202141453.189">def __init__(self, project, name):
    poes_subpath = project._extract_subpath(project._get_points_of_entry_path())
    # Points of entry start with created attribute equal to 0, as they are
    # not up-to-date until they're run. See finalize_inspection().
    Localizable.__init__(self, project, os.path.join(poes_subpath, name), created=0)

    self.name = name
    # After an inspection run, this will be a reference to the top level call.
    self.call_graph = None

    self._preserved_objects = []
    self._gobjects = []

</t>
<t tx="ekr.20081202141453.190">def get_path(self):
    return os.path.join(self.project._get_points_of_entry_path(), self.name)

</t>
<t tx="ekr.20081202141453.191">def get_content(self):
    return read_file_contents(self.get_path())

</t>
<t tx="ekr.20081202141453.192">def clear_previous_run(self):
    for klass in self.project.iter_classes():
        klass.remove_live_objects_from(self)
    for function in self.project.iter_functions():
        function.remove_calls_from(self)
    self.call_graph = None

</t>
<t tx="ekr.20081202141453.193">def create_method_call(self, name, classname, modulepath, object, input, code, frame):
    try:
        live_object, method = self._retrieve_live_object_for_method(object, name, classname, modulepath)
        if is_generator_code(code):
            call = self._retrieve_generator_object(live_object, method, input, code, frame)
        else:
            call = MethodCall(method, serialize_call_arguments(input))
        live_object.add_call(call)
        return call
    except LookupError:
        pass

</t>
<t tx="ekr.20081202141453.194">def create_function_call(self, name, modulepath, input, code, frame):
    function = self.project.find_object(Function, name, modulepath)
    if function:
        if is_generator_code(code):
            return self._retrieve_generator_object(function, function, input, code, frame)
        else:
            call = FunctionCall(self, function, serialize_call_arguments(input))
            function.add_call(call)
            return call

</t>
<t tx="ekr.20081202141453.195">def finalize_inspection(self):
    # We can release preserved objects now.
    self._preserved_objects = []
    # Mark the point of entry as up-to-date.
    self.created = time.time()
    # Fix output of generator objects.
    self._fix_generator_objects()

</t>
<t tx="ekr.20081202141453.196">def _retrieve_live_object_for_method(self, object, name, classname, modulepath):
    klass = self.project.find_object(Class, classname, modulepath)
    if not klass:
        raise LookupError("Couldn't find class %s in %s." %\
                              (classname, modulepath))

    method = klass.find_method_by_name(name)
    if not method:
        raise LookupError("Couldn't find method %s in %s:%s." %\
                              (name, modulepath, classname))

    live_object = self._retrieve_live_object(object, klass)

    return live_object, method

</t>
<t tx="ekr.20081202141453.197">def _retrieve_generator_object(self, callable, generator, input, code, frame):
    gobject = callable.get_generator_object((self.name, id(code)))

    if not gobject:
        gobject = GeneratorObject(id(code), generator, self, serialize_call_arguments(input))
        callable.add_call(gobject)
        self._gobjects.append(gobject)
        self._preserve(code)

        # Generator objects return None to the tracer when stopped. That
        # extra None we have to filter out manually (see
        # _fix_generator_objects method). The only way to distinguish
        # between active and stopped generators is to ask garbage collector
        # about them. So we temporarily save the generator frame inside the
        # GeneratorObject, so it can be inspected later.
        gobject._frame = frame

    return gobject

</t>
<t tx="ekr.20081202141453.198">def _retrieve_live_object(self, object, klass):
    try:
        live_object = klass.live_objects[(self.name, id(object))]
    except KeyError:
        live_object = LiveObject(id(object), klass, self)
        klass.add_live_object(live_object)
        self._preserve(object)
    return live_object

</t>
<t tx="ekr.20081202141453.199">def _preserve(self, object):
    """Preserve an object from garbage collection, so its id won't get
    occupied by any other object.
    """
    self._preserved_objects.append(object)

</t>
<t tx="ekr.20081202141453.200">def _fix_generator_objects(self):
    """Remove last yielded values of generator objects, as those are
    just bogus Nones placed on generator stop.
    """
    for gobject in self._gobjects:
        if not contains_active_generator(gobject._frame) \
               and gobject.output \
               and gobject.output[-1] == serialize(None):
            gobject.output.pop()
        # Once we know if the generator is active or not, we can discard
        # the frame.
        del gobject._frame

    self._gobjects = []
</t>
<t tx="ekr.20081202141453.201">import gc
import os
import re
import types
import warnings

# Portability code.
try:
    set = set
except NameError:
    from sets import Set as set

try:
    frozenset = frozenset
except NameError:
    from sets import ImmutableSet as frozenset

try:
    sorted = sorted
except NameError:
    def sorted(iterable, cmp=cmp, key=None):
        if key:
            cmp = lambda x,y: cmp(key(x), key(y))
        alist = list(iterable)
        alist.sort(cmp)
        return alist

try:
    all = all
except NameError:
    def all(iterable):
        for element in iterable:
            if not element:
                return False
        return True

try:
    from itertools import groupby
except ImportError:
    # Code taken from http://docs.python.org/lib/itertools-functions.html .
    class groupby(object):
        def __init__(self, iterable, key=None):
            if key is None:
                key = lambda x: x
            self.keyfunc = key
            self.it = iter(iterable)
            self.tgtkey = self.currkey = self.currvalue = xrange(0)
        def __iter__(self):
            return self
        def next(self):
            while self.currkey == self.tgtkey:
                self.currvalue = self.it.next() # Exit on StopIteration
                self.currkey = self.keyfunc(self.currvalue)
            self.tgtkey = self.currkey
            return (self.currkey, self._grouper(self.tgtkey))
        def _grouper(self, tgtkey):
            while self.currkey == tgtkey:
                yield self.currvalue
                self.currvalue = self.it.next() # Exit on StopIteration
                self.currkey = self.keyfunc(self.currvalue)

try:
    from os.path import samefile
except ImportError:
    def samefile(file1, file2):
        return os.path.realpath(file1) == os.path.realpath(file2)

</t>
<t tx="ekr.20081202141453.202">def camelize(name):
    """Covert name into CamelCase.

    &gt;&gt;&gt; camelize('underscore_name')
    'UnderscoreName'
    &gt;&gt;&gt; camelize('AlreadyCamelCase')
    'AlreadyCamelCase'
    &gt;&gt;&gt; camelize('')
    ''
    """
    def upcase(match):
        return match.group(1).upper()
    return re.sub(r'(?:^|_)(.)', upcase, name)


</t>
<t tx="ekr.20081202141453.203">def underscore(name):
    """Convert name into underscore_name.

    &gt;&gt;&gt; underscore('CamelCase')
    'camel_case'
    &gt;&gt;&gt; underscore('already_underscore_name')
    'already_underscore_name'
    &gt;&gt;&gt; underscore('BigHTMLClass')
    'big_html_class'
    &gt;&gt;&gt; underscore('')
    ''
    """
    if name and name[0].isupper():
        name = name[0].lower() + name[1:]

    def capitalize(match):
        string = match.group(1).capitalize()
        return string[:-1] + string[-1].upper()

    def underscore(match):
        return '_' + match.group(1).lower()

    name = re.sub(r'([A-Z]+)', capitalize, name)
    return re.sub(r'([A-Z])', underscore, name)

</t>
<t tx="ekr.20081202141453.204">def read_file_contents(filename):
    fd = file(filename)
    contents = fd.read()
    fd.close()
    return contents

</t>
<t tx="ekr.20081202141453.205">def write_string_to_file(string, filename):
    fd = file(filename, 'w')
    fd.write(string)
    fd.close()

</t>
<t tx="ekr.20081202141453.206">def all_of_type(objects, type):
    """Return all objects that are instances of a given type.
    """
    return [o for o in objects if isinstance(o, type)]

</t>
<t tx="ekr.20081202141453.207">def max_by_not_zero(func, collection):
    """Return the element of a collection for which func returns the highest
    value, greater than 0.

    Return None if there is no such value.

    &gt;&gt;&gt; max_by_not_zero(len, ["abc", "d", "ef"])
    'abc'
    &gt;&gt;&gt; max_by_not_zero(lambda x: x, [0, 0, 0, 0]) is None
    True
    &gt;&gt;&gt; max_by_not_zero(None, []) is None
    True
    """
    if not collection:
        return None

    def annotate(element):
        return (func(element), element)

    highest = max(map(annotate, collection))
    if highest and highest[0] &gt; 0:
        return highest[1]
    else:
        return None

</t>
<t tx="ekr.20081202141453.208">def python_modules_below(path):
    def is_python_module(path):
        return path.endswith(".py")
    return filter(is_python_module, rlistdir(path))

</t>
<t tx="ekr.20081202141453.209">def rlistdir(path):
    """Resursive directory listing. Yield all files below given path,
    ignoring those which names begin with a dot.
    """
    if os.path.basename(path).startswith('.'):
        return

    if os.path.isdir(path):
        for entry in os.listdir(path):
            for subpath in rlistdir(os.path.join(path, entry)):
                yield subpath
    else:
        yield path

</t>
<t tx="ekr.20081202141453.210">def get_names(objects):
    return map(lambda c: c.name, objects)

</t>
<t tx="ekr.20081202141453.211">class DirectoryException(Exception):
    pass

</t>
<t tx="ekr.20081202141453.212">def ensure_directory(directory):
    """Make sure given directory exists, creating it if necessary.
    """
    if os.path.exists(directory):
        if not os.path.isdir(directory):
            raise DirectoryException("Destination is not a directory.")
    else:
        os.makedirs(directory)

</t>
<t tx="ekr.20081202141453.213">def get_last_modification_time(path):
    try:
        # Casting to int, because we don't need better resolution anyway and it
        # eases testing on different OSes.
        return int(os.path.getmtime(path))
    except OSError:
        # File may not exist, in which case it was never modified.
        return 0

</t>
<t tx="ekr.20081202141453.214">def extract_subpath(path, prefix):
    """Remove prefix from given path to generate subpath, so the following
    correspondence is preserved:

      path &lt;=&gt; os.path.join(prefix, subpath)

    in terms of physical path (i.e. not necessarily strict string
    equality).
    """
    prefix_length = len(prefix)
    if not prefix.endswith(os.path.sep):
        prefix_length += 1
    return os.path.realpath(path)[prefix_length:]

</t>
<t tx="ekr.20081202141453.215">def directories_under(path):
    """Return names of directories under given path (not recursive).
    """
    for entry in os.listdir(path):
        if os.path.isdir(os.path.join(path, entry)):
            yield entry

</t>
<t tx="ekr.20081202141453.216">def findfirst(pred, seq):
    """Return the first element of given sequence that matches predicate.
    """
    for item in seq:
        if pred(item):
            return item

</t>
<t tx="ekr.20081202141453.217">def contains_active_generator(frame):
    return bool(all_of_type(gc.get_referrers(frame), types.GeneratorType))

</t>
<t tx="ekr.20081202141453.218">def is_generator_code(code):
    return code.co_flags &amp; 0x20 != 0

</t>
<t tx="ekr.20081202141453.219">def compile_without_warnings(stmt):
    """Compile single interactive statement with Python interpreter warnings
    disabled.
    """
    warnings.simplefilter('ignore')
    code = compile(stmt, '', 'single')
    warnings.resetwarnings()
    return code

</t>
<t tx="ekr.20081202141453.220">def quoted_block(text):
    return ''.join(["&gt; %s" % line for line in text.splitlines(True)])

</t>
<t tx="ekr.20081202141453.221">def cname(obj):
    """Return name of this object's class."""
    return obj.__class__.__name__

</t>
<t tx="ekr.20081202141453.222">def module_path_to_name(module_path, newsep="_"):
    return re.sub(r'(%s__init__)?\.py$' % re.escape(os.path.sep), '', module_path).\
        replace(os.path.sep, newsep)

</t>
<t tx="ekr.20081202141453.223"># Regular expressions helpers.

RePatternType = type(re.compile(''))

def regexp_flags_as_string(flags):
    """Return an expression in string form that corresponds to given set of
    regexp flags.
    """
    strings = []
    if flags &amp; re.IGNORECASE:
        strings.append('re.IGNORECASE')
    if flags &amp; re.LOCALE:
        strings.append('re.LOCALE')
    if flags &amp; re.MULTILINE:
        strings.append('re.MULTILINE')
    if flags &amp; re.DOTALL:
        strings.append('re.DOTALL')
    if flags &amp; re.VERBOSE:
        strings.append('re.VERBOSE')
    if flags &amp; re.UNICODE:
        strings.append('re.UNICODE')
    return " | ".join(strings)
</t>
<t tx="ekr.20081202141453.224">import getopt
import os
import sys

import logger

from inspector import inspect_project
from generator import add_tests_to_project, UnknownTemplate
from logger import log
from store import Project, ModuleNotFound, ModuleNeedsAnalysis, \
     ModuleSaveError, get_pythoscope_path, get_points_of_entry_path
from util import samefile


__version__ = '0.3.2'

BUGTRACKER_URL = "https://bugs.launchpad.net/pythoscope"
USAGE = """Pythoscope usage:

    %s [options] [module names...]

By default, this command generates test suites for the listed modules.
It will automatically check for any source code changes and rerun all
points of entry if necessary.

As a module name, you can use both direct path or a locator in dot-style
notation. For example, both of the following are acceptable:

  package/sub/module.py
  package.sub.module

All test files will be written to a single directory.

Options:
  -f, --force    Go ahead and overwrite any existing test files. Default
                 is to skip generation of tests for files that would
                 otherwise get overwriten.
  -h, --help     Show this help message and exit.
  -i. --init     This option will initialize given project directory for
                 further Pythoscope usage. This is required for each new
                 project.
                 Initialization creates .pythoscope/ directory in the
                 project directory, which will store all information
                 related to test generation.
                 It will also perform a static (thus perfectly safe)
                 inspection of the project source code.
                 You may provide an argument after this option, which
                 should be a path pointing to a directory of a project
                 you want to initialize. If you don't provide one,
                 current directory will be used.
  -t TEMPLATE_NAME, --template=TEMPLATE_NAME
                 Name of a template to use (see below for a list of
                 available templates). Default is "unittest".
  -q, --quiet    Don't print anything unless it's an error.
  -v, --verbose  Be very verbose (basically enable debug output).
  -V, --version  Print Pythoscope version and exit.

Available templates:
  * unittest     All tests are placed into classes which derive from
                 unittest.TestCase. Each test module ends with an
                 import-safe call to unittest.main().
  * nose         Nose-style tests, which don't import unittest and use
                 SkipTest as a default test body.
"""

</t>
<t tx="ekr.20081202141453.225">class PythoscopeDirectoryMissing(Exception):
    pass

</t>
<t tx="ekr.20081202141453.226">def find_project_directory(path):
    """Try to find a pythoscope project directory for a given path,
    i.e. the closest directory that contains .pythoscope/ subdirectory.

    Will go up the directory tree and return the first matching path.
    """
    path = os.path.realpath(path)

    if not os.path.isdir(path):
        return find_project_directory(os.path.dirname(path))

    pythoscope_path = get_pythoscope_path(path)
    parent_path = os.path.join(path, os.path.pardir)

    # We reached the root.
    if samefile(path, parent_path):
        raise PythoscopeDirectoryMissing()
    elif os.path.isdir(pythoscope_path):
        return path
    else:
        return find_project_directory(os.path.join(path, os.path.pardir))

</t>
<t tx="ekr.20081202141453.227">def init_project(path):
    pythoscope_path = get_pythoscope_path(path)

    try:
        log.debug("Initializing .pythoscope directory: %s" % (os.path.abspath(pythoscope_path)))
        os.makedirs(pythoscope_path)
        os.makedirs(get_points_of_entry_path(path))
    except OSError, err:
        log.error("Couldn't initialize Pythoscope directory: %s." % err.strerror)

</t>
<t tx="ekr.20081202141453.228">def generate_tests(modules, force, template):
    try:
        project = Project.from_directory(find_project_directory(modules[0]))
        inspect_project(project)
        add_tests_to_project(project, modules, template, force)
        project.save()
    except PythoscopeDirectoryMissing:
        log.error("Can't find .pythoscope/ directory for this project. "
                  "Initialize the project with the '--init' option first.")
    except ModuleNeedsAnalysis, err:
        if err.out_of_sync:
            log.error("Tried to generate tests for test module located at %r, "
                      "but it has been modified during this run. Please try "
                      "running pythoscope again." % err.path)
        else:
            log.error("Tried to generate tests for test module located at %r, "
                      "but it was created during this run. Please try running "
                      "pythoscope again." % err.path)
    except ModuleNotFound, err:
        if os.path.exists(err.module):
            log.error("Couldn't find information on module %r. This shouldn't "
                      "happen, please file a bug report at %s." % (err.module, BUGTRACKER_URL))
        else:
            log.error("File doesn't exist: %s." % err.module)
    except ModuleSaveError, err:
        log.error("Couldn't save module %r: %s." % (err.module, err.reason))
    except UnknownTemplate, err:
        log.error("Couldn't find template named %r. Available templates are "
                  "'nose' and 'unittest'." % err.template)

</t>
<t tx="ekr.20081202141453.229">def main():
    appname = os.path.basename(sys.argv[0])

    try:
        options, args = getopt.getopt(sys.argv[1:], "fhit:qvV",
                        ["force", "help", "init", "template=", "quiet", "verbose", "version"])
    except getopt.GetoptError, err:
        log.error("Error: %s\n" % err)
        print USAGE % appname
        sys.exit(1)

    force = False
    init = False
    template = "unittest"

    for opt, value in options:
        if opt in ("-f", "--force"):
            force = True
        elif opt in ("-h", "--help"):
            print USAGE % appname
            sys.exit()
        elif opt in ("-i", "--init"):
            init = True
        elif opt in ("-t", "--template"):
            template = value
        elif opt in ("-q", "--quiet"):
            log.level = logger.ERROR
        elif opt in ("-v", "--verbose"):
            log.level = logger.DEBUG
        elif opt in ("-V", "--version"):
            print "%s %s" % (appname, __version__)
            sys.exit()

    try:
        if init:
            if args:
                project_path = args[0]
            else:
                project_path = "."
            init_project(project_path)
        else:
            if not args:
                log.error("You didn't specify any modules for test generation.\n")
                print USAGE % appname
            else:
                generate_tests(args, force, template)
    except:
        log.error("Oops, it seems internal Pythoscope error occured. Please file a bug report at %s\n" % BUGTRACKER_URL)
        raise
</t>
<t tx="ekr.20081202141453.230">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202141453.231">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202142943.1">"""Module responsible for adding generated test cases to a project.

Client of this module should use it through add_test_case_to_project() function.
"""

import os.path

from pythoscope.logger import log
from pythoscope.util import max_by_not_zero, module_path_to_name


</t>
<t tx="ekr.20081202142943.2">def add_test_case_to_project(project, test_class, force=False):
    existing_test_class = find_test_class_by_name(project, test_class.name)
    if not existing_test_class:
        place = find_place_for_test_class(project, test_class)
        log.info("Adding generated %s to %s." % (test_class.name, place.subpath))
        place.add_test_case(test_class)
    else:
        merge_test_classes(existing_test_class, test_class, force)

</t>
<t tx="ekr.20081202142943.3">def find_test_class_by_name(project, name):
    for tcase in project.iter_test_cases():
        if tcase.name == name:
            return tcase

</t>
<t tx="ekr.20081202142943.4">def merge_test_classes(test_class, other_test_class, force):
    """Merge other_test_case into test_case.
    """
    for method in other_test_class.test_cases:
        existing_test_method = test_class.find_method_by_name(method.name)
        if not existing_test_method:
            log.info("Adding generated %s to %s in %s." % \
                         (method.name, test_class.name, test_class.parent.subpath))
            test_class.add_test_case(method)
        elif force:
            log.info("Replacing %s.%s from %s with generated version." % \
                         (test_class.name, existing_test_method.name, test_class.parent.subpath))
            test_class.replace_test_case(existing_test_method, method)
        else:
            log.info("Test case %s.%s already exists in %s, skipping." % \
                         (test_class.name, existing_test_method.name, test_class.parent.subpath))
    test_class.ensure_imports(other_test_class.imports)

</t>
<t tx="ekr.20081202142943.5">def find_place_for_test_class(project, test_class):
    """Find the best place for the new test case to be added. If there is
    no such place in existing test modules, a new one will be created.
    """
    return find_test_module(project, test_class) or \
        create_test_module(project, test_class)

</t>
<t tx="ekr.20081202142943.6">def find_test_module(project, test_class):
    """Find test module that will be good for the given test case.
    """
    for module in test_class.associated_modules:
        test_module = find_associate_test_module_by_name(project, module) or \
                      find_associate_test_module_by_test_classs(project, module)
        if test_module:
            return test_module

</t>
<t tx="ekr.20081202142943.7">def find_associate_test_module_by_name(project, module):
    """Try to find a test module with name corresponding to the name of
    the application module.
    """
    possible_paths = possible_test_module_paths(module, project.new_tests_directory)
    for module in project.get_modules():
        if module.subpath in possible_paths:
            return module

</t>
<t tx="ekr.20081202142943.8">def find_associate_test_module_by_test_classs(project, module):
    """Try to find a test module with most test cases for the given
    application module.
    """
    def test_classs_number(mod):
        return len(mod.get_test_cases_for_module(module))
    test_module = max_by_not_zero(test_classs_number, project.get_modules())
    if test_module:
        return test_module

</t>
<t tx="ekr.20081202142943.9">def test_module_name_for_test_case(test_case):
    """Come up with a name for a test module which will contain given test case.
    """
    # Assuming the test case has at least one associated module, which indeed
    # is a case in current implementation of generator.
    return module_path_to_test_path(test_case.associated_modules[0].subpath)

</t>
<t tx="ekr.20081202142943.10">def create_test_module(project, test_case):
    """Create a new test module for a given test case.
    """
    test_name = test_module_name_for_test_case(test_case)
    return project.create_test_module_from_name(test_name)

</t>
<t tx="ekr.20081202142943.11">def module_path_to_test_path(module):
    """Convert a module locator to a proper test filename.
    """
    return "test_%s.py" % module_path_to_name(module)

</t>
<t tx="ekr.20081202142943.12">def possible_test_module_names(module):
    module_name = module_path_to_name(module.subpath)

    for name in ["test_%s", "%s_test", "%sTest", "tests_%s", "%s_tests", "%sTests"]:
        yield (name % module_name) + ".py"
    for name in ["test%s", "Test%s", "%sTest", "tests%s", "Tests%s", "%sTests"]:
        yield (name % module_name.capitalize()) + ".py"

</t>
<t tx="ekr.20081202142943.13">def possible_test_module_paths(module, new_tests_directory):
    """Return possible locations of a test module corresponding to given
    application module.
    """
    test_directories = ["", "test", "tests"]
    if new_tests_directory not in test_directories:
        test_directories.append(new_tests_directory)
    def generate():
        for name in possible_test_module_names(module):
            for test_directory in test_directories:
                yield os.path.join(test_directory, name)
    return list(generate())
</t>
<t tx="ekr.20081202142943.14">import exceptions

from pythoscope.astvisitor import descend, parse_fragment, ASTVisitor, \
    EmptyCode
from pythoscope.logger import log
from pythoscope.generator.adder import add_test_case_to_project
from pythoscope.serializer import SerializedObject, can_be_constructed, \
    serialize, serialize_call_arguments
from pythoscope.store import Class, Function, TestClass, TestMethod, ModuleNotFound, \
    LiveObject, MethodCall, Method, Project, PointOfEntry, GeneratorObject
from pythoscope.util import camelize, underscore, sorted, groupby, set


</t>
<t tx="ekr.20081202142943.15"># :: [string] -&gt; string
def list_of(strings):
    return "[%s]" % ', '.join(strings)

</t>
<t tx="ekr.20081202142943.16"># :: SerializedObject | [SerializedObject] -&gt; string
def type_as_string(object):
    """Return a most common representation of the wrapped object type.

    &gt;&gt;&gt; type_as_string([serialize(()), serialize({})])
    '[tuple, dict]'
    """
    if isinstance(object, list):
        return list_of(map(type_as_string, object))

    return object.type_name

</t>
<t tx="ekr.20081202142943.17">class CallString(str):
    """A string that holds information on the function/method call it
    represents.

    `uncomplete` attribute denotes whether it is a complete call
    or just a template.

    `imports` is a list of imports that this call requires.
    """
    @others
</t>
<t tx="ekr.20081202142943.18">def __new__(cls, string, uncomplete=False, imports=None):
    if imports is None:
        imports = set()
    call_string = str.__new__(cls, string)
    call_string.uncomplete = uncomplete
    call_string.imports = imports
    return call_string

</t>
<t tx="ekr.20081202142943.19">def extend(self, value, uncomplete=False, imports=set()):
    return CallString(value, self.uncomplete or uncomplete,
                      self.imports.union(imports))

</t>
<t tx="ekr.20081202142943.20"># :: SerializedObject | LiveObject | list -&gt; CallString
def constructor_as_string(object):
    """For a given object (either SerializedObject, a LiveObject instance or list
    of any combination of those) return a string representing a code that will
    construct it.

    &gt;&gt;&gt; constructor_as_string(serialize(123))
    '123'
    &gt;&gt;&gt; constructor_as_string(serialize('string'))
    "'string'"
    &gt;&gt;&gt; constructor_as_string([serialize(1), serialize('two')])
    "[1, 'two']"
    &gt;&gt;&gt; obj = LiveObject(None, Class('SomeClass'), PointOfEntry(Project('.'), 'poe'))
    &gt;&gt;&gt; constructor_as_string(obj)
    'SomeClass()'
    &gt;&gt;&gt; obj.add_call(MethodCall(Method('__init__'), serialize_call_arguments({'arg': 'whatever'}), None))
    &gt;&gt;&gt; constructor_as_string(obj)
    "SomeClass(arg='whatever')"
    """
    if isinstance(object, LiveObject):
        args = {}
        # Look for __init__ call and base the constructor on that.
        init_call = object.get_init_call()
        if init_call:
            args = init_call.input
        return call_as_string(object.klass.name, args)
    elif isinstance(object, list):
        return list_of(map(constructor_as_string, object))
    elif isinstance(object, SerializedObject):
        try:
            reconstructor, imports = object.reconstructor_with_imports
            return CallString(reconstructor, imports=imports)
        except TypeError:
            return CallString("&lt;TODO: %s&gt;" % object.partial_reconstructor, uncomplete=True)
    else:
        raise TypeError("constructor_as_string expected SerializedObject or LiveObject object at input, not %s" % object)

</t>
<t tx="ekr.20081202142943.21"># :: (string, dict) -&gt; CallString
def call_as_string(object_name, input):
    """Generate code for calling an object with given input.

    &gt;&gt;&gt; call_as_string('fun', serialize_call_arguments({'a': 1, 'b': 2}))
    'fun(a=1, b=2)'
    &gt;&gt;&gt; call_as_string('capitalize', serialize_call_arguments({'str': 'string'}))
    "capitalize(str='string')"

    &gt;&gt;&gt; result = call_as_string('call', serialize_call_arguments({'f': call_as_string}))
    &gt;&gt;&gt; result
    'call(f=call_as_string)'
    &gt;&gt;&gt; result.uncomplete
    False

    &gt;&gt;&gt; result = call_as_string('map', serialize_call_arguments({'f': lambda x: 42, 'L': [1,2,3]}))
    &gt;&gt;&gt; result
    'map(L=[1, 2, 3], f=&lt;TODO: function&gt;)'
    &gt;&gt;&gt; result.uncomplete
    True
    """
    arguments = []
    uncomplete = False
    imports = set()
    for arg, value in input.iteritems():
        constructor = constructor_as_string(value)
        uncomplete = uncomplete or constructor.uncomplete
        imports.update(constructor.imports)
        arguments.append("%s=%s" % (arg, constructor))
    return CallString("%s(%s)" % (object_name, ', '.join(arguments)),
                      uncomplete=uncomplete, imports=imports)

</t>
<t tx="ekr.20081202142943.22"># :: SerializedObject -&gt; string
def object2id(object):
    """Convert object to string that can be used as an identifier.
    """
    if not isinstance(object, SerializedObject):
        raise TypeError("object2id() should be called with a SerializedObject argument, not %s" % object)
    return object.human_readable_id

</t>
<t tx="ekr.20081202142943.23">def objects_list_to_id(objects):
    """Convert given list of objects into string that can be used as an
    identifier.
    """
    if not objects:
        return 'nothing'
    return '_then_'.join(map(object2id, objects))

</t>
<t tx="ekr.20081202142943.24">def input_as_string(input):
    """Generate an underscored description of given input arguments.

    &gt;&gt;&gt; input_as_string({})
    ''
    &gt;&gt;&gt; input_as_string(serialize_call_arguments({'x': 7, 'y': 13}))
    'x_equal_7_and_y_equal_13'
    """
    if len(input) == 1:
        return object2id(input.values()[0])
    return "_and_".join(["%s_equal_%s" % (arg, object2id(value))
                         for arg, value in sorted(input.iteritems())])

</t>
<t tx="ekr.20081202142943.25">def objcall2testname(object_name, input, output):
    """Generate a test method name that describes given object call.

    &gt;&gt;&gt; objcall2testname('do_this', {}, serialize(True))
    'test_do_this_returns_true'
    &gt;&gt;&gt; objcall2testname('compute', {}, serialize('whatever you say'))
    'test_compute_returns_whatever_you_say'
    &gt;&gt;&gt; objcall2testname('square', serialize_call_arguments({'x': 7}), serialize(49))
    'test_square_returns_49_for_7'
    &gt;&gt;&gt; objcall2testname('capitalize', serialize_call_arguments({'str': 'a word.'}), serialize('A word.'))
    'test_capitalize_returns_A_word_for_a_word'

    Two or more arguments are mentioned by name.
        &gt;&gt;&gt; objcall2testname('ackermann', serialize_call_arguments({'m': 3, 'n': 2}), serialize(29))
        'test_ackermann_returns_29_for_m_equal_3_and_n_equal_2'

    Will sort arguments alphabetically.
        &gt;&gt;&gt; objcall2testname('concat', serialize_call_arguments({'s1': 'Hello ', 's2': 'world!'}), serialize('Hello world!'))
        'test_concat_returns_Hello_world_for_s1_equal_Hello_and_s2_equal_world'

    Always starts and ends a word with a letter or number.
        &gt;&gt;&gt; objcall2testname('strip', serialize_call_arguments({'n': 1, 's': '  A bit of whitespace  '}), serialize(' A bit of whitespace '))
        'test_strip_returns_A_bit_of_whitespace_for_n_equal_1_and_s_equal_A_bit_of_whitespace'
    """
    if input:
        call_description = "%s_for_%s" % (object2id(output), input_as_string(input))
    else:
        call_description = object2id(output)
    return "test_%s_returns_%s" % (underscore(object_name), call_description)

</t>
<t tx="ekr.20081202142943.26">def exccall2testname(object_name, input, exception):
    """Generate a test method name that describes given object call raising
    an exception.

    &gt;&gt;&gt; exccall2testname('do_this', {}, serialize(Exception()))
    'test_do_this_raises_exception'
    &gt;&gt;&gt; exccall2testname('square', serialize_call_arguments({'x': 'a string'}), serialize(TypeError()))
    'test_square_raises_type_error_for_a_string'
    """
    if input:
        call_description = "%s_for_%s" % (object2id(exception), input_as_string(input))
    else:
        call_description = object2id(exception)
    return "test_%s_raises_%s" % (underscore(object_name), call_description)

</t>
<t tx="ekr.20081202142943.27">def gencall2testname(object_name, input, yields):
    """Generate a test method name that describes given generator object call
    yielding some values.

    &gt;&gt;&gt; gencall2testname('generate', {}, [])
    'test_generate_yields_nothing'
    &gt;&gt;&gt; gencall2testname('generate', {}, [serialize(1), serialize(2), serialize(3)])
    'test_generate_yields_1_then_2_then_3'
    &gt;&gt;&gt; gencall2testname('backwards', serialize_call_arguments({'x': 321}), [serialize('one'), serialize('two'), serialize('three')])
    'test_backwards_yields_one_then_two_then_three_for_321'
    """
    if input:
        call_description = "%s_for_%s" % (objects_list_to_id(yields), input_as_string(input))
    else:
        call_description = objects_list_to_id(yields)
    return "test_%s_yields_%s" % (underscore(object_name), call_description)

</t>
<t tx="ekr.20081202142943.28">def call2testname(call, object_name):
    # Note: order is significant. We may have a GeneratorObject that raised
    # an exception, and we care about exceptions more.
    if call.raised_exception():
        return exccall2testname(object_name, call.input, call.exception)
    elif isinstance(call, GeneratorObject):
        return gencall2testname(object_name, call.input, call.output)
    else:
        return objcall2testname(object_name, call.input, call.output)

</t>
<t tx="ekr.20081202142943.29">def sorted_test_method_descriptions(descriptions):
    return sorted(descriptions, key=lambda md: md.name)

</t>
<t tx="ekr.20081202142943.30">def name2testname(name):
    if name[0].isupper():
        return "Test%s" % name
    return "test_%s" % name

</t>
<t tx="ekr.20081202142943.31">def in_lambda(string):
    return "lambda: %s" % string

</t>
<t tx="ekr.20081202142943.32">def in_list(string):
    return "list(%s)" % string

</t>
<t tx="ekr.20081202142943.33">def type_of(string):
    return "type(%s)" % string

</t>
<t tx="ekr.20081202142943.34">def map_types(string):
    return "map(type, %s)" % string

</t>
<t tx="ekr.20081202142943.35"># :: (Call, CallString) -&gt; CallString
def decorate_call(call, string):
    if isinstance(call, GeneratorObject):
        invocations = len(call.output)
        if call.raised_exception():
            invocations += 1
        # TODO: generators were added to Python 2.2, while itertools appeared in
        # release  2.3, so we may generate incompatible tests here.
        return string.extend("list(islice(%s, %d))" % (string, invocations),
                             imports=[("itertools", "islice")])
    return string

</t>
<t tx="ekr.20081202142943.36">def should_ignore_method(method):
    return method.name.startswith('_') and method.name != "__init__"

</t>
<t tx="ekr.20081202142943.37">def testable_calls(calls):
    return [c for c in calls if c.is_testable()]

</t>
<t tx="ekr.20081202142943.38">def is_builtin_exception(exception):
    return exception in dir(exceptions)

</t>
<t tx="ekr.20081202142943.39">class UnknownTemplate(Exception):
    @others
</t>
<t tx="ekr.20081202142943.40">def __init__(self, template):
    Exception.__init__(self, "Couldn't find template %r." % template)
    self.template = template

</t>
<t tx="ekr.20081202142943.41">def find_method_code(code, method_name):
    """Return part of the code tree that corresponds to the given method
    definition.
    """
    class LocalizeMethodVisitor(ASTVisitor):
        def __init__(self):
            ASTVisitor.__init__(self)
            self.method_body = None
        def visit_function(self, name, args, body):
            if name == method_name:
                self.method_body = body

    return descend(code.children, LocalizeMethodVisitor).method_body

</t>
<t tx="ekr.20081202142943.42">class TestMethodDescription(object):
    @others
</t>
<t tx="ekr.20081202142943.43"># Assertions should be tuples (type, attributes...), where type is a string
# denoting a type of an assertion, e.g. 'equal' is an equality assertion.
#
# During test generation assertion attributes are passed to the corresponding
# TestGenerator method as arguments. E.g. assertion of type 'equal' invokes
# 'equal_assertion' method of the TestGenerator.
def __init__(self, name, assertions=[], setup=""):
    self.name = name
    self.assertions = assertions
    self.setup = setup

</t>
<t tx="ekr.20081202142943.44">def contains_code(self):
    return self._has_complete_setup() or self._get_code_assertions()

</t>
<t tx="ekr.20081202142943.45">def _get_code_assertions(self):
    return [a for a in self.assertions if a[0] in ['equal', 'raises']]

</t>
<t tx="ekr.20081202142943.46">def _has_complete_setup(self):
    return self.setup and not self.setup.startswith("#")

</t>
<t tx="ekr.20081202142943.47">class TestGenerator(object):
    main_snippet = EmptyCode()

    @others
</t>
<t tx="ekr.20081202142943.48">def from_template(cls, template):
    if template == 'unittest':
        return UnittestTestGenerator()
    elif template == 'nose':
        return NoseTestGenerator()
    else:
        raise UnknownTemplate(template)
</t>
<t tx="ekr.20081202142943.49">from_template = classmethod(from_template)

def __init__(self):
    self.imports = []

</t>
<t tx="ekr.20081202142943.50">def ensure_import(self, import_):
    if import_ not in self.imports:
        self.imports.append(import_)

</t>
<t tx="ekr.20081202142943.51">def ensure_imports(self, imports):
    for import_ in imports:
        self.ensure_import(import_)

</t>
<t tx="ekr.20081202142943.52">def add_tests_to_project(self, project, modnames, force=False):
    for modname in modnames:
        module = project.find_module_by_full_path(modname)
        self._add_tests_for_module(module, project, force)

</t>
<t tx="ekr.20081202142943.53">def create_test_class(self, class_name, method_descriptions):
    result = "%s\n" % (self.test_class_header(class_name))
    for method_description in method_descriptions:
        if method_description.assertions:
            result += "    def %s(self):\n" % method_description.name
            if method_description.setup:
                result += "        " + method_description.setup
            for assertion in method_description.assertions:
                apply_template = getattr(self, "%s_assertion" % assertion[0])
                result += "        %s\n" % apply_template(*assertion[1:])
            # We need at least one statement in a method to be syntatically correct.
            if not method_description.contains_code():
                result += "        pass\n"
            result += "\n"
        else:
            result += "    def %s(self):\n" % method_description.name
            result += "        %s\n\n" % self.missing_assertion()
    return result

</t>
<t tx="ekr.20081202142943.54">def comment_assertion(self, comment):
    return comment

</t>
<t tx="ekr.20081202142943.55">def equal_stub_assertion(self, expected, actual):
    return "# %s" % self.equal_assertion(expected, actual)

</t>
<t tx="ekr.20081202142943.56">def raises_stub_assertion(self, exception, code):
    return "# %s" % self.raises_assertion(exception, code)

</t>
<t tx="ekr.20081202142943.57">def _add_tests_for_module(self, module, project, force):
    log.info("Generating tests for module %s." % module.subpath)
    for test_case in self._generate_test_cases(module):
        add_test_case_to_project(project, test_case, force)

</t>
<t tx="ekr.20081202142943.58">def _generate_test_cases(self, module):
    for object in module.testable_objects:
        test_case = self._generate_test_case(object, module)
        if test_case:
            yield test_case

</t>
<t tx="ekr.20081202142943.59">def _generate_test_case(self, object, module):
    class_name = name2testname(camelize(object.name))
    method_descriptions = sorted_test_method_descriptions(self._generate_test_method_descriptions(object, module))

    # Don't generate empty test classes.
    if method_descriptions:
        test_body = self.create_test_class(class_name, method_descriptions)
        test_code = parse_fragment(test_body)
        def methoddesc2testmethod(method_description):
            name = method_description.name
            return TestMethod(name=name, code=find_method_code(test_code, name))
        return TestClass(name=class_name,
                         code=test_code,
                         test_cases=map(methoddesc2testmethod, method_descriptions),
                         imports=self.imports,
                         main_snippet=self.main_snippet,
                         associated_modules=[module])

</t>
<t tx="ekr.20081202142943.60">def _generate_test_method_descriptions(self, object, module):
    if isinstance(object, Function):
        return self._generate_test_method_descriptions_for_function(object, module)
    elif isinstance(object, Class):
        return self._generate_test_method_descriptions_for_class(object, module)
    else:
        raise TypeError("Don't know how to generate test method descriptions for %s" % object)

</t>
<t tx="ekr.20081202142943.61">def _generate_test_method_descriptions_for_function(self, function, module):
    if testable_calls(function.calls):
        log.debug("Detected %d testable calls in function %s." % \
                      (len(testable_calls(function.calls)), function.name))

        # We're calling the function, so we have to make sure it will
        # be imported in the test
        self.ensure_import((module.locator, function.name))

        # We have at least one call registered, so use it.
        return self._method_descriptions_from_function(function)
    else:
        # No calls were traced, so we're go for a single test stub.
        log.debug("Detected _no_ testable calls in function %s." % function.name)
        return [TestMethodDescription(name2testname(underscore(function.name)))]

</t>
<t tx="ekr.20081202142943.62">def _generate_test_method_descriptions_for_class(self, klass, module):
    if klass.live_objects:
        # We're calling the method, so we have to make sure its class
        # will be imported in the test.
        self.ensure_import((module.locator, klass.name))

    for live_object in klass.live_objects.values():
        yield self._method_description_from_live_object(live_object)

    # No calls were traced for those methods, so we'll go for simple test stubs.
    for method in klass.get_untraced_methods():
        if not should_ignore_method(method):
            yield self._generate_test_method_description_for_method(method)

</t>
<t tx="ekr.20081202142943.63">def _generate_test_method_description_for_method(self, method):
    if method.name == '__init__':
        name = "object_initialization"
    else:
        name = method.name
    return TestMethodDescription(name2testname(name))

</t>
<t tx="ekr.20081202142943.64">def _method_descriptions_from_function(self, function):
    for call in testable_calls(function.get_unique_calls()):
        name = call2testname(call, function.name)
        assertions = [self._create_assertion(function.name, call)]

        yield TestMethodDescription(name, assertions)

</t>
<t tx="ekr.20081202142943.65">def _method_description_from_live_object(self, live_object):
    init_call = live_object.get_init_call()
    external_calls = testable_calls(live_object.get_external_calls())
    local_name = underscore(live_object.klass.name)
    constructor = constructor_as_string(live_object)
    stub_all = constructor.uncomplete

    self.ensure_imports(constructor.imports)

    def test_name():
        if len(external_calls) == 0 and init_call:
            test_name = "test_creation"
            if init_call.input:
                test_name += "_with_%s" % input_as_string(init_call.input)
            if init_call.raised_exception():
                test_name += "_raises_%s" % object2id(init_call.exception)
        else:
            if len(external_calls) == 1:
                call = external_calls[0]
                test_name = call2testname(call, call.definition.name)
            # Methods with more than one external call use more brief
            # descriptions that don't include inputs and outputs.
            else:
                methods = []
                for method, icalls in groupby(sorted([call.definition.name for call in external_calls])):
                    calls = list(icalls)
                    if len(calls) == 1:
                        methods.append(method)
                    else:
                        methods.append("%s_%d_times" % (method, len(calls)))
                test_name = "test_%s" % '_and_'.join(methods)
            if init_call and init_call.input:
                test_name += "_after_creation_with_%s" % input_as_string(init_call.input)
        return test_name

    def assertions():
        if init_call and len(external_calls) == 0:
            # If the constructor raised an exception, object creation should be an assertion.
            if init_call.raised_exception():
                yield self._create_assertion(live_object.klass.name, init_call, stub_all)
            else:
                yield(('comment', "# Make sure it doesn't raise any exceptions."))

        for call in external_calls:
            name = "%s.%s" % (local_name, call.definition.name)
            yield(self._create_assertion(name, call, stub_all))

    def setup():
        if init_call and init_call.raised_exception():
            return ""
        else:
            setup = "%s = %s\n" % (local_name, constructor)
            # Comment out the constructor if it isn't complete.
            if stub_all:
                setup = "# %s" % setup
            return setup

    return TestMethodDescription(test_name(), list(assertions()), setup())

</t>
<t tx="ekr.20081202142943.66">def _create_assertion(self, name, call, stub=False):
    """Create a new assertion based on a given call and a name provided
    for it.

    Generated assertion will be a stub if input of a call cannot be
    constructed or if stub argument is True.
    """
    callstring = decorate_call(call, call_as_string(name, call.input))

    self.ensure_imports(callstring.imports)

    if call.raised_exception():
        if callstring.uncomplete or stub:
            assertion_type = 'raises_stub'
        else:
            assertion_type = 'raises'
        if not is_builtin_exception(call.exception):
            self.ensure_import(call.exception.type_import)
        return (assertion_type,
                call.exception.type_name,
                in_lambda(callstring))
    else:
        if callstring.uncomplete or stub:
            assertion_type = 'equal_stub'
        else:
            assertion_type = 'equal'

        if can_be_constructed(call.output):
            return (assertion_type, constructor_as_string(call.output),
                    callstring)
        else:
            # If we can't test for real values, let's at least test for the right type.
            output_type = type_as_string(call.output)
            if isinstance(call, GeneratorObject):
                callstring_type = map_types(callstring)
            else:
                callstring_type = type_of(callstring)
            self.ensure_import('types')
            return (assertion_type, output_type, callstring_type)

</t>
<t tx="ekr.20081202142943.67">class UnittestTestGenerator(TestGenerator):
    main_snippet = parse_fragment("if __name__ == '__main__':\n    unittest.main()\n")

    @others
</t>
<t tx="ekr.20081202142943.68">def test_class_header(self, name):
    self.ensure_import('unittest')
    return "class %s(unittest.TestCase):" % name

</t>
<t tx="ekr.20081202142943.69">def equal_assertion(self, expected, actual):
    return "self.assertEqual(%s, %s)" % (expected, actual)

</t>
<t tx="ekr.20081202142943.70">def raises_assertion(self, exception, code):
    return "self.assertRaises(%s, %s)" % (exception, code)

</t>
<t tx="ekr.20081202142943.71">def missing_assertion(self):
    return "assert False # TODO: implement your test here"

</t>
<t tx="ekr.20081202142943.72">class NoseTestGenerator(TestGenerator):
    @others
</t>
<t tx="ekr.20081202142943.73">def test_class_header(self, name):
    return "class %s:" % name

</t>
<t tx="ekr.20081202142943.74">def equal_assertion(self, expected, actual):
    self.ensure_import(('nose.tools', 'assert_equal'))
    return "assert_equal(%s, %s)" % (expected, actual)

</t>
<t tx="ekr.20081202142943.75">def raises_assertion(self, exception, code):
    self.ensure_import(('nose.tools', 'assert_raises'))
    return "assert_raises(%s, %s)" % (exception, code)

</t>
<t tx="ekr.20081202142943.76">def missing_assertion(self):
    self.ensure_import(('nose', 'SkipTest'))
    return "raise SkipTest # TODO: implement your test here"

</t>
<t tx="ekr.20081202142943.77">def add_tests_to_project(project, modnames, template, force=False):
    generator = TestGenerator.from_template(template)
    generator.add_tests_to_project(project, modnames, force)
</t>
<t tx="ekr.20081202142943.78">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202142943.79">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202142943.80">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081202143139.1">import inspect
import sys
import types


IGNORED_NAMES = ["&lt;module&gt;", "&lt;genexpr&gt;"]

_traced_callables = None
_top_level_function = None
_sys_modules = None
_point_of_entry = None
_call_stack = None

</t>
<t tx="ekr.20081202143139.2">class CallStack(object):
    @others
</t>
<t tx="ekr.20081202143139.3">def __init__(self):
    self.last_traceback = None
    self.stack = []
    self.top_level_calls = []

</t>
<t tx="ekr.20081202143139.4">def called(self, call):
    if self.stack:
        self.stack[-1].add_subcall(call)
    else:
        self.top_level_calls.append(call)
    self.stack.append(call)

</t>
<t tx="ekr.20081202143139.5">def returned(self, output):
    if self.stack:
        caller = self.stack.pop()
        caller.set_output(output)

        # If the last exception is reported by sys.exc_info() it means
        # it was handled inside the returning call.
        handled_traceback = sys.exc_info()[2]
        if handled_traceback is self.last_traceback:
            caller.clear_exception()

</t>
<t tx="ekr.20081202143139.6">def raised(self, exception, traceback):
    if self.stack:
        caller = self.stack[-1]
        caller.set_exception(exception)
        self.last_traceback = traceback

</t>
<t tx="ekr.20081202143139.7">def compact(lst):
    "Remove all occurences of None from the given list."
    return [x for x in lst if x is not None]

</t>
<t tx="ekr.20081202143139.8">def find_variable(frame, varname):
    """Find variable named varname in the scope of a frame.

    Raise a KeyError when the varname cannot be found.
    """
    try:
        return frame.f_locals[varname]
    except KeyError:
        return frame.f_globals[varname]

</t>
<t tx="ekr.20081202143139.9">def callable_type(frame):
    """Return a type of a called frame or raise a KeyError if it can't be
    retrieved.

    The latter is the case for class definitions and method calls, which are
    not refrenced neither in local nor global scope.
    """
    return type(find_variable(frame.f_back, frame.f_code.co_name))

</t>
<t tx="ekr.20081202143139.10">def is_class_definition(frame):
    "Return True if given frame represents a class definition."
    try:
        # Old-style classes are of type "ClassType", while new-style
        # classes or of type "type".
        return callable_type(frame) in [types.ClassType, type]
    except KeyError:
        return frame.f_code.co_names[:2] == ('__name__', '__module__')

</t>
<t tx="ekr.20081202143139.11">class NotMethodFrame(Exception):
    pass

</t>
<t tx="ekr.20081202143139.12">def get_method_information(frame):
    """Analyze the frame and return relevant information about the method
    call it presumably represents.

    Returns a tuple: (self_object, input_dictionary).

    If the frame doesn't represent a method call, raises NotMethodFrame
    exception.
    """
    try:
        args, varargs, varkw, locals = inspect.getargvalues(frame)
        if args:
            # Will raise TypeError if args[0] is a list.
            self = locals[args[0]]
        else:
            # Will raise an IndexError if no arguments were passed.
            self = locals[varargs][0]

        methodname = frame.f_code.co_name
        # Will raise AttributeError when the self is None or doesn't
        # have method with given name.
        method = getattr(self, methodname)

        # This isn't a call on the first argument's method.
        if not method.im_func.func_code == frame.f_code:
            raise NotMethodFrame

        # Remove the "self" argument.
        if args:
            args.pop(0)
        elif varargs and locals[varargs]:
            # No pop(), because locals[varargs] is a tuple.
            locals[varargs] = locals[varargs][1:]
        else:
            raise NotMethodFrame

        return (self, input_from_argvalues(args, varargs, varkw, locals))
    except (AttributeError, KeyError, TypeError, IndexError):
        raise NotMethodFrame

</t>
<t tx="ekr.20081202143139.13">def resolve_args(names, locals):
    """Returns a list of tuples representing argument names and values.

    Handles nested arguments lists well.
        &gt;&gt;&gt; resolve_args([['a', 'b'], 'c'], {'.0': (1, 2), 'c': 3})
        [('a', 1), ('b', 2), ('c', 3)]

        &gt;&gt;&gt; resolve_args(['a', ['b', 'c']], {'.1': (8, 7), 'a': 9})
        [('a', 9), ('b', 8), ('c', 7)]
    """
    result = []
    for i, name in enumerate(names):
        if isinstance(name, list):
            result.extend(zip(name, locals['.%d' % i]))
        else:
            result.append((name, locals[name]))
    return result

</t>
<t tx="ekr.20081202143139.14">def input_from_argvalues(args, varargs, varkw, locals):
    return dict(resolve_args(args + compact([varargs, varkw]), locals))

</t>
<t tx="ekr.20081202143139.15">def is_ignored_code(code):
    if code.co_name in IGNORED_NAMES:
        return True
    if code in [_top_level_function.func_code, stop_tracing.func_code]:
        return True
    return False

</t>
<t tx="ekr.20081202143139.16">def create_call(frame):
    code = frame.f_code
    name = code.co_name
    modulepath = code.co_filename

    if not is_ignored_code(code):
        try:
            self, input = get_method_information(frame)
            classname = self.__class__.__name__
            return _point_of_entry.create_method_call(name, classname, modulepath, self, input, code, frame)
        except NotMethodFrame:
            input = input_from_argvalues(*inspect.getargvalues(frame))
            return _point_of_entry.create_function_call(name, modulepath, input, code, frame)

</t>
<t tx="ekr.20081202143139.17">def tracer(frame, event, arg):
    if event == 'call':
        if not is_class_definition(frame):
            call = create_call(frame)
            if call:
                _call_stack.called(call)
                return tracer
    elif event == 'return':
        _call_stack.returned(arg)
    elif event == 'exception':
        if arg[0] is not GeneratorExit:
            _call_stack.raised(arg[1], arg[2])

</t>
<t tx="ekr.20081202143139.18">def start_tracing():
    sys.settrace(tracer)

</t>
<t tx="ekr.20081202143139.19">def stop_tracing():
    sys.settrace(None)

</t>
<t tx="ekr.20081202143139.20">def trace_function(fun):
    """Trace given function and add Calls to given PointOfEntry instance.
    """
    global _top_level_function
    _top_level_function = fun

    start_tracing()
    try:
        fun()
    finally:
        stop_tracing()

</t>
<t tx="ekr.20081202143139.21">def trace_exec(exec_string, scope={}):
    def fun():
        exec exec_string in scope
    return trace_function(fun)

</t>
<t tx="ekr.20081202143139.22">def setup_tracing(point_of_entry):
    global _sys_modules, _point_of_entry, _call_stack

    # Put project's path into PYTHONPATH, so point of entry's imports work.
    sys.path.insert(0, point_of_entry.project.path)
    point_of_entry.clear_previous_run()

    _call_stack = CallStack()
    _point_of_entry = point_of_entry
    _sys_modules = sys.modules.keys()

</t>
<t tx="ekr.20081202143139.23">def teardown_tracing(point_of_entry):
    global _sys_modules, _point_of_entry, _call_stack

    # Revert any changes to sys.modules.
    # This unfortunatelly doesn't include changes to the modules' state itself.
    # Replaced module instances in sys.modules are also not reverted.
    modnames = [m for m in sys.modules.keys() if m not in _sys_modules]
    for modname in modnames:
        del sys.modules[modname]

    # Copy the call graph structure to the point of entry.
    _point_of_entry.call_graph = _call_stack.top_level_calls
    _point_of_entry.finalize_inspection()

    _sys_modules = None
    _point_of_entry = None
    _call_stack = None

    sys.path.remove(point_of_entry.project.path)

</t>
<t tx="ekr.20081202143139.24">def inspect_point_of_entry(point_of_entry):
    setup_tracing(point_of_entry)
    try:
        trace_exec(point_of_entry.get_content())
    finally:
        teardown_tracing(point_of_entry)
</t>
<t tx="ekr.20081202143139.25">import re
import types

from pythoscope.astvisitor import descend, parse, ParseError, ASTVisitor
from pythoscope.store import Class, Function, Method, TestClass,TestMethod
from pythoscope.util import all_of_type, is_generator_code, \
    read_file_contents, compile_without_warnings


</t>
<t tx="ekr.20081202143139.26">def is_test_class(name, bases):
    """Look at the name and bases of a class to determine whether it's a test
    class or not.

    &gt;&gt;&gt; is_test_class("TestSomething", [])
    True
    &gt;&gt;&gt; is_test_class("SomethingElse", [])
    False
    &gt;&gt;&gt; is_test_class("ItDoesntLookLikeOne", ["unittest.TestCase"])
    True
    """
    return name.startswith("Test") or name.endswith("Test") \
           or "unittest.TestCase" in bases

</t>
<t tx="ekr.20081202143139.27">def unindent(string):
    """Remove the initial part of whitespace from string.

    &gt;&gt;&gt; unindent("1 + 2 + 3\\n")
    '1 + 2 + 3\\n'
    &gt;&gt;&gt; unindent("  def fun():\\n    return 42\\n")
    'def fun():\\n  return 42\\n'
    """
    match = re.match(r'^([\t ]+)', string)
    if not match:
        return string
    whitespace = match.group(1)

    lines = []
    for line in string.splitlines(True):
        if line.startswith(whitespace):
            lines.append(line[len(whitespace):])
        else:
            return string
    return ''.join(lines)

</t>
<t tx="ekr.20081202143139.28">def function_code_from_definition(definition):
    """Return a code object of a given function definition.

    Can raise SyntaxError if the definition is not valid.
    """
    consts = compile_without_warnings(unindent(str(definition))).co_consts
    return all_of_type(consts, types.CodeType)[0]

</t>
<t tx="ekr.20081202143139.29">def is_generator_definition(definition):
    """Return True if given piece of code is a generator definition.

    &gt;&gt;&gt; is_generator_definition("def f():\\n  return 1\\n")
    False
    &gt;&gt;&gt; is_generator_definition("def g():\\n  yield 2\\n")
    True
    &gt;&gt;&gt; is_generator_definition("  def indented_gen():\\n    yield 3\\n")
    True
    """
    try:
        return is_generator_code(function_code_from_definition(definition))
    except SyntaxError:
        # This most likely means given code used "return" with argument
        # inside generator.
        return False

</t>
<t tx="ekr.20081202143139.30">def create_definition(name, body, definition_type):
    return definition_type(name, body, is_generator=is_generator_definition(body))

</t>
<t tx="ekr.20081202143139.31">class ModuleVisitor(ASTVisitor):
    @others
</t>
<t tx="ekr.20081202143139.32">def __init__(self):
    ASTVisitor.__init__(self)
    self.imports = []
    self.objects = []
    self.main_snippet = None

</t>
<t tx="ekr.20081202143139.33">def visit_class(self, name, bases, body):
    visitor = descend(body.children, ClassVisitor)
    if is_test_class(name, bases):
        methods = [TestMethod(n, c) for (n, c) in visitor.methods]
        klass = TestClass(name=name, test_cases=methods, code=body)
    else:
        methods = [create_definition(n, b, Method) for (n, b) in visitor.methods]
        klass = Class(name=name, methods=methods, bases=bases)
    self.objects.append(klass)

</t>
<t tx="ekr.20081202143139.34">def visit_function(self, name, args, body):
    self.objects.append(create_definition(name, body, Function))

</t>
<t tx="ekr.20081202143139.35">def visit_lambda_assign(self, name):
    self.objects.append(Function(name))

</t>
<t tx="ekr.20081202143139.36">def visit_import(self, names, import_from):
    if import_from:
        for name in names:
            self.imports.append((import_from, name))
    else:
        self.imports.extend(names)

</t>
<t tx="ekr.20081202143139.37">def visit_main_snippet(self, body):
    self.main_snippet = body

</t>
<t tx="ekr.20081202143139.38">class ClassVisitor(ASTVisitor):
    @others
</t>
<t tx="ekr.20081202143139.39">def __init__(self):
    ASTVisitor.__init__(self)
    self.methods = []

</t>
<t tx="ekr.20081202143139.40">def visit_class(self, name, bases, body):
    # Ignore definitions of subclasses.
    pass

</t>
<t tx="ekr.20081202143139.41">def visit_function(self, name, args, body):
    self.methods.append((name, body))

</t>
<t tx="ekr.20081202143139.42">def inspect_module(project, path):
    return inspect_code(project, path, read_file_contents(path))

</t>
<t tx="ekr.20081202143139.43">def inspect_code(project, path, code):
    try:
        tree = parse(code)
    except ParseError, e:
        return project.create_module(path, errors=[e])
    visitor = descend(tree, ModuleVisitor)

    # We assume that all test classes in this module has dependencies on
    # imports and a main snippet the module contains.
    for test_class in [o for o in visitor.objects if isinstance(o, TestClass)]:
        # We gathered all imports in a single list, but import lists of those
        # classes may diverge in time, so we don't want to share their
        # structure.
        test_class.imports = visitor.imports[:]
        test_class.main_snippet = visitor.main_snippet

    return project.create_module(path, code=tree, objects=visitor.objects,
                                 imports=visitor.imports,
                                 main_snippet=visitor.main_snippet)
</t>
<t tx="ekr.20081202143139.44">from pythoscope.inspector import static, dynamic
from pythoscope.logger import log
from pythoscope.store import ModuleNotFound
from pythoscope.util import python_modules_below


</t>
<t tx="ekr.20081202143139.45">def inspect_project(project):
    remove_deleted_modules(project)
    remove_deleted_points_of_entry(project)

    updates = add_and_update_modules(project) + add_and_update_points_of_entry(project)

    # If nothing new was discovered statically and there are no new points of
    # entry, don't run dynamic inspection.
    if updates:
        inspect_project_dynamically(project)
    else:
        log.info("No changes discovered in the source code, skipping dynamic inspection.")

</t>
<t tx="ekr.20081202143139.46">def remove_deleted_modules(project):
    subpaths = [mod.subpath for mod in project.iter_modules() if not mod.exists()]
    for subpath in subpaths:
        project.remove_module(subpath)

</t>
<t tx="ekr.20081202143139.47">def add_and_update_modules(project):
    count = 0
    for modpath in python_modules_below(project.path):
        try:
            module = project.find_module_by_full_path(modpath)
            if module.is_up_to_date():
                log.info("%s hasn't changed since last inspection, skipping." % module.subpath)
                continue
        except ModuleNotFound:
            pass
        log.info("Inspecting module %s." % project._extract_subpath(modpath))
        static.inspect_module(project, modpath)
        count += 1
    return count

</t>
<t tx="ekr.20081202143139.48">def remove_deleted_points_of_entry(project):
    names = [poe.name for poe in project.points_of_entry.values() if not poe.exists()]
    for name in names:
        project.remove_point_of_entry(name)

</t>
<t tx="ekr.20081202143139.49">def add_and_update_points_of_entry(project):
    count = 0
    for path in python_modules_below(project._get_points_of_entry_path()):
        poe = project.ensure_point_of_entry(path)
        if poe.is_out_of_sync():
            count += 1
    return count

</t>
<t tx="ekr.20081202143139.50">def inspect_project_dynamically(project):
    for poe in project.points_of_entry.values():
        try:
            log.info("Inspecting point of entry %s." % poe.name)
            dynamic.inspect_point_of_entry(poe)
        except SyntaxError, err:
            log.warning("Point of entry contains a syntax error: %s" % err)
        except (Exception, KeyboardInterrupt, SystemExit), err:
            log.warning("Point of entry exited with error: %s" % repr(err))
</t>
<t tx="ekr.20081203091734.1"></t>
<t tx="ekr.20081203091734.11">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.12">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.13">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.14">@language python
@tabwidth -4
@others
#empty
</t>
<t tx="ekr.20081203091734.15"></t>
<t tx="ekr.20081203091734.16">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.17">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.18">@language python
@tabwidth -4
@others
@ignore
    # First mismatch at line 140
    # The @ sign in column 1 confuses Leo's importer.
# Map from operator to number (since tokenize doesn't do this)

opmap_raw = """
( LPAR
) RPAR
[ LSQB
] RSQB
: COLON
, COMMA
; SEMI
+ PLUS
- MINUS
* STAR
/ SLASH
| VBAR
&amp; AMPER
&lt; LESS
&gt; GREATER
= EQUAL
. DOT
% PERCENT
` BACKQUOTE
{ LBRACE
} RBRACE
@ AT
== EQEQUAL
!= NOTEQUAL
&lt;&gt; NOTEQUAL
&lt;= LESSEQUAL
&gt;= GREATEREQUAL
~ TILDE
^ CIRCUMFLEX
&lt;&lt; LEFTSHIFT
&gt;&gt; RIGHTSHIFT
** DOUBLESTAR
+= PLUSEQUAL
-= MINEQUAL
*= STAREQUAL
/= SLASHEQUAL
%= PERCENTEQUAL
&amp;= AMPEREQUAL
|= VBAREQUAL
^= CIRCUMFLEXEQUAL
&lt;&lt;= LEFTSHIFTEQUAL
&gt;&gt;= RIGHTSHIFTEQUAL
**= DOUBLESTAREQUAL
// DOUBLESLASH
//= DOUBLESLASHEQUAL
-&gt; RARROW
"""

opmap = {}
for line in opmap_raw.splitlines():
    if line:
        op, name = line.split()
        opmap[op] = getattr(token, name)
</t>
<t tx="ekr.20081203091734.19">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    test()
</t>
<t tx="ekr.20081203091734.20">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.21">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.22">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203091734.23">@language python
@tabwidth -4
@others
if __name__ == '__main__':                     # testing
    import sys
    if len(sys.argv) &gt; 1: tokenize(open(sys.argv[1]).readline)
    else: tokenize(sys.stdin.readline)
</t>
<t tx="ekr.20081203091734.24">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20081203092030.1"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""This module defines the data structures used to represent a grammar.

These are a bit arcane because they are derived from the data
structures used by Python's 'pgen' parser generator.

There's also a table here mapping operators to their names in the
token module; the Python tokenize module reports all operators as the
fallback token code OP, but the parser needs the actual token code.

"""

# Python imports
import pickle

# Local imports
import token, tokenize


</t>
<t tx="ekr.20081203092030.2">class Grammar(object):
    """Pgen parsing tables tables conversion class.

    Once initialized, this class supplies the grammar tables for the
    parsing engine implemented by parse.py.  The parsing engine
    accesses the instance variables directly.  The class here does not
    provide initialization of the tables; several subclasses exist to
    do this (see the conv and pgen modules).

    The load() method reads the tables from a pickle file, which is
    much faster than the other ways offered by subclasses.  The pickle
    file is written by calling dump() (after loading the grammar
    tables using a subclass).  The report() method prints a readable
    representation of the tables to stdout, for debugging.

    The instance variables are as follows:

    symbol2number -- a dict mapping symbol names to numbers.  Symbol
                     numbers are always 256 or higher, to distinguish
                     them from token numbers, which are between 0 and
                     255 (inclusive).

    number2symbol -- a dict mapping numbers to symbol names;
                     these two are each other's inverse.

    states        -- a list of DFAs, where each DFA is a list of
                     states, each state is is a list of arcs, and each
                     arc is a (i, j) pair where i is a label and j is
                     a state number.  The DFA number is the index into
                     this list.  (This name is slightly confusing.)
                     Final states are represented by a special arc of
                     the form (0, j) where j is its own state number.

    dfas          -- a dict mapping symbol numbers to (DFA, first)
                     pairs, where DFA is an item from the states list
                     above, and first is a set of tokens that can
                     begin this grammar rule (represented by a dict
                     whose values are always 1).

    labels        -- a list of (x, y) pairs where x is either a token
                     number or a symbol number, and y is either None
                     or a string; the strings are keywords.  The label
                     number is the index in this list; label numbers
                     are used to mark state transitions (arcs) in the
                     DFAs.

    start         -- the number of the grammar's start symbol.

    keywords      -- a dict mapping keyword strings to arc labels.

    tokens        -- a dict mapping token numbers to arc labels.

    """
    @others
</t>
<t tx="ekr.20081203092030.3">
def __init__(self):
    self.symbol2number = {}
    self.number2symbol = {}
    self.states = []
    self.dfas = {}
    self.labels = [(0, "EMPTY")]
    self.keywords = {}
    self.tokens = {}
    self.symbol2label = {}
    self.start = 256

</t>
<t tx="ekr.20081203092030.4">def dump(self, filename):
    """Dump the grammar tables to a pickle file."""
    f = open(filename, "wb")
    pickle.dump(self.__dict__, f, 2)
    f.close()

</t>
<t tx="ekr.20081203092030.5">def load(self, filename):
    """Load the grammar tables from a pickle file."""
    f = open(filename, "rb")
    d = pickle.load(f)
    f.close()
    self.__dict__.update(d)

</t>
<t tx="ekr.20081203092030.6">def report(self):
    """Dump the grammar tables to standard output, for debugging."""
    from pprint import pprint
    print "s2n"
    pprint(self.symbol2number)
    print "n2s"
    pprint(self.number2symbol)
    print "states"
    pprint(self.states)
    print "dfas"
    pprint(self.dfas)
    print "labels"
    pprint(self.labels)
    print "start", self.start


</t>
<t tx="ekr.20081203092030.7"># Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Pattern compiler.

The grammer is taken from PatternGrammar.txt.

The compiler compiles a pattern to a pytree.*Pattern instance.
"""

__author__ = "Guido van Rossum &lt;guido@python.org&gt;"

# Python imports
import os

# Fairly local imports
from pgen2 import driver
from pgen2 import literals
from pgen2 import token
from pgen2 import tokenize

# Really local imports
import pytree
import pygram

# The pattern grammar file
_PATTERN_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__),
                                     "PatternGrammar.txt")


</t>
<t tx="ekr.20081203092030.8">def tokenize_wrapper(input):
    """Tokenizes a string suppressing significant whitespace."""
    skip = (token.NEWLINE, token.INDENT, token.DEDENT)
    tokens = tokenize.generate_tokens(driver.generate_lines(input).next)
    for quintuple in tokens:
        type, value, start, end, line_text = quintuple
        if type not in skip:
            yield quintuple


</t>
<t tx="ekr.20081203092030.9">class PatternCompiler(object):
    @others
</t>
<t tx="ekr.20081203092030.10">
def __init__(self, grammar_file=_PATTERN_GRAMMAR_FILE):
    """Initializer.

    Takes an optional alternative filename for the pattern grammar.
    """
    self.grammar = driver.load_grammar(grammar_file)
    self.syms = pygram.Symbols(self.grammar)
    self.pygrammar = pygram.python_grammar
    self.pysyms = pygram.python_symbols
    self.driver = driver.Driver(self.grammar, convert=pattern_convert)

</t>
<t tx="ekr.20081203092030.11">def compile_pattern(self, input, debug=False):
    """Compiles a pattern string to a nested pytree.*Pattern object."""
    tokens = tokenize_wrapper(input)
    root = self.driver.parse_tokens(tokens, debug=debug)
    return self.compile_node(root)

</t>
<t tx="ekr.20081203092030.12">def compile_node(self, node):
    """Compiles a node, recursively.

    This is one big switch on the node type.
    """
    # XXX Optimize certain Wildcard-containing-Wildcard patterns
    # that can be merged
    if node.type == self.syms.Matcher:
        node = node.children[0] # Avoid unneeded recursion

    if node.type == self.syms.Alternatives:
        # Skip the odd children since they are just '|' tokens
        alts = [self.compile_node(ch) for ch in node.children[::2]]
        if len(alts) == 1:
            return alts[0]
        p = pytree.WildcardPattern([[a] for a in alts], min=1, max=1)
        return p.optimize()

    if node.type == self.syms.Alternative:
        units = [self.compile_node(ch) for ch in node.children]
        if len(units) == 1:
            return units[0]
        p = pytree.WildcardPattern([units], min=1, max=1)
        return p.optimize()

    if node.type == self.syms.NegatedUnit:
        pattern = self.compile_basic(node.children[1:])
        p = pytree.NegatedPattern(pattern)
        return p.optimize()

    assert node.type == self.syms.Unit

    name = None
    nodes = node.children
    if len(nodes) &gt;= 3 and nodes[1].type == token.EQUAL:
        name = nodes[0].value
        nodes = nodes[2:]
    repeat = None
    if len(nodes) &gt;= 2 and nodes[-1].type == self.syms.Repeater:
        repeat = nodes[-1]
        nodes = nodes[:-1]

    # Now we've reduced it to: STRING | NAME [Details] | (...) | [...]
    pattern = self.compile_basic(nodes, repeat)

    if repeat is not None:
        assert repeat.type == self.syms.Repeater
        children = repeat.children
        child = children[0]
        if child.type == token.STAR:
            min = 0
            max = pytree.HUGE
        elif child.type == token.PLUS:
            min = 1
            max = pytree.HUGE
        elif child.type == token.LBRACE:
            assert children[-1].type == token.RBRACE
            assert  len(children) in (3, 5)
            min = max = self.get_int(children[1])
            if len(children) == 5:
                max = self.get_int(children[3])
        else:
            assert False
        if min != 1 or max != 1:
            pattern = pattern.optimize()
            pattern = pytree.WildcardPattern([[pattern]], min=min, max=max)

    if name is not None:
        pattern.name = name
    return pattern.optimize()

</t>
<t tx="ekr.20081203092030.13">def compile_basic(self, nodes, repeat=None):
    # Compile STRING | NAME [Details] | (...) | [...]
    assert len(nodes) &gt;= 1
    node = nodes[0]
    if node.type == token.STRING:
        value = literals.evalString(node.value)
        return pytree.LeafPattern(content=value)
    elif node.type == token.NAME:
        value = node.value
        if value.isupper():
            if value not in TOKEN_MAP:
                raise SyntaxError("Invalid token: %r" % value)
            return pytree.LeafPattern(TOKEN_MAP[value])
        else:
            if value == "any":
                type = None
            elif not value.startswith("_"):
                type = getattr(self.pysyms, value, None)
                if type is None:
                    raise SyntaxError("Invalid symbol: %r" % value)
            if nodes[1:]: # Details present
                content = [self.compile_node(nodes[1].children[1])]
            else:
                content = None
            return pytree.NodePattern(type, content)
    elif node.value == "(":
        return self.compile_node(nodes[1])
    elif node.value == "[":
        assert repeat is None
        subpattern = self.compile_node(nodes[1])
        return pytree.WildcardPattern([[subpattern]], min=0, max=1)
    assert False, node

</t>
<t tx="ekr.20081203092030.14">def get_int(self, node):
    assert node.type == token.NUMBER
    return int(node.value)


</t>
<t tx="ekr.20081203092030.15"># Map named tokens to the type value for a LeafPattern
TOKEN_MAP = {"NAME": token.NAME,
             "STRING": token.STRING,
             "NUMBER": token.NUMBER,
             "TOKEN": None}


def pattern_convert(grammar, raw_node_info):
    """Converts raw node information to a Node or Leaf instance."""
    type, value, context, children = raw_node_info
    if children or type in grammar.number2symbol:
        return pytree.Node(type, children, context=context)
    else:
        return pytree.Leaf(type, value, context=context)


</t>
<t tx="ekr.20081203092030.16">def compile_pattern(pattern):
    return PatternCompiler().compile_pattern(pattern)
</t>
<t tx="ekr.20081203092030.17"># Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Export the Python grammar and symbols."""

# Python imports
import os

# Local imports
from pgen2 import token
from pgen2 import driver
import pytree

# The grammar file
_GRAMMAR_FILE = os.path.join(os.path.dirname(__file__), "Grammar.txt")


</t>
<t tx="ekr.20081203092030.18">class Symbols(object):
    @others
</t>
<t tx="ekr.20081203092030.19">
def __init__(self, grammar):
    """Initializer.

    Creates an attribute for each grammar symbol (nonterminal),
    whose value is the symbol's type (an int &gt;= 256).
    """
    for name, symbol in grammar.symbol2number.iteritems():
        setattr(self, name, symbol)


</t>
<t tx="ekr.20081203092030.20">python_grammar = driver.load_grammar(_GRAMMAR_FILE)
python_symbols = Symbols(python_grammar)


def parenthesize(node):
    return pytree.Node(python_symbols.atom,
                       (pytree.Leaf(token.LPAR, "("),
                        node,
                        pytree.Leaf(token.RPAR, ")")))
</t>
<t tx="ekr.20081203092030.21"># Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Python parse tree definitions.

This is a very concrete parse tree; we need to keep every token and
even the comments and whitespace between tokens.

There's also a pattern matching implementation here.
"""

__author__ = "Guido van Rossum &lt;guido@python.org&gt;"


HUGE = 0x7FFFFFFF  # maximum repeat count, default max

_type_reprs = {}
</t>
<t tx="ekr.20081203092030.22">def type_repr(type_num):
    global _type_reprs
    if not _type_reprs:
        from pygram import python_symbols
        # printing tokens is possible but not as useful
        # from .pgen2 import token // token.__dict__.items():
        for name, val in python_symbols.__dict__.items():
            if type(val) == int: _type_reprs[val] = name
    return _type_reprs.setdefault(type_num, type_num)


</t>
<t tx="ekr.20081203092030.23">class Base(object):

    """Abstract base class for Node and Leaf.

    This provides some default functionality and boilerplate using the
    template pattern.

    A node may be a subnode of at most one parent.
    """

    # Default values for instance variables
    type = None    # int: token number (&lt; 256) or symbol number (&gt;= 256)
    parent = None  # Parent node pointer, or None
    children = ()  # Tuple of subnodes
    was_changed = False

    @others
</t>
<t tx="ekr.20081203092030.24">def __new__(cls, *args, **kwds):
    """Constructor that prevents Base from being instantiated."""
    assert cls is not Base, "Cannot instantiate Base"
    return object.__new__(cls)

</t>
<t tx="ekr.20081203092030.25">def __eq__(self, other):
    """Compares two nodes for equality.

    This calls the method _eq().
    """
    if self.__class__ is not other.__class__:
        return NotImplemented
    return self._eq(other)

</t>
<t tx="ekr.20081203092030.26">def __ne__(self, other):
    """Compares two nodes for inequality.

    This calls the method _eq().
    """
    if self.__class__ is not other.__class__:
        return NotImplemented
    return not self._eq(other)

</t>
<t tx="ekr.20081203092030.27">def _eq(self, other):
    """Compares two nodes for equality.

    This is called by __eq__ and __ne__.  It is only called if the
    two nodes have the same type.  This must be implemented by the
    concrete subclass.  Nodes should be considered equal if they
    have the same structure, ignoring the prefix string and other
    context information.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.28">def clone(self):
    """Returns a cloned (deep) copy of self.

    This must be implemented by the concrete subclass.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.29">def post_order(self):
    """Returns a post-order iterator for the tree.

    This must be implemented by the concrete subclass.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.30">def pre_order(self):
    """Returns a pre-order iterator for the tree.

    This must be implemented by the concrete subclass.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.31">def set_prefix(self, prefix):
    """Sets the prefix for the node (see Leaf class).

    This must be implemented by the concrete subclass.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.32">def get_prefix(self):
    """Returns the prefix for the node (see Leaf class).

    This must be implemented by the concrete subclass.
    """
    raise NotImplementedError

</t>
<t tx="ekr.20081203092030.33">def replace(self, new):
    """Replaces this node with a new one in the parent."""
    assert self.parent is not None, str(self)
    assert new is not None
    if not isinstance(new, list):
        new = [new]
    l_children = []
    found = False
    for ch in self.parent.children:
        if ch is self:
            assert not found, (self.parent.children, self, new)
            if new is not None:
                l_children.extend(new)
            found = True
        else:
            l_children.append(ch)
    assert found, (self.children, self, new)
    self.parent.changed()
    self.parent.children = l_children
    for x in new:
        x.parent = self.parent
    self.parent = None

</t>
<t tx="ekr.20081203092030.34">def get_lineno(self):
    """Returns the line number which generated the invocant node."""
    node = self
    while not isinstance(node, Leaf):
        if not node.children:
            return
        node = node.children[0]
    return node.lineno

</t>
<t tx="ekr.20081203092030.35">def changed(self):
    if self.parent:
        self.parent.changed()
    self.was_changed = True

</t>
<t tx="ekr.20081203092030.36">def remove(self):
    """Remove the node from the tree. Returns the position of the node
    in its parent's children before it was removed."""
    if self.parent:
        for i, node in enumerate(self.parent.children):
            if node is self:
                self.parent.changed()
                del self.parent.children[i]
                self.parent = None
                return i

</t>
<t tx="ekr.20081203092030.37">def get_next_sibling(self):
    """Return the node immediately following the invocant in their
    parent's children list. If the invocant does not have a next
    sibling, return None."""
    if self.parent is None:
        return None

    # Can't use index(); we need to test by identity
    for i, child in enumerate(self.parent.children):
        if child is self:
            try:
                return self.parent.children[i+1]
            except IndexError:
                return None

</t>
<t tx="ekr.20081203092030.38">def get_prev_sibling(self):
    """Return the node immediately preceding the invocant in their
    parent's children list. If the invocant does not have a previous
    sibling, return None."""
    if self.parent is None:
        return None

    # Can't use index(); we need to test by identity
    for i, child in enumerate(self.parent.children):
        if child is self:
            if i == 0:
                return None
            return self.parent.children[i-1]

</t>
<t tx="ekr.20081203092030.39">def get_suffix(self):
    """Return the string immediately following the invocant node. This
    is effectively equivalent to node.get_next_sibling().get_prefix()"""
    next_sib = self.get_next_sibling()
    if next_sib is None:
        return ""
    return next_sib.get_prefix()


</t>
<t tx="ekr.20081203092030.40">class Node(Base):

    """Concrete implementation for interior nodes."""
    @others
</t>
<t tx="ekr.20081203092030.41">
def __init__(self, type, children, context=None, prefix=None):
    """Initializer.

    Takes a type constant (a symbol number &gt;= 256), a sequence of
    child nodes, and an optional context keyword argument.

    As a side effect, the parent pointers of the children are updated.
    """
    assert type &gt;= 256, type
    self.type = type
    self.children = list(children)
    for ch in self.children:
        assert ch.parent is None, repr(ch)
        ch.parent = self
    if prefix is not None:
        self.set_prefix(prefix)

</t>
<t tx="ekr.20081203092030.42">def __repr__(self):
    """Returns a canonical string representation."""
    return "%s(%s, %r)" % (self.__class__.__name__,
                           type_repr(self.type),
                           self.children)

</t>
<t tx="ekr.20081203092030.43">def __str__(self):
    """Returns a pretty string representation.

    This reproduces the input source exactly.
    """
    return "".join(map(str, self.children))

</t>
<t tx="ekr.20081203092030.44">def _eq(self, other):
    """Compares two nodes for equality."""
    return (self.type, self.children) == (other.type, other.children)

</t>
<t tx="ekr.20081203092030.45">def clone(self):
    """Returns a cloned (deep) copy of self."""
    return Node(self.type, [ch.clone() for ch in self.children])

</t>
<t tx="ekr.20081203092030.46">def post_order(self):
    """Returns a post-order iterator for the tree."""
    for child in self.children:
        for node in child.post_order():
            yield node
    yield self

</t>
<t tx="ekr.20081203092030.47">def pre_order(self):
    """Returns a pre-order iterator for the tree."""
    yield self
    for child in self.children:
        for node in child.post_order():
            yield node

</t>
<t tx="ekr.20081203092030.48">def set_prefix(self, prefix):
    """Sets the prefix for the node.

    This passes the responsibility on to the first child.
    """
    if self.children:
        self.children[0].set_prefix(prefix)

</t>
<t tx="ekr.20081203092030.49">def get_prefix(self):
    """Returns the prefix for the node.

    This passes the call on to the first child.
    """
    if not self.children:
        return ""
    return self.children[0].get_prefix()

</t>
<t tx="ekr.20081203092030.50">def set_child(self, i, child):
    """Equivalent to 'node.children[i] = child'. This method also sets the
    child's parent attribute appropriately."""
    child.parent = self
    self.children[i].parent = None
    self.children[i] = child

</t>
<t tx="ekr.20081203092030.51">def insert_child(self, i, child):
    """Equivalent to 'node.children.insert(i, child)'. This method also
    sets the child's parent attribute appropriately."""
    child.parent = self
    self.children.insert(i, child)

</t>
<t tx="ekr.20081203092030.52">def append_child(self, child):
    """Equivalent to 'node.children.append(child)'. This method also
    sets the child's parent attribute appropriately."""
    child.parent = self
    self.children.append(child)


</t>
<t tx="ekr.20081203092030.53">class Leaf(Base):

    """Concrete implementation for leaf nodes."""

    # Default values for instance variables
    prefix = ""  # Whitespace and comments preceding this token in the input
    lineno = 0   # Line where this token starts in the input
    column = 0   # Column where this token tarts in the input

    @others
</t>
<t tx="ekr.20081203092030.54">def __init__(self, type, value, context=None, prefix=None):
    """Initializer.

    Takes a type constant (a token number &lt; 256), a string value,
    and an optional context keyword argument.
    """
    assert 0 &lt;= type &lt; 256, type
    if context is not None:
        self.prefix, (self.lineno, self.column) = context
    self.type = type
    self.value = value
    if prefix is not None:
        self.prefix = prefix

</t>
<t tx="ekr.20081203092030.55">def __repr__(self):
    """Returns a canonical string representation."""
    return "%s(%r, %r)" % (self.__class__.__name__,
                           self.type,
                           self.value)

</t>
<t tx="ekr.20081203092030.56">def __str__(self):
    """Returns a pretty string representation.

    This reproduces the input source exactly.
    """
    return self.prefix + str(self.value)

</t>
<t tx="ekr.20081203092030.57">def _eq(self, other):
    """Compares two nodes for equality."""
    return (self.type, self.value) == (other.type, other.value)

</t>
<t tx="ekr.20081203092030.58">def clone(self):
    """Returns a cloned (deep) copy of self."""
    return Leaf(self.type, self.value,
                (self.prefix, (self.lineno, self.column)))

</t>
<t tx="ekr.20081203092030.59">def post_order(self):
    """Returns a post-order iterator for the tree."""
    yield self

</t>
<t tx="ekr.20081203092030.60">def pre_order(self):
    """Returns a pre-order iterator for the tree."""
    yield self

</t>
<t tx="ekr.20081203092030.61">def set_prefix(self, prefix):
    """Sets the prefix for the node."""
    self.changed()
    self.prefix = prefix

</t>
<t tx="ekr.20081203092030.62">def get_prefix(self):
    """Returns the prefix for the node."""
    return self.prefix


</t>
<t tx="ekr.20081203092030.63">def convert(gr, raw_node):
    """Converts raw node information to a Node or Leaf instance.

    This is passed to the parser driver which calls it whenever a
    reduction of a grammar rule produces a new complete node, so that
    the tree is build strictly bottom-up.
    """
    type, value, context, children = raw_node
    if children or type in gr.number2symbol:
        # If there's exactly one child, return that child instead of
        # creating a new node.
        if len(children) == 1:
            return children[0]
        return Node(type, children, context=context)
    else:
        return Leaf(type, value, context=context)


</t>
<t tx="ekr.20081203092030.64">class BasePattern(object):

    """A pattern is a tree matching pattern.

    It looks for a specific node type (token or symbol), and
    optionally for a specific content.

    This is an abstract base class.  There are three concrete
    subclasses:

    - LeafPattern matches a single leaf node;
    - NodePattern matches a single node (usually non-leaf);
    - WildcardPattern matches a sequence of nodes of variable length.
    """

    # Defaults for instance variables
    type = None     # Node type (token if &lt; 256, symbol if &gt;= 256)
    content = None  # Optional content matching pattern
    name = None     # Optional name used to store match in results dict

    @others
</t>
<t tx="ekr.20081203092030.65">def __new__(cls, *args, **kwds):
    """Constructor that prevents BasePattern from being instantiated."""
    assert cls is not BasePattern, "Cannot instantiate BasePattern"
    return object.__new__(cls)

</t>
<t tx="ekr.20081203092030.66">def __repr__(self):
    args = [type_repr(self.type), self.content, self.name]
    while args and args[-1] is None:
        del args[-1]
    return "%s(%s)" % (self.__class__.__name__, ", ".join(map(repr, args)))

</t>
<t tx="ekr.20081203092030.67">def optimize(self):
    """A subclass can define this as a hook for optimizations.

    Returns either self or another node with the same effect.
    """
    return self

</t>
<t tx="ekr.20081203092030.68">def match(self, node, results=None):
    """Does this pattern exactly match a node?

    Returns True if it matches, False if not.

    If results is not None, it must be a dict which will be
    updated with the nodes matching named subpatterns.

    Default implementation for non-wildcard patterns.
    """
    if self.type is not None and node.type != self.type:
        return False
    if self.content is not None:
        r = None
        if results is not None:
            r = {}
        if not self._submatch(node, r):
            return False
        if r:
            results.update(r)
    if results is not None and self.name:
        results[self.name] = node
    return True

</t>
<t tx="ekr.20081203092030.69">def match_seq(self, nodes, results=None):
    """Does this pattern exactly match a sequence of nodes?

    Default implementation for non-wildcard patterns.
    """
    if len(nodes) != 1:
        return False
    return self.match(nodes[0], results)

</t>
<t tx="ekr.20081203092030.70">def generate_matches(self, nodes):
    """Generator yielding all matches for this pattern.

    Default implementation for non-wildcard patterns.
    """
    r = {}
    if nodes and self.match(nodes[0], r):
        yield 1, r


</t>
<t tx="ekr.20081203092030.71">class LeafPattern(BasePattern):
    @others
</t>
<t tx="ekr.20081203092030.72">
def __init__(self, type=None, content=None, name=None):
    """Initializer.  Takes optional type, content, and name.

    The type, if given must be a token type (&lt; 256).  If not given,
    this matches any *leaf* node; the content may still be required.

    The content, if given, must be a string.

    If a name is given, the matching node is stored in the results
    dict under that key.
    """
    if type is not None:
        assert 0 &lt;= type &lt; 256, type
    if content is not None:
        assert isinstance(content, basestring), repr(content)
    self.type = type
    self.content = content
    self.name = name

</t>
<t tx="ekr.20081203092030.73">def match(self, node, results=None):
    """Override match() to insist on a leaf node."""
    if not isinstance(node, Leaf):
        return False
    return BasePattern.match(self, node, results)

</t>
<t tx="ekr.20081203092030.74">def _submatch(self, node, results=None):
    """Match the pattern's content to the node's children.

    This assumes the node type matches and self.content is not None.

    Returns True if it matches, False if not.

    If results is not None, it must be a dict which will be
    updated with the nodes matching named subpatterns.

    When returning False, the results dict may still be updated.
    """
    return self.content == node.value


</t>
<t tx="ekr.20081203092030.75">class NodePattern(BasePattern):

    wildcards = False

    @others
</t>
<t tx="ekr.20081203092030.76">def __init__(self, type=None, content=None, name=None):
    """Initializer.  Takes optional type, content, and name.

    The type, if given, must be a symbol type (&gt;= 256).  If the
    type is None this matches *any* single node (leaf or not),
    except if content is not None, in which it only matches
    non-leaf nodes that also match the content pattern.

    The content, if not None, must be a sequence of Patterns that
    must match the node's children exactly.  If the content is
    given, the type must not be None.

    If a name is given, the matching node is stored in the results
    dict under that key.
    """
    if type is not None:
        assert type &gt;= 256, type
    if content is not None:
        assert not isinstance(content, basestring), repr(content)
        content = list(content)
        for i, item in enumerate(content):
            assert isinstance(item, BasePattern), (i, item)
            if isinstance(item, WildcardPattern):
                self.wildcards = True
    self.type = type
    self.content = content
    self.name = name

</t>
<t tx="ekr.20081203092030.77">def _submatch(self, node, results=None):
    """Match the pattern's content to the node's children.

    This assumes the node type matches and self.content is not None.

    Returns True if it matches, False if not.

    If results is not None, it must be a dict which will be
    updated with the nodes matching named subpatterns.

    When returning False, the results dict may still be updated.
    """
    if self.wildcards:
        for c, r in generate_matches(self.content, node.children):
            if c == len(node.children):
                if results is not None:
                    results.update(r)
                return True
        return False
    if len(self.content) != len(node.children):
        return False
    for subpattern, child in zip(self.content, node.children):
        if not subpattern.match(child, results):
            return False
    return True


</t>
<t tx="ekr.20081203092030.78">class WildcardPattern(BasePattern):

    """A wildcard pattern can match zero or more nodes.

    This has all the flexibility needed to implement patterns like:

    .*      .+      .?      .{m,n}
    (a b c | d e | f)
    (...)*  (...)+  (...)?  (...){m,n}

    except it always uses non-greedy matching.
    """
    @others
</t>
<t tx="ekr.20081203092030.79">
def __init__(self, content=None, min=0, max=HUGE, name=None):
    """Initializer.

    Args:
        content: optional sequence of subsequences of patterns;
                 if absent, matches one node;
                 if present, each subsequence is an alternative [*]
        min: optinal minumum number of times to match, default 0
        max: optional maximum number of times tro match, default HUGE
        name: optional name assigned to this match

    [*] Thus, if content is [[a, b, c], [d, e], [f, g, h]] this is
        equivalent to (a b c | d e | f g h); if content is None,
        this is equivalent to '.' in regular expression terms.
        The min and max parameters work as follows:
            min=0, max=maxint: .*
            min=1, max=maxint: .+
            min=0, max=1: .?
            min=1, max=1: .
        If content is not None, replace the dot with the parenthesized
        list of alternatives, e.g. (a b c | d e | f g h)*
    """
    assert 0 &lt;= min &lt;= max &lt;= HUGE, (min, max)
    if content is not None:
        content = tuple(map(tuple, content))  # Protect against alterations
        # Check sanity of alternatives
        assert len(content), repr(content)  # Can't have zero alternatives
        for alt in content:
            assert len(alt), repr(alt) # Can have empty alternatives
    self.content = content
    self.min = min
    self.max = max
    self.name = name

</t>
<t tx="ekr.20081203092030.80">def optimize(self):
    """Optimize certain stacked wildcard patterns."""
    subpattern = None
    if (self.content is not None and
        len(self.content) == 1 and len(self.content[0]) == 1):
        subpattern = self.content[0][0]
    if self.min == 1 and self.max == 1:
        if self.content is None:
            return NodePattern(name=self.name)
        if subpattern is not None and  self.name == subpattern.name:
            return subpattern.optimize()
    if (self.min &lt;= 1 and isinstance(subpattern, WildcardPattern) and
        subpattern.min &lt;= 1 and self.name == subpattern.name):
        return WildcardPattern(subpattern.content,
                               self.min*subpattern.min,
                               self.max*subpattern.max,
                               subpattern.name)
    return self

</t>
<t tx="ekr.20081203092030.81">def match(self, node, results=None):
    """Does this pattern exactly match a node?"""
    return self.match_seq([node], results)

</t>
<t tx="ekr.20081203092030.82">def match_seq(self, nodes, results=None):
    """Does this pattern exactly match a sequence of nodes?"""
    for c, r in self.generate_matches(nodes):
        if c == len(nodes):
            if results is not None:
                results.update(r)
                if self.name:
                    results[self.name] = list(nodes)
            return True
    return False

</t>
<t tx="ekr.20081203092030.83">def generate_matches(self, nodes):
    """Generator yielding matches for a sequence of nodes.

    Args:
        nodes: sequence of nodes

    Yields:
        (count, results) tuples where:
        count: the match comprises nodes[:count];
        results: dict containing named submatches.
    """
    if self.content is None:
        # Shortcut for special case (see __init__.__doc__)
        for count in xrange(self.min, 1 + min(len(nodes), self.max)):
            r = {}
            if self.name:
                r[self.name] = nodes[:count]
            yield count, r
    elif self.name == "bare_name":
        yield self._bare_name_matches(nodes)
    else:
        for count, r in self._recursive_matches(nodes, 0):
            if self.name:
                r[self.name] = nodes[:count]
            yield count, r

</t>
<t tx="ekr.20081203092030.84">def _bare_name_matches(self, nodes):
    """Special optimized matcher for bare_name."""
    count = 0
    r = {}
    done = False
    max = len(nodes)
    while not done and count &lt; max:
        done = True
        for leaf in self.content:
            if leaf[0].match(nodes[count], r):
                count += 1
                done = False
                break
    r[self.name] = nodes[:count]
    return count, r

</t>
<t tx="ekr.20081203092030.85">def _recursive_matches(self, nodes, count):
    """Helper to recursively yield the matches."""
    assert self.content is not None
    if count &gt;= self.min:
        yield 0, {}
    if count &lt; self.max:
        for alt in self.content:
            for c0, r0 in generate_matches(alt, nodes):
                for c1, r1 in self._recursive_matches(nodes[c0:], count+1):
                    r = {}
                    r.update(r0)
                    r.update(r1)
                    yield c0 + c1, r


</t>
<t tx="ekr.20081203092030.86">class NegatedPattern(BasePattern):
    @others
</t>
<t tx="ekr.20081203092030.87">
def __init__(self, content=None):
    """Initializer.

    The argument is either a pattern or None.  If it is None, this
    only matches an empty sequence (effectively '$' in regex
    lingo).  If it is not None, this matches whenever the argument
    pattern doesn't have any matches.
    """
    if content is not None:
        assert isinstance(content, BasePattern), repr(content)
    self.content = content

</t>
<t tx="ekr.20081203092030.88">def match(self, node):
    # We never match a node in its entirety
    return False

</t>
<t tx="ekr.20081203092030.89">def match_seq(self, nodes):
    # We only match an empty sequence of nodes in its entirety
    return len(nodes) == 0

</t>
<t tx="ekr.20081203092030.90">def generate_matches(self, nodes):
    if self.content is None:
        # Return a match if there is an empty sequence
        if len(nodes) == 0:
            yield 0, {}
    else:
        # Return a match if the argument pattern has no matches
        for c, r in self.content.generate_matches(nodes):
            return
        yield 0, {}


</t>
<t tx="ekr.20081203092030.91">def generate_matches(patterns, nodes):
    """Generator yielding matches for a sequence of patterns and nodes.

    Args:
        patterns: a sequence of patterns
        nodes: a sequence of nodes

    Yields:
        (count, results) tuples where:
        count: the entire sequence of patterns matches nodes[:count];
        results: dict containing named submatches.
        """
    if not patterns:
        yield 0, {}
    else:
        p, rest = patterns[0], patterns[1:]
        for c0, r0 in p.generate_matches(nodes):
            if not rest:
                yield c0, r0
            else:
                for c1, r1 in generate_matches(rest, nodes[c0:]):
                    r = {}
                    r.update(r0)
                    r.update(r1)
                    yield c0 + c1, r
</t>
<t tx="ekr.20081203092030.92"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Convert graminit.[ch] spit out by pgen to Python code.

Pgen is the Python parser generator.  It is useful to quickly create a
parser from a grammar file in Python's grammar notation.  But I don't
want my parsers to be written in C (yet), so I'm translating the
parsing tables to Python data structures and writing a Python parse
engine.

Note that the token numbers are constants determined by the standard
Python tokenizer.  The standard token module defines these numbers and
their names (the names are not used much).  The token numbers are
hardcoded into the Python tokenizer and into pgen.  A Python
implementation of the Python tokenizer is also available, in the
standard tokenize module.

On the other hand, symbol numbers (representing the grammar's
non-terminals) are assigned by pgen based on the actual grammar
input.

Note: this module is pretty much obsolete; the pgen module generates
equivalent grammar tables directly from the Grammar.txt input file
without having to invoke the Python pgen C program.

"""

# Python imports
import re

# Local imports
import grammar, token


</t>
<t tx="ekr.20081203092030.93">class Converter(grammar.Grammar):
    """Grammar subclass that reads classic pgen output files.

    The run() method reads the tables as produced by the pgen parser
    generator, typically contained in two C files, graminit.h and
    graminit.c.  The other methods are for internal use only.

    See the base class for more documentation.

    """
    @others
</t>
<t tx="ekr.20081203092030.94">
def run(self, graminit_h, graminit_c):
    """Load the grammar tables from the text files written by pgen."""
    self.parse_graminit_h(graminit_h)
    self.parse_graminit_c(graminit_c)
    self.finish_off()

</t>
<t tx="ekr.20081203092030.95">def parse_graminit_h(self, filename):
    """Parse the .h file writen by pgen.  (Internal)

    This file is a sequence of #define statements defining the
    nonterminals of the grammar as numbers.  We build two tables
    mapping the numbers to names and back.

    """
    try:
        f = open(filename)
    except IOError, err:
        print "Can't open %s: %s" % (filename, err)
        return False
    self.symbol2number = {}
    self.number2symbol = {}
    lineno = 0
    for line in f:
        lineno += 1
        mo = re.match(r"^#define\s+(\w+)\s+(\d+)$", line)
        if not mo and line.strip():
            print "%s(%s): can't parse %s" % (filename, lineno,
                                              line.strip())
        else:
            symbol, number = mo.groups()
            number = int(number)
            assert symbol not in self.symbol2number
            assert number not in self.number2symbol
            self.symbol2number[symbol] = number
            self.number2symbol[number] = symbol
    return True

</t>
<t tx="ekr.20081203092030.96">def parse_graminit_c(self, filename):
    """Parse the .c file writen by pgen.  (Internal)

    The file looks as follows.  The first two lines are always this:

    #include "pgenheaders.h"
    #include "grammar.h"

    After that come four blocks:

    1) one or more state definitions
    2) a table defining dfas
    3) a table defining labels
    4) a struct defining the grammar

    A state definition has the following form:
    - one or more arc arrays, each of the form:
      static arc arcs_&lt;n&gt;_&lt;m&gt;[&lt;k&gt;] = {
              {&lt;i&gt;, &lt;j&gt;},
              ...
      };
    - followed by a state array, of the form:
      static state states_&lt;s&gt;[&lt;t&gt;] = {
              {&lt;k&gt;, arcs_&lt;n&gt;_&lt;m&gt;},
              ...
      };

    """
    try:
        f = open(filename)
    except IOError, err:
        print "Can't open %s: %s" % (filename, err)
        return False
    # The code below essentially uses f's iterator-ness!
    lineno = 0

    # Expect the two #include lines
    lineno, line = lineno+1, f.next()
    assert line == '#include "pgenheaders.h"\n', (lineno, line)
    lineno, line = lineno+1, f.next()
    assert line == '#include "grammar.h"\n', (lineno, line)

    # Parse the state definitions
    lineno, line = lineno+1, f.next()
    allarcs = {}
    states = []
    while line.startswith("static arc "):
        while line.startswith("static arc "):
            mo = re.match(r"static arc arcs_(\d+)_(\d+)\[(\d+)\] = {$",
                          line)
            assert mo, (lineno, line)
            n, m, k = map(int, mo.groups())
            arcs = []
            for _ in range(k):
                lineno, line = lineno+1, f.next()
                mo = re.match(r"\s+{(\d+), (\d+)},$", line)
                assert mo, (lineno, line)
                i, j = map(int, mo.groups())
                arcs.append((i, j))
            lineno, line = lineno+1, f.next()
            assert line == "};\n", (lineno, line)
            allarcs[(n, m)] = arcs
            lineno, line = lineno+1, f.next()
        mo = re.match(r"static state states_(\d+)\[(\d+)\] = {$", line)
        assert mo, (lineno, line)
        s, t = map(int, mo.groups())
        assert s == len(states), (lineno, line)
        state = []
        for _ in range(t):
            lineno, line = lineno+1, f.next()
            mo = re.match(r"\s+{(\d+), arcs_(\d+)_(\d+)},$", line)
            assert mo, (lineno, line)
            k, n, m = map(int, mo.groups())
            arcs = allarcs[n, m]
            assert k == len(arcs), (lineno, line)
            state.append(arcs)
        states.append(state)
        lineno, line = lineno+1, f.next()
        assert line == "};\n", (lineno, line)
        lineno, line = lineno+1, f.next()
    self.states = states

    # Parse the dfas
    dfas = {}
    mo = re.match(r"static dfa dfas\[(\d+)\] = {$", line)
    assert mo, (lineno, line)
    ndfas = int(mo.group(1))
    for i in range(ndfas):
        lineno, line = lineno+1, f.next()
        mo = re.match(r'\s+{(\d+), "(\w+)", (\d+), (\d+), states_(\d+),$',
                      line)
        assert mo, (lineno, line)
        symbol = mo.group(2)
        number, x, y, z = map(int, mo.group(1, 3, 4, 5))
        assert self.symbol2number[symbol] == number, (lineno, line)
        assert self.number2symbol[number] == symbol, (lineno, line)
        assert x == 0, (lineno, line)
        state = states[z]
        assert y == len(state), (lineno, line)
        lineno, line = lineno+1, f.next()
        mo = re.match(r'\s+("(?:\\\d\d\d)*")},$', line)
        assert mo, (lineno, line)
        first = {}
        rawbitset = eval(mo.group(1))
        for i, c in enumerate(rawbitset):
            byte = ord(c)
            for j in range(8):
                if byte &amp; (1&lt;&lt;j):
                    first[i*8 + j] = 1
        dfas[number] = (state, first)
    lineno, line = lineno+1, f.next()
    assert line == "};\n", (lineno, line)
    self.dfas = dfas

    # Parse the labels
    labels = []
    lineno, line = lineno+1, f.next()
    mo = re.match(r"static label labels\[(\d+)\] = {$", line)
    assert mo, (lineno, line)
    nlabels = int(mo.group(1))
    for i in range(nlabels):
        lineno, line = lineno+1, f.next()
        mo = re.match(r'\s+{(\d+), (0|"\w+")},$', line)
        assert mo, (lineno, line)
        x, y = mo.groups()
        x = int(x)
        if y == "0":
            y = None
        else:
            y = eval(y)
        labels.append((x, y))
    lineno, line = lineno+1, f.next()
    assert line == "};\n", (lineno, line)
    self.labels = labels

    # Parse the grammar struct
    lineno, line = lineno+1, f.next()
    assert line == "grammar _PyParser_Grammar = {\n", (lineno, line)
    lineno, line = lineno+1, f.next()
    mo = re.match(r"\s+(\d+),$", line)
    assert mo, (lineno, line)
    ndfas = int(mo.group(1))
    assert ndfas == len(self.dfas)
    lineno, line = lineno+1, f.next()
    assert line == "\tdfas,\n", (lineno, line)
    lineno, line = lineno+1, f.next()
    mo = re.match(r"\s+{(\d+), labels},$", line)
    assert mo, (lineno, line)
    nlabels = int(mo.group(1))
    assert nlabels == len(self.labels), (lineno, line)
    lineno, line = lineno+1, f.next()
    mo = re.match(r"\s+(\d+)$", line)
    assert mo, (lineno, line)
    start = int(mo.group(1))
    assert start in self.number2symbol, (lineno, line)
    self.start = start
    lineno, line = lineno+1, f.next()
    assert line == "};\n", (lineno, line)
    try:
        lineno, line = lineno+1, f.next()
    except StopIteration:
        pass
    else:
        assert 0, (lineno, line)

</t>
<t tx="ekr.20081203092030.97">def finish_off(self):
    """Create additional useful structures.  (Internal)."""
    self.keywords = {} # map from keyword strings to arc labels
    self.tokens = {}   # map from numeric token values to arc labels
    for ilabel, (type, value) in enumerate(self.labels):
        if type == token.NAME and value is not None:
            self.keywords[value] = ilabel
        elif value is None:
            self.tokens[type] = ilabel
</t>
<t tx="ekr.20081203092030.98"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

# Modifications:
# Copyright 2006 Google, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Parser driver.

This provides a high-level interface to parse a file into a syntax tree.

"""

__author__ = "Guido van Rossum &lt;guido@python.org&gt;"

__all__ = ["Driver", "load_grammar"]

# Python imports
import os
import logging
import sys

# Pgen imports
import grammar, parse, token, tokenize, pgen


</t>
<t tx="ekr.20081203092030.99">class Driver(object):
    @others
</t>
<t tx="ekr.20081203092030.100">
def __init__(self, grammar, convert=None, logger=None):
    self.grammar = grammar
    if logger is None:
        logger = logging.getLogger()
    self.logger = logger
    self.convert = convert

</t>
<t tx="ekr.20081203092030.101">def parse_tokens(self, tokens, debug=False):
    """Parse a series of tokens and return the syntax tree."""
    # XXX Move the prefix computation into a wrapper around tokenize.
    p = parse.Parser(self.grammar, self.convert)
    p.setup()
    lineno = 1
    column = 0
    type = value = start = end = line_text = None
    prefix = ""
    for quintuple in tokens:
        type, value, start, end, line_text = quintuple
        if start != (lineno, column):
            assert (lineno, column) &lt;= start, ((lineno, column), start)
            s_lineno, s_column = start
            if lineno &lt; s_lineno:
                prefix += "\n" * (s_lineno - lineno)
                lineno = s_lineno
                column = 0
            if column &lt; s_column:
                prefix += line_text[column:s_column]
                column = s_column
        if type in (tokenize.COMMENT, tokenize.NL):
            prefix += value
            lineno, column = end
            if value.endswith("\n"):
                lineno += 1
                column = 0
            continue
        if type == token.OP:
            type = grammar.opmap[value]
        if debug:
            self.logger.debug("%s %r (prefix=%r)",
                              token.tok_name[type], value, prefix)
        if p.addtoken(type, value, (prefix, start)):
            if debug:
                self.logger.debug("Stop.")
            break
        prefix = ""
        lineno, column = end
        if value.endswith("\n"):
            lineno += 1
            column = 0
    else:
        # We never broke out -- EOF is too soon (how can this happen???)
        raise parse.ParseError("incomplete input", t, v, x)
    return p.rootnode

</t>
<t tx="ekr.20081203092030.102">def parse_stream_raw(self, stream, debug=False):
    """Parse a stream and return the syntax tree."""
    tokens = tokenize.generate_tokens(stream.readline)
    return self.parse_tokens(tokens, debug)

</t>
<t tx="ekr.20081203092030.103">def parse_stream(self, stream, debug=False):
    """Parse a stream and return the syntax tree."""
    return self.parse_stream_raw(stream, debug)

</t>
<t tx="ekr.20081203092030.104">def parse_file(self, filename, debug=False):
    """Parse a file and return the syntax tree."""
    stream = open(filename)
    try:
        return self.parse_stream(stream, debug)
    finally:
        stream.close()

</t>
<t tx="ekr.20081203092030.105">def parse_string(self, text, debug=False):
    """Parse a string and return the syntax tree."""
    tokens = tokenize.generate_tokens(generate_lines(text).next)
    return self.parse_tokens(tokens, debug)


</t>
<t tx="ekr.20081203092030.106">def generate_lines(text):
    """Generator that behaves like readline without using StringIO."""
    for line in text.splitlines(True):
        yield line
    while True:
        yield ""


</t>
<t tx="ekr.20081203092030.107">def load_grammar(gt="Grammar.txt", gp=None,
                 save=True, force=False, logger=None):
    """Load the grammar (maybe from a pickle)."""
    if logger is None:
        logger = logging.getLogger()
    if gp is None:
        head, tail = os.path.splitext(gt)
        if tail == ".txt":
            tail = ""
        gp = head + tail + ".".join(map(str, sys.version_info)) + ".pickle"
    if force or not _newer(gp, gt):
        logger.info("Generating grammar tables from %s", gt)
        g = pgen.generate_grammar(gt)
        if save:
            logger.info("Writing grammar tables to %s", gp)
            try:
                g.dump(gp)
            except IOError, e:
                logger.info("Writing failed:"+str(e))
    else:
        g = grammar.Grammar()
        g.load(gp)
    return g


</t>
<t tx="ekr.20081203092030.108">def _newer(a, b):
    """Inquire whether file a was written since file b."""
    if not os.path.exists(a):
        return False
    if not os.path.exists(b):
        return True
    return os.path.getmtime(a) &gt;= os.path.getmtime(b)
</t>
<t tx="ekr.20081203092030.109"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Safely evaluate Python string literals without using eval()."""

import re

simple_escapes = {"a": "\a",
                  "b": "\b",
                  "f": "\f",
                  "n": "\n",
                  "r": "\r",
                  "t": "\t",
                  "v": "\v",
                  "'": "'",
                  '"': '"',
                  "\\": "\\"}

</t>
<t tx="ekr.20081203092030.110">def escape(m):
    all, tail = m.group(0, 1)
    assert all.startswith("\\")
    esc = simple_escapes.get(tail)
    if esc is not None:
        return esc
    if tail.startswith("x"):
        hexes = tail[1:]
        if len(hexes) &lt; 2:
            raise ValueError("invalid hex string escape ('\\%s')" % tail)
        try:
            i = int(hexes, 16)
        except ValueError:
            raise ValueError("invalid hex string escape ('\\%s')" % tail)
    else:
        try:
            i = int(tail, 8)
        except ValueError:
            raise ValueError("invalid octal string escape ('\\%s')" % tail)
    return chr(i)

</t>
<t tx="ekr.20081203092030.111">def evalString(s):
    assert s.startswith("'") or s.startswith('"'), repr(s[:1])
    q = s[0]
    if s[:3] == q*3:
        q = q*3
    assert s.endswith(q), repr(s[-len(q):])
    assert len(s) &gt;= 2*len(q)
    s = s[len(q):-len(q)]
    return re.sub(r"\\(\'|\"|\\|[abfnrtv]|x.{0,2}|[0-7]{1,3})", escape, s)

</t>
<t tx="ekr.20081203092030.112">def test():
    for i in range(256):
        c = chr(i)
        s = repr(c)
        e = evalString(s)
        if e != c:
            print i, c, s, e


</t>
<t tx="ekr.20081203092030.113"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Parser engine for the grammar tables generated by pgen.

The grammar table must be loaded first.

See Parser/parser.c in the Python distribution for additional info on
how this parsing engine works.

"""

# Get a usable 'set' constructor
try:
    set
except NameError:
    from sets import Set as set

# Local imports
import token

</t>
<t tx="ekr.20081203092030.114">class ParseError(Exception):
    """Exception to signal the parser is stuck."""
    @others
</t>
<t tx="ekr.20081203092030.115">
def __init__(self, msg, type, value, context):
    Exception.__init__(self, "%s: type=%r, value=%r, context=%r" %
                       (msg, type, value, context))
    self.msg = msg
    self.type = type
    self.value = value
    self.context = context

</t>
<t tx="ekr.20081203092030.116">def __reduce__(self):
    """Implemented so pickle can serialize this object.

    &gt;&gt;&gt; import pickle
    &gt;&gt;&gt; pickle.loads(pickle.dumps(ParseError(1, 2, 3, 4)))
    ParseError('1: type=2, value=3, context=4',)
    """
    return (ParseError, (self.msg, self.type, self.value, self.context))

</t>
<t tx="ekr.20081203092030.117">class Parser(object):
    """Parser engine.

    The proper usage sequence is:

    p = Parser(grammar, [converter])  # create instance
    p.setup([start])                  # prepare for parsing
    &lt;for each input token&gt;:
        if p.addtoken(...):           # parse a token; may raise ParseError
            break
    root = p.rootnode                 # root of abstract syntax tree

    A Parser instance may be reused by calling setup() repeatedly.

    A Parser instance contains state pertaining to the current token
    sequence, and should not be used concurrently by different threads
    to parse separate token sequences.

    See driver.py for how to get input tokens by tokenizing a file or
    string.

    Parsing is complete when addtoken() returns True; the root of the
    abstract syntax tree can then be retrieved from the rootnode
    instance variable.  When a syntax error occurs, addtoken() raises
    the ParseError exception.  There is no error recovery; the parser
    cannot be used after a syntax error was reported (but it can be
    reinitialized by calling setup()).

    """
    @others
</t>
<t tx="ekr.20081203092030.118">
def __init__(self, grammar, convert=None):
    """Constructor.

    The grammar argument is a grammar.Grammar instance; see the
    grammar module for more information.

    The parser is not ready yet for parsing; you must call the
    setup() method to get it started.

    The optional convert argument is a function mapping concrete
    syntax tree nodes to abstract syntax tree nodes.  If not
    given, no conversion is done and the syntax tree produced is
    the concrete syntax tree.  If given, it must be a function of
    two arguments, the first being the grammar (a grammar.Grammar
    instance), and the second being the concrete syntax tree node
    to be converted.  The syntax tree is converted from the bottom
    up.

    A concrete syntax tree node is a (type, value, context, nodes)
    tuple, where type is the node type (a token or symbol number),
    value is None for symbols and a string for tokens, context is
    None or an opaque value used for error reporting (typically a
    (lineno, offset) pair), and nodes is a list of children for
    symbols, and None for tokens.

    An abstract syntax tree node may be anything; this is entirely
    up to the converter function.

    """
    self.grammar = grammar
    self.convert = convert or (lambda grammar, node: node)

</t>
<t tx="ekr.20081203092030.119">def setup(self, start=None):
    """Prepare for parsing.

    This *must* be called before starting to parse.

    The optional argument is an alternative start symbol; it
    defaults to the grammar's start symbol.

    You can use a Parser instance to parse any number of programs;
    each time you call setup() the parser is reset to an initial
    state determined by the (implicit or explicit) start symbol.

    """
    if start is None:
        start = self.grammar.start
    # Each stack entry is a tuple: (dfa, state, node).
    # A node is a tuple: (type, value, context, children),
    # where children is a list of nodes or None, and context may be None.
    newnode = (start, None, None, [])
    stackentry = (self.grammar.dfas[start], 0, newnode)
    self.stack = [stackentry]
    self.rootnode = None
    self.used_names = set() # Aliased to self.rootnode.used_names in pop()

</t>
<t tx="ekr.20081203092030.120">def addtoken(self, type, value, context):
    """Add a token; return True iff this is the end of the program."""
    # Map from token to label
    ilabel = self.classify(type, value, context)
    # Loop until the token is shifted; may raise exceptions
    while True:
        dfa, state, node = self.stack[-1]
        states, first = dfa
        arcs = states[state]
        # Look for a state with this label
        for i, newstate in arcs:
            t, v = self.grammar.labels[i]
            if ilabel == i:
                # Look it up in the list of labels
                assert t &lt; 256
                # Shift a token; we're done with it
                self.shift(type, value, newstate, context)
                # Pop while we are in an accept-only state
                state = newstate
                while states[state] == [(0, state)]:
                    self.pop()
                    if not self.stack:
                        # Done parsing!
                        return True
                    dfa, state, node = self.stack[-1]
                    states, first = dfa
                # Done with this token
                return False
            elif t &gt;= 256:
                # See if it's a symbol and if we're in its first set
                itsdfa = self.grammar.dfas[t]
                itsstates, itsfirst = itsdfa
                if ilabel in itsfirst:
                    # Push a symbol
                    self.push(t, self.grammar.dfas[t], newstate, context)
                    break # To continue the outer while loop
        else:
            if (0, state) in arcs:
                # An accepting state, pop it and try something else
                self.pop()
                if not self.stack:
                    # Done parsing, but another token is input
                    raise ParseError("too much input",
                                     type, value, context)
            else:
                # No success finding a transition
                raise ParseError("bad input", type, value, context)

</t>
<t tx="ekr.20081203092030.121">def classify(self, type, value, context):
    """Turn a token into a label.  (Internal)"""
    if type == token.NAME:
        # Keep a listing of all used names
        self.used_names.add(value)
        # Check for reserved words
        ilabel = self.grammar.keywords.get(value)
        if ilabel is not None:
            return ilabel
    ilabel = self.grammar.tokens.get(type)
    if ilabel is None:
        raise ParseError("bad token", type, value, context)
    return ilabel

</t>
<t tx="ekr.20081203092030.122">def shift(self, type, value, newstate, context):
    """Shift a token.  (Internal)"""
    dfa, state, node = self.stack[-1]
    newnode = (type, value, context, None)
    newnode = self.convert(self.grammar, newnode)
    if newnode is not None:
        node[-1].append(newnode)
    self.stack[-1] = (dfa, newstate, node)

</t>
<t tx="ekr.20081203092030.123">def push(self, type, newdfa, newstate, context):
    """Push a nonterminal.  (Internal)"""
    dfa, state, node = self.stack[-1]
    newnode = (type, None, context, [])
    self.stack[-1] = (dfa, newstate, node)
    self.stack.append((newdfa, 0, newnode))

</t>
<t tx="ekr.20081203092030.124">def pop(self):
    """Pop a nonterminal.  (Internal)"""
    popdfa, popstate, popnode = self.stack.pop()
    newnode = self.convert(self.grammar, popnode)
    if newnode is not None:
        if self.stack:
            dfa, state, node = self.stack[-1]
            node[-1].append(newnode)
        else:
            self.rootnode = newnode
            self.rootnode.used_names = self.used_names
</t>
<t tx="ekr.20081203092030.125"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

# Pgen imports
import grammar, token, tokenize

</t>
<t tx="ekr.20081203092030.126">class PgenGrammar(grammar.Grammar):
    pass

</t>
<t tx="ekr.20081203092030.127">class ParserGenerator(object):
    @others
</t>
<t tx="ekr.20081203092030.128">
def __init__(self, filename, stream=None):
    close_stream = None
    if stream is None:
        stream = open(filename)
        close_stream = stream.close
    self.filename = filename
    self.stream = stream
    self.generator = tokenize.generate_tokens(stream.readline)
    self.gettoken() # Initialize lookahead
    self.dfas, self.startsymbol = self.parse()
    if close_stream is not None:
        close_stream()
    self.first = {} # map from symbol name to set of tokens
    self.addfirstsets()

</t>
<t tx="ekr.20081203092030.129">def make_grammar(self):
    c = PgenGrammar()
    names = self.dfas.keys()
    names.sort()
    names.remove(self.startsymbol)
    names.insert(0, self.startsymbol)
    for name in names:
        i = 256 + len(c.symbol2number)
        c.symbol2number[name] = i
        c.number2symbol[i] = name
    for name in names:
        dfa = self.dfas[name]
        states = []
        for state in dfa:
            arcs = []
            for label, next in state.arcs.iteritems():
                arcs.append((self.make_label(c, label), dfa.index(next)))
            if state.isfinal:
                arcs.append((0, dfa.index(state)))
            states.append(arcs)
        c.states.append(states)
        c.dfas[c.symbol2number[name]] = (states, self.make_first(c, name))
    c.start = c.symbol2number[self.startsymbol]
    return c

</t>
<t tx="ekr.20081203092030.130">def make_first(self, c, name):
    rawfirst = self.first[name]
    first = {}
    for label in rawfirst:
        ilabel = self.make_label(c, label)
        ##assert ilabel not in first # XXX failed on &lt;&gt; ... !=
        first[ilabel] = 1
    return first

</t>
<t tx="ekr.20081203092030.131">def make_label(self, c, label):
    # XXX Maybe this should be a method on a subclass of converter?
    ilabel = len(c.labels)
    if label[0].isalpha():
        # Either a symbol name or a named token
        if label in c.symbol2number:
            # A symbol name (a non-terminal)
            if label in c.symbol2label:
                return c.symbol2label[label]
            else:
                c.labels.append((c.symbol2number[label], None))
                c.symbol2label[label] = ilabel
                return ilabel
        else:
            # A named token (NAME, NUMBER, STRING)
            itoken = getattr(token, label, None)
            assert isinstance(itoken, int), label
            assert itoken in token.tok_name, label
            if itoken in c.tokens:
                return c.tokens[itoken]
            else:
                c.labels.append((itoken, None))
                c.tokens[itoken] = ilabel
                return ilabel
    else:
        # Either a keyword or an operator
        assert label[0] in ('"', "'"), label
        value = eval(label)
        if value[0].isalpha():
            # A keyword
            if value in c.keywords:
                return c.keywords[value]
            else:
                c.labels.append((token.NAME, value))
                c.keywords[value] = ilabel
                return ilabel
        else:
            # An operator (any non-numeric token)
            itoken = grammar.opmap[value] # Fails if unknown token
            if itoken in c.tokens:
                return c.tokens[itoken]
            else:
                c.labels.append((itoken, None))
                c.tokens[itoken] = ilabel
                return ilabel

</t>
<t tx="ekr.20081203092030.132">def addfirstsets(self):
    names = self.dfas.keys()
    names.sort()
    for name in names:
        if name not in self.first:
            self.calcfirst(name)
        #print name, self.first[name].keys()

</t>
<t tx="ekr.20081203092030.133">def calcfirst(self, name):
    dfa = self.dfas[name]
    self.first[name] = None # dummy to detect left recursion
    state = dfa[0]
    totalset = {}
    overlapcheck = {}
    for label, next in state.arcs.iteritems():
        if label in self.dfas:
            if label in self.first:
                fset = self.first[label]
                if fset is None:
                    raise ValueError("recursion for rule %r" % name)
            else:
                self.calcfirst(label)
                fset = self.first[label]
            totalset.update(fset)
            overlapcheck[label] = fset
        else:
            totalset[label] = 1
            overlapcheck[label] = {label: 1}
    inverse = {}
    for label, itsfirst in overlapcheck.iteritems():
        for symbol in itsfirst:
            if symbol in inverse:
                raise ValueError("rule %s is ambiguous; %s is in the"
                                 " first sets of %s as well as %s" %
                                 (name, symbol, label, inverse[symbol]))
            inverse[symbol] = label
    self.first[name] = totalset

</t>
<t tx="ekr.20081203092030.134">def parse(self):
    dfas = {}
    startsymbol = None
    # MSTART: (NEWLINE | RULE)* ENDMARKER
    while self.type != token.ENDMARKER:
        while self.type == token.NEWLINE:
            self.gettoken()
        # RULE: NAME ':' RHS NEWLINE
        name = self.expect(token.NAME)
        self.expect(token.OP, ":")
        a, z = self.parse_rhs()
        self.expect(token.NEWLINE)
        #self.dump_nfa(name, a, z)
        dfa = self.make_dfa(a, z)
        #self.dump_dfa(name, dfa)
        oldlen = len(dfa)
        self.simplify_dfa(dfa)
        newlen = len(dfa)
        dfas[name] = dfa
        #print name, oldlen, newlen
        if startsymbol is None:
            startsymbol = name
    return dfas, startsymbol

</t>
<t tx="ekr.20081203092030.135">def make_dfa(self, start, finish):
    # To turn an NFA into a DFA, we define the states of the DFA
    # to correspond to *sets* of states of the NFA.  Then do some
    # state reduction.  Let's represent sets as dicts with 1 for
    # values.
    assert isinstance(start, NFAState)
    assert isinstance(finish, NFAState)
    def closure(state):
        base = {}
        addclosure(state, base)
        return base
    def addclosure(state, base):
        assert isinstance(state, NFAState)
        if state in base:
            return
        base[state] = 1
        for label, next in state.arcs:
            if label is None:
                addclosure(next, base)
    states = [DFAState(closure(start), finish)]
    for state in states: # NB states grows while we're iterating
        arcs = {}
        for nfastate in state.nfaset:
            for label, next in nfastate.arcs:
                if label is not None:
                    addclosure(next, arcs.setdefault(label, {}))
        for label, nfaset in arcs.iteritems():
            for st in states:
                if st.nfaset == nfaset:
                    break
            else:
                st = DFAState(nfaset, finish)
                states.append(st)
            state.addarc(st, label)
    return states # List of DFAState instances; first one is start

</t>
<t tx="ekr.20081203092030.136">def dump_nfa(self, name, start, finish):
    print "Dump of NFA for", name
    todo = [start]
    for i, state in enumerate(todo):
        print "  State", i, state is finish and "(final)" or ""
        for label, next in state.arcs:
            if next in todo:
                j = todo.index(next)
            else:
                j = len(todo)
                todo.append(next)
            if label is None:
                print "    -&gt; %d" % j
            else:
                print "    %s -&gt; %d" % (label, j)

</t>
<t tx="ekr.20081203092030.137">def dump_dfa(self, name, dfa):
    print "Dump of DFA for", name
    for i, state in enumerate(dfa):
        print "  State", i, state.isfinal and "(final)" or ""
        for label, next in state.arcs.iteritems():
            print "    %s -&gt; %d" % (label, dfa.index(next))

</t>
<t tx="ekr.20081203092030.138">def simplify_dfa(self, dfa):
    # This is not theoretically optimal, but works well enough.
    # Algorithm: repeatedly look for two states that have the same
    # set of arcs (same labels pointing to the same nodes) and
    # unify them, until things stop changing.

    # dfa is a list of DFAState instances
    changes = True
    while changes:
        changes = False
        for i, state_i in enumerate(dfa):
            for j in range(i+1, len(dfa)):
                state_j = dfa[j]
                if state_i == state_j:
                    #print "  unify", i, j
                    del dfa[j]
                    for state in dfa:
                        state.unifystate(state_j, state_i)
                    changes = True
                    break

</t>
<t tx="ekr.20081203092030.139">def parse_rhs(self):
    # RHS: ALT ('|' ALT)*
    a, z = self.parse_alt()
    if self.value != "|":
        return a, z
    else:
        aa = NFAState()
        zz = NFAState()
        aa.addarc(a)
        z.addarc(zz)
        while self.value == "|":
            self.gettoken()
            a, z = self.parse_alt()
            aa.addarc(a)
            z.addarc(zz)
        return aa, zz

</t>
<t tx="ekr.20081203092030.140">def parse_alt(self):
    # ALT: ITEM+
    a, b = self.parse_item()
    while (self.value in ("(", "[") or
           self.type in (token.NAME, token.STRING)):
        c, d = self.parse_item()
        b.addarc(c)
        b = d
    return a, b

</t>
<t tx="ekr.20081203092030.141">def parse_item(self):
    # ITEM: '[' RHS ']' | ATOM ['+' | '*']
    if self.value == "[":
        self.gettoken()
        a, z = self.parse_rhs()
        self.expect(token.OP, "]")
        a.addarc(z)
        return a, z
    else:
        a, z = self.parse_atom()
        value = self.value
        if value not in ("+", "*"):
            return a, z
        self.gettoken()
        z.addarc(a)
        if value == "+":
            return a, z
        else:
            return a, a

</t>
<t tx="ekr.20081203092030.142">def parse_atom(self):
    # ATOM: '(' RHS ')' | NAME | STRING
    if self.value == "(":
        self.gettoken()
        a, z = self.parse_rhs()
        self.expect(token.OP, ")")
        return a, z
    elif self.type in (token.NAME, token.STRING):
        a = NFAState()
        z = NFAState()
        a.addarc(z, self.value)
        self.gettoken()
        return a, z
    else:
        self.raise_error("expected (...) or NAME or STRING, got %s/%s",
                         self.type, self.value)

</t>
<t tx="ekr.20081203092030.143">def expect(self, type, value=None):
    if self.type != type or (value is not None and self.value != value):
        self.raise_error("expected %s/%s, got %s/%s",
                         type, value, self.type, self.value)
    value = self.value
    self.gettoken()
    return value

</t>
<t tx="ekr.20081203092030.144">def gettoken(self):
    tup = self.generator.next()
    while tup[0] in (tokenize.COMMENT, tokenize.NL):
        tup = self.generator.next()
    self.type, self.value, self.begin, self.end, self.line = tup
    #print token.tok_name[self.type], repr(self.value)

</t>
<t tx="ekr.20081203092030.145">def raise_error(self, msg, *args):
    if args:
        try:
            msg = msg % args
        except:
            msg = " ".join([msg] + map(str, args))
    raise SyntaxError(msg, (self.filename, self.end[0],
                            self.end[1], self.line))

</t>
<t tx="ekr.20081203092030.146">class NFAState(object):
    @others
</t>
<t tx="ekr.20081203092030.147">
def __init__(self):
    self.arcs = [] # list of (label, NFAState) pairs

</t>
<t tx="ekr.20081203092030.148">def addarc(self, next, label=None):
    assert label is None or isinstance(label, str)
    assert isinstance(next, NFAState)
    self.arcs.append((label, next))

</t>
<t tx="ekr.20081203092030.149">class DFAState(object):
    @others
</t>
<t tx="ekr.20081203092030.150">
def __init__(self, nfaset, final):
    assert isinstance(nfaset, dict)
    assert isinstance(iter(nfaset).next(), NFAState)
    assert isinstance(final, NFAState)
    self.nfaset = nfaset
    self.isfinal = final in nfaset
    self.arcs = {} # map from label to DFAState

</t>
<t tx="ekr.20081203092030.151">def addarc(self, next, label):
    assert isinstance(label, str)
    assert label not in self.arcs
    assert isinstance(next, DFAState)
    self.arcs[label] = next

</t>
<t tx="ekr.20081203092030.152">def unifystate(self, old, new):
    for label, next in self.arcs.iteritems():
        if next is old:
            self.arcs[label] = new

</t>
<t tx="ekr.20081203092030.153">def __eq__(self, other):
    # Equality test -- ignore the nfaset instance variable
    assert isinstance(other, DFAState)
    if self.isfinal != other.isfinal:
        return False
    # Can't just return self.arcs == other.arcs, because that
    # would invoke this method recursively, with cycles...
    if len(self.arcs) != len(other.arcs):
        return False
    for label, next in self.arcs.iteritems():
        if next is not other.arcs.get(label):
            return False
    return True

</t>
<t tx="ekr.20081203092030.154">def generate_grammar(filename="Grammar.txt"):
    p = ParserGenerator(filename)
    return p.make_grammar()
</t>
<t tx="ekr.20081203092030.155">#! /usr/bin/env python

"""Token constants (from "token.h")."""

#  Taken from Python (r53757) and modified to include some tokens
#   originally monkeypatched in by pgen2.tokenize

#--start constants--
ENDMARKER = 0
NAME = 1
NUMBER = 2
STRING = 3
NEWLINE = 4
INDENT = 5
DEDENT = 6
LPAR = 7
RPAR = 8
LSQB = 9
RSQB = 10
COLON = 11
COMMA = 12
SEMI = 13
PLUS = 14
MINUS = 15
STAR = 16
SLASH = 17
VBAR = 18
AMPER = 19
LESS = 20
GREATER = 21
EQUAL = 22
DOT = 23
PERCENT = 24
BACKQUOTE = 25
LBRACE = 26
RBRACE = 27
EQEQUAL = 28
NOTEQUAL = 29
LESSEQUAL = 30
GREATEREQUAL = 31
TILDE = 32
CIRCUMFLEX = 33
LEFTSHIFT = 34
RIGHTSHIFT = 35
DOUBLESTAR = 36
PLUSEQUAL = 37
MINEQUAL = 38
STAREQUAL = 39
SLASHEQUAL = 40
PERCENTEQUAL = 41
AMPEREQUAL = 42
VBAREQUAL = 43
CIRCUMFLEXEQUAL = 44
LEFTSHIFTEQUAL = 45
RIGHTSHIFTEQUAL = 46
DOUBLESTAREQUAL = 47
DOUBLESLASH = 48
DOUBLESLASHEQUAL = 49
AT = 50
OP = 51
COMMENT = 52
NL = 53
RARROW = 54
ERRORTOKEN = 55
N_TOKENS = 56
NT_OFFSET = 256
#--end constants--

tok_name = {}
for _name, _value in globals().items():
    if type(_value) is type(0):
        tok_name[_value] = _name


</t>
<t tx="ekr.20081203092030.156">def ISTERMINAL(x):
    return x &lt; NT_OFFSET

</t>
<t tx="ekr.20081203092030.157">def ISNONTERMINAL(x):
    return x &gt;= NT_OFFSET

</t>
<t tx="ekr.20081203092030.158">def ISEOF(x):
    return x == ENDMARKER
</t>
<t tx="ekr.20081203092030.159"># Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.
# All rights reserved.

"""Tokenization help for Python programs.

generate_tokens(readline) is a generator that breaks a stream of
text into Python tokens.  It accepts a readline-like method which is called
repeatedly to get the next line of input (or "" for EOF).  It generates
5-tuples with these members:

    the token type (see token.py)
    the token (a string)
    the starting (row, column) indices of the token (a 2-tuple of ints)
    the ending (row, column) indices of the token (a 2-tuple of ints)
    the original line (string)

It is designed to match the working of the Python tokenizer exactly, except
that it produces COMMENT tokens for comments and gives type OP for all
operators

Older entry points
    tokenize_loop(readline, tokeneater)
    tokenize(readline, tokeneater=printtoken)
are the same, except instead of generating tokens, tokeneater is a callback
function to which the 5 fields described above are passed as 5 arguments,
each time a new token is found."""

__author__ = 'Ka-Ping Yee &lt;ping@lfw.org&gt;'
__credits__ = \
    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'

import string, re
from token import *

import token
__all__ = [x for x in dir(token) if x[0] != '_'] + ["tokenize",
           "generate_tokens", "untokenize"]
del token

</t>
<t tx="ekr.20081203092030.160">def group(*choices): return '(' + '|'.join(choices) + ')'
</t>
<t tx="ekr.20081203092030.161">def any(*choices): return group(*choices) + '*'
</t>
<t tx="ekr.20081203092030.162">def maybe(*choices): return group(*choices) + '?'

</t>
<t tx="ekr.20081203092030.163">Whitespace = r'[ \f\t]*'
Comment = r'#[^\r\n]*'
Ignore = Whitespace + any(r'\\\r?\n' + Whitespace) + maybe(Comment)
Name = r'[a-zA-Z_]\w*'

Binnumber = r'0[bB][01]*'
Hexnumber = r'0[xX][\da-fA-F]*[lL]?'
Octnumber = r'0[oO]?[0-7]*[lL]?'
Decnumber = r'[1-9]\d*[lL]?'
Intnumber = group(Binnumber, Hexnumber, Octnumber, Decnumber)
Exponent = r'[eE][-+]?\d+'
Pointfloat = group(r'\d+\.\d*', r'\.\d+') + maybe(Exponent)
Expfloat = r'\d+' + Exponent
Floatnumber = group(Pointfloat, Expfloat)
Imagnumber = group(r'\d+[jJ]', Floatnumber + r'[jJ]')
Number = group(Imagnumber, Floatnumber, Intnumber)

# Tail end of ' string.
Single = r"[^'\\]*(?:\\.[^'\\]*)*'"
# Tail end of " string.
Double = r'[^"\\]*(?:\\.[^"\\]*)*"'
# Tail end of ''' string.
Single3 = r"[^'\\]*(?:(?:\\.|'(?!''))[^'\\]*)*'''"
# Tail end of """ string.
Double3 = r'[^"\\]*(?:(?:\\.|"(?!""))[^"\\]*)*"""'
Triple = group("[ubUB]?[rR]?'''", '[ubUB]?[rR]?"""')
# Single-line ' or " string.
String = group(r"[uU]?[rR]?'[^\n'\\]*(?:\\.[^\n'\\]*)*'",
               r'[uU]?[rR]?"[^\n"\\]*(?:\\.[^\n"\\]*)*"')

# Because of leftmost-then-longest match semantics, be sure to put the
# longest operators first (e.g., if = came before ==, == would get
# recognized as two instances of =).
Operator = group(r"\*\*=?", r"&gt;&gt;=?", r"&lt;&lt;=?", r"&lt;&gt;", r"!=",
                 r"//=?", r"-&gt;",
                 r"[+\-*/%&amp;|^=&lt;&gt;]=?",
                 r"~")

Bracket = '[][(){}]'
Special = group(r'\r?\n', r'[:;.,`@]')
Funny = group(Operator, Bracket, Special)

PlainToken = group(Number, Funny, String, Name)
Token = Ignore + PlainToken

# First (or only) line of ' or " string.
ContStr = group(r"[uUbB]?[rR]?'[^\n'\\]*(?:\\.[^\n'\\]*)*" +
                group("'", r'\\\r?\n'),
                r'[uUbB]?[rR]?"[^\n"\\]*(?:\\.[^\n"\\]*)*' +
                group('"', r'\\\r?\n'))
PseudoExtras = group(r'\\\r?\n', Comment, Triple)
PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)

tokenprog, pseudoprog, single3prog, double3prog = map(
    re.compile, (Token, PseudoToken, Single3, Double3))
endprogs = {"'": re.compile(Single), '"': re.compile(Double),
            "'''": single3prog, '"""': double3prog,
            "r'''": single3prog, 'r"""': double3prog,
            "u'''": single3prog, 'u"""': double3prog,
            "b'''": single3prog, 'b"""': double3prog,
            "ur'''": single3prog, 'ur"""': double3prog,
            "br'''": single3prog, 'br"""': double3prog,
            "R'''": single3prog, 'R"""': double3prog,
            "U'''": single3prog, 'U"""': double3prog,
            "B'''": single3prog, 'B"""': double3prog,
            "uR'''": single3prog, 'uR"""': double3prog,
            "Ur'''": single3prog, 'Ur"""': double3prog,
            "UR'''": single3prog, 'UR"""': double3prog,
            "bR'''": single3prog, 'bR"""': double3prog,
            "Br'''": single3prog, 'Br"""': double3prog,
            "BR'''": single3prog, 'BR"""': double3prog,
            'r': None, 'R': None,
            'u': None, 'U': None,
            'b': None, 'B': None}

triple_quoted = {}
for t in ("'''", '"""',
          "r'''", 'r"""', "R'''", 'R"""',
          "u'''", 'u"""', "U'''", 'U"""',
          "b'''", 'b"""', "B'''", 'B"""',
          "ur'''", 'ur"""', "Ur'''", 'Ur"""',
          "uR'''", 'uR"""', "UR'''", 'UR"""',
          "br'''", 'br"""', "Br'''", 'Br"""',
          "bR'''", 'bR"""', "BR'''", 'BR"""',):
    triple_quoted[t] = t
single_quoted = {}
for t in ("'", '"',
          "r'", 'r"', "R'", 'R"',
          "u'", 'u"', "U'", 'U"',
          "b'", 'b"', "B'", 'B"',
          "ur'", 'ur"', "Ur'", 'Ur"',
          "uR'", 'uR"', "UR'", 'UR"',
          "br'", 'br"', "Br'", 'Br"',
          "bR'", 'bR"', "BR'", 'BR"', ):
    single_quoted[t] = t

tabsize = 8

class TokenError(Exception): pass

</t>
<t tx="ekr.20081203092030.164">class StopTokenizing(Exception): pass

</t>
<t tx="ekr.20081203092030.165">def printtoken(type, token, (srow, scol), (erow, ecol), line): # for testing
    print "%d,%d-%d,%d:\t%s\t%s" % \
        (srow, scol, erow, ecol, tok_name[type], repr(token))

</t>
<t tx="ekr.20081203092030.166">def tokenize(readline, tokeneater=printtoken):
    """
    The tokenize() function accepts two parameters: one representing the
    input stream, and one providing an output mechanism for tokenize().

    The first parameter, readline, must be a callable object which provides
    the same interface as the readline() method of built-in file objects.
    Each call to the function should return one line of input as a string.

    The second parameter, tokeneater, must also be a callable object. It is
    called once for each token, with five arguments, corresponding to the
    tuples generated by generate_tokens().
    """
    try:
        tokenize_loop(readline, tokeneater)
    except StopTokenizing:
        pass

</t>
<t tx="ekr.20081203092030.167"># backwards compatible interface
def tokenize_loop(readline, tokeneater):
    for token_info in generate_tokens(readline):
        tokeneater(*token_info)

</t>
<t tx="ekr.20081203092030.168">class Untokenizer:
    @others
</t>
<t tx="ekr.20081203092030.169">
def __init__(self):
    self.tokens = []
    self.prev_row = 1
    self.prev_col = 0

</t>
<t tx="ekr.20081203092030.170">def add_whitespace(self, start):
    row, col = start
    assert row &lt;= self.prev_row
    col_offset = col - self.prev_col
    if col_offset:
        self.tokens.append(" " * col_offset)

</t>
<t tx="ekr.20081203092030.171">def untokenize(self, iterable):
    for t in iterable:
        if len(t) == 2:
            self.compat(t, iterable)
            break
        tok_type, token, start, end, line = t
        self.add_whitespace(start)
        self.tokens.append(token)
        self.prev_row, self.prev_col = end
        if tok_type in (NEWLINE, NL):
            self.prev_row += 1
            self.prev_col = 0
    return "".join(self.tokens)

</t>
<t tx="ekr.20081203092030.172">def compat(self, token, iterable):
    startline = False
    indents = []
    toks_append = self.tokens.append
    toknum, tokval = token
    if toknum in (NAME, NUMBER):
        tokval += ' '
    if toknum in (NEWLINE, NL):
        startline = True
    for tok in iterable:
        toknum, tokval = tok[:2]

        if toknum in (NAME, NUMBER):
            tokval += ' '

        if toknum == INDENT:
            indents.append(tokval)
            continue
        elif toknum == DEDENT:
            indents.pop()
            continue
        elif toknum in (NEWLINE, NL):
            startline = True
        elif startline and indents:
            toks_append(indents[-1])
            startline = False
        toks_append(tokval)

</t>
<t tx="ekr.20081203092030.173">def untokenize(iterable):
    """Transform tokens back into Python source code.

    Each element returned by the iterable must be a token sequence
    with at least two elements, a token number and token value.  If
    only two tokens are passed, the resulting output is poor.

    Round-trip invariant for full input:
        Untokenized source will match input source exactly

    Round-trip invariant for limited intput:
        # Output text will tokenize the back to the input
        t1 = [tok[:2] for tok in generate_tokens(f.readline)]
        newcode = untokenize(t1)
        readline = iter(newcode.splitlines(1)).next
        t2 = [tok[:2] for tokin generate_tokens(readline)]
        assert t1 == t2
    """
    ut = Untokenizer()
    return ut.untokenize(iterable)

</t>
<t tx="ekr.20081203092030.174">def generate_tokens(readline):
    """
    The generate_tokens() generator requires one argment, readline, which
    must be a callable object which provides the same interface as the
    readline() method of built-in file objects. Each call to the function
    should return one line of input as a string.  Alternately, readline
    can be a callable function terminating with StopIteration:
        readline = open(myfile).next    # Example of alternate readline

    The generator produces 5-tuples with these members: the token type; the
    token string; a 2-tuple (srow, scol) of ints specifying the row and
    column where the token begins in the source; a 2-tuple (erow, ecol) of
    ints specifying the row and column where the token ends in the source;
    and the line on which the token was found. The line passed is the
    logical line; continuation lines are included.
    """
    lnum = parenlev = continued = 0
    namechars, numchars = string.ascii_letters + '_', '0123456789'
    contstr, needcont = '', 0
    contline = None
    indents = [0]

    while 1:                                   # loop over lines in stream
        try:
            line = readline()
        except StopIteration:
            line = ''
        lnum = lnum + 1
        pos, max = 0, len(line)

        if contstr:                            # continued string
            if not line:
                raise TokenError, ("EOF in multi-line string", strstart)
            endmatch = endprog.match(line)
            if endmatch:
                pos = end = endmatch.end(0)
                yield (STRING, contstr + line[:end],
                       strstart, (lnum, end), contline + line)
                contstr, needcont = '', 0
                contline = None
            elif needcont and line[-2:] != '\\\n' and line[-3:] != '\\\r\n':
                yield (ERRORTOKEN, contstr + line,
                           strstart, (lnum, len(line)), contline)
                contstr = ''
                contline = None
                continue
            else:
                contstr = contstr + line
                contline = contline + line
                continue

        elif parenlev == 0 and not continued:  # new statement
            if not line: break
            column = 0
            while pos &lt; max:                   # measure leading whitespace
                if line[pos] == ' ': column = column + 1
                elif line[pos] == '\t': column = (column/tabsize + 1)*tabsize
                elif line[pos] == '\f': column = 0
                else: break
                pos = pos + 1
            if pos == max: break

            if line[pos] in '#\r\n':           # skip comments or blank lines
                if line[pos] == '#':
                    comment_token = line[pos:].rstrip('\r\n')
                    nl_pos = pos + len(comment_token)
                    yield (COMMENT, comment_token,
                           (lnum, pos), (lnum, pos + len(comment_token)), line)
                    yield (NL, line[nl_pos:],
                           (lnum, nl_pos), (lnum, len(line)), line)
                else:
                    yield ((NL, COMMENT)[line[pos] == '#'], line[pos:],
                           (lnum, pos), (lnum, len(line)), line)
                continue

            if column &gt; indents[-1]:           # count indents or dedents
                indents.append(column)
                yield (INDENT, line[:pos], (lnum, 0), (lnum, pos), line)
            while column &lt; indents[-1]:
                if column not in indents:
                    raise IndentationError(
                        "unindent does not match any outer indentation level",
                        ("&lt;tokenize&gt;", lnum, pos, line))
                indents = indents[:-1]
                yield (DEDENT, '', (lnum, pos), (lnum, pos), line)

        else:                                  # continued statement
            if not line:
                raise TokenError, ("EOF in multi-line statement", (lnum, 0))
            continued = 0

        while pos &lt; max:
            pseudomatch = pseudoprog.match(line, pos)
            if pseudomatch:                                # scan for tokens
                start, end = pseudomatch.span(1)
                spos, epos, pos = (lnum, start), (lnum, end), end
                token, initial = line[start:end], line[start]

                if initial in numchars or \
                   (initial == '.' and token != '.'):      # ordinary number
                    yield (NUMBER, token, spos, epos, line)
                elif initial in '\r\n':
                    newline = NEWLINE
                    if parenlev &gt; 0:
                        newline = NL
                    yield (newline, token, spos, epos, line)
                elif initial == '#':
                    assert not token.endswith("\n")
                    yield (COMMENT, token, spos, epos, line)
                elif token in triple_quoted:
                    endprog = endprogs[token]
                    endmatch = endprog.match(line, pos)
                    if endmatch:                           # all on one line
                        pos = endmatch.end(0)
                        token = line[start:pos]
                        yield (STRING, token, spos, (lnum, pos), line)
                    else:
                        strstart = (lnum, start)           # multiple lines
                        contstr = line[start:]
                        contline = line
                        break
                elif initial in single_quoted or \
                    token[:2] in single_quoted or \
                    token[:3] in single_quoted:
                    if token[-1] == '\n':                  # continued string
                        strstart = (lnum, start)
                        endprog = (endprogs[initial] or endprogs[token[1]] or
                                   endprogs[token[2]])
                        contstr, needcont = line[start:], 1
                        contline = line
                        break
                    else:                                  # ordinary string
                        yield (STRING, token, spos, epos, line)
                elif initial in namechars:                 # ordinary name
                    yield (NAME, token, spos, epos, line)
                elif initial == '\\':                      # continued stmt
                    # This yield is new; needed for better idempotency:
                    yield (NL, token, spos, (lnum, pos), line)
                    continued = 1
                else:
                    if initial in '([{': parenlev = parenlev + 1
                    elif initial in ')]}': parenlev = parenlev - 1
                    yield (OP, token, spos, epos, line)
            else:
                yield (ERRORTOKEN, line[pos],
                           (lnum, pos), (lnum, pos+1), line)
                pos = pos + 1

    for indent in indents[1:]:                 # pop remaining indent levels
        yield (DEDENT, '', (lnum, 0), (lnum, 0), '')
    yield (ENDMARKER, '', (lnum, 0), (lnum, 0), '')

</t>
<t tx="ekr.20081203092030.175"># Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""The pgen2 package."""
</t>
<t tx="ekr.20081203092326.1">@nocolor-node

/*

Description
-----------

The parser's interface is different than usual: the function addtoken()
must be called for each token in the input.  This makes it possible to
turn it into an incremental parsing system later.  The parsing system
constructs a parse tree as it goes.

A parsing rule is represented as a Deterministic Finite-state Automaton
(DFA).  A node in a DFA represents a state of the parser; an arc represents
a transition.  Transitions are either labeled with terminal symbols or
with non-terminals.  When the parser decides to follow an arc labeled
with a non-terminal, it is invoked recursively with the DFA representing
the parsing rule for that as its initial state; when that DFA accepts,
the parser that invoked it continues.  The parse tree constructed by the
recursively called parser is inserted as a child in the current parse tree.

The DFA's can be constructed automatically from a more conventional
language description.  An extended LL(1) grammar (ELL(1)) is suitable.
Certain restrictions make the parser's life easier: rules that can produce
the empty string should be outlawed (there are other ways to put loops
or optional parts in the language).  To avoid the need to construct
FIRST sets, we can require that all but the last alternative of a rule
(really: arc going out of a DFA's state) must begin with a terminal
symbol.

As an example, consider this grammar:

expr:	term (OP term)*
term:	CONSTANT | '(' expr ')'

The DFA corresponding to the rule for expr is:

-------&gt;.---term--&gt;.-------&gt;
	^          |
	|          |
	\----OP----/

The parse tree generated for the input a+b is:

(expr: (term: (NAME: a)), (OP: +), (term: (NAME: b)))

*/
</t>
<t tx="ekr.20081204111623.1"># d = c.scanAllDirectives(p)
# g.es(d.get('path'))

aList = g.get_directives_dict_list(p)
g.es(c.scanAtPathDirectives(aList))</t>
</tnodes>
</leo_file>
